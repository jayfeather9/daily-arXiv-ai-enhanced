{"id": "2511.19445", "categories": ["cs.DC", "cs.DM"], "pdf": "https://arxiv.org/pdf/2511.19445", "abs": "https://arxiv.org/abs/2511.19445", "authors": ["Luca Accorsi", "Demetrio Lagan\u00e0", "Federico Michelotto", "Roberto Musmanno", "Daniele Vigo"], "title": "Asynchronous Cooperative Optimization of a Capacitated Vehicle Routing Problem Solution", "comment": null, "summary": "We propose a parallel shared-memory schema to cooperatively optimize the solution of a Capacitated Vehicle Routing Problem instance with minimal synchronization effort and without the need for an explicit decomposition. To this end, we design FILO2$^x$ as a single-trajectory parallel adaptation of the FILO2 algorithm originally proposed for extremely large-scale instances and described in Accorsi and Vigo (2024). Using the locality of the FILO2 optimization applications, in FILO2$^x$ several possibly unrelated solution areas are concurrently asynchronously optimized. The overall search trajectory emerges as an iteration-based parallelism obtained by the simultaneous optimization of the same underlying solution performed by several solvers. Despite the high efficiency exhibited by the single-threaded FILO2 algorithm, the computational results show that, by better exploiting the available computing resources, FILO2$^x$ can greatly enhance the resolution time compared to the original approach, still maintaining a similar final solution quality for instances ranging from hundreds to hundreds of thousands customers.", "AI": {"tldr": "This paper is not directly related to DSL, graph processing, MLIR, compiler, or HLS. It focuses on the parallel optimization of a classic operations research problem (Capacitated Vehicle Routing Problem, CVRP). The paper proposes FILO2$^x$, a parallel, shared-memory adaptation of the existing FILO2 algorithm, designed to minimize synchronization effort and avoid explicit decomposition. It achieves iteration-based parallelism by having multiple solvers concurrently and asynchronously optimize potentially unrelated local solution areas of the same underlying solution, resulting in a significant reduction in computation time while maintaining similar solution quality across a wide range of instance sizes.", "motivation": "\u89e3\u51b3\u5bb9\u91cf\u9650\u5236\u8f66\u8f86\u8def\u5f84\u95ee\u9898 (Capacitated Vehicle Routing Problem, CVRP)\uff0c\u65e8\u5728\u5728\u6700\u5c0f\u5316\u540c\u6b65\u5f00\u9500\u4e14\u65e0\u9700\u663e\u5f0f\u5206\u89e3\u7684\u60c5\u51b5\u4e0b\uff0c\u5408\u4f5c\u4f18\u5316\u5927\u5b9e\u4f8b\u7684\u89e3\u3002\u5c3d\u7ba1\u5355\u7ebf\u7a0b FILO2 \u7b97\u6cd5\u6548\u7387\u9ad8\uff0c\u4f46\u5e0c\u671b\u901a\u8fc7\u66f4\u597d\u5730\u5229\u7528\u53ef\u7528\u8ba1\u7b97\u8d44\u6e90\uff08\u5e76\u884c\u5316\uff09\u6765\u8fdb\u4e00\u6b65\u7f29\u77ed\u6c42\u89e3\u65f6\u95f4\u3002", "method": "\u63d0\u51fa FILO2$^x$\uff0c\u8fd9\u662f FILO2 \u7b97\u6cd5\u7684\u5355\u8f68\u8ff9\u5e76\u884c\u5316\u7248\u672c\uff0c\u4e13\u4e3a\u5171\u4eab\u5185\u5b58\u7cfb\u7edf\u8bbe\u8ba1\u3002\u5b83\u5229\u7528 FILO2 \u4f18\u5316\u5e94\u7528\u7684\u5c40\u90e8\u6027\uff0c\u5141\u8bb8\u591a\u4e2a\u53ef\u80fd\u4e0d\u76f8\u5173\u7684\u89e3\u533a\u57df\u540c\u65f6\u5f02\u6b65\u4f18\u5316\u3002\u901a\u8fc7\u591a\u4e2a\u6c42\u89e3\u5668\u5bf9\u540c\u4e00\u5e95\u5c42\u89e3\u7684\u540c\u65f6\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u8fed\u4ee3\u7684\u5e76\u884c\u6027\u3002", "result": "\u8ba1\u7b97\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u539f\u65b9\u6cd5\u76f8\u6bd4\uff0cFILO2$^x$ \u5728\u4fdd\u6301\u76f8\u4f3c\u7684\u6700\u7ec8\u89e3\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u53ef\u4ee5\u5927\u5927\u7f29\u77ed\u6c42\u89e3\u65f6\u95f4\uff0c\u9002\u7528\u4e8e\u4ece\u6570\u767e\u5230\u6570\u5341\u4e07\u5ba2\u6237\u89c4\u6a21\u7684\u5b9e\u4f8b\u3002\u8fd9\u8bc1\u660e\u4e86\u5b83\u5728\u63d0\u9ad8\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\u7387\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002", "conclusion": "FILO2$^x$ \u901a\u8fc7\u5e76\u884c\u5316 FILO2 \u7b97\u6cd5\uff0c\u5728\u5171\u4eab\u5185\u5b58\u67b6\u6784\u4e0b\u5b9e\u73b0\u4e86\u5bf9 CVRP \u95ee\u9898\u7684\u52a0\u901f\u6c42\u89e3\uff0c\u663e\u8457\u7f29\u77ed\u4e86\u6c42\u89e3\u65f6\u95f4\uff0c\u800c\u6700\u7ec8\u89e3\u7684\u8d28\u91cf\u4e0e\u539f\u7b97\u6cd5\u76f8\u8fd1\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u9ad8\u6548\u5229\u7528\u8ba1\u7b97\u8d44\u6e90\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.19450", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.19450", "abs": "https://arxiv.org/abs/2511.19450", "authors": ["M. Zeeshan Haider", "Tayyaba Noreen", "M. D. Assuncao", "Kaiwen Zhang"], "title": "AI-driven Predictive Shard Allocation for Scalable Next Generation Blockchains", "comment": null, "summary": "Sharding has emerged as a key technique to address blockchain scalability by partitioning the ledger into multiple shards that process transactions in parallel. Although this approach improves throughput, static or heuristic shard allocation often leads to workload skew, congestion, and excessive cross-shard communication diminishing the scalability benefits of sharding. To overcome these challenges, we propose the Predictive Shard Allocation Protocol (PSAP), a dynamic and intelligent allocation framework that proactively assigns accounts and transactions to shards based on workload forecasts. PSAP integrates a Temporal Workload Forecasting (TWF) model with a safety-constrained reinforcement learning (Safe-PPO) controller, jointly enabling multi-block-ahead prediction and adaptive shard reconfiguration. The protocol enforces deterministic inference across validators through a synchronized quantized runtime and a safety gate that limits stake concentration, migration gas, and utilization thresholds. By anticipating hotspot formation and executing bounded, atomic migrations, PSAP achieves stable load balance while preserving Byzantine safety. Experimental evaluation on heterogeneous datasets, including Ethereum, NEAR, and Hyperledger Fabric mapped via address-clustering heuristics, demonstrates up to 2x throughput improvement, 35\\% lower latency, and 20\\% reduced cross-shard overhead compared to existing dynamic sharding baselines. These results confirm that predictive, deterministic, and security-aware shard allocation is a promising direction for next-generation scalable blockchain systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u4e0e\u9886\u57df\u76f8\u5173\u6027\uff1a\u56fe\u5904\u7406\uff08\u901a\u8fc7\u5730\u5740\u805a\u7c7b\u542f\u53d1\u5f0f\u6620\u5c04\uff0c\u53ef\u4ee5\u8054\u60f3\u5230\u56fe\u6570\u636e\u7ed3\u6784\u548c\u5904\u7406\uff09\uff1b\u7f16\u8bd1\u5668/HLS/MLIR/DSL\uff08\u4e0d\u76f8\u5173\uff09\uff1b\u6216\uff08\u4e0d\u76f8\u5173\uff09\u3002\n\u592a\u957f\u4e0d\u770b\uff1aPSAP\u662f\u4e00\u79cd\u7528\u4e8e\u533a\u5757\u94fe\u7684\u52a8\u6001\u667a\u80fd\u5206\u7247\u5206\u914d\u534f\u8bae\uff0c\u5b83\u7ed3\u5408\u4e86**\u65f6\u95f4\u5de5\u4f5c\u8d1f\u8f7d\u9884\u6d4b**\uff08TWF\uff09\u6a21\u578b\u548c**\u5b89\u5168\u7ea6\u675f\u7684\u5f3a\u5316\u5b66\u4e60**\uff08Safe-PPO\uff09\u63a7\u5236\u5668\uff0c\u901a\u8fc7**\u9884\u6d4b\u6027\u5730**\u5206\u914d\u8d26\u6237\u548c\u4ea4\u6613**\uff0c\u5b9e\u73b0**\u591a\u533a\u5757\u63d0\u524d\u9884\u6d4b\u548c\u81ea\u9002\u5e94\u5206\u7247\u91cd\u914d\u7f6e\uff0c\u65e8\u5728**\u89e3\u51b3\u73b0\u6709\u5206\u7247\u5206\u914d\u4e2d\u7684\u5de5\u4f5c\u8d1f\u8f7d\u503e\u659c\u548c\u9ad8\u8de8\u5206\u7247\u901a\u4fe1\u95ee\u9898**\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPSAP\u5728\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u548c\u8de8\u5206\u7247\u5f00\u9500\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u7247\u6280\u672f\uff08\u5982\u9759\u6001\u6216\u542f\u53d1\u5f0f\u5206\u7247\u5206\u914d\uff09\u867d\u7136\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u4f46\u5e38\u56e0\u5de5\u4f5c\u8d1f\u8f7d\u503e\u659c\u3001\u62e5\u585e\u548c\u8fc7\u591a\u7684\u8de8\u5206\u7247\u901a\u4fe1\u800c\u5bfc\u81f4\u53ef\u6269\u5c55\u6027\u6548\u76ca\u4e0b\u964d\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u5b9e\u73b0\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u8d1f\u8f7d\u5747\u8861\uff0c\u540c\u65f6\u7ef4\u62a4\u62dc\u5360\u5ead\u5b89\u5168\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u4e14\u667a\u80fd\u7684\u5206\u7247\u5206\u914d\u6846\u67b6\u2014\u2014\u9884\u6d4b\u6027\u5206\u7247\u5206\u914d\u534f\u8bae\uff08PSAP\uff09\u3002PSAP\u6574\u5408\u4e86\u65f6\u95f4\u5de5\u4f5c\u91cf\u9884\u6d4b\u6a21\u578b\uff08TWF\uff09\u548c\u5b89\u5168\u7ea6\u675f\u7684\u5f3a\u5316\u5b66\u4e60\uff08Safe-PPO\uff09\u63a7\u5236\u5668\u3002\u5177\u4f53\u6765\u8bf4\uff0cTWF\u6a21\u578b\u5b9e\u73b0\u591a\u533a\u5757\u63d0\u524d\u9884\u6d4b\uff0c\u800cSafe-PPO\u63a7\u5236\u5668\u5219\u8d1f\u8d23\u6839\u636e\u9884\u6d4b\u7ed3\u679c\u81ea\u9002\u5e94\u5730\u91cd\u65b0\u914d\u7f6e\u5206\u7247\uff0c\u4ee5\u5b9e\u73b0\u8d1f\u8f7d\u5747\u8861\u3002\u4e3a\u4e86\u4fdd\u8bc1\u786e\u5b9a\u6027\u63a8\u65ad\u548c\u5b89\u5168\u6027\uff0cPSAP\u91c7\u7528\u4e86\u540c\u6b65\u91cf\u5316\u8fd0\u884c\u65f6\u548c\u5b89\u5168\u95e8\u673a\u5236\uff0c\u9650\u5236\u4e86\u8d28\u62bc\u96c6\u4e2d\u5ea6\u3001\u8fc1\u79fb\u6d88\u8017\u548c\u5229\u7528\u7387\u9608\u503c\u3002\u534f\u8bae\u901a\u8fc7\u6267\u884c\u6709\u754c\u9650\u7684\u539f\u5b50\u8fc1\u79fb\u6765\u5e94\u5bf9\u70ed\u70b9\u5f62\u6210\u3002", "result": "\u5728\u5305\u62ec\u4ee5\u592a\u574a\u3001NEAR\u548cHyperledger Fabric\u5728\u5185\u7684\u5f02\u6784\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\uff08\u901a\u8fc7\u5730\u5740\u805a\u7c7b\u542f\u53d1\u5f0f\u6620\u5c04\uff09\uff0c\u7ed3\u679c\u663e\u793a\uff0cPSAP\u76f8\u6bd4\u73b0\u6709\u52a8\u6001\u5206\u7247\u57fa\u7ebf\uff0c\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe2\u500d\uff0c\u5ef6\u8fdf\u964d\u4f4e35\\%\uff0c\u8de8\u5206\u7247\u5f00\u9500\u51cf\u5c1120\\%\u3002\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86PSAP\u5728\u5b9e\u73b0\u7a33\u5b9a\u8d1f\u8f7d\u5747\u8861\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "PSAP\u901a\u8fc7\u6574\u5408\u65f6\u95f4\u5de5\u4f5c\u91cf\u9884\u6d4b\u6a21\u578b\uff08TWF\uff09\u548c\u5b89\u5168\u7ea6\u675f\u7684\u5f3a\u5316\u5b66\u4e60\u63a7\u5236\u5668\uff08Safe-PPO\uff09\uff0c\u5b9e\u73b0\u4e86\u524d\u77bb\u6027\u3001\u786e\u5b9a\u6027\u548c\u5b89\u5168\u611f\u77e5\u7684\u5206\u7247\u5206\u914d\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\uff0cPSAP\u5728\u541e\u5410\u91cf\u3001\u5ef6\u8fdf\u548c\u8de8\u5206\u7247\u5f00\u9500\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u7684\u52a8\u6001\u5206\u7247\u57fa\u7ebf\uff0c\u8fd9\u8868\u660e\u9884\u6d4b\u6027\u3001\u786e\u5b9a\u6027\u4e14\u6ce8\u91cd\u5b89\u5168\u6027\u7684\u5206\u7247\u5206\u914d\u662f\u4e0b\u4e00\u4ee3\u53ef\u6269\u5c55\u533a\u5757\u94fe\u7cfb\u7edf\u7684\u4e00\u4e2a\u6709\u524d\u9014\u7684\u65b9\u5411\u3002"}}
{"id": "2511.19453", "categories": ["cs.DC", "cs.DB", "cs.OS", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19453", "abs": "https://arxiv.org/abs/2511.19453", "authors": ["Yuxin Wang", "Yuankai He", "Weisong Shi"], "title": "AVS: A Computational and Hierarchical Storage System for Autonomous Vehicles", "comment": null, "summary": "Autonomous vehicles (AVs) are evolving into mobile computing platforms, equipped with powerful processors and diverse sensors that generate massive heterogeneous data, for example 14 TB per day. Supporting emerging third-party applications calls for a general-purpose, queryable onboard storage system. Yet today's data loggers and storage stacks in vehicles fail to deliver efficient data storage and retrieval. This paper presents AVS, an Autonomous Vehicle Storage system that co-designs computation with a hierarchical layout: modality-aware reduction and compression, hot-cold tiering with daily archival, and a lightweight metadata layer for indexing. The design is grounded with system-level benchmarks on AV data that cover SSD and HDD filesystems and embedded indexing, and is validated on embedded hardware with real L4 autonomous driving traces. The prototype delivers predictable real-time ingest, fast selective retrieval, and substantial footprint reduction under modest resource budgets. The work also outlines observations and next steps toward more scalable and longer deployments to motivate storage as a first-class component in AV stacks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u4ee5\u4e0b\u9886\u57df\u76f8\u5173\uff1a\u7f16\u8bd1\u5668\uff08\u7cfb\u7edf\u6808\u3001\u5b58\u50a8\u6808\uff09\u3001\u56fe\u5904\u7406\uff08\u53ef\u80fd\u5904\u7406\u56fe\u7ed3\u6784\u6570\u636e\uff0c\u4f46\u672a\u660e\u786e\u63d0\u53ca\uff09\u3001MLIR\uff08\u672a\u63d0\u53ca\uff09\u3001HLS\uff08\u672a\u63d0\u53ca\uff09\u3001DSL\uff08\u672a\u63d0\u53ca\uff09\u3002\n\u603b\u7ed3\uff1a\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff08AVs\uff09\u6bcf\u5929\u4ea7\u751f\u6d77\u91cf\u6570\u636e\uff0c\u73b0\u6709\u8f66\u8f7d\u5b58\u50a8\u7cfb\u7edf\u6548\u7387\u4f4e\u4e0b\u3002\u672c\u6587\u63d0\u51fa\u4e86AVS\u8f66\u8f7d\u5b58\u50a8\u7cfb\u7edf\uff0c\u901a\u8fc7\u6a21\u6001\u611f\u77e5\u7f29\u51cf/\u538b\u7f29\u3001\u51b7\u70ed\u5206\u5c42\u548c\u8f7b\u91cf\u7ea7\u5143\u6570\u636e\u7d22\u5f15\u7684\u5206\u5c42\u5171\u8bbe\u8ba1\u8ba1\u7b97\u4e0e\u5b58\u50a8\uff0c\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u80fd\u5b9e\u73b0\u5b9e\u65f6\u6444\u53d6\u3001\u5feb\u901f\u68c0\u7d22\u548c\u663e\u8457\u7684\u5b58\u50a8\u7a7a\u95f4\u7f29\u51cf\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u53d1\u5c55\u6210\u4e3a\u79fb\u52a8\u8ba1\u7b97\u5e73\u53f0\uff0c\u5176\u5f3a\u5927\u7684\u5904\u7406\u5668\u548c\u591a\u6837\u5316\u7684\u4f20\u611f\u5668\u6bcf\u5929\u751f\u6210\u6d77\u91cf\u5f02\u6784\u6570\u636e\uff08\u4f8b\u5982\u6bcf\u592914 TB\uff09\u3002\u73b0\u6709\u7684\u8f66\u8f7d\u6570\u636e\u8bb0\u5f55\u5668\u548c\u5b58\u50a8\u6808\u65e0\u6cd5\u63d0\u4f9b\u9ad8\u6548\u7684\u6570\u636e\u5b58\u50a8\u548c\u68c0\u7d22\u80fd\u529b\uff0c\u800c\u652f\u6301\u65b0\u5174\u7684\u7b2c\u4e09\u65b9\u5e94\u7528\u9700\u8981\u4e00\u4e2a\u901a\u7528\u7684\u3001\u53ef\u67e5\u8be2\u7684\u8f66\u8f7d\u5b58\u50a8\u7cfb\u7edf\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u9ad8\u6548\u7ba1\u7406\u548c\u68c0\u7d22\u81ea\u52a8\u9a7e\u9a76\uff08AV\uff09\u6570\u636e\u7684\u5b58\u50a8\u7cfb\u7edf\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86AVS\uff08Autonomous Vehicle Storage\uff09\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u901a\u8fc7\u8ba1\u7b97\u4e0e\u5206\u5c42\u5e03\u5c40\u7684\u534f\u540c\u8bbe\u8ba1\u6765\u89e3\u51b3\u8f66\u8f7d\u5b58\u50a8\u7684\u6311\u6218\u3002\u5176\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a\u6a21\u6001\u611f\u77e5\u7684\u6570\u636e\u7f29\u51cf\u548c\u538b\u7f29\u3001\u5177\u6709\u65e5\u5e38\u5f52\u6863\u529f\u80fd\u7684\u51b7\u70ed\u5206\u5c42\u3001\u4ee5\u53ca\u7528\u4e8e\u7d22\u5f15\u7684\u8f7b\u91cf\u7ea7\u5143\u6570\u636e\u5c42\u3002\u8be5\u8bbe\u8ba1\u901a\u8fc7\u5728AV\u6570\u636e\u4e0a\u8fdb\u884c\u7cfb\u7edf\u7ea7\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ecSSD\u548cHDD\u6587\u4ef6\u7cfb\u7edf\u548c\u5d4c\u5165\u5f0f\u7d22\u5f15\uff09\uff0c\u5e76\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u4f7f\u7528\u771f\u5b9e\u7684L4\u81ea\u52a8\u9a7e\u9a76\u8ddf\u8e2a\u6570\u636e\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "AVS\u539f\u578b\u7cfb\u7edf\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u5b9e\u73b0\u4e86\u53ef\u9884\u6d4b\u7684\u5b9e\u65f6\u6570\u636e\u6444\u53d6\u3001\u5feb\u901f\u7684\u9009\u62e9\u6027\u68c0\u7d22\uff0c\u5e76\u5728\u9002\u5ea6\u7684\u8d44\u6e90\u9884\u7b97\u4e0b\u5927\u5e45\u51cf\u5c11\u4e86\u5b58\u50a8\u5360\u7528\u7a7a\u95f4\uff08\u5373\u201c\u5360\u5730\u9762\u79ef\u201d\uff09\u3002\u7814\u7a76\u7ed3\u679c\u8868\u660e\u4e86\u5c06\u5b58\u50a8\u89c6\u4e3aAV\u5806\u6808\u4e2d\u4e00\u7b49\u516c\u6c11\u7ec4\u4ef6\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u8fdb\u4e00\u6b65\u5b9e\u73b0\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u66f4\u957f\u4e45\u90e8\u7f72\u7684\u89c1\u89e3\u548c\u540e\u7eed\u6b65\u9aa4\u3002", "conclusion": "AVS\u7cfb\u7edf\u901a\u8fc7\u5206\u5c42\u5e03\u5c40\u548c\u8ba1\u7b97\u4e0e\u5b58\u50a8\u7684\u534f\u540c\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u4e86\u5bf9\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u7684\u9ad8\u6548\u5b58\u50a8\u548c\u68c0\u7d22\uff0c\u5e76\u5728\u5d4c\u5165\u5f0f\u786c\u4ef6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u65f6\u6444\u53d6\u3001\u5feb\u901f\u9009\u62e9\u6027\u68c0\u7d22\u548c\u5927\u5e45\u51cf\u5c11\u5b58\u50a8\u5360\u7528\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u672a\u6765\u7684\u5de5\u4f5c\u5c06\u4fa7\u91cd\u4e8e\u5b9e\u73b0\u66f4\u5177\u53ef\u6269\u5c55\u6027\u548c\u66f4\u957f\u4e45\u90e8\u7f72\u7684\u5b58\u50a8\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19740", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19740", "abs": "https://arxiv.org/abs/2511.19740", "authors": ["Tergel Molom-Ochir", "Benjamin F. Morris", "Mark Horton", "Chiyue Wei", "Cong Guo", "Brady Taylor", "Peter Liu", "Shan X. Wang", "Deliang Fan", "Hai Helen Li", "Yiran Chen"], "title": "CAMformer: Associative Memory is All You Need", "comment": "7 pages, 10 figures", "summary": "Transformers face scalability challenges due to the quadratic cost of attention, which involves dense similarity computations between queries and keys. We propose CAMformer, a novel accelerator that reinterprets attention as an associative memory operation and computes attention scores using a voltage-domain Binary Attention Content Addressable Memory (BA-CAM). This enables constant-time similarity search through analog charge sharing, replacing digital arithmetic with physical similarity sensing. CAMformer integrates hierarchical two-stage top-k filtering, pipelined execution, and high-precision contextualization to achieve both algorithmic accuracy and architectural efficiency. Evaluated on BERT and Vision Transformer workloads, CAMformer achieves over 10x energy efficiency, up to 4x higher throughput, and 6-8x lower area compared to state-of-the-art accelerators--while maintaining near-lossless accuracy.", "AI": {"tldr": "\u4e0eDSL\u6216\u56fe\u5904\u7406\u6216MLIR\u6216\u7f16\u8bd1\u5668\u6216HLS\u65e0\u5173\u3002\nCAMformer\u662f\u4e00\u79cd\u65b0\u578b\u7684Transformer\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u673a\u5236\u91cd\u65b0\u89e3\u91ca\u4e3a\u4e00\u79cd\u5173\u8054\u5b58\u50a8\u5668\u64cd\u4f5c\uff0c\u5e76\u5728\u4e00\u79cd\u79f0\u4e3a\u7535\u538b\u57df\u4e8c\u5143\u6ce8\u610f\u529b\u5185\u5bb9\u53ef\u5bfb\u5740\u5b58\u50a8\u5668\uff08BA-CAM\uff09\u7684\u786c\u4ef6\u4e2d\u8ba1\u7b97\u6ce8\u610f\u529b\u5206\u6570\u3002\u8fd9\u79cd\u65b9\u6cd5\u901a\u8fc7\u6a21\u62df\u7535\u8377\u5171\u4eab\u5b9e\u73b0\u6052\u5b9a\u65f6\u95f4\uff08Constant-time\uff09\u7684\u76f8\u4f3c\u6027\u641c\u7d22\uff0c\u53d6\u4ee3\u4e86\u4f20\u7edf\u7684\u6570\u5b57\u7b97\u672f\u8fd0\u7b97\u3002CAMformer\u8fd8\u7ed3\u5408\u4e86\u5206\u5c42Top-k\u8fc7\u6ee4\u548c\u6d41\u6c34\u7ebf\u6267\u884c\u7b49\u4f18\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cCAMformer\u5728BERT\u548cVision Transformer\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc710\u500d\u7684\u80fd\u6548\u63d0\u5347\u3001\u9ad8\u8fbe4\u500d\u7684\u541e\u5410\u91cf\uff0c\u4ee5\u53ca6-8\u500d\u7684\u9762\u79ef\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a5\u8fd1\u65e0\u635f\u7684\u51c6\u786e\u6027\u3002", "motivation": "Transformer\u6a21\u578b\u7531\u4e8e\u5176\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u4e8c\u6b21\u65b9\u8ba1\u7b97\u6210\u672c\uff08Quadratic cost\uff09\uff0c\u7279\u522b\u662f\u67e5\u8be2\uff08Queries\uff09\u548c\u952e\uff08Keys\uff09\u4e4b\u95f4\u5bc6\u96c6\u7684\u76f8\u4f3c\u6027\u8ba1\u7b97\uff0c\u5728\u53ef\u6269\u5c55\u6027\u65b9\u9762\u9762\u4e34\u7740\u4e25\u5cfb\u7684\u6311\u6218\u3002\u4f5c\u8005\u65e8\u5728\u8bbe\u8ba1\u4e00\u4e2a\u65b0\u578b\u52a0\u901f\u5668\uff0c\u4ee5\u89e3\u51b3\u8fd9\u4e00\u6548\u7387\u74f6\u9888\uff0c\u5e76\u5b9e\u73b0\u9ad8\u80fd\u6548\u3001\u9ad8\u541e\u5410\u91cf\u548c\u4f4e\u9762\u79ef\u5360\u7528\u3002", "method": "CAMformer\u7684\u5173\u952e\u65b9\u6cd5\u662f\u5c06\u6ce8\u610f\u529b\u673a\u5236\u91cd\u65b0\u89e3\u91ca\u4e3a\u5173\u8054\u5b58\u50a8\u5668\uff08Associative Memory\uff09\u64cd\u4f5c\uff0c\u5e76\u4f7f\u7528\u7535\u538b\u57df\u4e8c\u5143\u6ce8\u610f\u529b\u5185\u5bb9\u53ef\u5bfb\u5740\u5b58\u50a8\u5668\uff08BA-CAM\uff09\u6765\u8ba1\u7b97\u6ce8\u610f\u529b\u5206\u6570\u3002\n\u4e3b\u8981\u7684\u521b\u65b0\u70b9\u5305\u62ec\uff1a\n1. **\u6a21\u62df\u8ba1\u7b97\uff08Analog Computation\uff09**\uff1a\u5229\u7528\u6a21\u62df\u7535\u8377\u5171\u4eab\u5b9e\u73b0\u6052\u5b9a\u65f6\u95f4\uff08Constant-time\uff09\u7684\u76f8\u4f3c\u6027\u641c\u7d22\uff0c\u4ece\u800c\u53d6\u4ee3\u4e86\u4f20\u7edf\u7684\u6570\u5b57\u7b97\u672f\u8fd0\u7b97\u3002\n2. **\u786c\u4ef6\u67b6\u6784\u4f18\u5316**\uff1a\u96c6\u6210\u4e86\u5206\u5c42\u4e24\u9636\u6bb5\uff08Hierarchical Two-stage\uff09Top-k \u8fc7\u6ee4\u3001\u6d41\u6c34\u7ebf\u5f0f\u6267\u884c\uff08Pipelined execution\uff09\u548c\u9ad8\u7cbe\u5ea6\u4e0a\u4e0b\u6587\u5904\u7406\uff08High-precision contextualization\uff09\u3002", "result": "CAMformer\u5728BERT\u548cVision Transformer\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660e\uff1a\n1. **\u80fd\u6548\uff08Energy Efficiency\uff09**\uff1a\u76f8\u6bd4\u4e8e\u73b0\u6709\u7684\u5148\u8fdb\u52a0\u901f\u5668\uff0c\u80fd\u6548\u63d0\u5347\u8d85\u8fc710\u500d\u3002\n2. **\u541e\u5410\u91cf\uff08Throughput\uff09**\uff1a\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe4\u500d\u3002\n3. **\u9762\u79ef\uff08Area\uff09**\uff1a\u9762\u79ef\u964d\u4f4e6-8\u500d\u3002\n4. **\u51c6\u786e\u6027\uff08Accuracy\uff09**\uff1a\u5728\u5b9e\u73b0\u4e0a\u8ff0\u6548\u7387\u63d0\u5347\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u63a5\u8fd1\u65e0\u635f\u7684\u51c6\u786e\u6027\uff08near-lossless accuracy\uff09\u3002", "conclusion": "CAMformer\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u673a\u5236\u91cd\u65b0\u89e3\u91ca\u4e3a\u5173\u8054\u5b58\u50a8\u5668\u64cd\u4f5c\uff0c\u5e76\u5728\u7535\u538b\u57df\u4e8c\u5143\u6ce8\u610f\u529b\u5185\u5bb9\u53ef\u5bfb\u5740\u5b58\u50a8\u5668\uff08BA-CAM\uff09\u4e2d\u8ba1\u7b97\u6ce8\u610f\u529b\u5206\u6570\uff0c\u5b9e\u73b0\u4e86\u6052\u5b9a\u65f6\u95f4\u76f8\u4f3c\u6027\u641c\u7d22\u3002\u8fd9\u79cd\u65b9\u6cd5\u53d6\u4ee3\u4e86\u6570\u5b57\u7b97\u672f\u8fd0\u7b97\uff0c\u901a\u8fc7\u7269\u7406\u76f8\u4f3c\u6027\u611f\u5e94\u8fdb\u884c\u8ba1\u7b97\uff0c\u5e26\u6765\u4e86\u663e\u8457\u7684\u80fd\u6548\u3001\u541e\u5410\u91cf\u548c\u9762\u79ef\u4f18\u52bf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a5\u8fd1\u65e0\u635f\u7684\u51c6\u786e\u6027\u3002CAMformer\u662f\u4e3a\u89e3\u51b3Transformer\u6a21\u578b\u4e2d\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e8c\u6b21\u65b9\u8ba1\u7b97\u6210\u672c\u548c\u53ef\u6269\u5c55\u6027\u6311\u6218\u800c\u8bbe\u8ba1\u7684\u9ad8\u6548\u3001\u9ad8\u7cbe\u5ea6\u52a0\u901f\u5668\u3002"}}
{"id": "2511.19690", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.19690", "abs": "https://arxiv.org/abs/2511.19690", "authors": ["Niklas Haas", "S\u00f6ren Schmitt", "Rob van Stee"], "title": "The Buffer Minimization Problem for Scheduling Flow Jobs with Conflicts", "comment": "17 pages, 1 figure, to appear in SOFSEM 2026", "summary": "We consider the online buffer minimization in multiprocessor systems with conflicts problem (in short, the buffer minimization problem) in the recently introduced flow model. In an online fashion, workloads arrive on some of the $n$ processors and are stored in an input buffer. Processors can run and reduce these workloads, but conflicts between pairs of processors restrict simultaneous task execution. Conflicts are represented by a graph, where vertices correspond to processors and edges indicate conflicting pairs. An online algorithm must decide which processors are run at a time; so provide a valid schedule respecting the conflict constraints.\n  The objective is to minimize the maximal workload observed across all processors during the schedule. Unlike the original model, where workloads arrive as discrete blocks at specific time points, the flow model assumes workloads arrive continuously over intervals or not at all. We present tight bounds for all graphs with four vertices (except the path, which has been solved previously) and for the families of general complete graphs and complete bipartite graphs. We also recover almost tight bounds for complete $k$-partite graphs.\n  For the original model, we narrow the gap for the graph consisting of a triangle and an additional edge to a fourth vertex.", "AI": {"tldr": "\u8fd9\u4e2a\u6458\u8981\u4e0e\u56fe\u5904\u7406\uff08\u51b2\u7a81\u56fe\uff09\u548c\u7f16\u8bd1\u5668\u6216HLS\uff08\u8c03\u5ea6/\u7f13\u51b2\u533a\u6700\u5c0f\u5316\uff09\u76f8\u5173\u3002\n\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6d41\u6a21\u578b\u4e0b\u591a\u5904\u7406\u5668\u7cfb\u7edf\u4e2d\u5177\u6709\u51b2\u7a81\u7684\u5728\u7ebf\u7f13\u51b2\u533a\u6700\u5c0f\u5316\u95ee\u9898\u3002\u5de5\u4f5c\u8d1f\u8f7d\u8fde\u7eed\u5230\u8fbe\uff0c\u76ee\u6807\u662f\u6700\u5c0f\u5316\u5728\u9075\u5b88\u51b2\u7a81\u9650\u5236\u7684\u6709\u6548\u8c03\u5ea6\u4e0b\uff0c\u6240\u6709\u5904\u7406\u5668\u4e0a\u89c2\u5bdf\u5230\u7684\u6700\u5927\u5de5\u4f5c\u8d1f\u8f7d\u3002\u4f5c\u8005\u4e3a\u7279\u5b9a\u7684\u56db\u9876\u70b9\u56fe\u3001\u5b8c\u5168\u56fe\u3001\u5b8c\u5168\u4e8c\u5206\u56fe\u63d0\u4f9b\u4e86\u7d27\u5bc6\u754c\u9650\uff0c\u4e3a\u5b8c\u5168 k-\u5206\u56fe\u63d0\u4f9b\u4e86\u63a5\u8fd1\u7d27\u5bc6\u7684\u754c\u9650\uff0c\u5e76\u6536\u7d27\u4e86\u539f\u59cb\u6a21\u578b\u4e2d\u67d0\u4e2a\u7279\u5b9a\u56fe\u7684\u754c\u9650\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u7814\u7a76\u5728\u5f15\u5165\u7684\u6d41\u6a21\u578b\u4e2d\uff0c\u591a\u5904\u7406\u5668\u7cfb\u7edf\u4e2d\u7684\u5728\u7ebf\u7f13\u51b2\u533a\u6700\u5c0f\u5316\u95ee\u9898\u3002\u5728\u8fd9\u4e2a\u6a21\u578b\u4e2d\uff0c\u5de5\u4f5c\u8d1f\u8f7d\u8fde\u7eed\u5230\u8fbe\uff0c\u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u6709\u6548\u7684\u8c03\u5ea6\u7b56\u7565\uff0c\u6700\u5c0f\u5316\u6240\u6709\u5904\u7406\u5668\u4e0a\u7684\u6700\u5927\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u540c\u65f6\u9075\u5b88\u51b2\u7a81\u56fe\u6240\u5b9a\u4e49\u7684\u9650\u5236\u3002\u540c\u65f6\uff0c\u672c\u6587\u4e5f\u65e8\u5728\u7f29\u77ed\u539f\u59cb\u6a21\u578b\u4e2d\u7279\u5b9a\u56fe\u7684\u754c\u9650\u5dee\u8ddd\u3002", "method": "\u7814\u7a76\u65b9\u6cd5\u662f\u4e3a\u6d41\u6a21\u578b\u4e0b\u7684\u5728\u7ebf\u7f13\u51b2\u533a\u6700\u5c0f\u5316\u95ee\u9898\u63d0\u4f9b\u7d27\u5bc6\u6216\u63a5\u8fd1\u7d27\u5bc6\u7684\u7ade\u4e89\u754c\u9650\u3002\u5177\u4f53\u800c\u8a00\uff0c\u8be5\u65b9\u6cd5\u9488\u5bf9\u6240\u6709\u5177\u6709\u56db\u4e2a\u9876\u70b9\uff08\u9664\u4e86\u5df2\u88ab\u89e3\u51b3\u7684\u8def\u5f84\u56fe\uff09\u3001\u4e00\u822c\u5b8c\u5168\u56fe\u3001\u5b8c\u5168\u4e8c\u5206\u56fe\u4ee5\u53ca\u5b8c\u5168 k-\u5206\u56fe\u8fdb\u884c\u4e86\u5206\u6790\u3002\u6b64\u5916\uff0c\u4e5f\u5bf9\u539f\u59cb\u6a21\u578b\u4e2d\u5305\u542b\u4e00\u4e2a\u4e09\u89d2\u5f62\u548c\u4e00\u4e2a\u9644\u52a0\u8fb9\u7684\u56fe\u7684\u754c\u9650\u8fdb\u884c\u4e86\u6536\u7d27\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u4e3a\u6d41\u6a21\u578b\u4e2d\u7684\u5728\u7ebf\u7f13\u51b2\u533a\u6700\u5c0f\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u4ee5\u4e0b\u6210\u679c\uff1a\uff081\uff09\u4e3a\u6240\u6709\u56db\u9876\u70b9\u56fe\uff08\u9664\u4e86\u8def\u5f84\u56fe\uff09\u63d0\u4f9b\u4e86\u7d27\u5bc6\u7684\u754c\u9650\u3002\uff082\uff09\u4e3a\u4e00\u822c\u5b8c\u5168\u56fe\u548c\u5b8c\u5168\u4e8c\u5206\u56fe\u63d0\u4f9b\u4e86\u7d27\u5bc6\u7684\u754c\u9650\u3002\uff083\uff09\u4e3a\u5b8c\u5168 k-\u5206\u56fe\u63d0\u4f9b\u4e86\u63a5\u8fd1\u7d27\u5bc6\u7684\u754c\u9650\u3002\uff084\uff09\u5c06\u539f\u59cb\u6a21\u578b\u4e2d\u5305\u542b\u4e00\u4e2a\u4e09\u89d2\u5f62\u548c\u4e00\u4e2a\u9644\u52a0\u8fb9\u7684\u56fe\u7684\u754c\u9650\u5dee\u8ddd\u7f29\u5c0f\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u6d41\u6a21\u578b\u4e0b\u591a\u5904\u7406\u5668\u7cfb\u7edf\u4e2d\u7684\u5728\u7ebf\u7f13\u51b2\u533a\u6700\u5c0f\u5316\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u4e86\u56db\u9876\u70b9\u56fe\u3001\u5b8c\u5168\u56fe\u3001\u5b8c\u5168\u4e8c\u5206\u56fe\u4ee5\u53ca\u5b8c\u5168 k-\u5206\u56fe\uff0c\u5e76\u4e3a\u8fd9\u4e9b\u56fe\u63d0\u4f9b\u4e86\u7d27\u5bc6\u6216\u63a5\u8fd1\u7d27\u5bc6\u7684\u754c\u9650\u3002\u540c\u65f6\uff0c\u5bf9\u539f\u59cb\u6a21\u578b\u4e2d\u67d0\u4e2a\u7279\u5b9a\u56fe\u7684\u754c\u9650\u4e5f\u8fdb\u884c\u4e86\u6536\u7d27\u3002\u7814\u7a76\u7ed3\u679c\u63d0\u4f9b\u4e86\u5173\u4e8e\u5728\u7ebf\u8c03\u5ea6\u7b97\u6cd5\u5728\u4e0d\u540c\u51b2\u7a81\u56fe\u7ed3\u6784\u4e0b\u7684\u6027\u80fd\u4fdd\u8bc1\u3002"}}
{"id": "2511.19456", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.19456", "abs": "https://arxiv.org/abs/2511.19456", "authors": ["Anton Reinhard", "Simeon Ehrig", "Ren\u00e9 Widera", "Michael Bussmann", "Uwe Hernandez Acosta"], "title": "Optimizations on Graph-Level for Domain Specific Computations in Julia and Application to QED", "comment": null, "summary": "Complex computational problems in science often consist of smaller parts that can have largely distinct compute requirements from one another. For optimal efficiency, analyzing each subtask and scheduling it on the best-suited hardware would be necessary. Other considerations must be taken into account, too, such as parallelism, dependencies between different subtasks, and data transfer speeds between devices. To achieve this, directed acyclic graphs are often employed to represent these problems and enable utilizing as much hardware as possible on a given machine. In this paper, we present a software framework written in Julia capable of automatically and dynamically producing statically scheduled and compiled code. We lay theoretical foundations and add domain-specific information about the computation to the existing concepts of DAG scheduling, enabling optimizations that would otherwise be impossible. To illustrate the theory we implement an example application: the computation of matrix elements for scattering processes with many external particles in quantum electrodynamics.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e DSL\u3001\u56fe\u5904\u7406\uff08\u6709\u5411\u65e0\u73af\u56fe DAG\uff09\u3001\u7f16\u8bd1\u5668\uff08\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u4ee3\u7801\uff09\u548c HLS\uff08\u786c\u4ef6\u8c03\u5ea6\u4f18\u5316\uff09\u76f8\u5173\uff1a1. DSL\uff1a\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u8bf4\u660e\u662f DSL\uff0c\u4f46\u201c\u57df\u7279\u5b9a\u4fe1\u606f\u201d\u548c\u201c\u57df\u7279\u5b9a\u8ba1\u7b97\u201d\u6697\u793a\u4e86\u5bf9\u7279\u5b9a\u95ee\u9898\u9886\u57df\u7684\u5173\u6ce8\uff0c\u53ef\u80fd\u6d89\u53ca\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u6216\u6982\u5ff5\u30022. \u56fe\u5904\u7406\uff1a\u8bba\u6587\u660e\u786e\u4f7f\u7528\u4e86\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u6765\u8868\u793a\u548c\u8c03\u5ea6\u8ba1\u7b97\u95ee\u9898\u30023. \u7f16\u8bd1\u5668\uff1a\u8be5\u6846\u67b6\u80fd\u591f\u751f\u6210\u201c\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u7684\u4ee3\u7801\u201d\uff0c\u8fd9\u76f4\u63a5\u6d89\u53ca\u7f16\u8bd1\u5668\u7684\u529f\u80fd\u30024. HLS\uff1a\u63cf\u8ff0\u4e2d\u63d0\u5230\u7684\u201c\u8c03\u5ea6\u5b83\u5728\u6700\u9002\u5408\u7684\u786c\u4ef6\u4e0a\u201d\u3001\u201c\u6700\u5927\u9650\u5ea6\u5730\u5229\u7528\u786c\u4ef6\u201d\u548c\u201c\u786c\u4ef6\u5206\u6790\u201d\u4e0e\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u786c\u4ef6\u7ea7\u4f18\u5316\u6709\u5173\u3002\n\n**\u592a\u957f\u4e0d\u8bfb\uff1a** \u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e Julia, \u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u6765\u8868\u793a\u590d\u6742\u79d1\u5b66\u8ba1\u7b97\u95ee\u9898\u7684\u8f6f\u4ef6\u6846\u67b6\u3002\u5b83\u80fd\u81ea\u52a8\u3001\u52a8\u6001\u5730\u751f\u6210\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u7684\u4ee3\u7801\u3002\u901a\u8fc7\u5c06\u9886\u57df\u7279\u5b9a\u7684\u8ba1\u7b97\u4fe1\u606f\u878d\u5165 DAG \u8c03\u5ea6\u4e2d\uff0c\u5b9e\u73b0\u4e86\u4f18\u5316\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u591a\u7c7b\u578b\u786c\u4ef6\u4e0a\u7684\u8ba1\u7b97\u6548\u7387\u3002\u4ee5\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u7684\u77e9\u9635\u5143\u7d20\u8ba1\u7b97\u4f5c\u4e3a\u6848\u4f8b\u8fdb\u884c\u4e86\u6f14\u793a\u3002", "motivation": "\u590d\u6742\u79d1\u5b66\u8ba1\u7b97\u95ee\u9898\u901a\u5e38\u7531\u8ba1\u7b97\u9700\u6c42\u4e0d\u540c\u7684\u8f83\u5c0f\u5b50\u4efb\u52a1\u7ec4\u6210\u3002\u4e3a\u4e86\u5b9e\u73b0\u6700\u4f18\u6548\u7387\uff0c\u9700\u8981\u5bf9\u6bcf\u4e2a\u5b50\u4efb\u52a1\u8fdb\u884c\u5206\u6790\uff0c\u5e76\u5c06\u5176\u8c03\u5ea6\u5230\u6700\u5408\u9002\u7684\u786c\u4ef6\u4e0a\u3002\u540c\u65f6\uff0c\u8fd8\u9700\u8981\u8003\u8651\u5e76\u884c\u6027\u3001\u5b50\u4efb\u52a1\u4e4b\u95f4\u7684\u4f9d\u8d56\u5173\u7cfb\u4ee5\u53ca\u8bbe\u5907\u95f4\u7684\u6570\u636e\u4f20\u8f93\u901f\u5ea6\u7b49\u56e0\u7d20\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u4f7f\u7528\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u6765\u8868\u793a\u8fd9\u4e9b\u95ee\u9898\uff0c\u5e76\u5b9e\u73b0\u5c3d\u53ef\u80fd\u591a\u5730\u5229\u7528\u7ed9\u5b9a\u673a\u5668\u4e0a\u786c\u4ef6\u7684\u8f6f\u4ef6\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e Julia \u7684\u8f6f\u4ef6\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u4e14\u52a8\u6001\u5730\u751f\u6210\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u7684\u4ee3\u7801\u3002\u5b83\u5c06\u7279\u5b9a\u9886\u57df\u7684\u8ba1\u7b97\u4fe1\u606f\u878d\u5165\u5230 DAG \u8c03\u5ea6\u7684\u73b0\u6709\u6982\u5ff5\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u989d\u5916\u7684\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e00\u4e2a\u5177\u4f53\u7684\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u6563\u5c04\u8fc7\u7a0b\u77e9\u9635\u5143\u7d20\u8ba1\u7b97\u7684\u4f8b\u5b50\u6765\u9610\u8ff0\u548c\u5b9e\u73b0\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u548c\u52a8\u6001\u5730\u751f\u6210\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u7684\u4ee3\u7801\u3002\u901a\u8fc7\u5c06\u5173\u4e8e\u8ba1\u7b97\u7684\u7279\u5b9a\u9886\u57df\u4fe1\u606f\u6dfb\u52a0\u5230\u73b0\u6709\u7684 DAG \u8c03\u5ea6\u6982\u5ff5\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\u4e0d\u53ef\u80fd\u5b9e\u73b0\u7684\u4f18\u5316\u3002\u7528\u91cf\u5b50\u7535\u52a8\u529b\u5b66\u4e2d\u6d89\u53ca\u591a\u4e2a\u5916\u90e8\u7c92\u5b50\u7684\u6563\u5c04\u8fc7\u7a0b\u7684\u77e9\u9635\u5143\u7d20\u8ba1\u7b97\u7684\u6848\u4f8b\u8bc1\u660e\u4e86\u8be5\u7406\u8bba\u4e0e\u5b9e\u73b0\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e Julia \u7684\u8f6f\u4ef6\u6846\u67b6\uff0c\u53ef\u4ee5\u81ea\u52a8\u3001\u52a8\u6001\u5730\u751f\u6210\u9759\u6001\u8c03\u5ea6\u548c\u7f16\u8bd1\u7684\u4ee3\u7801\u3002\u901a\u8fc7\u5c06\u7279\u5b9a\u9886\u57df\u7684\u8ba1\u7b97\u4fe1\u606f\u548c\u73b0\u6709\u7684 DAG \u8c03\u5ea6\u6982\u5ff5\u76f8\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u8c03\u5ea6\u548c\u4f18\u5316\uff0c\u4e3a\u590d\u6742\u79d1\u5b66\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19973", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.19973", "abs": "https://arxiv.org/abs/2511.19973", "authors": ["Hoa Nguyen", "Pongstorn Maidee", "Jason Lowe-Power", "Alireza Kaviani"], "title": "Pickle Prefetcher: Programmable and Scalable Last-Level Cache Prefetcher", "comment": "13 pages, 13 figures", "summary": "Modern high-performance architectures employ large last-level caches (LLCs). While large LLCs can reduce average memory access latency for workloads with a high degree of locality, they can also increase latency for workloads with irregular memory access patterns. Prefetchers are widely used to reduce memory latency by prefetching data into the cache hierarchy before it is accessed by the core. However, existing prediction-based prefetchers often struggle with irregular memory access patterns, which are especially prevalent in modern applications. This paper introduces the Pickle Prefetcher, a programmable and scalable LLC prefetcher designed to handle independent irregular memory access patterns effectively. Instead of relying on static heuristics or complex prediction algorithms, Pickle Prefetcher allows software to define its own prefetching strategies using a simple programming interface without expanding the instruction set architecture (ISA). By trading the logic complexity of hardware prediction for software programmability, Pickle Prefetcher can adapt to a wide range of access patterns without requiring extensive hardware resources for prediction. This allows the prefetcher to dedicate its resources to scheduling and issuing timely prefetch requests. Graph applications are an example where the memory access pattern is irregular but easily predictable by software. Through extensive evaluations of the Pickle Prefetcher on gem5 full-system simulations, we demonstrate tha Pickle Prefetcher significantly outperforms traditional prefetching techniques. Our results show that Pickle Prefetcher achieves speedups of up to 1.74x on the GAPBS breadth-first search (BFS) implementation over a baseline system. When combined with private cache prefetchers, Pickle Prefetcher provides up to a 1.40x speedup over systems using only private cache prefetchers.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\uff08\u5728\u8bc4\u4f30\u4e2d\u4f7f\u7528\u56fe\u5e94\u7528\uff0c\u7279\u522b\u662fBFS\uff09\u3001\u7f16\u8bd1\u5668\uff08\u901a\u8fc7\u8f6f\u4ef6\u53ef\u7f16\u7a0b\u63a5\u53e3\u5b9a\u4e49\u9884\u53d6\u7b56\u7565\uff0c\u9690\u542b\u6709\u7f16\u8bd1\u6216\u8fd0\u884c\u65f6\u652f\u6301\uff09\u76f8\u5173\u3002\n\u73b0\u4ee3\u5927\u578b LLC \u5bf9\u4e8e\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u73b0\u6709\u9884\u53d6\u5668\u96be\u4ee5\u5e94\u5bf9\u3002Pickle Prefetcher \u662f\u4e00\u79cd\u53ef\u7f16\u7a0b\u3001\u53ef\u6269\u5c55\u7684 LLC \u9884\u53d6\u5668\uff0c\u5b83\u5141\u8bb8\u8f6f\u4ef6\u5b9a\u4e49\u9884\u53d6\u7b56\u7565\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u786c\u4ef6\u9884\u6d4b\u903b\u8f91\uff0c\u4e13\u6ce8\u4e8e\u8c03\u5ea6\u548c\u8bf7\u6c42\u3002\u901a\u8fc7\u5728 gem5 \u5168\u7cfb\u7edf\u6a21\u62df\u4e2d\u7684\u5e7f\u6cdb\u8bc4\u4f30\uff0cPickle Prefetcher \u5728\u56fe\u5e94\u7528\uff08\u5982 BFS\uff09\u4e0a\uff0c\u76f8\u6bd4\u57fa\u7ebf\u7cfb\u7edf\u5b9e\u73b0\u4e86\u9ad8\u8fbe 1.74 \u500d\u7684\u52a0\u901f\u6bd4\uff0c\u5e76\u4e0e\u5176\u4ed6\u9884\u53d6\u5668\u7ed3\u5408\u65f6\u4e5f\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u8f6f\u4ef6\u6307\u5bfc\u9884\u53d6\u5728\u5904\u7406\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u4ee3\u9ad8\u6027\u80fd\u67b6\u6784\u4e2d\u7684\u5927\u578b\u672b\u7ea7\u7f13\u5b58\uff08LLC\uff09\u867d\u7136\u6709\u52a9\u4e8e\u5177\u6709\u9ad8\u5c40\u90e8\u6027\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u4f46\u5bf9\u4e8e\u5177\u6709\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff0c\u53ef\u80fd\u4f1a\u589e\u52a0\u5ef6\u8fdf\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u9884\u6d4b\u7684\u9884\u53d6\u5668\u5728\u5904\u7406\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u800c\u8fd9\u79cd\u6a21\u5f0f\u5728\u73b0\u4ee3\u5e94\u7528\u4e2d\u5c24\u4e3a\u666e\u904d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u6709\u6548\u5904\u7406\u72ec\u7acb\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u7684\u9884\u53d6\u5668\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u8bbe\u8ba1\u4e00\u4e2a\u80fd\u591f\u5c06\u9884\u53d6\u7b56\u7565\u7684\u5b9a\u4e49\u6743\u4ea4\u7ed9\u8f6f\u4ef6\uff0c\u4ece\u800c\u66f4\u597d\u5730\u9002\u5e94\u8fd9\u4e9b\u590d\u6742\u8bbf\u95ee\u6a21\u5f0f\u7684LLC\u9884\u53d6\u5668\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aPickle Prefetcher\u7684\u53ef\u7f16\u7a0b\u4e14\u53ef\u6269\u5c55\u7684\u672b\u7ea7\u7f13\u5b58\uff08LLC\uff09\u9884\u53d6\u5668\u3002\u8be5\u9884\u53d6\u5668\u653e\u5f03\u4e86\u4f20\u7edf\u7684\u9759\u6001\u542f\u53d1\u5f0f\u6216\u590d\u6742\u7684\u9884\u6d4b\u7b97\u6cd5\uff0c\u800c\u662f\u5141\u8bb8\u8f6f\u4ef6\u901a\u8fc7\u4e00\u4e2a\u7b80\u5355\u7684\u7f16\u7a0b\u63a5\u53e3\u6765\u5b9a\u4e49\u9884\u53d6\u7b56\u7565\uff0c\u800c\u65e0\u9700\u6269\u5c55\u6307\u4ee4\u96c6\u67b6\u6784\uff08ISA\uff09\u3002\u8fd9\u79cd\u65b9\u6cd5\u5c06\u786c\u4ef6\u9884\u6d4b\u7684\u903b\u8f91\u590d\u6742\u6027\u8f6c\u5316\u4e3a\u8f6f\u4ef6\u7684\u53ef\u7f16\u7a0b\u6027\uff0c\u4f7f\u9884\u53d6\u5668\u80fd\u591f\u9002\u5e94\u5e7f\u6cdb\u7684\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\uff0c\u5e76\u5c06\u786c\u4ef6\u8d44\u6e90\u96c6\u4e2d\u4e8e\u8c03\u5ea6\u548c\u53ca\u65f6\u53d1\u51fa\u9884\u53d6\u8bf7\u6c42\u3002\u4f5c\u8005\u901a\u8fc7\u5728 gem5 \u5168\u7cfb\u7edf\u6a21\u62df\u4e2d\u5bf9 Pickle Prefetcher \u8fdb\u884c\u5e7f\u6cdb\u8bc4\u4f30\uff0c\u5e76\u5c06\u5176\u6027\u80fd\u4e0e\u4f20\u7edf\u9884\u53d6\u6280\u672f\u8fdb\u884c\u6bd4\u8f83\uff0c\u7279\u522b\u5173\u6ce8\u5728\u56fe\u5e94\u7528\u7b49\u5177\u6709\u4e0d\u89c4\u5219\u8bbf\u95ee\u6a21\u5f0f\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u5728 gem5 \u5168\u7cfb\u7edf\u6a21\u62df\u4e2d\u8fdb\u884c\u7684\u5e7f\u6cdb\u8bc4\u4f30\uff0cPickle Prefetcher \u76f8\u6bd4\u4f20\u7edf\u9884\u53d6\u6280\u672f\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\u3002\u5728 GAPBS \u5e7f\u5ea6\u4f18\u5148\u641c\u7d22\uff08BFS\uff09\u5b9e\u73b0\u4e0a\uff0cPickle Prefetcher \u5b9e\u73b0\u4e86\u9ad8\u8fbe 1.74 \u500d\u7684\u52a0\u901f\u6bd4\u3002\u5f53\u4e0e\u79c1\u6709\u7f13\u5b58\u9884\u53d6\u5668\u7ed3\u5408\u4f7f\u7528\u65f6\uff0c\u76f8\u6bd4\u4e8e\u4ec5\u4f7f\u7528\u79c1\u6709\u7f13\u5b58\u9884\u53d6\u5668\u7684\u7cfb\u7edf\uff0cPickle Prefetcher \u5e26\u6765\u4e86\u9ad8\u8fbe 1.40 \u500d\u7684\u52a0\u901f\u6bd4\u3002\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86 Pickle Prefetcher \u5728\u5904\u7406\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "Pickle Prefetcher\u901a\u8fc7\u4ea4\u6613\u786c\u4ef6\u9884\u6d4b\u7684\u903b\u8f91\u590d\u6742\u6027\u4ee5\u6362\u53d6\u8f6f\u4ef6\u53ef\u7f16\u7a0b\u6027\uff0c\u4ece\u800c\u80fd\u591f\u6709\u6548\u5730\u9002\u5e94\u5404\u79cd\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u3002\u5b83\u5728\u5168\u7cfb\u7edf\u6a21\u62df\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u56fe\u5e94\u7528\u7b49\u5177\u6709\u4e0d\u89c4\u5219\u4f46\u53ef\u9884\u6d4b\u8bbf\u95ee\u6a21\u5f0f\u7684\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\uff0c\u8bc1\u660e\u4e86\u8f6f\u4ef6\u6307\u5bfc\u7684\u9884\u53d6\u7b56\u7565\u5728\u5904\u7406\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u6a21\u5f0f\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u548c\u6f5c\u529b\u3002"}}
{"id": "2511.20111", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2511.20111", "abs": "https://arxiv.org/abs/2511.20111", "authors": ["Ben Bals", "Joakim Blikstad", "Greg Bodwin", "Daniel Dadush", "Sebastian Forster", "Yasamin Nazari"], "title": "Greedy Algorithms for Shortcut Sets and Hopsets", "comment": null, "summary": "We explore the power of greedy algorithms for hopsets and shortcut sets. In particular, we propose simple greedy algorithms that, given an input graph $G$ and a parameter $\u03b2$, compute a shortcut set or an exact hopset $H$ of hopbound at most $\u03b2$, and we prove the following guarantees about the size $|H|$ of the output:\n  For shortcut sets, we prove the bound $$|H| \\le \\tilde{O}\\left( \\frac{n^2}{\u03b2^3} + \\frac{n^{3/2}}{\u03b2^{3/2}} \\right).$$ This matches the current state-of-the-art upper bound by Kogan and Parter [SODA '22].\n  For exact hopsets of $n$-node, $m$-edge weighted graphs, the size of the output hopset is existentially optimal up to subpolynomial factors, under some technical assumptions.\n  Despite their simplicity and conceptual implications, these greedy algorithms are slower than existing sampling-based approaches. Our second set of results focus on faster deterministic algorithms that are based on a certain greedy set cover approximation algorithm on paths in the transitive closure. One consequence is a deterministic algorithm that takes $O(mn^{2/3})$ time to compute a shortcut set of size $\\tilde{O}(n)$ and hopbound $O(n^{1/3})$.", "AI": {"tldr": "\u4e0eDSL\u6216\u56fe\u5904\u7406\u6216MLIR\u6216\u7f16\u8bd1\u5668\u6216HLS\u76f8\u5173\u5417\uff1a\u672c\u6587\u4e0e\u56fe\u5904\u7406\u76f8\u5173\u3002\nToo long; didn't read: \u672c\u6587\u63a2\u7d22\u4e86\u7528\u4e8e\u8df3\u8dc3\u96c6\u548c\u5feb\u6377\u96c6\u7684\u7b80\u5355\u8d2a\u5a6a\u7b97\u6cd5\u7684\u6027\u80fd\u3002\u5728\u5feb\u6377\u96c6\u65b9\u9762\uff0c\u8d2a\u5a6a\u7b97\u6cd5\u7684\u89c4\u6a21\u754c\u9650\u4e0e\u73b0\u6709\u6700\u4f73\u7ed3\u679c\u76f8\u5339\u914d\uff1b\u5728\u7cbe\u786e\u8df3\u8dc3\u96c6\u65b9\u9762\uff0c\u5176\u7ed3\u679c\u89c4\u6a21\u5728\u5b58\u5728\u6027\u610f\u4e49\u4e0a\u662f\u8fd1\u4e4e\u6700\u4f18\u7684\u3002\u5c3d\u7ba1\u8d2a\u5a6a\u7b97\u6cd5\u5728\u6982\u5ff5\u4e0a\u7b80\u5355\uff0c\u4f46\u901f\u5ea6\u8f83\u6162\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u8f6c\u5411\u7814\u7a76\u57fa\u4e8e\u4f20\u9012\u95ed\u5305\u8def\u5f84\u4e0a\u96c6\u5408\u8986\u76d6\u8fd1\u4f3c\u7b97\u6cd5\u7684\u66f4\u5feb\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u6700\u7ec8\u63a8\u51fa\u4e86\u4e00\u4e2a\u80fd\u5728 $O(mn^{2/3})$ \u65f6\u95f4\u8ba1\u7b97\u51fa $O(n^{1/3})$ \u8df3\u8dc3\u754c\u7684 $\\tilde{O}(n)$ \u89c4\u6a21\u5feb\u6377\u96c6\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22\u8d2a\u5a6a\u7b97\u6cd5\u5728\u8ba1\u7b97\u8df3\u8dc3\u96c6\uff08Hopsets\uff09\u548c\u5feb\u6377\u96c6\uff08Shortcut Sets\uff09\u65b9\u9762\u7684\u80fd\u529b\uff0c\u76ee\u7684\u662f\u63d0\u51fa\u7b80\u5355\u800c\u6709\u6548\u7684\u7b97\u6cd5\uff0c\u5e76\u5206\u6790\u5176\u5728\u7b97\u6cd5\u89c4\u6a21\u548c\u8ba1\u7b97\u901f\u5ea6\u65b9\u9762\u7684\u6027\u80fd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u7b80\u5355\u7684\u8d2a\u5a6a\u7b97\u6cd5\u6765\u8ba1\u7b97\u8df3\u8dc3\u96c6\u548c\u5feb\u6377\u96c6\u3002\u5bf9\u4e8e\u5feb\u6377\u96c6\uff0c\u8d2a\u5a6a\u7b97\u6cd5\u5f97\u5230\u7684\u89c4\u6a21\u4e0a\u754c\u4e3a $|H| \\le \\tilde{O}(n^2/\\beta^3 + n^{3/2}/\\beta^{3/2})$\u3002\u5bf9\u4e8e\u7cbe\u786e\u8df3\u8dc3\u96c6\uff0c\u8f93\u51fa\u96c6\u5408\u7684\u5927\u5c0f\u5728\u6280\u672f\u5047\u8bbe\u4e0b\u662f\u5b58\u5728\u6027\u6700\u4f18\u7684\u3002\u540c\u65f6\uff0c\u672c\u6587\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f20\u9012\u95ed\u5305\u8def\u5f84\u7684\u96c6\u5408\u8986\u76d6\u8fd1\u4f3c\u7b97\u6cd5\u7684\u66f4\u5feb\u786e\u5b9a\u6027\u7b97\u6cd5\u3002", "result": "\u672c\u6587\u6709\u4e24\u4e2a\u4e3b\u8981\u7ed3\u679c\uff1a\n1. **\u8d2a\u5a6a\u7b97\u6cd5\u7684\u6027\u80fd**\uff1a\n    * **\u5feb\u6377\u96c6**\uff1a\u7b97\u6cd5\u5f97\u5230\u7684\u89c4\u6a21\u4e0a\u754c $|H| \\le \\tilde{O}(n^2/\\beta^3 + n^{3/2}/\\beta^{3/2})$\uff0c\u4e0e\u73b0\u6709\u6700\u4f73\u4e0a\u754c\u76f8\u5339\u914d\u3002\n    * **\u7cbe\u786e\u8df3\u8dc3\u96c6**\uff1a\u5728\u7279\u5b9a\u6280\u672f\u5047\u8bbe\u4e0b\uff0c\u8f93\u51fa\u96c6\u5408\u7684\u5927\u5c0f\u662f\u5b58\u5728\u6027\u6700\u4f18\u7684\uff08\u6700\u591a\u76f8\u5dee\u4e9a\u591a\u9879\u5f0f\u56e0\u5b50\uff09\u3002\n2. **\u66f4\u5feb\u786e\u5b9a\u6027\u7b97\u6cd5**\uff1a\u4e00\u4e2a\u57fa\u4e8e\u8d2a\u5a6a\u96c6\u5408\u8986\u76d6\u8fd1\u4f3c\u7684\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u80fd\u5728 $O(mn^{2/3})$ \u65f6\u95f4\u5185\u8ba1\u7b97\u51fa\u5927\u5c0f\u4e3a $\\tilde{O}(n)$\u3001\u8df3\u8dc3\u754c\u4e3a $O(n^{1/3})$ \u7684\u5feb\u6377\u96c6\u3002", "conclusion": "\u672c\u6587\u63a2\u7d22\u4e86\u7528\u4e8e\u8df3\u8dc3\u96c6\u548c\u5feb\u6377\u96c6\u7684\u8d2a\u5a6a\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f20\u9012\u95ed\u5305\u8def\u5f84\u4e0a\u7684\u96c6\u5408\u8986\u76d6\u8fd1\u4f3c\u7b97\u6cd5\u7684\u66f4\u5feb\u786e\u5b9a\u6027\u65b9\u6cd5\u3002\u6700\u540e\u4e00\u90e8\u5206\u7ed3\u679c\u662f\u57fa\u4e8e\u66f4\u5feb\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4e14\u8be5\u7b97\u6cd5\u91c7\u7528\u4e86\u4f20\u9012\u95ed\u5305\u8def\u5f84\u4e0a\u7684\u67d0\u4e2a\u8d2a\u5fc3\u96c6\u5408\u8986\u76d6\u8fd1\u4f3c\u7b97\u6cd5\u3002\u4e00\u79cd\u63a8\u8bba\u662f\u5f97\u5230\u4e00\u4e2a\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u80fd\u5728 $O(mn^{2/3})$ \u65f6\u95f4\u5185\u8ba1\u7b97\u51fa\u5927\u5c0f\u4e3a $\\tilde{O}(n)$\u3001\u8df3\u8dc3\u754c\u4e3a $O(n^{1/3})$ \u7684\u5feb\u6377\u96c6\u3002"}}
{"id": "2511.19521", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.19521", "abs": "https://arxiv.org/abs/2511.19521", "authors": ["Tesla Zhang", "Asher Kornfeld", "Rui Li", "Sonya Simkin", "Yue Yao", "Stephanie Balzer"], "title": "Mechanizing a Proof-Relevant Logical Relation for Timed Message-Passing Protocols", "comment": "15 pages, 9 figures", "summary": "Semantic typing has become a powerful tool for program verification, applying the technique of logical relations as not only a proof method, but also a device for prescribing program behavior. In recent work, Yao et al. scaled semantic typing to the verification of timed message-passing protocols, which are prevalent in, e.g., IoT and real-time systems applications. The appeal of semantic typing in this context is precisely because of its ability to support typed and untyped program components alike -- including physical objects -- which caters to the heterogeneity of these applications. Another demand inherent to these applications is timing: constraining the time or time window within which a message exchange must happen. Yao et al. equipped their logical relation not only with temporal predicates, but also with computable trajectories, to supply the evidence that an inhabitant can step from one time point to another one. While Yao et al. provide the formalization for such a verification tool, it lacks a mechanization. Mechanizing the system would not only provide a machine proof for it, but also facilitate scalability for future extensions and applications.\n  This paper tackles the challenge of mechanizing the resulting proof-relevant logical relation in a proof assistant. allowing trajectories to be interleaved, partitioned, and concatenated, while the intended equality on trajectories is the equality of their graphs when seen as processes indexed by time. Unfortunately, proof assistants based on intensional type theory only have modest support for such equations, forcing a prolific use of transports. This paper reports on the process of mechanizing Yao et al.'s results, comprising the logical relation, the algebra of computable trajectories with supporting lemmas, and the fundamental theorem of the logical relation, in the Rocq theorem prover.", "AI": {"tldr": "\u5173\u8054\u9886\u57df\uff1a\u7f16\u8bd1\u5668\u9886\u57df\uff08Specifically, theorem prover, which is a tool for formal verification\uff09\u3002\nToo long; didn't read: \u8bed\u4e49\u7c7b\u578b\u88ab\u7528\u4e8e\u9a8c\u8bc1 timed message-passing \u534f\u8bae\uff0c\u4f46 Yao \u7b49\u4eba\u7684\u5f62\u5f0f\u5316\u5de5\u4f5c\u7f3a\u4e4f\u673a\u68b0\u5316\u3002\u672c\u6587\u5728 Rocq \u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u6210\u529f\u5730\u673a\u68b0\u5316\u4e86\u8be5\u7cfb\u7edf\uff0c\u5305\u62ec\u903b\u8f91\u5173\u7cfb\u548c\u53ef\u8ba1\u7b97\u8f68\u8ff9\u7684\u4ee3\u6570\uff0c\u514b\u670d\u4e86\u5185\u6db5\u5f0f\u7c7b\u578b\u7406\u8bba\u4e2d\u8f68\u8ff9\u7b49\u5f0f\u652f\u6301\u6709\u9650\u7684\u6311\u6218\uff0c\u4e3a\u8be5\u9a8c\u8bc1\u5de5\u5177\u63d0\u4f9b\u4e86\u673a\u5668\u8bc1\u660e\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002", "motivation": "\u8bed\u4e49\u7c7b\u578b\uff08Semantic typing\uff09\u662f\u7a0b\u5e8f\u9a8c\u8bc1\u7684\u6709\u529b\u5de5\u5177\uff0c\u5c24\u5176\u662f\u5728 Yao \u7b49\u4eba\u5c06\u5176\u5e94\u7528\u4e8e\u9a8c\u8bc1 timed message-passing \u534f\u8bae\uff08\u5e38\u89c1\u4e8e IoT \u548c\u5b9e\u65f6\u7cfb\u7edf\uff09\u540e\u3002\u8fd9\u4e9b\u5e94\u7528\u5177\u6709\u5f02\u6784\u6027\u548c\u5bf9\u65f6\u95f4\u7ea6\u675f\uff08Timing\uff09\u7684\u56fa\u6709\u9700\u6c42\u3002\u5c3d\u7ba1 Yao \u7b49\u4eba\u7684\u5de5\u4f5c\u63d0\u4f9b\u4e86\u5e26\u6709\u65f6\u5e8f\u8c13\u8bcd\u548c\u53ef\u8ba1\u7b97\u8f68\u8ff9\u7684\u903b\u8f91\u5173\u7cfb\u5f62\u5f0f\u5316\uff0c\u4f46\u7f3a\u4e4f\u673a\u68b0\u5316\u9a8c\u8bc1\u3002\u673a\u68b0\u5316\u4e0d\u4ec5\u80fd\u63d0\u4f9b\u673a\u5668\u8bc1\u660e\uff0c\u8fd8\u80fd\u4fc3\u8fdb\u672a\u6765\u6269\u5c55\u548c\u5e94\u7528\u7684\u53ef\u6269\u5c55\u6027\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u89e3\u51b3\u8be5\u7cfb\u7edf\u7684\u673a\u68b0\u5316\u6311\u6218\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5728 Rocq \u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5bf9\u59da\u7b49\u4eba\u63d0\u51fa\u7684 timed message-passing \u534f\u8bae\u7684\u8bed\u4e49\u7c7b\u578b\u7cfb\u7edf\u8fdb\u884c\u673a\u68b0\u5316\uff0c\u89e3\u51b3\u4e86\u7f3a\u4e4f\u673a\u68b0\u5316\u7684\u95ee\u9898\u3002\u673a\u68b0\u5316\u7684\u5185\u5bb9\u5305\u62ec\u903b\u8f91\u5173\u7cfb\u3001\u53ef\u8ba1\u7b97\u8f68\u8ff9\u7684\u4ee3\u6570\u53ca\u5176\u652f\u6491\u5f15\u7406\uff0c\u4ee5\u53ca\u903b\u8f91\u5173\u7cfb\u7684\u57fa\u672c\u5b9a\u7406\u3002\u5b83\u5904\u7406\u4e86\u8f68\u8ff9\u7684\u4ea4\u9519\u3001\u5212\u5206\u548c\u8fde\u63a5\uff0c\u514b\u670d\u4e86\u5185\u6db5\u5f0f\u7c7b\u578b\u7406\u8bba\u4e2d\u5bf9\u4e8e\u8f68\u8ff9\u7b49\u5f0f\u652f\u6301\u4e0d\u8db3\u7684\u6311\u6218\u3002", "result": "\u672c\u6587\u6210\u529f\u5730\u5728 Rocq \u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5bf9 Yao \u7b49\u4eba\u63d0\u51fa\u7684 timed message-passing \u534f\u8bae\u7684\u8bed\u4e49\u7c7b\u578b\u7cfb\u7edf\u8fdb\u884c\u4e86\u673a\u68b0\u5316\uff1a\n1. \u5b9e\u73b0\u4e86\u903b\u8f91\u5173\u7cfb\u3001\u53ef\u8ba1\u7b97\u8f68\u8ff9\u7684\u4ee3\u6570\u53ca\u5176\u652f\u6491\u5f15\u7406\uff0c\u4ee5\u53ca\u903b\u8f91\u5173\u7cfb\u7684\u57fa\u672c\u5b9a\u7406\u3002\n2. \u514b\u670d\u4e86\u57fa\u4e8e\u5185\u6db5\u5f0f\u7c7b\u578b\u7406\u8bba\u7684\u8bc1\u660e\u52a9\u624b\u5bf9\u8f68\u8ff9\u7b49\u5f0f\u7684\u652f\u6301\u6709\u9650\u7684\u6311\u6218\u3002\n3. \u4e3a\u539f\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u63d0\u4f9b\u4e86\u673a\u5668\u8bc1\u660e\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u6269\u5c55\u548c\u5e94\u7528\u5960\u5b9a\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u5728 Rocq \u5b9a\u7406\u8bc1\u660e\u5668\u4e2d\u5bf9 Yao \u7b49\u4eba\u63d0\u51fa\u7684 timed message-passing \u534f\u8bae\u7684\u8bed\u4e49\u7c7b\u578b\u7cfb\u7edf\u8fdb\u884c\u4e86\u673a\u68b0\u5316\u3002\u8fd9\u5305\u62ec\u4e86\u903b\u8f91\u5173\u7cfb\u3001\u53ef\u8ba1\u7b97\u8f68\u8ff9\u7684\u4ee3\u6570\u53ca\u5176\u652f\u6491\u5f15\u7406\uff0c\u4ee5\u53ca\u903b\u8f91\u5173\u7cfb\u7684\u57fa\u672c\u5b9a\u7406\u3002\u673a\u68b0\u5316\u514b\u670d\u4e86\u5185\u6db5\u5f0f\u7c7b\u578b\u7406\u8bba\u4e2d\u5bf9\u8f68\u8ff9\u7b49\u5f0f\u652f\u6301\u6709\u9650\u7684\u6311\u6218\uff0c\u901a\u8fc7\u673a\u68b0\u8bc1\u660e\u9a8c\u8bc1\u4e86\u539f\u7cfb\u7edf\u7684\u6b63\u786e\u6027\uff0c\u4e3a\u7cfb\u7edf\u672a\u6765\u7684\u6269\u5c55\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2511.20090", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20090", "abs": "https://arxiv.org/abs/2511.20090", "authors": ["Zizhang Luo", "Fan Cui", "Kexing Zhou", "Runlin Guo", "Mile Xia", "Hongyuan Hou", "Yun Lian"], "title": "R3A: Reliable RTL Repair Framework with Multi-Agent Fault Localization and Stochastic Tree-of-Thoughts Patch Generation", "comment": null, "summary": "Repairing RTL bugs is crucial for hardware design and verification. Traditional automatic program repair (APR) methods define dedicated search spaces to locate and fix bugs with program synthesis. However, they heavily rely on fixed templates and can only deal with limited bugs. As an alternative, Large Language Models with the ability to understand code semantics can be explored for RTL repair. However, they suffer from unreliable outcomes due to inherent randomness and long input contexts of RTL code and waveform. To address these challenges, we propose R3A, an LLM-based automatic RTL program repair framework upon the basic model to improve reliability. R3A proposes the stochastic Tree-Of-Thoughts method to control a patch generation agent to explore a validated solution for the bug. The algorithm samples search states according to a heuristic function to balance between exploration and exploitation for a reliable outcome. Besides, R3A proposes a multi-agent fault localization method to find fault candidates as the starting points for the patch generation agent, further increasing the reliability. Experiments show R3A can fix 90.6% of bugs in the RTL-repair dataset within a given time limit, which covers 45% more bugs than traditional methods and other LLM-based approaches, while achieving an 86.7% pass@5 rate on average, showing a high reliability.", "AI": {"tldr": "\u76f8\u5173\u9886\u57df\uff1a\u7f16\u8bd1\u5668\u3001DSL\u3002\n\u592a\u957f\u4e0d\u770b\u7248\uff1aRTL \u9519\u8bef\u4fee\u590d\u5bf9\u4e8e\u786c\u4ef6\u8bbe\u8ba1\u548c\u9a8c\u8bc1\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7684\u6a21\u677f\uff0c\u6548\u679c\u6709\u9650\u3002\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u7406\u89e3\u4ee3\u7801\u8bed\u4e49\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u56fa\u6709\u968f\u673a\u6027\u548c\u957f\u4e0a\u4e0b\u6587\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9760\u3002\u672c\u6587\u63d0\u51fa\u4e86 R3A\uff0c\u4e00\u4e2a\u57fa\u4e8e LLM \u7684\u81ea\u52a8 RTL \u7a0b\u5e8f\u4fee\u590d\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u53ef\u9760\u6027\u3002R3A \u5f15\u5165\u4e86\u968f\u673a\u601d\u60f3\u6811\uff08Stochastic Tree-Of-Thoughts\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u51fd\u6570\u91c7\u6837\u6765\u5e73\u8861\u63a2\u7d22\u548c\u5229\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\u6765\u786e\u5b9a\u8865\u4e01\u751f\u6210\u7684\u8d77\u70b9\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cR3A \u80fd\u4fee\u590d 90.6% \u7684 RTL-repair \u9519\u8bef\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u5347 45%\uff0c\u5e76\u5b9e\u73b0\u4e86 86.7% \u7684\u5e73\u5747 pass@5 \u6210\u529f\u7387\uff0c\u5c55\u793a\u4e86\u9ad8\u53ef\u9760\u6027\u548c\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u7684\u6a21\u677f\uff0c\u53ea\u80fd\u5904\u7406\u6709\u9650\u7684\u9519\u8bef\u3002\u63a2\u7d22\u4f7f\u7528\u7406\u89e3\u4ee3\u7801\u8bed\u4e49\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c RTL \u4fee\u590d\uff0c\u4f46\u5b83\u4eec\u53c8\u53d7\u9650\u4e8e\u56fa\u6709\u968f\u673a\u6027\u4ee5\u53ca RTL \u4ee3\u7801\u548c\u6ce2\u5f62\u7684\u957f\u8f93\u5165\u4e0a\u4e0b\u6587\uff0c\u5bfc\u81f4\u7ed3\u679c\u4e0d\u53ef\u9760\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u63d0\u9ad8 LLM \u5728 RTL \u4fee\u590d\u4e2d\u53ef\u9760\u6027\u7684\u65b9\u6cd5\u3002", "method": "R3A \u63d0\u51fa\u4e86\u4e00\u79cd\u968f\u673a\u601d\u60f3\u6811\uff08Stochastic Tree-Of-Thoughts\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u63a7\u5236\u8865\u4e01\u751f\u6210\u667a\u80fd\u4f53\uff0c\u4ee5\u63a2\u7d22\u7ecf\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u7b97\u6cd5\u6839\u636e\u542f\u53d1\u5f0f\u51fd\u6570\u5bf9\u641c\u7d22\u72b6\u6001\u8fdb\u884c\u91c7\u6837\uff0c\u4ee5\u5e73\u8861\u63a2\u7d22\u4e0e\u5229\u7528\uff0c\u4ece\u800c\u83b7\u5f97\u53ef\u9760\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0cR3A \u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u4ee5\u627e\u5230\u6545\u969c\u5019\u9009\u70b9\u4f5c\u4e3a\u8865\u4e01\u751f\u6210\u667a\u80fd\u4f53\u7684\u8d77\u70b9\uff0c\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u53ef\u9760\u6027\u3002", "result": "R3A \u53ef\u4ee5\u5728\u7ed9\u5b9a\u7684\u65f6\u95f4\u9650\u5236\u5185\u4fee\u590d RTL-repair \u6570\u636e\u96c6\u4e2d 90.6% \u7684\u9519\u8bef\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u548c\u5176\u4ed6\u57fa\u4e8e LLM \u7684\u65b9\u6cd5\u591a\u8986\u76d6 45% \u7684\u9519\u8bef\uff0c\u540c\u65f6\u5e73\u5747\u5b9e\u73b0 86.7% \u7684 pass@5 \u6210\u529f\u7387\uff0c\u663e\u793a\u51fa\u9ad8\u53ef\u9760\u6027\u3002", "conclusion": "R3A \u901a\u8fc7\u63d0\u51fa\u968f\u673a\u601d\u60f3\u6811\uff08Stochastic Tree-Of-Thoughts\uff09\u65b9\u6cd5\u548c\u591a\u667a\u80fd\u4f53\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u57fa\u4e8e LLM \u7684 RTL \u9519\u8bef\u81ea\u52a8\u4fee\u590d\u7684\u53ef\u9760\u6027\u548c\u4fee\u590d\u7387\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cR3A \u5728 RTL-repair \u6570\u636e\u96c6\u4e0a\u7684\u4fee\u590d\u7387\uff0890.6%\uff09\u548c pass@5 \u6210\u529f\u7387\uff0886.7%\uff09\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u5176\u4ed6\u57fa\u4e8e LLM \u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.19764", "categories": ["cs.PL", "cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19764", "abs": "https://arxiv.org/abs/2511.19764", "authors": ["Ayaka Yorihiro", "Griffin Berlstein", "Pedro Pontes Garc\u00eda", "Kevin Laeufer", "Adrian Sampson"], "title": "Understanding Accelerator Compilers via Performance Profiling", "comment": null, "summary": "Accelerator design languages (ADLs), high-level languages that compile to hardware units, help domain experts quickly design efficient application-specific hardware. ADL compilers optimize datapaths and convert software-like control flow constructs into control paths. Such compilers are necessarily complex and often unpredictable: they must bridge the wide semantic gap between high-level semantics and cycle-level schedules, and they typically rely on advanced heuristics to optimize circuits. The resulting performance can be difficult to control, requiring guesswork to find and resolve performance problems in the generated hardware. We conjecture that ADL compilers will never be perfect: some performance unpredictability is endemic to the problem they solve.\n  In lieu of compiler perfection, we argue for compiler understanding tools that give ADL programmers insight into how the compiler's decisions affect performance. We introduce Petal, a cycle-level Petal for the Calyx intermediate language (IL). Petal instruments the Calyx code with probes and then analyzes the trace from a register-transfer-level simulation. It maps the events in the trace back to high-level control constructs in the Calyx code to track the clock cycles when each construct was active. Using case studies, we demonstrate that Petal's cycle-level profiles can identify performance problems in existing accelerator designs. We show that these insights can also guide developers toward optimizations that the compiler was unable to perform automatically, including a reduction by 46.9\\% of total cycles for one application.", "AI": {"tldr": "\u662f\u7684\uff0c\u8fd9\u7bc7\u8bba\u6587\u4e0e DSL (\u52a0\u901f\u5668\u8bbe\u8ba1\u8bed\u8a00 ADL)\u3001\u7f16\u8bd1\u5668\u3001HLS (\u901a\u8fc7 ADL \u7f16\u8bd1\u5230\u786c\u4ef6)\u3001\u548c\u56fe\u5904\u7406\uff08\u672a\u76f4\u63a5\u63d0\u53ca\uff0c\u4f46\u52a0\u901f\u5668\u8bbe\u8ba1\u901a\u5e38\u6d89\u53ca\u6570\u636e\u6d41\u56fe\u6216\u63a7\u5236\u6d41\u56fe\uff0c\u867d\u7136\u91cd\u70b9\u5728\u63a7\u5236\u6d41\u5206\u6790\uff09\u76f8\u5173\u3002\u52a0\u901f\u5668\u8bbe\u8ba1\u8bed\u8a00\uff08ADL\uff09\u7f16\u8bd1\u5668\u7531\u4e8e\u590d\u6742\u7684\u8c03\u5ea6\u548c\u4f18\u5316\uff0c\u5b58\u5728\u56fa\u6709\u7684\u6027\u80fd\u4e0d\u53ef\u9884\u6d4b\u6027\u3002\u672c\u6587\u4ecb\u7ecd\u4e86 Petal\uff0c\u4e00\u4e2a\u9488\u5bf9 Calyx \u4e2d\u95f4\u8bed\u8a00\u7684\u5468\u671f\u7ea7\u6027\u80fd\u5206\u6790\u5de5\u5177\uff0c\u5b83\u901a\u8fc7\u690d\u5165\u63a2\u9488\u3001\u5206\u6790 RTL \u4eff\u771f\u8f68\u8ff9\u5e76\u5c06\u5176\u6620\u5c04\u56de\u9ad8\u7ea7\u63a7\u5236\u7ed3\u6784\uff0c\u5e2e\u52a9 ADL \u7a0b\u5e8f\u5458\u7406\u89e3\u7f16\u8bd1\u5668\u51b3\u7b56\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002Petal \u80fd\u591f\u8bc6\u522b\u6027\u80fd\u74f6\u9888\u5e76\u6307\u5bfc\u624b\u52a8\u4f18\u5316\uff0c\u5728\u4e00\u4e2a\u6848\u4f8b\u4e2d\u5b9e\u73b0\u4e86 46.9% \u7684\u603b\u5468\u671f\u6570\u51cf\u5c11\u3002", "motivation": "\u52a0\u901f\u5668\u8bbe\u8ba1\u8bed\u8a00\uff08ADL\uff09\u7f16\u8bd1\u5668\u867d\u7136\u6709\u52a9\u4e8e\u5feb\u901f\u8bbe\u8ba1\u9ad8\u6548\u7684\u4e13\u7528\u786c\u4ef6\uff0c\u4f46\u5b83\u4eec\u5728\u9ad8\u7ea7\u8bed\u4e49\u548c\u5468\u671f\u7ea7\u8c03\u5ea6\u4e4b\u95f4\u5b58\u5728\u5de8\u5927\u7684\u8bed\u4e49\u9e3f\u6c9f\uff0c\u5e76\u4e14\u901a\u5e38\u4f9d\u8d56\u590d\u6742\u7684\u542f\u53d1\u5f0f\u7b97\u6cd5\u8fdb\u884c\u7535\u8def\u4f18\u5316\uff0c\u5bfc\u81f4\u6027\u80fd\u96be\u4ee5\u63a7\u5236\u548c\u9884\u6d4b\u3002\u5f00\u53d1\u4eba\u5458\u9700\u8981\u8fdb\u884c\u731c\u6d4b\u624d\u80fd\u627e\u5230\u5e76\u89e3\u51b3\u751f\u6210\u786c\u4ef6\u4e2d\u7684\u6027\u80fd\u95ee\u9898\u3002\u672c\u6587\u8ba4\u4e3a ADL \u7f16\u8bd1\u5668\u6c38\u8fdc\u65e0\u6cd5\u5b8c\u7f8e\uff0c\u4e00\u4e9b\u6027\u80fd\u4e0d\u53ef\u9884\u6d4b\u6027\u662f\u56fa\u6709\u7684\u3002\u56e0\u6b64\uff0c\u5f00\u53d1\u4eba\u5458\u9700\u8981\u5de5\u5177\u6765\u7406\u89e3\u7f16\u8bd1\u5668\u51b3\u7b56\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "Petal \u7684\u65b9\u6cd5\u5982\u4e0b\uff1a1. \u5b83\u9488\u5bf9 Calyx \u4e2d\u95f4\u8bed\u8a00\uff08IL\uff09\u8bbe\u8ba1\u30022. \u5b83\u901a\u8fc7\u5728 Calyx \u4ee3\u7801\u4e2d\u690d\u5165\u63a2\u9488\uff08probes\uff09\u6765\u5bf9\u4ee3\u7801\u8fdb\u884c\u68c0\u6d4b\uff08instruments\uff09\u30023. \u5b83\u5206\u6790\u5bc4\u5b58\u5668\u4f20\u8f93\u7ea7\uff08RTL\uff09\u4eff\u771f\u4ea7\u751f\u7684\u8f68\u8ff9\uff08trace\uff09\u30024. \u5b83\u5c06\u8f68\u8ff9\u4e2d\u7684\u4e8b\u4ef6\u6620\u5c04\u56de Calyx \u4ee3\u7801\u4e2d\u7684\u9ad8\u7ea7\u63a7\u5236\u7ed3\u6784\uff0c\u4ee5\u8ddf\u8e2a\u6bcf\u4e2a\u6784\u9020\u6d3b\u8dc3\u7684\u5468\u671f\u6570\uff0c\u4ece\u800c\u751f\u6210\u5468\u671f\u7ea7\u6027\u80fd\u5206\u6790\uff08cycle-level profiles\uff09\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86 Petal\uff0c\u4e00\u4e2a\u9488\u5bf9 Calyx \u4e2d\u95f4\u8bed\u8a00\uff08IL\uff09\u7684\u5468\u671f\u7ea7\u6027\u80fd\u5206\u6790\u5de5\u5177\uff08cycle-level profiler\uff09\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86 Petal \u7684\u5468\u671f\u7ea7\u6027\u80fd\u5206\u6790\u80fd\u591f\u8bc6\u522b\u73b0\u6709\u52a0\u901f\u5668\u8bbe\u8ba1\u4e2d\u7684\u6027\u80fd\u74f6\u9888\uff08performance problems\uff09\u3002\u8fd9\u4e9b\u6d1e\u5bdf\u53ef\u4ee5\u6307\u5bfc\u5f00\u53d1\u4eba\u5458\u8fdb\u884c\u7f16\u8bd1\u5668\u65e0\u6cd5\u81ea\u52a8\u6267\u884c\u7684\u4f18\u5316\uff0c\u4f8b\u5982\u5728\u4e00\u4e2a\u5e94\u7528\u4e2d\u5c06\u603b\u5468\u671f\u6570\u51cf\u5c11\u4e86 46.9%\u3002", "conclusion": "\u672c\u6587\u8ba4\u4e3a\uff0cADL \u7f16\u8bd1\u5668\u5b58\u5728\u56fa\u6709\u7684\u6027\u80fd\u4e0d\u53ef\u9884\u6d4b\u6027\u3002\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\uff0c\u672c\u6587\u63d0\u51fa\u4e86 Petal \u5de5\u5177\uff0c\u8be5\u5de5\u5177\u901a\u8fc7\u8ddf\u8e2a RTL \u4eff\u771f\u5e76\u6620\u5c04\u56de Calyx \u7a0b\u5e8f\u7684\u63a7\u5236\u7ed3\u6784\uff0c\u4e3a ADL \u7a0b\u5e8f\u5458\u63d0\u4f9b\u5bf9\u7f16\u8bd1\u5668\u51b3\u7b56\u5982\u4f55\u5f71\u54cd\u6027\u80fd\u7684\u6df1\u5165\u7406\u89e3\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff0cPetal \u80fd\u591f\u8bc6\u522b\u73b0\u6709\u52a0\u901f\u5668\u8bbe\u8ba1\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u5e76\u6307\u5bfc\u5f00\u53d1\u4eba\u5458\u8fdb\u884c\u4f18\u5316\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u6027\u80fd\uff0c\u4f8b\u5982\u5728\u4e00\u4e2a\u5e94\u7528\u4e2d\u5c06\u603b\u5468\u671f\u6570\u51cf\u5c11\u4e86 46.9%\u3002"}}
{"id": "2511.19460", "categories": ["cs.DC", "cs.AI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19460", "abs": "https://arxiv.org/abs/2511.19460", "authors": ["Sofiane Ben Amor", "Guillaume Guerard", "Loup-No\u00e9 Levy"], "title": "Systemic approach for modeling a generic smart grid", "comment": null, "summary": "Smart grid technological advances present a recent class of complex interdisciplinary modeling and increasingly difficult simulation problems to solve using traditional computational methods. To simulate a smart grid requires a systemic approach to integrated modeling of power systems, energy markets, demand-side management, and much other resources and assets that are becoming part of the current paradigm of the power grid. This paper presents a backbone model of a smart grid to test alternative scenarios for the grid. This tool simulates disparate systems to validate assumptions before the human scale model. Thanks to a distributed optimization of subsystems, the production and consumption scheduling is achieved while maintaining flexibility and scalability.", "AI": {"tldr": "\u5426\u3002\u8bba\u6587\u5185\u5bb9\u6d89\u53ca\u667a\u80fd\u7535\u7f51\u5efa\u6a21\u4e0e\u4eff\u771f\u548c\u5206\u5e03\u5f0f\u4f18\u5316\u3002\u8fd9\u662f\u4e00\u4e2a\u5173\u4e8e\u667a\u80fd\u7535\u7f51\u5efa\u6a21\u4e0e\u4eff\u771f\u3001\u5206\u5e03\u5f0f\u4f18\u5316\u7684\u7814\u7a76\u3002\u667a\u80fd\u7535\u7f51\u7684\u6280\u672f\u8fdb\u6b65\u5e26\u6765\u4e86\u590d\u6742\u7684\u8de8\u5b66\u79d1\u5efa\u6a21\u548c\u4eff\u771f\u96be\u9898\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u667a\u80fd\u7535\u7f51\u7684\u4e3b\u5e72\u6a21\u578b\uff0c\u901a\u8fc7\u96c6\u6210\u5efa\u6a21\u7535\u529b\u7cfb\u7edf\u3001\u80fd\u6e90\u5e02\u573a\u3001\u9700\u6c42\u4fa7\u7ba1\u7406\u7b49\u4e0d\u540c\u7cfb\u7edf\uff0c\u5e76\u5229\u7528\u5b50\u7cfb\u7edf\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u6765\u5b9e\u73b0\u751f\u4ea7\u548c\u6d88\u8d39\u8c03\u5ea6\uff0c\u4ece\u800c\u5728\u4fdd\u6301\u7075\u6d3b\u6027\u548c\u53ef\u4f38\u7f29\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u7535\u7f51\u66ff\u4ee3\u573a\u666f\u7684\u6d4b\u8bd5\u548c\u5047\u8bbe\u9a8c\u8bc1\u3002", "motivation": "\u667a\u80fd\u7535\u7f51\u7684\u6280\u672f\u8fdb\u6b65\u5e26\u6765\u4e86\u590d\u6742\u7684\u8de8\u5b66\u79d1\u5efa\u6a21\u548c\u65e5\u76ca\u56f0\u96be\u7684\u4eff\u771f\u95ee\u9898\uff0c\u4f20\u7edf\u7684\u8ba1\u7b97\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u3002\u4e3a\u4e86\u6a21\u62df\u667a\u80fd\u7535\u7f51\uff0c\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u6027\u7684\u65b9\u6cd5\u6765\u96c6\u6210\u5efa\u6a21\u7535\u529b\u7cfb\u7edf\u3001\u80fd\u6e90\u5e02\u573a\u3001\u9700\u6c42\u4fa7\u7ba1\u7406\u4ee5\u53ca\u5176\u4ed6\u8d44\u6e90\u548c\u8d44\u4ea7\u3002\u5176\u52a8\u673a\u6b63\u662f\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u667a\u80fd\u7535\u7f51\u7684\u4e3b\u5e72\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u5bf9\u7535\u529b\u7cfb\u7edf\u3001\u80fd\u6e90\u5e02\u573a\u3001\u9700\u6c42\u4fa7\u7ba1\u7406\u7b49\u4e0d\u540c\u7cfb\u7edf\u8fdb\u884c\u96c6\u6210\u5efa\u6a21\u548c\u4eff\u771f\u3002\u5176\u6838\u5fc3\u65b9\u6cd5\u662f\u901a\u8fc7\u5bf9\u5b50\u7cfb\u7edf\u8fdb\u884c\u5206\u5e03\u5f0f\u4f18\u5316\uff0c\u4ee5\u5b9e\u73b0\u751f\u4ea7\u548c\u6d88\u8d39\u8c03\u5ea6\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u667a\u80fd\u7535\u7f51\u4e3b\u5e72\u6a21\u578b\u80fd\u591f\u4eff\u771f\u4e0d\u540c\u7684\u7cfb\u7edf\uff0c\u7528\u4ee5\u5728\u5f15\u5165\u5927\u89c4\u6a21\u5b9e\u7269\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u4e4b\u524d\u9a8c\u8bc1\u5047\u8bbe\u3002\u901a\u8fc7\u5bf9\u5b50\u7cfb\u7edf\u8fdb\u884c\u5206\u5e03\u5f0f\u4f18\u5316\uff0c\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u751f\u4ea7\u548c\u6d88\u8d39\u8c03\u5ea6\uff0c\u5e76\u4fdd\u6301\u4e86\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u53ef\u4f38\u7f29\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u667a\u80fd\u7535\u7f51\u4e3b\u5e72\u6a21\u578b\uff0c\u7528\u4ee5\u6d4b\u8bd5\u7535\u7f51\u7684\u66ff\u4ee3\u573a\u666f\u3002\u8be5\u6a21\u578b\u901a\u8fc7\u5206\u5e03\u5f0f\u4f18\u5316\u5b50\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u751f\u4ea7\u548c\u6d88\u8d39\u8c03\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7075\u6d3b\u6027\u548c\u53ef\u4f38\u7f29\u6027\u3002\u8fd9\u4e00\u5de5\u5177\u80fd\u591f\u5e2e\u52a9\u5728\u5f15\u5165\u5b9e\u7269\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u4e4b\u524d\u9a8c\u8bc1\u5047\u8bbe\u3002"}}
{"id": "2511.20376", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.20376", "abs": "https://arxiv.org/abs/2511.20376", "authors": ["Andreas G\u00f6bel", "Janosch Ruff", "Leon Schiller"], "title": "Robust Algorithms for Finding Cliques in Random Intersection Graphs via Sum-of-Squares", "comment": null, "summary": "We study efficient algorithms for recovering cliques in dense random intersection graphs (RIGs). In this model, $d = n^{\u03a9(1)}$ cliques of size approximately $k$ are randomly planted by choosing the vertices to participate in each clique independently with probability $\u03b4$. While there has been extensive work on recovering one, or multiple disjointly planted cliques in random graphs, the natural extension of this question to recovering overlapping cliques has been, surprisingly, largely unexplored. Moreover, because every vertex can be part of polynomially many cliques, this task is significantly harder than in case of disjointly planted cliques (as recently studied by Kothari, Vempala, Wein and Xu [COLT'23]) and manifests in the failure of simple combinatorial and even spectral algorithms.\n  In this work we obtain the first efficient algorithms for recovering the community structure of RIGs both from the perspective of exact and approximate recovery. Our algorithms are further robust to noise, monotone adversaries, a certain, optimal number of edge corruptions, and work whenever $k \\gg \\sqrt{n \\log(n)}$. Our techniques follow the proofs-to-algorithms framework utilizing the sum-of-squares hierarchy.", "AI": {"tldr": "\u90e8\u5206\u76f8\u5173\uff08Graph Processing\uff09\uff1a\u672c\u6587\u7814\u7a76\u7684\u662f\u7a20\u5bc6\u968f\u673a\u4ea4\u96c6\u56fe\uff08RIGs\uff09\u4e0a\u7684\u56e2\u6062\u590d\u7b97\u6cd5\uff0c\u8fd9\u5c5e\u4e8e\u56fe\u5904\u7406\u548c\u793e\u533a\u53d1\u73b0\u7684\u8303\u7574\u3002\n\n\u592a\u957f\u4e0d\u770b\uff08TLDR\uff09\uff1a\u672c\u6587\u9488\u5bf9\u4e00\u4e2a\u62d3\u6251\u7ed3\u6784\u66f4\u590d\u6742\u3001\u73b0\u6709\u7b80\u5355\u65b9\u6cd5\u5931\u6548\u7684\u9886\u57df\u2014\u2014\u7a20\u5bc6\u968f\u673a\u4ea4\u96c6\u56fe\uff08RIGs\uff09\u4e2d\u91cd\u53e0\u56e2\u7684\u6062\u590d\u95ee\u9898\uff0c\u9996\u6b21\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u80fd\u591f\u8fdb\u884c\u7cbe\u786e\u548c\u8fd1\u4f3c\u6062\u590d\uff0c\u5bf9\u5404\u79cd\u566a\u58f0\u548c\u635f\u574f\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5e76\u5728\u56e2\u5927\u5c0f $k \\gg \\sqrt{n \\log(n)}$ \u65f6\u6709\u6548\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u57fa\u4e8e\u5e73\u65b9\u548c\uff08SoS\uff09\u5c42\u6b21\u7684\u201c\u8bc1\u660e\u5230\u7b97\u6cd5\u201d\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u6062\u590d\u968f\u673a\u56fe\u4e2d\u7684\u5355\u4e2a\u6216\u591a\u4e2a\u4e0d\u76f8\u4ea4\u7684\u690d\u5165\u56e2\uff0c\u800c\u6062\u590d\u91cd\u53e0\u690d\u5165\u56e2\u8fd9\u4e00\u81ea\u7136\u6269\u5c55\u95ee\u9898\u5374\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u63a2\u7d22\u3002\u5728\u7a20\u5bc6\u968f\u673a\u4ea4\u96c6\u56fe\uff08RIGs\uff09\u6a21\u578b\u4e2d\uff0c\u6bcf\u4e2a\u9876\u70b9\u53ef\u4ee5\u5c5e\u4e8e\u591a\u9879\u5f0f\u6570\u91cf\u7684\u56e2\uff0c\u8fd9\u4f7f\u5f97\u4efb\u52a1\u6bd4\u4e0d\u76f8\u4ea4\u56e2\u6062\u590d\u56f0\u96be\u5f97\u591a\uff0c\u5e76\u5bfc\u81f4\u7b80\u5355\u7684\u7ec4\u5408\u548c\u8c31\u7b97\u6cd5\u5931\u6548\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u4e3a\u7a20\u5bc6\u968f\u673a\u4ea4\u96c6\u56fe\u4e2d\u7684\u91cd\u53e0\u56e2\u6062\u590d\u8bbe\u8ba1\u9996\u6279\u9ad8\u6548\u7b97\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u7a20\u5bc6\u968f\u673a\u4ea4\u96c6\u56fe\uff08RIGs\uff09\u4e2d\u91cd\u53e0\u56e2\u6062\u590d\u95ee\u9898\u7684\u9996\u6279\u9ad8\u6548\u7b97\u6cd5\u3002\u8fd9\u4e9b\u7b97\u6cd5\u5229\u7528\u4e86\u5e73\u65b9\u548c\uff08Sum-of-Squares, SoS\uff09\u5c42\u6b21\u7684\u201c\u8bc1\u660e\u5230\u7b97\u6cd5\u201d\uff08proofs-to-algorithms\uff09\u6846\u67b6\u6765\u89e3\u51b3\u56e2\u6062\u590d\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7cbe\u786e\u6062\u590d\u548c\u8fd1\u4f3c\u6062\u590d\u3002\u7b97\u6cd5\u8bbe\u8ba1\u540c\u65f6\u8003\u8651\u4e86\u5bf9\u566a\u58f0\u3001\u5355\u8c03\u5bf9\u6297\u8005\u4ee5\u53ca\u4e00\u5b9a\u6570\u91cf\u7684\u8fb9\u635f\u574f\u7684\u9c81\u68d2\u6027\u3002", "result": "\u672c\u6587\u83b7\u5f97\u4e86\u9996\u6279\u9488\u5bf9\u7a20\u5bc6\u968f\u673a\u4ea4\u96c6\u56fe\uff08RIGs\uff09\u793e\u533a\u7ed3\u6784\u6062\u590d\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u56ca\u62ec\u4e86\u7cbe\u786e\u6062\u590d\u548c\u8fd1\u4f3c\u6062\u590d\u3002\u8fd9\u4e9b\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u5bf9\u566a\u58f0\u3001\u5355\u8c03\u5bf9\u6297\u8005\u4ee5\u53ca\u4e00\u5b9a\u6570\u91cf\u7684\u8fb9\u635f\u574f\u5177\u6709\u9c81\u68d2\u6027\u3002\u7b97\u6cd5\u5728\u56e2\u5927\u5c0f $k \\gg \\sqrt{n \\log(n)}$ \u7684\u6761\u4ef6\u4e0b\u6709\u6548\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u9488\u5bf9\u7a20\u5bc6\u968f\u673a\u4ea4\u96c6\u56fe\uff08RIGs\uff09\u4e2d\u91cd\u53e0\u56e2\u6062\u590d\u7684\u9ad8\u6548\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u88ab\u8bc1\u660e\u5728\u7cbe\u786e\u548c\u8fd1\u4f3c\u6062\u590d\u65b9\u9762\u5747\u6709\u6548\uff0c\u4e14\u5bf9\u566a\u58f0\u3001\u5bf9\u6297\u3001\u8fb9\u635f\u574f\u7b49\u5177\u6709\u9c81\u68d2\u6027\u3002\u672c\u6587\u7684\u65b9\u6cd5\u57fa\u4e8e\u5229\u7528\u5e73\u65b9\u548c\uff08Sum-of-Squares, SoS\uff09\u5c42\u6b21\u7684\u201c\u8bc1\u660e\u5230\u7b97\u6cd5\u201d\u6846\u67b6\uff0c\u6709\u671b\u63a8\u5e7f\u5230\u5176\u4ed6\u91cd\u53e0\u793e\u533a\u690d\u5165\u6a21\u578b\uff0c\u8fdb\u4e00\u6b65\u63a8\u52a8\u5bf9\u91cd\u53e0\u3001\u975e\u9ad8\u65af\u793e\u533a\u53d1\u73b0\u95ee\u9898\u7684\u7814\u7a76\u3002"}}
{"id": "2511.20369", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2511.20369", "abs": "https://arxiv.org/abs/2511.20369", "authors": ["Frank Sch\u00fcssele", "Matthias Zumkeller", "Miriam Lagunes-Rochin", "Dominik Klumpp"], "title": "The Ghosts of Empires: Extracting Modularity from Interleaving-Based Proofs (Extended Version)", "comment": "39 pages, 10 figures, 1 table. Extended version with proofs of the paper published at POPL'2026 (https://doi.org/10.1145/3776684)", "summary": "Implementation bugs threaten the soundness of algorithmic software verifiers. Generating correctness certificates for correct programs allows for efficient independent validation of verification results, and thus helps to reveal such bugs. Automatic generation of small, compact correctness proofs for concurrent programs is challenging, as the correctness arguments may depend on the particular interleaving, which can lead to exponential explosion. We present an approach that converts an interleaving-based correctness proof, as generated by many algorithmic verifiers, into a thread-modular correctness proof in the style of Owicki and Gries. We automatically synthesize ghost variables that capture the relevant interleaving information, and abstract away irrelevant details. Our evaluation shows that the approach is efficient in practice and generates compact proofs, compared to a baseline.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e DSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216 HLS **\u5747\u4e0d\u76f8\u5173**\u3002\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5e76\u53d1\u7a0b\u5e8f\u9a8c\u8bc1\u5668\u751f\u6210\u7684\u57fa\u4e8e\u4ea4\u9519\u7684\u6b63\u786e\u6027\u8bc1\u660e\u8f6c\u6362\u4e3a Owicki-Gries \u98ce\u683c\u7684\u7ebf\u7a0b\u6a21\u5757\u5316\u8bc1\u660e\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u81ea\u52a8\u5408\u6210\u5e7d\u7075\u53d8\u91cf\u6765\u6355\u83b7\u5173\u952e\u7684\u4ea4\u9519\u4fe1\u606f\u5e76\u62bd\u8c61\u4e0d\u76f8\u5173\u7ec6\u8282\uff0c\u8be5\u65b9\u6cd5\u65e8\u5728\u751f\u6210\u7d27\u51d1\u7684\u6b63\u786e\u6027\u8bc1\u4e66\uff0c\u4ee5\u4fbf\u72ec\u7acb\u9ad8\u6548\u5730\u9a8c\u8bc1\u9a8c\u8bc1\u5668\u7684\u7ed3\u679c\uff0c\u4ece\u800c\u5e2e\u52a9\u63ed\u793a\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u4e2d\u7684\u5b9e\u73b0\u9519\u8bef\u3002\u8bc4\u4f30\u663e\u793a\u8be5\u65b9\u6cd5\u9ad8\u6548\u4e14\u80fd\u751f\u6210\u7d27\u51d1\u7684\u8bc1\u660e\u3002", "motivation": "\u73b0\u6709\u7684\u7b97\u6cd5\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u53ef\u80fd\u5b58\u5728\u5b9e\u73b0\u9519\u8bef\uff0c\u5a01\u80c1\u5176\u6b63\u786e\u6027\uff08soundness\uff09\u3002\u751f\u6210\u6b63\u786e\u7a0b\u5e8f\uff08correct programs\uff09\u7684\u6b63\u786e\u6027\u8bc1\u4e66\uff08correctness certificates\uff09\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u9a8c\u8bc1\u7ed3\u679c\u7684\u72ec\u7acb\u9ad8\u6548\u9a8c\u8bc1\uff0c\u8fd9\u6709\u52a9\u4e8e\u53d1\u73b0\u9a8c\u8bc1\u5668\u4e2d\u7684\u9519\u8bef\u3002\u7136\u800c\uff0c\u81ea\u52a8\u4e3a\u5e76\u53d1\u7a0b\u5e8f\u751f\u6210\u5c0f\u5de7\u4e14\u7d27\u51d1\u7684\u6b63\u786e\u6027\u8bc1\u660e\u662f\u4e00\u9879\u6311\u6218\uff0c\u56e0\u4e3a\u6b63\u786e\u6027\u8bba\u8bc1\u53ef\u80fd\u4f9d\u8d56\u4e8e\u7279\u5b9a\u7684\u7ebf\u7a0b\u4ea4\u9519\uff08interleaving\uff09\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u6307\u6570\u7ea7\u7206\u70b8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u57fa\u4e8e\u4ea4\u9519\u7684\u6b63\u786e\u6027\u8bc1\u660e\u8f6c\u6362\u4e3a Owicki-Gries \u98ce\u683c\u7ebf\u7a0b\u6a21\u5757\u5316\u6b63\u786e\u6027\u8bc1\u660e\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u6d89\u53ca\u81ea\u52a8\u5408\u6210\u5e7d\u7075\u53d8\u91cf\uff08ghost variables\uff09\u6765\u6355\u83b7\u76f8\u5173\u7684\u4ea4\u9519\u4fe1\u606f\uff0c\u5e76\u62bd\u8c61\u5316\u4e0d\u76f8\u5173\u7684\u7ec6\u8282\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u8df5\u4e2d\u662f\u9ad8\u6548\u7684\uff0c\u5e76\u4e14\u80fd\u591f\u751f\u6210\u7d27\u51d1\u7684\u8bc1\u660e\u3002", "conclusion": "\u672c\u65b9\u6cd5\u5c06\u57fa\u4e8e\u4ea4\u9519\u7684\u6b63\u786e\u6027\u8bc1\u660e\u8f6c\u6362\u4e3a Owicki-Gries \u98ce\u683c\u7684\u7ebf\u7a0b\u6a21\u5757\u5316\u8bc1\u660e\uff0c\u8bc1\u660e\u4e2d\u5305\u542b\u4e86\u81ea\u52a8\u5408\u6210\u7684\u5e7d\u7075\u53d8\u91cf\uff0c\u8fd9\u4e9b\u53d8\u91cf\u6355\u83b7\u4e86\u76f8\u5173\u7684\u4ea4\u9519\u4fe1\u606f\u5e76\u62bd\u8c61\u4e86\u4e0d\u76f8\u5173\u7684\u7ec6\u8282\u3002\u8fd9\u4e00\u8f6c\u6362\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u751f\u6210\u7d27\u51d1\u7684\u6b63\u786e\u6027\u8bc1\u4e66\uff0c\u7528\u4e8e\u72ec\u7acb\u9a8c\u8bc1\u5e76\u53d1\u7a0b\u5e8f\u8f6f\u4ef6\u9a8c\u8bc1\u5668\u7684\u7ed3\u679c\uff0c\u4ece\u800c\u63d0\u9ad8\u9a8c\u8bc1\u5668\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.19463", "categories": ["cs.DC", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2511.19463", "abs": "https://arxiv.org/abs/2511.19463", "authors": ["Aldo Canfora", "Eleonora Bergamaschi", "Riccardo Mioli", "Federico Battini", "Mirko Degli Esposti", "Giorgio Pedrazzi", "Chiara Dellacasa"], "title": "Urban Buildings Energy Consumption Estimation Using HPC: A Case Study of Bologna", "comment": "Preprint submitted for publication", "summary": "Urban Building Energy Modeling (UBEM) plays a central role in understanding and forecasting energy consumption at the city scale. In this work, we present a UBEM pipeline that integrates EnergyPlus simulations, high-performance computing (HPC), and open geospatial datasets to estimate the energy demand of buildings in Bologna, Italy. Geometric information including building footprints and heights was obtained from the Bologna Open Data portal and enhanced with aerial LiDAR measurements. Non-geometric attributes such as construction materials, insulation characteristics, and window performance were derived from regional building regulations and the European TABULA database. The computation was carried out on Leonardo, the Cineca-hosted supercomputer, enabling the simulation of approximately 25,000 buildings in under 30 minutes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u4e0d\u76f8\u5173\u3002\n\nTLDR: \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57ce\u5e02\u5efa\u7b51\u80fd\u8017\u5efa\u6a21\uff08UBEM\uff09\u6d41\u7a0b\uff0c\u8be5\u6d41\u7a0b\u6574\u5408\u4e86EnergyPlus\u80fd\u8017\u6a21\u62df\u5de5\u5177\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff0c\u4f7f\u7528Cineca\u7684Leonardo\u8d85\u7ea7\u8ba1\u7b97\u673a\uff09\u548c\u5f00\u653e\u5730\u7406\u7a7a\u95f4\u6570\u636e\u96c6\u3002\u7814\u7a76\u5229\u7528Bologna\u7684\u5f00\u653e\u6570\u636e\u548cLiDAR\u83b7\u53d6\u5efa\u7b51\u51e0\u4f55\u6570\u636e\uff0c\u5e76\u4ece\u533a\u57df\u6cd5\u89c4\u548cTABULA\u6570\u636e\u5e93\u83b7\u53d6\u975e\u51e0\u4f55\u5c5e\u6027\u3002\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u6210\u529f\u5728\u4e0d\u523030\u5206\u949f\u5185\u5b8c\u6210\u4e86\u5bf9Bologna\u5e02\u7ea625,000\u680b\u5efa\u7b51\u7684\u80fd\u8017\u4f30\u7b97\u3002", "motivation": "\u57ce\u5e02\u5efa\u7b51\u80fd\u8017\u5efa\u6a21\uff08UBEM\uff09\u5bf9\u4e8e\u7406\u89e3\u548c\u9884\u6d4b\u57ce\u5e02\u5c3a\u5ea6\u7684\u80fd\u8017\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u5efa\u7acb\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u9760\u7684UBEM\u6d41\u7a0b\uff0c\u80fd\u591f\u6574\u5408\u73b0\u6709\u7684\u5f00\u653e\u5730\u7406\u7a7a\u95f4\u6570\u636e\u3001\u9ad8\u6027\u80fd\u8ba1\u7b97\u8d44\u6e90\u548c\u4e13\u4e1a\u7684\u80fd\u8017\u6a21\u62df\u5de5\u5177\uff08EnergyPlus\uff09\uff0c\u4ee5\u5feb\u901f\u4f30\u7b97\u50cfBologna\u8fd9\u6837\u6574\u4e2a\u57ce\u5e02\u7684\u5efa\u7b51\u80fd\u8017\u3002", "method": "\u7814\u7a76\u56e2\u961f\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684UBEM\u6d41\u7a0b\uff1a\u9996\u5148\uff0c\u6574\u5408\u6765\u81eaBologna\u5f00\u653e\u6570\u636e\u95e8\u6237\u7684\u5efa\u7b51\u8db3\u8ff9\u548c\u9ad8\u5ea6\u7b49\u51e0\u4f55\u4fe1\u606f\uff0c\u5e76\u5229\u7528LiDAR\u6d4b\u91cf\u6570\u636e\u8fdb\u884c\u589e\u5f3a\u3002\u5176\u6b21\uff0c\u4ece\u533a\u57df\u5efa\u7b51\u6cd5\u89c4\u548c\u6b27\u6d32TABULA\u6570\u636e\u5e93\u83b7\u53d6\u5efa\u7b51\u6750\u6599\u3001\u9694\u70ed\u7279\u6027\u548c\u7a97\u6237\u6027\u80fd\u7b49\u975e\u51e0\u4f55\u5c5e\u6027\u3002\u6700\u540e\uff0c\u5229\u7528Cineca\u7684Leonardo\u8d85\u7ea7\u8ba1\u7b97\u673a\u6267\u884cEnergyPlus\u6a21\u62df\uff0c\u4ee5\u5b9e\u73b0\u5927\u89c4\u6a21\u3001\u9ad8\u6548\u7387\u7684\u80fd\u8017\u4f30\u7b97\u3002", "result": "\u7814\u7a76\u56e2\u961f\u6210\u529f\u5730\u5229\u7528Leonardo\u8d85\u7ea7\u8ba1\u7b97\u673a\uff0c\u5728\u4e0d\u523030\u5206\u949f\u5185\u5b8c\u6210\u4e86\u5bf9Bologna\u5e02\u7ea625,000\u680b\u5efa\u7b51\u7684\u80fd\u8017\u6a21\u62df\u3002\u8fd9\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684UBEM\u6d41\u7a0b\u5728\u5904\u7406\u5927\u89c4\u6a21\u57ce\u5e02\u6570\u636e\u548c\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5c55\u793a\u4e86\u4e00\u4e2a\u6574\u5408EnergyPlus\u3001HPC\uff08\u8d85\u7ea7\u8ba1\u7b97\u673a\uff09\u548c\u5f00\u653e\u5730\u7406\u7a7a\u95f4\u6570\u636e\u96c6\u7684\u57ce\u5e02\u5efa\u7b51\u80fd\u8017\u5efa\u6a21\uff08UBEM\uff09\u6d41\u7a0b\uff0c\u5e76\u5728Bologna\u5e02\u5f97\u5230\u4e86\u5feb\u901f\u4e14\u5927\u89c4\u6a21\u7684\u5e94\u7528\u3002\u8be5\u6d41\u7a0b\u4e3a\u57ce\u5e02\u5c3a\u5ea6\u7684\u80fd\u8017\u5206\u6790\u548c\u9884\u6d4b\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u5de5\u5177\uff0c\u5176\u8ba1\u7b97\u6548\u7387\u5df2\u5728\u5b9e\u9645\u6d4b\u8bd5\u4e2d\u5f97\u5230\u9a8c\u8bc1\u3002"}}
{"id": "2511.20385", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2511.20385", "abs": "https://arxiv.org/abs/2511.20385", "authors": ["Christine Awofeso", "Patrick Greaves", "Oded Lachish", "Felix Reidl"], "title": "Counting large patterns in degenerate graphs", "comment": null, "summary": "The problem of subgraph counting asks for the number of occurrences of a pattern graph $H$ as a subgraph of a host graph $G$ and is known to be computationally challenging: it is $\\#W[1]$-hard even when $H$ is restricted to simple structures such as cliques or paths. Curticapean and Marx (FOCS'14) show that if the graph $H$ has vertex cover number $\u03c4$, subgraph counting has time complexity $O(|H|^{2^{O(\u03c4)}} |G|^{\u03c4+ O(1)})$. This raises the question of whether this upper bound can be improved for input graphs $G$ from a restricted family of graphs. Earlier work by Eppstein~(IPL'94) shows that this is indeed possible, by proving that when $G$ is a $d$-degenerate graph and $H$ is a biclique of arbitrary size, subgraph counting has time complexity $O(d 3^{d/3} |G|)$. We show that if the input is restricted to $d$-degenerate graphs, the upper bound of Curticapean and Marx can be improved for a family of graphs $H$ that includes all bicliques and satisfies a property we call $(c,d)$-locatable. Importantly, our algorithm's running time only has a polynomial dependence on the size of~$H$. A key feature of $(c,d)$-locatable graphs $H$ is that they admit a vertex cover of size at most $cd$. We further characterize $(1,d)$-locatable graphs, for which our algorithms achieve a linear running time dependence on $|G|$, and we establish a lower bound showing that counting graphs which are barely not $(1,d)$-locatable is already $\\#\\text{W}[1]$-hard. We note that the restriction to $d$-degenerate graphs has been a fruitful line of research leading to two very general results (FOCS'21, SODA'25) and this creates the impression that we largely understand the complexity of counting substructures in degenerate graphs. However, all aforementioned results have an exponential dependency on the size of the pattern graph $H$.", "AI": {"tldr": "This paper is related to **graph processing**. The paper addresses the problem of subgraph counting, which involves finding the number of occurrences of a pattern graph $H$ in a host graph $G$. This is a core problem in graph processing. **tldr:** Subgraph counting is $\\#\\text{W}[1]$-hard. Curticapean and Marx gave an FPT upper bound based on the vertex cover number $\\tau$ of the pattern graph $H$. This paper improves this bound for $d$-degenerate host graphs $G$ and a family of pattern graphs $H$ (including all bicliques) that are $(c,d)$-locatable. The key improvement is that the running time's dependency on the size of $H$ becomes polynomial, rather than exponential. For the special case of $(1,d)$-locatable graphs $H$, the algorithm achieves linear running time dependency on $|G|$. Furthermore, a lower bound is established, showing that counting slightly non-$(1,d)$-locatable graphs is already $\\#\\text{W}[1]$-hard. The paper highlights that, despite progress in counting substructures in degenerate graphs, existing general results still have an exponential dependency on the pattern graph size.", "motivation": "\u5b50\u56fe\u8ba1\u6570\u95ee\u9898\u662f\u8ba1\u7b97\u9886\u57df\u7684\u7ecf\u5178\u6311\u6218\uff0c\u5b83\u5728\u6a21\u5f0f\u56fe $H$ \u5177\u6709\u7b80\u5355\u7ed3\u6784\u65f6\uff0c\u4ecd\u7136\u662f $\\#\\text{W}[1]$ \u96be\u7684\u3002Curticapean \u548c Marx \u7684\u5de5\u4f5c\u7ed9\u51fa\u4e86\u57fa\u4e8e $H$ \u7684\u70b9\u8986\u76d6\u6570 $\\tau$ \u7684\u4e0a\u754c $O(|H|^{2^{O(\u03c4)}} |G|^{\u03c4+ O(1)})$\u3002\u5148\u524d\u7684\u5de5\u4f5c\u8868\u660e\uff0c\u5982\u679c\u5c06\u5bbf\u4e3b\u56fe $G$ \u9650\u5236\u5728\u7279\u5b9a\u7684\u56fe\u65cf\u4e2d\uff08\u4f8b\u5982 $d$-\u9000\u5316\u56fe\uff09\uff0c\u8fd9\u4e2a\u4e0a\u754c\u53ef\u80fd\u4f1a\u5f97\u5230\u6539\u8fdb\u3002\u7279\u522b\u5730\uff0cEppstein \u7684\u5de5\u4f5c\u8bc1\u5b9e\u4e86\u8fd9\u4e00\u70b9\u3002\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\uff0c\u63a2\u7a76\u662f\u5426\u53ef\u4ee5\u5c06 Curticapean \u548c Marx \u7684\u4e0a\u754c\u63a8\u5e7f\u5230\u66f4\u5e7f\u6cdb\u7684\u6a21\u5f0f\u56fe $H$\uff08\u5305\u62ec\u6240\u6709\u53cc\u91cd\u56e2\uff09\uff0c\u5e76\u5728 $G$ \u9650\u4e8e $d$-\u9000\u5316\u56fe\u65f6\uff0c\u5c06\u8fd0\u884c\u65f6\u95f4\u5bf9 $|H|$ \u7684\u4f9d\u8d56\u6027\u964d\u81f3\u591a\u9879\u5f0f\u7ea7\u522b\uff0c\u4ece\u800c\u5728\u9000\u5316\u56fe\u4e0a\u7684\u5b50\u7ed3\u6784\u8ba1\u6570\u65b9\u9762\u5bfb\u627e\u66f4\u7cbe\u7ec6\u7684\u754c\u9650\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5f15\u5165 $(c,d)$-\u53ef\u5b9a\u4f4d\u56fe $H$ \u7684\u6982\u5ff5\uff0c\u5728\u8f93\u5165\u56fe $G$ \u53d7\u9650\u4e8e $d$-\u9000\u5316\u56fe\u65f6\uff0c\u6539\u8fdb\u4e86 Curticapean \u548c Marx \u5173\u4e8e\u5b50\u56fe\u8ba1\u6570\u95ee\u9898\u7684 FPT \u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u3002\u8be5\u65b9\u6cd5\u7684\u6838\u5fc3\u5728\u4e8e\u5229\u7528 $d$-\u9000\u5316\u56fe\u7684\u7279\u6027\u548c\u53ef\u5b9a\u4f4d\u56fe\u7684\u7ed3\u6784\uff0c\u5c06\u8fd0\u884c\u65f6\u95f4\u5bf9 $|H|$ \u7684\u4f9d\u8d56\u6027\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u591a\u9879\u5f0f\u7ea7\u3002\u5bf9\u4e8e $(1,d)$-\u53ef\u5b9a\u4f4d\u56fe\uff0c\u7b97\u6cd5\u8fbe\u5230\u4e86\u5bf9 $|G|$ \u7684\u7ebf\u6027\u8fd0\u884c\u65f6\u95f4\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u901a\u8fc7\u8bc1\u660e\u4e0b\u754c\uff0c\u6765\u523b\u753b\u8fd9\u4e00\u6539\u8fdb\u7684\u754c\u9650\u3002", "result": "\u5f53\u8f93\u5165\u56fe $G$ \u9650\u5236\u4e3a $d$-\u9000\u5316\u56fe\u65f6\uff0c\u672c\u6587\u63d0\u51fa\u6539\u8fdb\u7684\u5b50\u56fe\u8ba1\u6570\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u4e00\u7c7b\u6ee1\u8db3 $(c,d)$-\u53ef\u5b9a\u4f4d\u5c5e\u6027\u7684\u6a21\u5f0f\u56fe $H$\uff0c\u8be5\u56fe\u65cf\u5305\u542b\u4e86\u6240\u6709\u7684\u53cc\u91cd\u56e2\u3002\u4e0e Curticapean \u548c Marx \u7684\u4e0a\u754c\u76f8\u6bd4\uff0c\u65b0\u7b97\u6cd5\u7684\u5173\u952e\u5728\u4e8e\u8fd0\u884c\u65f6\u95f4\u5bf9\u6a21\u5f0f\u56fe $|H|$ \u7684\u5927\u5c0f\u4ec5\u5177\u6709\u591a\u9879\u5f0f\u4f9d\u8d56\u6027\u3002\u672c\u6587\u8fdb\u4e00\u6b65\u523b\u753b\u4e86 $(1,d)$-\u53ef\u5b9a\u4f4d\u56fe\uff0c\u5bf9\u4e8e\u8fd9\u4e9b\u56fe\uff0c\u7b97\u6cd5\u5b9e\u73b0\u4e86\u5bf9 $|G|$ \u7684\u7ebf\u6027\u8fd0\u884c\u65f6\u95f4\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u5efa\u7acb\u4e86\u4e00\u4e2a\u4e0b\u754c\uff0c\u8bc1\u660e\u4e86\u5bf9\u4e8e\u7565\u5fae\u4e0d\u6ee1\u8db3 $(1,d)$-\u53ef\u5b9a\u4f4d\u6027\u8d28\u7684\u56fe\uff0c\u8ba1\u6570\u95ee\u9898\u5df2\u7ecf\u662f $\\#\\text{W}[1]$ \u96be\u7684\u3002", "conclusion": "\u672c\u6587\u5c06 Curticapean \u548c Marx \u7684\u4e0a\u754c\u63a8\u5e7f\u5230\u4e86\u66f4\u5e7f\u7684\u6a21\u5f0f\u56fe $H$ \u65cf\uff08\u5305\u62ec\u6240\u6709\u7684\u53cc\u91cd\u56e2\uff0c\u6ee1\u8db3 $(c,d)$-\u53ef\u5b9a\u4f4d\u5c5e\u6027\uff09\uff0c\u5e76\u5728 $G$ \u9650\u5236\u4e3a $d$-\u9000\u5316\u56fe\u7684\u60c5\u51b5\u4e0b\uff0c\u5c06\u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u5bf9 $|H|$ \u7684\u4f9d\u8d56\u6027\u964d\u4f4e\u5230\u591a\u9879\u5f0f\u7ea7\u522b\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u7ed9\u51fa\u4e86 $(1,d)$-\u53ef\u5b9a\u4f4d\u56fe $H$ \u7684\u66f4\u7cbe\u786e\u7684\u7ebf\u6027\u65f6\u95f4\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5bf9\u4e8e\u7565\u5fae\u4e0d\u6ee1\u8db3 $(1,d)$-\u53ef\u5b9a\u4f4d\u6027\u8d28\u7684\u56fe\uff0c\u5b50\u56fe\u8ba1\u6570\u95ee\u9898\u4ecd\u7136\u662f $\\#\\text{W}[1]$ \u96be\u7684\uff0c\u4ece\u800c\u786e\u7acb\u4e86\u65b0\u7684\u590d\u6742\u6027\u754c\u9650\u3002\u6587\u7ae0\u8fd8\u6307\u51fa\uff0c\u5c3d\u7ba1\u5728\u9000\u5316\u56fe\u4e2d\u5b50\u7ed3\u6784\u8ba1\u6570\u7684\u7814\u7a76\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u7684\u901a\u7528\u7ed3\u679c\u5728\u6a21\u5f0f\u56fe\u5927\u5c0f\u4e0a\u4ecd\u5b58\u5728\u6307\u6570\u4f9d\u8d56\u6027\uff0c\u8fd9\u4e3a\u672a\u6765\u7684\u7814\u7a76\u7559\u4e0b\u4e86\u6311\u6218\u3002"}}
{"id": "2511.19464", "categories": ["cs.DC", "cs.AI", "cs.CR", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.19464", "abs": "https://arxiv.org/abs/2511.19464", "authors": ["Marcio Pohlmann", "Alex Severo", "Geft\u00e9 Almeida", "Diego Kreutz", "Tiago Heinrich", "Louren\u00e7o Pereira"], "title": "Temperature in SLMs: Impact on Incident Categorization in On-Premises Environments", "comment": "5 pages, 3 figures, 2 tables, submitted to ERRC/WRSeg 2025", "summary": "SOCs and CSIRTs face increasing pressure to automate incident categorization, yet the use of cloud-based LLMs introduces costs, latency, and confidentiality risks. We investigate whether locally executed SLMs can meet this challenge. We evaluated 21 models ranging from 1B to 20B parameters, varying the temperature hyperparameter and measuring execution time and precision across two distinct architectures. The results indicate that temperature has little influence on performance, whereas the number of parameters and GPU capacity are decisive factors.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e DSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS \u5747\u4e0d\u76f8\u5173\u3002\n\u672c\u6587\u65e8\u5728\u63a2\u7a76\u5728\u672c\u5730\u6267\u884c\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u7528\u4e8e\u81ea\u52a8\u5316\u5b89\u5168\u4e8b\u4ef6\u5206\u7c7b\u7684\u53ef\u884c\u6027\uff0c\u4ee5\u907f\u514d\u4f7f\u7528\u57fa\u4e8e\u4e91\u7684 LLMs \u6240\u5e26\u6765\u7684\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u4fdd\u5bc6\u6027\u98ce\u9669\u3002\u7814\u7a76\u8bc4\u4f30\u4e86 21 \u4e2a\u53c2\u6570\u91cf\u5728 1B \u5230 20B \u4e4b\u95f4\u3001\u8fd0\u884c\u5728\u4e24\u79cd\u4e0d\u540c\u67b6\u6784\u4e0a\u7684 SLMs\uff0c\u5e76\u6d4b\u91cf\u4e86\u5b83\u4eec\u5728\u4e0d\u540c\u6e29\u5ea6\u8bbe\u7f6e\u4e0b\u7684\u6267\u884c\u65f6\u95f4\u4e0e\u7cbe\u5ea6\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6e29\u5ea6\u5bf9\u6027\u80fd\u5f71\u54cd\u751a\u5fae\uff0c\u800c\u6a21\u578b\u7684\u53c2\u6570\u91cf\u548c GPU \u6027\u80fd\u662f\u5173\u952e\u51b3\u5b9a\u6027\u56e0\u7d20\u3002\u7814\u7a76\u8bc1\u5b9e\uff0c\u5728\u73b0\u4ee3\u786c\u4ef6\u4e0a\u4f7f\u7528\u5c0f\u4e8e 7B \u53c2\u6570\u7684 SLM \u8fdb\u884c\u4f4e\u5ef6\u8fdf\u3001\u9ad8\u51c6\u786e\u7387\u7684\u4e8b\u4ef6\u5206\u7c7b\u662f\u53ef\u884c\u7684\u3002", "motivation": "\u9762\u5bf9 SOCs \u548c CSIRTs \u81ea\u52a8\u5316\u4e8b\u4ef6\u5206\u7c7b\u7684\u65e5\u76ca\u589e\u957f\u7684\u538b\u529b\uff0c\u7814\u7a76\u4eba\u5458\u65e8\u5728\u63a2\u8ba8\u672c\u5730\u6267\u884c\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u662f\u5426\u53ef\u4ee5\u5e94\u5bf9\u8fd9\u4e00\u6311\u6218\u3002\u56e0\u4e3a\u4f7f\u7528\u57fa\u4e8e\u4e91\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b58\u5728\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u4fdd\u5bc6\u6027\u98ce\u9669\u3002", "method": "\u7814\u7a76\u4eba\u5458\u8bc4\u4f30\u4e86 21 \u4e2a\u53c2\u6570\u91cf\u5728 1B \u5230 20B \u4e4b\u95f4\u7684\u672c\u5730\u6267\u884c SLM\uff0c\u5e76\u6539\u53d8\u6e29\u5ea6\u8d85\u53c2\u6570\u3002\u4ed6\u4eec\u6d4b\u91cf\u4e86\u5728\u4e24\u79cd\u4e0d\u540c\u67b6\u6784\u4e0a\u7684\u6267\u884c\u65f6\u95f4\u548c\u7cbe\u5ea6\uff0c\u4ee5\u8bc4\u4f30 SLM \u5728\u4e8b\u4ef6\u5206\u7c7b\u4e2d\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6e29\u5ea6\u8d85\u53c2\u6570\u5bf9\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\u3002\u800c\u6a21\u578b\u7684\u53c2\u6570\u91cf\u548c GPU \u5bb9\u91cf\u662f\u51b3\u5b9a\u6027\u56e0\u7d20\u3002\u7ed3\u679c\u8bc1\u5b9e\u4e86\u5728\u73b0\u4ee3\u786c\u4ef6\u4e0a\u4f7f\u7528\u5c0f\u4e8e 7B \u53c2\u6570\u7684 SLM \u8fdb\u884c\u672c\u5730\u4e8b\u4ef6\u5206\u7c7b\u662f\u53ef\u884c\u7684\uff0c\u540c\u65f6\u80fd\u63d0\u4f9b\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u5728\u672c\u5730\u6267\u884c SLM \u8fdb\u884c\u4e8b\u4ef6\u5206\u7c7b\u662f\u53ef\u884c\u7684\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5c0f\u4e8e 7B \u53c2\u6570\u7684\u6a21\u578b\uff0c\u5728\u73b0\u4ee3\u786c\u4ef6\u4e0a\u53ef\u4ee5\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u51c6\u786e\u7387\u3002\u7136\u800c\uff0c\u6a21\u578b\u7684\u53c2\u6570\u91cf\u548c GPU \u6027\u80fd\u662f\u51b3\u5b9a\u6027\u56e0\u7d20\uff0c\u800c\u6e29\u5ea6\u8d85\u53c2\u6570\u7684\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\u3002"}}
{"id": "2511.19880", "categories": ["cs.DC", "cs.DS", "cs.MA", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.19880", "abs": "https://arxiv.org/abs/2511.19880", "authors": ["Prabhat Kumar Chand", "Anisur Rahaman Molla"], "title": "Improved Linear-Time Construction of Minimal Dominating Set via Mobile Agents", "comment": null, "summary": "Mobile agents have emerged as a powerful framework for solving fundamental graph problems in distributed settings in recent times. These agents, modelled as autonomous physical or software entities, possess local computation power, finite memory and have the ability to traverse a graph, offering efficient solutions to a range of classical problems. In this work, we focus on the problem of computing a \\emph{minimal dominating set} (mDS) in anonymous graphs using mobile agents. Building on the recently proposed optimal dispersion algorithm on the synchronous mobile agent model, we design two new algorithms that achieve a \\emph{linear-time} solution for this problem in the synchronous setting. Specifically, given a connected $n$-node graph with $n$ agents initially placed in either rooted or arbitrary configurations, we show that an mDS can be computed in $O(n)$ rounds using only $O(\\log n)$ bits of memory per agent, without using any prior knowledge of any global parameters. This improves upon the best-known complexity results in the literature over the same model. In addition, as natural by-products of our methodology, our algorithms also construct a spanning tree and elect a unique leader in $O(n)$ rounds, which are also important results of independent interest in the mobile-agent framework.", "AI": {"tldr": "DSL or graph processing or MLIR or compiler or HLS: graph processing.\n\u592a\u957f\u4e0d\u770b\uff1a\u672c\u6587\u5728\u540c\u6b65\u79fb\u52a8\u667a\u80fd\u4f53\u6a21\u578b\u4e0b\uff0c\u9488\u5bf9\u533f\u540d\u56fe\u7684\u6700\u5c0f\u652f\u914d\u96c6\uff08mDS\uff09\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7684\u7ebf\u6027\u65f6\u95f4$O(n)$\u7b97\u6cd5\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u4ec5\u9700$O(\\log n)$\u4f4d\u5185\u5b58\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u7ed3\u679c\u3002\u540c\u65f6\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u8fd8\u80fd\u5728$O(n)$\u8f6e\u5185\u5b9e\u73b0\u751f\u6210\u6811\u6784\u5efa\u548c\u9886\u5bfc\u8005\u9009\u4e3e\u3002", "motivation": "\u79fb\u52a8\u667a\u80fd\u4f53\u4f5c\u4e3a\u4e00\u79cd\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u89e3\u51b3\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u7684\u56fe\u95ee\u9898\uff0c\u5e76\u4e14\u5176\u5177\u5907\u5c40\u90e8\u8ba1\u7b97\u80fd\u529b\u3001\u6709\u9650\u5185\u5b58\u4ee5\u53ca\u5728\u56fe\u4e0a\u904d\u5386\u7684\u80fd\u529b\uff0c\u80fd\u591f\u63d0\u4f9b\u9ad8\u6548\u7684\u7ecf\u5178\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u805a\u7126\u4e8e\u5229\u7528\u79fb\u52a8\u667a\u80fd\u4f53\u5728\u533f\u540d\u56fe\u4e0a\u8ba1\u7b97\u6700\u5c0f\u652f\u914d\u96c6\uff08mDS\uff09\u8fd9\u4e00\u6838\u5fc3\u95ee\u9898\uff0c\u5e76\u65e8\u5728\u8bbe\u8ba1\u51fa\u6bd4\u73b0\u6709\u6280\u672f\u590d\u6742\u5ea6\u66f4\u4f18\u7684\u7b97\u6cd5\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e24\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u540c\u6b65\u79fb\u52a8\u667a\u80fd\u4f53\u6a21\u578b\u4e0b\u8ba1\u7b97\u533f\u540d\u56fe\u7684\u6700\u5c0f\u652f\u914d\u96c6\uff08mDS\uff09\u3002\u8fd9\u4e9b\u7b97\u6cd5\u57fa\u4e8e\u6700\u8fd1\u63d0\u51fa\u7684\u6700\u4f18\u5206\u6563\u7b97\u6cd5\uff0c\u65e8\u5728\u5b9e\u73b0\u7ebf\u6027\u65f6\u95f4$O(n)$\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7ed9\u5b9a\u4e00\u4e2a\u8fde\u901a\u7684$n$\u8282\u70b9\u56fe\uff0c\u521d\u59cb\u914d\u7f6e\u4e3a\u6709\u6839\u6216\u4efb\u610f\u914d\u7f6e\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u4ec5\u4f7f\u7528$O(\\log n)$\u4f4d\u7684\u5185\u5b58\uff0c\u5e76\u5b9e\u73b0\u4e86$O(n)$\u8f6e\u5185\u7684mDS\u8ba1\u7b97\u3002\u8be5\u65b9\u6cd5\u8fd8\u80fd\u5728$O(n)$\u8f6e\u5185\u6784\u5efa\u751f\u6210\u6811\u5e76\u9009\u4e3e\u552f\u4e00\u7684\u9886\u5bfc\u8005\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u4e24\u79cd\u65b0\u7b97\u6cd5\u5728\u540c\u6b65\u79fb\u52a8\u667a\u80fd\u4f53\u6a21\u578b\u4e0b\uff0c\u5b9e\u73b0\u4e86\u533f\u540d\u56fe\u6700\u5c0f\u652f\u914d\u96c6\uff08mDS\uff09\u8ba1\u7b97\u7684\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6$O(n)$\u89e3\u51b3\u65b9\u6848\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u4ec5\u9700\u8981$O(\\log n)$\u4f4d\u7684\u5185\u5b58\u3002\u8fd9\u6bd4\u540c\u6a21\u578b\u4e0b\u73b0\u6709\u6700\u4f73\u7ed3\u679c\u6709\u6240\u6539\u8fdb\u3002\u6b64\u5916\uff0c\u4f5c\u4e3a\u81ea\u7136\u526f\u4ea7\u54c1\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u8fd8\u80fd\u5728$O(n)$\u8f6e\u5185\u6784\u5efa\u4e00\u4e2a\u751f\u6210\u6811\u5e76\u9009\u4e3e\u51fa\u552f\u4e00\u7684\u9886\u5bfc\u8005\u3002", "conclusion": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e24\u79cd\u65b0\u7684\u7b97\u6cd5\uff0c\u5728\u540c\u6b65\u79fb\u52a8\u667a\u80fd\u4f53\u6a21\u578b\u4e0b\uff0c\u4ee5\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6$O(n)$\u89e3\u51b3\u4e86\u533f\u540d\u56fe\u4e2d\u7684\u6700\u5c0f\u652f\u914d\u96c6\uff08mDS\uff09\u8ba1\u7b97\u95ee\u9898\u3002\u8fd9\u4e00\u7ed3\u679c\u5728\u65f6\u95f4\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u7ed3\u679c\uff0c\u5e76\u4e14\u4f5c\u4e3a\u526f\u4ea7\u54c1\uff0c\u8fd9\u4e24\u79cd\u7b97\u6cd5\u8fd8\u80fd\u5728$O(n)$\u8f6e\u5185\u6784\u5efa\u4e00\u4e2a\u751f\u6210\u6811\u5e76\u9009\u4e3e\u51fa\u552f\u4e00\u7684\u9886\u5bfc\u8005\u3002\u8fd9\u8bc1\u660e\u4e86\u79fb\u52a8\u667a\u80fd\u4f53\u6846\u67b6\u5728\u89e3\u51b3\u5206\u5e03\u5f0f\u56fe\u95ee\u9898\u4e0a\u7684\u9ad8\u6548\u6027\u3002"}}
{"id": "2511.19468", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19468", "abs": "https://arxiv.org/abs/2511.19468", "authors": ["Blaise Ag\u00fcera y Arcas", "Travis Beals", "Maria Biggs", "Jessica V. Bloom", "Thomas Fischbacher", "Konstantin Gromov", "Urs K\u00f6ster", "Rishiraj Pravahan", "James Manyika"], "title": "Towards a future space-based, highly scalable AI infrastructure system design", "comment": "19 pages, 4 figures", "summary": "If AI is a foundational general-purpose technology, we should anticipate that demand for AI compute -- and energy -- will continue to grow. The Sun is by far the largest energy source in our solar system, and thus it warrants consideration how future AI infrastructure could most efficiently tap into that power. This work explores a scalable compute system for machine learning in space, using fleets of satellites equipped with solar arrays, inter-satellite links using free-space optics, and Google tensor processing unit (TPU) accelerator chips. To facilitate high-bandwidth, low-latency inter-satellite communication, the satellites would be flown in close proximity. We illustrate the basic approach to formation flight via a 81-satellite cluster of 1 km radius, and describe an approach for using high-precision ML-based models to control large-scale constellations. Trillium TPUs are radiation tested. They survive a total ionizing dose equivalent to a 5 year mission life without permanent failures, and are characterized for bit-flip errors. Launch costs are a critical part of overall system cost; a learning curve analysis suggests launch to low-Earth orbit (LEO) may reach $\\lesssim$\\$200/kg by the mid-2030s.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL\u3001MLIR\u3001\u56fe\u5904\u7406\u548cHLS\u7b49\u9886\u57df\u5747\u65e0\u5173\u3002\n\u6458\u8981\uff1a\u7531\u4e8eAI\u8ba1\u7b97\u5bf9\u80fd\u6e90\u7684\u9700\u6c42\u6301\u7eed\u589e\u957f\uff0c\u672c\u6587\u63d0\u51fa\u5e76\u5206\u6790\u4e86\u4e00\u79cd\u5229\u7528\u592a\u9633\u80fd\u5728\u592a\u7a7a\u90e8\u7f72AI\u8ba1\u7b97\u57fa\u7840\u8bbe\u65bd\u7684\u65b9\u6848\u3002\u8be5\u65b9\u6848\u4f7f\u7528\u914d\u5907\u592a\u9633\u80fd\u7535\u6c60\u9635\u5217\u3001\u81ea\u7531\u7a7a\u95f4\u5149\u5b66\u94fe\u8def\u548cGoogle TPU\uff08Trillium\u578b\uff09\u82af\u7247\u7684\u536b\u661f\u96c6\u7fa4\u3002\u4e3a\u5b9e\u73b0\u9ad8\u5e26\u5bbd\u3001\u4f4e\u5ef6\u8fdf\u901a\u4fe1\uff0c\u536b\u661f\u5c06\u91c7\u7528\u8fd1\u8ddd\u79bb\u7f16\u961f\u98de\u884c\uff0c\u5e76\u63d0\u51fa\u7528\u57fa\u4e8eML\u7684\u6a21\u578b\u6765\u63a7\u5236\u5927\u578b\u661f\u5ea7\u3002\u8f90\u5c04\u6d4b\u8bd5\u663e\u793aTrillium TPU\u80fd\u627f\u53d75\u5e74\u4efb\u52a1\u5bff\u547d\u7684\u8f90\u5c04\u5242\u91cf\u3002\u53d1\u5c04\u6210\u672c\u5206\u6790\u8868\u660e\uff0c\u672a\u6765\u53d1\u5c04\u6210\u672c\u6709\u671b\u663e\u8457\u964d\u4f4e\uff0c\u4f7f\u8be5\u65b9\u6848\u5728\u7ecf\u6d4e\u4e0a\u5177\u6709\u53ef\u884c\u6027\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u5e94\u5bf9AI\u8ba1\u7b97\u5bf9\u80fd\u6e90\u9700\u6c42\u7684\u6301\u7eed\u589e\u957f\u95ee\u9898\uff0c\u5e76\u63a2\u7d22\u5982\u4f55\u6700\u6709\u6548\u5730\u5229\u7528\u6700\u5927\u7684\u80fd\u6e90\u6765\u6e90\u2014\u2014\u592a\u9633\u80fd\u3002\u8003\u8651\u5230AI\u4f5c\u4e3a\u4e00\u79cd\u57fa\u7840\u6027\u901a\u7528\u6280\u672f\uff0c\u5176\u8ba1\u7b97\u548c\u80fd\u6e90\u9700\u6c42\u9884\u8ba1\u5c06\u7ee7\u7eed\u589e\u957f\uff0c\u56e0\u6b64\u63a2\u7d22\u5229\u7528\u592a\u7a7a\u548c\u592a\u9633\u80fd\u7684AI\u57fa\u7840\u8bbe\u65bd\u6210\u4e3a\u4e00\u4e2a\u5177\u6709\u6f5c\u529b\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u592a\u7a7a\u90e8\u7f72\u53ef\u6269\u5c55\u673a\u5668\u5b66\u4e60\u8ba1\u7b97\u7cfb\u7edf\u7684\u65b9\u6cd5\uff0c\u4e3b\u8981\u5305\u62ec\u4ee5\u4e0b\u51e0\u4e2a\u5173\u952e\u65b9\u9762\uff1a\u5229\u7528\u592a\u9633\u80fd\u4f5c\u4e3a\u80fd\u6e90\uff1b\u4f7f\u7528\u914d\u5907\u592a\u9633\u80fd\u7535\u6c60\u9635\u5217\u3001\u81ea\u7531\u7a7a\u95f4\u5149\u5b66\uff08FSO\uff09\u536b\u661f\u95f4\u94fe\u8def\u548cGoogle TPU\u52a0\u901f\u5668\u7684\u536b\u661f\u8230\u961f\uff1b\u4e3a\u4e86\u5b9e\u73b0\u9ad8\u5e26\u5bbd\u3001\u4f4e\u5ef6\u8fdf\u7684\u536b\u661f\u95f4\u901a\u4fe1\uff0c\u536b\u661f\u5c06\u8fd1\u8ddd\u79bb\u7f16\u961f\u98de\u884c\uff1b\u5e76\u63d0\u51fa\u4f7f\u7528\u57fa\u4e8eML\u7684\u9ad8\u7cbe\u5ea6\u6a21\u578b\u6765\u63a7\u5236\u5927\u89c4\u6a21\u661f\u5ea7\u3002\u540c\u65f6\uff0c\u9a8c\u8bc1\u4e86Trillium TPU\u7684\u6297\u8f90\u5c04\u6027\u80fd\u548c\u5206\u6790\u4e86\u53d1\u5c04\u6210\u672c\u7684\u672a\u6765\u8d8b\u52bf\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u90e8\u7f72\u5728\u592a\u7a7a\u4e2d\u7684AI\u8ba1\u7b97\u7cfb\u7edf\u662f\u53ef\u884c\u7684\uff1aTrillium TPU\u82af\u7247\u5df2\u7ecf\u901a\u8fc7\u8f90\u5c04\u6d4b\u8bd5\uff0c\u53ef\u4ee5\u627f\u53d7\u76f8\u5f53\u4e8e5\u5e74\u4efb\u52a1\u5bff\u547d\u7684\u603b\u7535\u79bb\u5242\u91cf\uff0c\u5e76\u8868\u5f81\u4e86\u4f4d\u7ffb\u8f6c\u9519\u8bef\uff1b\u63d0\u51fa\u4e86\u4e00\u4e2a\u534a\u5f841\u516c\u91cc\u768481\u9897\u536b\u661f\u7ec4\u6210\u7684\u96c6\u7fa4\u7f16\u961f\u98de\u884c\u7684\u57fa\u672c\u65b9\u6cd5\uff1b\u5b66\u4e60\u66f2\u7ebf\u5206\u6790\u8868\u660e\uff0c\u52302030\u5e74\u4ee3\u4e2d\u671f\uff0c\u4f4e\u5730\u7403\u8f68\u9053\uff08LEO\uff09\u7684\u53d1\u5c04\u6210\u672c\u53ef\u80fd\u964d\u81f3$\\lesssim$\\$200/kg\uff0c\u8fd9\u5c06\u6709\u52a9\u4e8e\u964d\u4f4e\u7cfb\u7edf\u7684\u603b\u4f53\u6210\u672c\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u4e00\u4e2a\u5728\u592a\u7a7a\u90e8\u7f72AI\u8ba1\u7b97\u7cfb\u7edf\u7684\u53ef\u80fd\u6027\u548c\u524d\u666f\uff0c\u8be5\u7cfb\u7edf\u5229\u7528\u592a\u9633\u80fd\u3001\u536b\u661f\u8230\u961f\u548cTPU\u82af\u7247\u3002\u867d\u7136\u9762\u4e34\u5de5\u7a0b\u6311\u6218\u548c\u6210\u672c\u95ee\u9898\uff0c\u4f46\u901a\u8fc7\u6280\u672f\u53d1\u5c55\uff08\u5982\u964d\u4f4e\u53d1\u5c04\u6210\u672c\u3001\u63d0\u9ad8\u786c\u4ef6\u53ef\u9760\u6027\u548c\u7814\u53d1AI\u9a71\u52a8\u7684\u661f\u5ea7\u63a7\u5236\uff09\u53ef\u4ee5\u4f7f\u8fd9\u4e00\u613f\u666f\u6210\u4e3a\u53ef\u80fd\uff0c\u5e76\u4e3a\u672a\u6765AI\u53ef\u6301\u7eed\u8ba1\u7b97\u63d0\u4f9b\u4e00\u4e2a\u6f5c\u5728\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19479", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19479", "abs": "https://arxiv.org/abs/2511.19479", "authors": ["Sangam Ghimire", "Paribartan Timalsina", "Nirjal Bhurtel", "Bishal Neupane", "Bigyan Byanju Shrestha", "Subarna Bhattarai", "Prajwal Gaire", "Jessica Thapa", "Sudan Jha"], "title": "Federated Learning Framework for Scalable AI in Heterogeneous HPC and Cloud Environments", "comment": null, "summary": "As the demand grows for scalable and privacy-aware AI systems, Federated Learning (FL) has emerged as a promising solution, allowing decentralized model training without moving raw data. At the same time, the combination of high- performance computing (HPC) and cloud infrastructure offers vast computing power but introduces new complexities, especially when dealing with heteroge- neous hardware, communication limits, and non-uniform data. In this work, we present a federated learning framework built to run efficiently across mixed HPC and cloud environments. Our system addresses key challenges such as system het- erogeneity, communication overhead, and resource scheduling, while maintaining model accuracy and data privacy. Through experiments on a hybrid testbed, we demonstrate strong performance in terms of scalability, fault tolerance, and convergence, even under non-Independent and Identically Distributed (non-IID) data distributions and varied hardware. These results highlight the potential of federated learning as a practical approach to building scalable Artificial Intelligence (AI) systems in modern, distributed computing settings.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0d\u6d89\u53ca DSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216 HLS\u3002\nToo Long; Didn't Read \u6458\u8981: \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u9ad8\u6548\u5730\u5728\u6df7\u5408 HPC \u548c\u4e91\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u5b83\u89e3\u51b3\u4e86\u7cfb\u7edf\u5f02\u6784\u6027\u3001\u9ad8\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u8c03\u5ea6\u7b49\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7cbe\u5ea6\u548c\u6570\u636e\u9690\u79c1\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u6846\u67b6\u5728\u53ef\u6269\u5c55\u6027\u3001\u5bb9\u9519\u6027\u548c\u6536\u655b\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5373\u4f7f\u5728\u975e IID \u6570\u636e\u548c\u4e0d\u540c\u786c\u4ef6\u6761\u4ef6\u4e0b\u4e5f\u662f\u5982\u6b64\uff0c\u51f8\u663e\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u6784\u5efa\u53ef\u6269\u5c55\u5206\u5e03\u5f0f AI \u7cfb\u7edf\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u968f\u7740\u5bf9\u53ef\u6269\u5c55\u548c\u6ce8\u91cd\u9690\u79c1\u7684 AI \u7cfb\u7edf\u7684\u9700\u6c42\u589e\u957f\uff0c\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u6210\u4e3a\u4e00\u79cd\u6709\u524d\u666f\u7684\u53bb\u4e2d\u5fc3\u5316\u6a21\u578b\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002\u7136\u800c\uff0c\u5c06\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u4e0e\u4e91\u57fa\u7840\u8bbe\u65bd\u76f8\u7ed3\u5408\u867d\u7136\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u8ba1\u7b97\u80fd\u529b\uff0c\u4f46\u5728\u5904\u7406\u5f02\u6784\u786c\u4ef6\u3001\u901a\u4fe1\u9650\u5236\u548c\u975e\u5747\u5300\u6570\u636e\u65f6\u5f15\u5165\u4e86\u65b0\u7684\u590d\u6742\u6027\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u6784\u5efa\u4e00\u4e2a\u80fd\u591f\u9ad8\u6548\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u5e76\u5728\u6df7\u5408 HPC \u548c\u4e91\u73af\u5883\u4e2d\u8fd0\u884c\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u5728\u6df7\u5408 HPC \u548c\u4e91\u73af\u5883\u4e2d\u9ad8\u6548\u8fd0\u884c\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff08Federated Learning Framework\uff09\u3002\u8be5\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u7cfb\u7edf\u5f02\u6784\u6027\u3001\u901a\u4fe1\u5f00\u9500\u9ad8\u548c\u8d44\u6e90\u8c03\u5ea6\u590d\u6742\u7b49\u5173\u952e\u6311\u6218\u3002\u8bba\u6587\u901a\u8fc7\u5728\u4e00\u4e2a\u6df7\u5408\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728\u6df7\u5408\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u672c\u6587\u63d0\u51fa\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u5728\u53ef\u6269\u5c55\u6027\u3001\u5bb9\u9519\u6027\u548c\u6536\u655b\u6027\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\u3002\u5373\u4f7f\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u5206\u5e03\u548c\u4e0d\u540c\u786c\u4ef6\u6761\u4ef6\u4e0b\uff0c\u7cfb\u7edf\u4e5f\u80fd\u4fdd\u6301\u826f\u597d\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u51f8\u663e\u4e86\u8054\u90a6\u5b66\u4e60\u4f5c\u4e3a\u5728\u73b0\u4ee3\u5206\u5e03\u5f0f\u8ba1\u7b97\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u6269\u5c55\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u4e00\u79cd\u5b9e\u7528\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u5728\u6df7\u5408\u7684 HPC \u548c\u4e91\u73af\u5883\u4e2d\u8fd0\u884c\uff0c\u89e3\u51b3\u4e86\u7cfb\u7edf\u5f02\u6784\u6027\u3001\u901a\u4fe1\u5f00\u9500\u548c\u8d44\u6e90\u8c03\u5ea6\u7b49\u5173\u952e\u6311\u6218\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7cbe\u5ea6\u548c\u6570\u636e\u9690\u79c1\u3002\u5b9e\u9a8c\u8bc1\u660e\u4e86\u8be5\u7cfb\u7edf\u5728\u53ef\u6269\u5c55\u6027\u3001\u5bb9\u9519\u6027\u548c\u6536\u655b\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5373\u4f7f\u5728\u975e\u72ec\u7acb\u540c\u5206\u5e03\uff08non-IID\uff09\u6570\u636e\u5206\u5e03\u548c\u4e0d\u540c\u786c\u4ef6\u6761\u4ef6\u4e0b\u4e5f\u80fd\u4fdd\u6301\u826f\u597d\u6027\u80fd\uff0c\u7a81\u51fa\u4e86\u8054\u90a6\u5b66\u4e60\u5728\u73b0\u4ee3\u5206\u5e03\u5f0f\u8ba1\u7b97\u73af\u5883\u4e2d\u6784\u5efa\u53ef\u6269\u5c55 AI \u7cfb\u7edf\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.19832", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.19832", "abs": "https://arxiv.org/abs/2511.19832", "authors": ["Aurelio Vivas", "Harold Castro"], "title": "Enabling Scientific Workflow Scheduling Research in Non-Uniform Memory Access Architectures", "comment": null, "summary": "Data-intensive scientific workflows increasingly rely on high-performance computing (HPC) systems, complementing traditional Grid and Cloud platforms. However, workflow scheduling on HPC infrastructures remains challenging due to the prevalence of non-uniform memory access (NUMA) architectures. These systems require schedulers to account for data locality not only across distributed environments but also within each node. Modern HPC nodes integrate multiple NUMA domains and heterogeneous memory regions, such as high-bandwidth memory (HBM) and DRAM, and frequently attach accelerators (GPUs or FPGAs) and network interface cards (NICs) to specific NUMA nodes. This design increases the variability of data-access latency and complicates the placement of both tasks and data. Despite these constraints, most workflow scheduling strategies were originally developed for Grid or Cloud environments and rarely incorporate NUMA-aware considerations. To address this gap, this work introduces nFlows, a NUMA-aware Workflow Execution Runtime System that enables the modeling, bare-metal execution, simulation, and validation of scheduling algorithms for data-intensive workflows on NUMA-based HPC systems. The system's design, implementation, and validation methodology are presented. nFlows supports the construction of simulation models and their direct execution on physical systems, enabling studies of NUMA effects on scheduling, the design of NUMA-aware algorithms, the analysis of data-movement behavior, the identification of performance bottlenecks, and the exploration of in-memory workflow execution.", "AI": {"tldr": "\u5173\u8054\uff1a\u7f16\u8bd1\u5668\uff08\u6d89\u53ca\u8fd0\u884c\u65f6\u7cfb\u7edf\u3001\u4efb\u52a1/\u6570\u636e\u653e\u7f6e\u3001\u6027\u80fd\u4f18\u5316\uff09\u3002TLDR\uff1a\u6570\u636e\u5bc6\u96c6\u578b\u79d1\u5b66\u5de5\u4f5c\u6d41\u5728\u57fa\u4e8eNUMA\u7684HPC\u7cfb\u7edf\u4e0a\u9762\u4e34\u8c03\u5ea6\u6311\u6218\uff0c\u56e0\u4e3a\u5927\u591a\u6570\u73b0\u6709\u8c03\u5ea6\u7b56\u7565\u7f3a\u4e4fNUMA\u611f\u77e5\u3002\u672c\u6587\u63d0\u51fa\u4e86nFlows\uff0c\u4e00\u4e2aNUMA\u611f\u77e5\u7684\u5de5\u4f5c\u6d41\u6267\u884c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff0c\u5b83\u5141\u8bb8\u5bf9\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u8fdb\u884c\u5efa\u6a21\u3001\u88f8\u673a\u6267\u884c\u3001\u4eff\u771f\u548c\u8c03\u5ea6\u7b97\u6cd5\u9a8c\u8bc1\uff0c\u4ee5\u7814\u7a76NUMA\u6548\u5e94\u3001\u8bbe\u8ba1\u65b0\u7684\u8c03\u5ea6\u7b97\u6cd5\u5e76\u89e3\u51b3HPC\u73af\u5883\u4e2d\u7684\u6027\u80fd\u74f6\u9888\u3002", "motivation": "\u6570\u636e\u5bc6\u96c6\u578b\u79d1\u5b66\u5de5\u4f5c\u6d41\u5728HPC\u7cfb\u7edf\u4e0a\u7684\u8c03\u5ea6\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u4e3b\u8981\u6e90\u4e8eHPC\u7cfb\u7edf\u4e2d\u5e38\u89c1\u7684\u975e\u7edf\u4e00\u5185\u5b58\u8bbf\u95ee\uff08NUMA\uff09\u67b6\u6784\u3002\u73b0\u4ee3HPC\u8282\u70b9\u96c6\u6210\u591aNUMA\u57df\u3001\u5f02\u6784\u5185\u5b58\uff08\u5982HBM\u548cDRAM\uff09\u4ee5\u53ca\u52a0\u901f\u5668\uff08GPU/FPGA\uff09\u548c\u7f51\u5361\uff08NIC\uff09\uff0c\u5bfc\u81f4\u6570\u636e\u8bbf\u95ee\u5ef6\u8fdf\u53d8\u5f02\u6027\u589e\u52a0\uff0c\u4efb\u52a1\u548c\u6570\u636e\u653e\u7f6e\u590d\u6742\u5316\u3002\u5f53\u524d\u5927\u591a\u6570\u5de5\u4f5c\u6d41\u8c03\u5ea6\u7b56\u7565\u6e90\u81eaGrid\u6216Cloud\u73af\u5883\uff0c\u5f88\u5c11\u8003\u8651NUMA\u7684\u5f71\u54cd\uff0c\u4ece\u800c\u65e0\u6cd5\u5145\u5206\u5229\u7528HPC\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3anFlows\u7684NUMA\u611f\u77e5\u5de5\u4f5c\u6d41\u6267\u884c\u8fd0\u884c\u65f6\u7cfb\u7edf\uff08NUMA-aware Workflow Execution Runtime System\uff09\u3002nFlows\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u5141\u8bb8\u5bf9NUMA\u611f\u77e5\u7684\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u8fdb\u884c\u5efa\u6a21\u3001\u8c03\u5ea6\u7b97\u6cd5\u7684\u88f8\u673a\u6267\u884c\u3001\u4eff\u771f\u548c\u9a8c\u8bc1\uff0c\u8fd8\u652f\u6301\u5c06\u6a21\u62df\u6a21\u578b\u76f4\u63a5\u90e8\u7f72\u5230\u7269\u7406\u7cfb\u7edf\u4e0a\u8fdb\u884c\u6267\u884c\u548c\u7814\u7a76\u3002", "result": "nFlows\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u9a8c\u8bc1\u65b9\u6cd5\u5df2\u7ecf\u63d0\u4f9b\u3002\u8be5\u7cfb\u7edf\u652f\u6301\u6784\u5efa\u6a21\u62df\u6a21\u578b\uff0c\u5e76\u80fd\u76f4\u63a5\u5728\u7269\u7406\u7cfb\u7edf\u4e0a\u6267\u884c\u8fd9\u4e9b\u6a21\u578b\u3002\u8fd9\u4f7f\u5f97\u7814\u7a76\u8005\u80fd\u591f\u7814\u7a76NUMA\u5bf9\u8c03\u5ea6\u7684\u5f71\u54cd\u3001\u8bbe\u8ba1NUMA\u611f\u77e5\u7b97\u6cd5\u3001\u5206\u6790\u6570\u636e\u79fb\u52a8\u884c\u4e3a\u3001\u8bc6\u522b\u6027\u80fd\u74f6\u9888\u4ee5\u53ca\u63a2\u7d22\u5185\u5b58\u5185\u5de5\u4f5c\u6d41\u6267\u884c\u3002", "conclusion": "nFlows\u586b\u8865\u4e86\u73b0\u6709\u5de5\u4f5c\u6d41\u8c03\u5ea6\u7b56\u7565\uff08\u591a\u6e90\u4e8eGrid/Cloud\u73af\u5883\uff09\u7f3a\u4e4f\u5bf9NUMA\u67b6\u6784\u8003\u8651\u7684\u7a7a\u767d\uff0c\u4e3a\u6570\u636e\u5bc6\u96c6\u578b\u5de5\u4f5c\u6d41\u5728\u57fa\u4e8eNUMA\u7684HPC\u7cfb\u7edf\u4e0a\u7684\u5efa\u6a21\u3001\u88f8\u673a\u6267\u884c\u3001\u4eff\u771f\u548c\u8c03\u5ea6\u7b97\u6cd5\u8bbe\u8ba1\u4e0e\u9a8c\u8bc1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u6709\u6548\u89e3\u51b3\u4e86NUMA\u67b6\u6784\u5e26\u6765\u7684\u8bbf\u5b58\u590d\u6742\u6027\u548c\u8c03\u5ea6\u6311\u6218\u3002"}}
{"id": "2511.19949", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.19949", "abs": "https://arxiv.org/abs/2511.19949", "authors": ["Qingda Hu", "Xinjun Yang", "Feifei Li", "Junru Li", "Ya Lin", "Yuqi Zhou", "Yicong Zhu", "Junwei Zhang", "Rongbiao Xie", "Ling Zhou", "Bin Wu", "Wenchao Zhou"], "title": "PolarStore: High-Performance Data Compression for Large-Scale Cloud-Native Databases", "comment": "13 pages, accepted by FAST'26", "summary": "In recent years, resource elasticity and cost optimization have become essential for RDBMSs. While cloud-native RDBMSs provide elastic computing resources via disaggregated computing and storage, storage costs remain a critical user concern. Consequently, data compression emerges as an effective strategy to reduce storage costs. However, existing compression approaches in RDBMSs present a stark trade-off: software-based approaches incur significant performance overheads, while hardware-based alternatives lack the flexibility required for diverse database workloads. In this paper, we present PolarStore, a compressed shared storage system for cloud-native RDBMSs. PolarStore employs a dual-layer compression mechanism that combines in-storage compression in PolarCSD hardware with lightweight compression in software. This design leverages the strengths of both approaches. PolarStore also incorporates database-oriented optimizations to maintain high performance on critical I/O paths. Drawing from large-scale deployment experiences, we also introduce hardware improvements for PolarCSD to ensure host-level stability and propose a compression-aware scheduling scheme to improve cluster-level space efficiency. PolarStore is currently deployed on thousands of storage servers within PolarDB, managing over 100 PB of data. It achieves a compression ratio of 3.55 and reduces storage costs by approximately 60%. Remarkably, these savings are achieved while maintaining performance comparable to uncompressed clusters.", "AI": {"tldr": "This paper is related to **compiler** (in a broad sense as the system involves low-level optimization for a database system) and **graph processing** (not directly, but RDBMS and data management are related to large-scale data structures which can be represented as graphs). The paper presents PolarStore, a compressed shared storage system for cloud-native RDBMSs, which uses a dual-layer compression mechanism with dedicated CSD hardware and software-based compression, along with database-oriented optimizations and compression-aware scheduling. Deployed in PolarDB, it achieves a 3.55 compression ratio and 60% storage cost reduction while maintaining uncompressed performance.", "motivation": "\u4e91\u539f\u751fRDBMS\u901a\u8fc7\u8ba1\u7b97\u548c\u5b58\u50a8\u5206\u79bb\u5b9e\u73b0\u8ba1\u7b97\u8d44\u6e90\u7684\u5f39\u6027\uff0c\u4f46\u5b58\u50a8\u6210\u672c\u4ecd\u662f\u7528\u6237\u5173\u6ce8\u7684\u7126\u70b9\u3002\u6570\u636e\u538b\u7f29\u662f\u964d\u4f4e\u5b58\u50a8\u6210\u672c\u7684\u6709\u6548\u7b56\u7565\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684RDBMS\u538b\u7f29\u65b9\u6cd5\u5b58\u5728\u5f0a\u7aef\uff1a\u8f6f\u4ef6\u65b9\u6cd5\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u5f00\u9500\uff0c\u800c\u786c\u4ef6\u65b9\u6cd5\u7f3a\u4e4f\u5e94\u5bf9\u591a\u6837\u5316\u6570\u636e\u5e93\u5de5\u4f5c\u8d1f\u8f7d\u6240\u9700\u7684\u7075\u6d3b\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u6709\u6548\u538b\u7f29\u6570\u636e\uff0c\u53c8\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\u548c\u7075\u6d3b\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86PolarStore\uff0c\u4e00\u4e2a\u4e3a\u4e91\u539f\u751fRDBMS\u8bbe\u8ba1\u7684\u538b\u7f29\u5171\u4eab\u5b58\u50a8\u7cfb\u7edf\u3002\u65b9\u6cd5\u7684\u6838\u5fc3\u662f\uff1a1. \u91c7\u7528\u53cc\u5c42\u538b\u7f29\u673a\u5236\uff0c\u7ed3\u5408PolarCSD\u786c\u4ef6\u7684\u5b58\u50a8\u5185\u538b\u7f29\u548c\u8f6f\u4ef6\u4e2d\u7684\u8f7b\u91cf\u7ea7\u538b\u7f29\u30022. \u6574\u5408\u9762\u5411\u6570\u636e\u5e93\u7684\u4f18\u5316\uff0c\u4ee5\u5728\u5173\u952eI/O\u8def\u5f84\u4e0a\u4fdd\u6301\u9ad8\u6027\u80fd\u30023. \u5f15\u5165PolarCSD\u7684\u786c\u4ef6\u6539\u8fdb\uff0c\u4ee5\u786e\u4fdd\u4e3b\u673a\u7ea7\u7a33\u5b9a\u6027\u30024. \u63d0\u51fa\u538b\u7f29\u611f\u77e5\u8c03\u5ea6\u65b9\u6848\uff0c\u4ee5\u63d0\u9ad8\u96c6\u7fa4\u7ea7\u7a7a\u95f4\u6548\u7387\u3002", "result": "PolarStore\u5728PolarDB\u5185\u90e8\u7f72\u4e8e\u6570\u5343\u4e2a\u5b58\u50a8\u670d\u52a1\u5668\u4e0a\uff0c\u7ba1\u7406\u7740\u8d85\u8fc7100 PB\u7684\u6570\u636e\u3002\u5b83\u5728\u4fdd\u6301\u4e0e\u672a\u538b\u7f29\u96c6\u7fa4\u76f8\u5f53\u7684\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e863.55\u7684\u538b\u7f29\u6bd4\uff0c\u5e76\u5c06\u5b58\u50a8\u6210\u672c\u964d\u4f4e\u4e86\u5927\u7ea660%\u3002", "conclusion": "PolarStore\u5728\u963f\u91cc\u4e91\u7684PolarDB\u4e2d\u5f97\u5230\u4e86\u5927\u89c4\u6a21\u90e8\u7f72\uff0c\u7ba1\u7406\u7740\u8d85\u8fc7100PB\u7684\u6570\u636e\u3002\u5b83\u5b9e\u73b0\u4e863.55\u7684\u538b\u7f29\u6bd4\uff0c\u964d\u4f4e\u4e86\u5927\u7ea660%\u7684\u5b58\u50a8\u6210\u672c\uff0c\u540c\u65f6\u6027\u80fd\u4e0e\u672a\u538b\u7f29\u96c6\u7fa4\u76f8\u5f53\u3002\u8fd9\u8bc1\u660e\u4e86PolarStore\u4f5c\u4e3a\u4e00\u79cd\u6709\u6548\u964d\u4f4e\u4e91\u539f\u751fRDBMS\u5b58\u50a8\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\u7684\u5b9e\u7528\u6027\u548c\u4f18\u8d8a\u6027\u3002"}}
{"id": "2511.20100", "categories": ["cs.DC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.20100", "abs": "https://arxiv.org/abs/2511.20100", "authors": ["Xinguo Zhu", "Shaohui Peng", "Jiaming Guo", "Yunji Chen", "Qi Guo", "Yuanbo Wen", "Hang Qin", "Ruizhi Chen", "Qirui Zhou", "Ke Gao", "Yanjun Wu", "Chen Zhao", "Ling Li"], "title": "QiMeng-Kernel: Macro-Thinking Micro-Coding Paradigm for LLM-Based High-Performance GPU Kernel Generation", "comment": "9 pages, 2 figures, accepted by AAAI 2026", "summary": "Developing high-performance GPU kernels is critical for AI and scientific computing, but remains challenging due to its reliance on expert crafting and poor portability. While LLMs offer promise for automation, both general-purpose and finetuned LLMs suffer from two fundamental and conflicting limitations: correctness and efficiency. The key reason is that existing LLM-based approaches directly generate the entire optimized low-level programs, requiring exploration of an extremely vast space encompassing both optimization policies and implementation codes. To address the challenge of exploring an intractable space, we propose Macro Thinking Micro Coding (MTMC), a hierarchical framework inspired by the staged optimization strategy of human experts. It decouples optimization strategy from implementation details, ensuring efficiency through high-level strategy and correctness through low-level implementation. Specifically, Macro Thinking employs reinforcement learning to guide lightweight LLMs in efficiently exploring and learning semantic optimization strategies that maximize hardware utilization. Micro Coding leverages general-purpose LLMs to incrementally implement the stepwise optimization proposals from Macro Thinking, avoiding full-kernel generation errors. Together, they effectively navigate the vast optimization space and intricate implementation details, enabling LLMs for high-performance GPU kernel generation. Comprehensive results on widely adopted benchmarks demonstrate the superior performance of MTMC on GPU kernel generation in both accuracy and running time. On KernelBench, MTMC achieves near 100% and 70% accuracy at Levels 1-2 and 3, over 50% than SOTA general-purpose and domain-finetuned LLMs, with up to 7.3x speedup over LLMs, and 2.2x over expert-optimized PyTorch Eager kernels. On the more challenging TritonBench, MTMC attains up to 59.64% accuracy and 34x speedup.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001HLS\u3001\u56fe\u5904\u7406\u3001DSL \u548c MLIR \u76f8\u5173\u3002\u5b83\u6d89\u53ca\u9ad8\u6027\u80fd GPU \u5185\u6838\u751f\u6210\uff0c\u5c5e\u4e8e\u7f16\u8bd1\u5668\u4f18\u5316\u548c HLS \u7684\u8303\u7574\u3002\n\n**TLDR \u6458\u8981:** \u9488\u5bf9\u73b0\u6709 LLM \u76f4\u63a5\u751f\u6210\u9ad8\u6027\u80fd GPU \u5185\u6838\u65f6\u5728\u6b63\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u8868\u73b0\u51fa\u7684\u5c40\u9650\u6027\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Macro Thinking Micro Coding (MTMC) \u7684\u5206\u5c42\u6846\u67b6\u3002\u8be5\u6846\u67b6\u5c06\u4f18\u5316\u7b56\u7565\u4e0e\u5b9e\u73b0\u7ec6\u8282\u89e3\u8026\uff0c\u5176\u4e2d\u201c\u5b8f\u89c2\u601d\u8003\u201d\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u6307\u5bfc\u7684\u8f7b\u91cf\u7ea7 LLM \u5b66\u4e60\u9ad8\u6548\u7684\u4f18\u5316\u7b56\u7565\uff0c\u201c\u5fae\u89c2\u7f16\u7801\u201d\u5229\u7528\u901a\u7528 LLM \u589e\u91cf\u5b9e\u73b0\u8fd9\u4e9b\u7b56\u7565\u4ee5\u786e\u4fdd\u6b63\u786e\u6027\u3002MTMC \u6709\u6548\u5730\u5bfc\u822a\u4e86\u5de8\u5927\u7684\u4f18\u5316\u7a7a\u95f4\uff0c\u5e76\u5728 KernelBench \u548c TritonBench \u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5b83\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u4e0a\u5747\u8d85\u8d8a\u4e86\u73b0\u6709\u7684 SOTA LLM \u548c\u4e13\u5bb6\u4f18\u5316\u5185\u6838\u3002", "motivation": "\u5f00\u53d1\u9ad8\u6027\u80fd GPU \u5185\u6838\u5bf9\u4e8e AI \u548c\u79d1\u5b66\u8ba1\u7b97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f53\u524d\u7684\u6311\u6218\u5728\u4e8e\u8fd9\u901a\u5e38\u4f9d\u8d56\u4e8e\u4e13\u5bb6\u624b\u5de5\u5236\u4f5c\u4e14\u53ef\u79fb\u690d\u6027\u5dee\u3002\u5c3d\u7ba1 LLM \u5728\u81ea\u52a8\u5316\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u73b0\u6709\u7684\u901a\u7528\u548c\u5fae\u8c03 LLM \u5728\u5185\u6838\u751f\u6210\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5373\u96be\u4ee5\u540c\u65f6\u4fdd\u8bc1**\u6b63\u786e\u6027**\u548c**\u6548\u7387**\u3002\u6839\u672c\u539f\u56e0\u5728\u4e8e\u73b0\u6709\u65b9\u6cd5\u76f4\u63a5\u751f\u6210\u6574\u4e2a\u4f18\u5316\u7684\u4f4e\u7ea7\u7a0b\u5e8f\uff0c\u9700\u8981\u5728\u5305\u542b\u4f18\u5316\u7b56\u7565\u548c\u5b9e\u73b0\u4ee3\u7801\u7684\u5de8\u5927\u7a7a\u95f4\u4e2d\u8fdb\u884c\u63a2\u7d22\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u5e94\u5bf9\u63a2\u7d22\u8fd9\u4e00\u68d8\u624b\u7a7a\u95f4\u7684\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86 Macro Thinking Micro Coding (MTMC) \u5206\u5c42\u6846\u67b6\u3002\u5b83\u5c06\u4f18\u5316\u7b56\u7565\u4e0e\u5b9e\u73b0\u7ec6\u8282\u89e3\u8026\u3002**\u5b8f\u89c2\u601d\u8003\uff08Macro Thinking\uff09**\u5229\u7528\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u6765\u6307\u5bfc\u8f7b\u91cf\u7ea7 LLM \u6709\u6548\u63a2\u7d22\u548c\u5b66\u4e60\u8bed\u4e49\u4f18\u5316\u7b56\u7565\uff0c\u4ee5\u6700\u5927\u5316\u786c\u4ef6\u5229\u7528\u7387\u3002**\u5fae\u89c2\u7f16\u7801\uff08Micro Coding\uff09**\u5229\u7528\u901a\u7528 LLM 0\u589e\u91cf\u5730\u5b9e\u73b0\u5b8f\u89c2\u601d\u8003\u63d0\u51fa\u7684\u9010\u6b65\u4f18\u5316\u5efa\u8bae\uff0c\u907f\u514d\u4e86\u5168\u5185\u6838\u751f\u6210\u9519\u8bef\u3002\u8fd9\u79cd\u5206\u7ea7\u65b9\u6cd5\u65e8\u5728\u89e3\u51b3\u73b0\u6709 LLM \u76f4\u63a5\u751f\u6210\u4f4e\u7ea7\u4f18\u5316\u7a0b\u5e8f\u65f6\u9762\u4e34\u7684\u6b63\u786e\u6027\u548c\u6548\u7387\u95ee\u9898\u3002", "result": "MTMC \u5728\u5e7f\u6cdb\u91c7\u7528\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\u65b9\u9762\u3002\n*   \u5728 KernelBench \u4e0a\uff0cMTMC \u5728 Level 1-2 \u548c Level 3 \u4e0a\u7684\u51c6\u786e\u7387\u63a5\u8fd1 100% \u548c 70%\uff0c\u6bd4 SOTA \u7684\u901a\u7528\u548c\u9886\u57df\u5fae\u8c03 LLM \u9ad8\u51fa 50% \u4ee5\u4e0a\u3002\n*   \u8fd0\u884c\u65f6\u95f4\u65b9\u9762\uff0cMTMC \u6bd4 LLM \u5feb\u8fbe 7.3 \u500d\uff0c\u6bd4\u4e13\u5bb6\u4f18\u5316\u7684 PyTorch Eager \u5185\u6838\u5feb\u8fbe 2.2 \u500d\u3002\n*   \u5728\u66f4\u5177\u6311\u6218\u6027\u7684 TritonBench \u4e0a\uff0cMTMC \u7684\u51c6\u786e\u7387\u9ad8\u8fbe 59.64%\uff0c\u901f\u5ea6\u63d0\u9ad8 34 \u500d\u3002\n\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e MTMC \u6210\u529f\u5730\u89e3\u51b3\u4e86\u73b0\u6709 LLM \u65b9\u6cd5\u5728\u9ad8\u6027\u80fd GPU \u5185\u6838\u751f\u6210\u4e2d\u7684\u5c40\u9650\u6027\u3002", "conclusion": "MTMC \u662f\u4e00\u79cd\u53d7\u4eba\u7c7b\u4e13\u5bb6\u5206\u9636\u6bb5\u4f18\u5316\u7b56\u7565\u542f\u53d1\u7684\u5206\u5c42\u6846\u67b6\uff0c\u5b83\u5c06\u4f18\u5316\u7b56\u7565\u4e0e\u5b9e\u73b0\u7ec6\u8282\u89e3\u8026\u3002\u901a\u8fc7\u5b8f\u89c2\u601d\u8003\uff08RL \u6307\u5bfc\u7684\u8f7b\u91cf\u7ea7 LLM\uff09\u548c\u5fae\u89c2\u7f16\u7801\uff08\u901a\u7528 LLM \u589e\u91cf\u5b9e\u73b0\uff09\u7684\u7ed3\u5408\uff0cMTMC \u80fd\u591f\u9ad8\u6548\u5730\u63a2\u7d22\u4f18\u5316\u7a7a\u95f4\u5e76\u786e\u4fdd\u5b9e\u73b0\u7684\u6b63\u786e\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86 MTMC \u5728 GPU \u5185\u6838\u751f\u6210\u65b9\u9762\u7684\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8fd0\u884c\u65f6\u95f4\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7684 SOTA \u901a\u7528\u548c\u9886\u57df\u5fae\u8c03 LLM\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86\u4e13\u5bb6\u4f18\u5316\u7684 PyTorch Eager \u5185\u6838\u3002"}}
{"id": "2511.20172", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.20172", "abs": "https://arxiv.org/abs/2511.20172", "authors": ["Xinjun Yang", "Qingda Hu", "Junru Li", "Feifei Li", "Yuqi Zhou", "Yicong Zhu", "Qiuru Lin", "Jian Dai", "Yang Kong", "Jiayu Zhang", "Guoqiang Xu", "Qiang Liu"], "title": "Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management", "comment": "13 pages, accepted by SIGMOD'26", "summary": "The rapid increase in LLM model sizes and the growing demand for long-context inference have made memory a critical bottleneck in GPU-accelerated serving systems. Although high-bandwidth memory (HBM) on GPUs offers fast access, its limited capacity necessitates reliance on host memory (CPU DRAM) to support larger working sets such as the KVCache. However, the maximum DRAM capacity is constrained by the limited number of memory channels per CPU socket. To overcome this limitation, current systems often adopt RDMA-based disaggregated memory pools, which introduce significant challenges including high access latency, complex communication protocols, and synchronization overhead. Fortunately, the emerging CXL technology introduces new opportunities in KVCache design. In this paper, we propose Beluga, a novel memory architecture that enables GPUs and CPUs to access a shared, large-scale memory pool through CXL switches. By supporting native load/store access semantics over the CXL fabric, our design delivers near-local memory latency, while reducing programming complexity and minimizing synchronization overhead. We conduct a systematic characterization of a commercial CXL switch-based memory pool and propose a set of design guidelines. Based on Beluga, we design and implement Beluga-KVCache, a system tailored for managing the large-scale KVCache in LLM inference. Beluga-KVCache achieves an 89.6% reduction in Time-To-First-Token (TTFT) and 7.35x throughput improvement in the vLLM inference engine compared to RDMA-based solutions. To the best of our knowledge, Beluga is the first system that enables GPUs to directly access large-scale memory pools through CXL switches, marking a significant step toward low-latency, shared access to vast memory resources by GPUs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6d89\u53ca\u56fe\u5904\u7406/DSL/MLIR/\u7f16\u8bd1\u5668/HLS\u5417\uff1f\u4e0d\u76f8\u5173\u3002\n\u592a\u957f\u4e0d\u770b\u6458\u8981\uff1a\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86Beluga\uff0c\u4e00\u4e2a\u5229\u7528CXL\u4ea4\u6362\u673a\u4e3aGPU\u548cCPU\u63d0\u4f9b\u5171\u4eab\u3001\u5927\u89c4\u6a21\u5185\u5b58\u6c60\u7684\u65b0\u578b\u5185\u5b58\u67b6\u6784\uff0c\u65e8\u5728\u89e3\u51b3LLM\u5927\u6a21\u578b\u63a8\u7406\u4e2dKVCache\u5bfc\u81f4\u7684\u5185\u5b58\u74f6\u9888\u3002Beluga\u652f\u6301\u539f\u751f\u7684load/store\u8bed\u4e49\uff0c\u63d0\u4f9b\u63a5\u8fd1\u672c\u5730\u5185\u5b58\u7684\u4f4e\u5ef6\u8fdf\u8bbf\u95ee\uff0c\u5e76\u51cf\u5c11\u4e86\u7f16\u7a0b\u548c\u540c\u6b65\u590d\u6742\u6027\u3002\u57fa\u4e8eBeluga\uff0c\u4f5c\u8005\u5b9e\u73b0\u4e86Beluga-KVCache\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5728vLLM\u63a8\u7406\u4e2d\uff0c\u76f8\u8f83\u4e8e\u57fa\u4e8eRDMA\u7684\u65b9\u6848\uff0c\u5c06\u9996\u4e2aToken\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u964d\u4f4e\u4e8689.6%\uff0c\u541e\u5410\u91cf\u63d0\u9ad8\u4e867.35\u500d\u3002", "motivation": "\u968f\u7740LLM\u6a21\u578b\u89c4\u6a21\u7684\u4e0d\u65ad\u589e\u52a0\u548c\u5bf9\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u9700\u6c42\u7684\u589e\u957f\uff0c\u5185\u5b58\u5df2\u6210\u4e3aGPU\u52a0\u901f\u670d\u52a1\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u74f6\u9888\u3002GPU\u4e0a\u7684HBM\u5bb9\u91cf\u6709\u9650\uff0c\u5bfc\u81f4KVCache\u7b49\u5927\u578b\u5de5\u4f5c\u96c6\u5fc5\u987b\u4f9d\u8d56\u4e3b\u673a\u5185\u5b58\uff08CPU DRAM\uff09\u3002\u7136\u800c\uff0cCPU DRAM\u7684\u5bb9\u91cf\u53d7\u5230\u6bcf\u4e2aCPU\u63d2\u69fd\u5185\u5b58\u901a\u9053\u6570\u91cf\u7684\u9650\u5236\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5982\u57fa\u4e8eRDMA\u7684\u5185\u5b58\u6c60\u89e3\u8026\uff0c\u5f15\u5165\u4e86\u9ad8\u8bbf\u95ee\u5ef6\u8fdf\u3001\u590d\u6742\u7684\u901a\u4fe1\u534f\u8bae\u548c\u540c\u6b65\u5f00\u9500\u3002\u65b0\u5174\u7684CXL\u6280\u672f\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Beluga\u5185\u5b58\u67b6\u6784\uff0c\u5b83\u5141\u8bb8GPU\u548cCPU\u901a\u8fc7CXL\u4ea4\u6362\u673a\u8bbf\u95ee\u4e00\u4e2a\u5171\u4eab\u7684\u3001\u5927\u89c4\u6a21\u5185\u5b58\u6c60\u3002Beluga\u652f\u6301\u539f\u751f\u7684load/store\u8bbf\u95ee\u8bed\u4e49\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u672c\u5730\u5185\u5b58\u7684\u5ef6\u8fdf\uff0c\u5e76\u7b80\u5316\u4e86\u7f16\u7a0b\u548c\u540c\u6b65\u5f00\u9500\u3002\u4f5c\u8005\u5bf9\u4e00\u4e2a\u5546\u7528CXL\u4ea4\u6362\u673a\u5185\u5b58\u6c60\u8fdb\u884c\u4e86\u7cfb\u7edf\u6027\u7684\u7279\u6027\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u5957\u8bbe\u8ba1\u6307\u5357\u3002\u57fa\u4e8eBeluga\uff0c\u4ed6\u4eec\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86Beluga-KVCache\u7cfb\u7edf\uff0c\u7528\u4e8e\u7ba1\u7406LLM\u63a8\u7406\u4e2d\u7684\u5927\u89c4\u6a21KVCache\u3002", "result": "Beluga-KVCache\uff08\u57fa\u4e8e\u6240\u63d0\u51fa\u7684Beluga\u5185\u5b58\u67b6\u6784\uff09\u5728vLLM\u63a8\u7406\u5f15\u64ce\u4e2d\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u57fa\u4e8eRDMA\u7684\u89e3\u51b3\u65b9\u6848\u3002\u5b83\u5b9e\u73b0\u4e86\u9996\u4e2aToken\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u964d\u4f4e89.6%\uff0c\u541e\u5410\u91cf\u63d0\u9ad8\u4e867.35\u500d\u3002", "conclusion": "Beluga\u662f\u9996\u4e2a\u5b9e\u73b0GPU\u901a\u8fc7CXL\u4ea4\u6362\u673a\u76f4\u63a5\u8bbf\u95ee\u5927\u89c4\u6a21\u5185\u5b58\u6c60\u7684\u7cfb\u7edf\uff0c\u5b83\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u5ef6\u8fdf\u3001\u5171\u4eab\u8bbf\u95ee\u5927\u5bb9\u91cf\u5185\u5b58\u8d44\u6e90\u7684\u65b0\u8303\u5f0f\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u5bf9\u4e8e\u57fa\u4e8eRDMA\u7684\u89e3\u51b3\u65b9\u6848\uff0cBeluga-KVCache\u5728vLLM\u63a8\u7406\u5f15\u64ce\u4e2d\u5c06\u9996\u4e2aToken\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u964d\u4f4e\u4e8689.6%\uff0c\u541e\u5410\u91cf\u63d0\u9ad8\u4e867.35\u500d\u3002"}}
