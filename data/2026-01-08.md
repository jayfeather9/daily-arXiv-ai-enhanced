<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 4]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.PL](#cs.PL) [Total: 3]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Optimizing Exact String Matching via Statistical Anchoring](https://arxiv.org/abs/2601.03271)
*Omar Garraoui*

Main category: cs.DS

TL;DR: Paper-related: Compiler (String pattern matching is a fundamental operation often utilized in text processing tools which are integral to compilation, though the paper is primarily focused on algorithm optimization).
Summary: 本文提出了一种针对自然语言文本优化的Boyer-Moore-Horspool字符串匹配算法增强方案。该方法通过预处理搜索模式，识别出统计上最不频繁的字符作为“锚点”，并在搜索过程中优先验证此高熵锚点位置，实现“快速失败”策略，从而减少不必要的比较并提升匹配效率，且不增加移位启发式的复杂性。


<details>
  <summary>Details</summary>
Motivation: 提升针对自然语言文本的字符串匹配（模式匹配）算法的效率，特别是优化Boyer-Moore-Horspool算法，通过引入基本的语言学统计信息以减少不必要的字符比较。

Method: 本文通过在搜索模式中识别出统计上最不频繁的字符（称为“锚点”），并在搜索过程中首先验证这个高熵位置，从而实现快速失败（fail-fast）策略，减少不必要的比较，提升效率。该方法是基于对自然语言文本的基本语言学统计信息的整合来实现的。

Result: 所提出的增强型Boyer-Moore-Horspool算法在不增加移位启发式（shift heuristics）的复杂性的情况下，通过整合基本的语言学统计信息，提高了整体性能。

Conclusion: 本文提出了一种利用统计语言学知识优化字符串匹配算法的有效方法，即通过识别并利用搜索模式中最不频繁字符作为锚点，实现了在不增加底层算法复杂性的情况下提升了Boyer-Moore-Horspool算法的性能。

Abstract: In this work, we propose an enhancement to the Boyer-Moore-Horspool algorithm tailored for natural language text. The approach involves preprocessing the search pattern to identify its statistically least frequent character, referred to as the "anchor." During the search, verification is first performed at this high-entropy position, allowing the algorithm to quickly discard non-matching windows. This fail-fast strategy reduces unnecessary comparisons, improving overall efficiency. Our implementation shows that incorporating basic linguistic statistics into classical pattern-matching techniques can boost performance without increasing complexity to the shift heuristics.

</details>


### [2] [Counting hypertriangles through hypergraph orientations](https://arxiv.org/abs/2601.03573)
*Daniel Paul-Pena,Vaishali Surianarayanan,Deeparnab Chakrabarty,C. Seshadhri*

Main category: cs.DS

TL;DR: This paper is related to graph processing (hypergraph motif counting). 
此论文探讨了超图中的同构模式计数问题，特别是计数超三角形。研究人员基于图论中方向和退化性的经典算法，提出了一个通用到超图的理论框架，并基于此设计了高效且内存友好的DITCH算法。实验结果表明，DITCH相较于现有最先进的方法，在速度上提高了10到100倍。


<details>
  <summary>Details</summary>
Motivation: 虽然图中的小模式计数问题已经被充分研究，但许多真实世界的数据集更自然地被建模为超图，这促使人们需要高效的超图同构模式计数算法。本文专注于研究计算超三角形的数量，即三个两两相交的超边的集合。与图三角形不同，这些超图模式具有丰富的结构和多种不同的相交模式。

Method: 受到经典的图算法中方向和退化性概念的启发，本文开发了一个理论框架，将这些概念推广到超图上，并产生了可证明的超三角形计数算法。基于这些思想，作者实现了DITCH（Degeneracy Inspired Triangle Counter for Hypergraphs）算法。

Result: 实现的DITCH算法在实验中证明比现有最先进的方法快10-100倍，并且内存效率更高。

Conclusion: 本文提出了DITCH算法，这是一种基于超图方向和退化性的理论框架，用于高效地计算超图中的同构模式（特别是超三角形）。实验证明，DITCH比现有最先进的方法快10-100倍，并且内存效率更高。

Abstract: Counting the number of small patterns is a central task in network analysis. While this problem is well studied for graphs, many real-world datasets are naturally modeled as hypergraphs, motivating the need for efficient hypergraph motif counting algorithms. In particular, we study the problem of counting hypertriangles - collections of three pairwise-intersecting hyperedges. These hypergraph patterns have a rich structure with multiple distinct intersection patterns unlike graph triangles.
  Inspired by classical graph algorithms based on orientations and degeneracy, we develop a theoretical framework that generalizes these concepts to hypergraphs and yields provable algorithms for hypertriangle counting. We implement these ideas in DITCH (Degeneracy Inspired Triangle Counter for Hypergraphs) and show experimentally that it is 10-100x faster and more memory efficient than existing state-of-the-art methods.

</details>


### [3] [On $k$-connectivity oracles in $k$-connected graphs](https://arxiv.org/abs/2601.03643)
*Zeev Nutov*

Main category: cs.DS

TL;DR: 该论文与图处理（Graph Processing）相关。它涉及图连通性预言机的数据结构和空间复杂度的下限。
TLDR: $k$-连通性预言机是一种数据结构，用于查询图$G$中给定$s,t$之间是否存在至少$k+1$条内部不相交的路径。STOC 2022的一项工作证明了这类预言机需要$\Omega(kn)$位的空间，并提出了一个开放问题：如果图$G$本身就是$k$-连通的，是否仍然需要$\Omega(kn)$位的空间？本文通过一个非常简单的证明，肯定地回答了这个问题，证明了即使图$G$是$k$-连通的，空间下限$\Omega(kn)$仍然是必要的。


<details>
  <summary>Details</summary>
Motivation: 现有的在无向图上研究$k$-连通性预言机的工作发现，其需要$\Omega(kn)$位的空间。针对这一结果，Pettie, Saranurak & Yin (STOC 2022) 提出了一个开放性问题：如果图$G$本身已经是$k$-连通的，是否仍然需要$\Omega(kn)$位的空间？本文的动机即在于回答这一开放问题。

Method: 本文通过一个非常简单的证明，证明了即使图$G$已经是$k$-连通的，任何$k$-连通性预言机仍需要$\Omega(kn)$位的空间。该方法直接回答了STOC 2022论文中提出的开放问题。

Result: 证明了即使图$G$是$k$-连通的，任何$k$-连通性预言机仍需要$\Omega(kn)$位的空间，从而确认了STOC 2022年论文中提出的空间下限$\Omega(kn)$在$G$是$k$-连通的情况下仍然成立。

Conclusion: 本文证明了$k$-连通性预言机在图$G$已经$k$-连通的情况下，仍然需要$\Omega(kn)$位的空间复杂度，从而回答了STOC 2022论文中提出的开放性问题。这一结果表明，即使图本身具有较高的连通性，对于任意一对顶点查询其连通度时，所需的空间复杂度的下限并不会降低。

Abstract: A $k$-connectivity oracle for a graph $G=(V,E)$ is a data structure that given $s,t \in V$ determines whether there are at least $k+1$ internally disjoint $st$-paths in $G$. For undirected graphs, Pettie, Saranurak & Yin [STOC 2022, pp. 151-161] proved that any $k$-connectivity oracle requires $Ω(kn)$ bits of space. They asked whether $Ω(kn)$ bits are still necessary if $G$ is $k$-connected. We will show by a very simple proof that this is so even if $G$ is $k$-connected, answering this open question.

</details>


### [4] [A Polynomial Kernel for Face Cover on Non-Embedded Planar Graphs](https://arxiv.org/abs/2601.04169)
*Thekla Hamm,Sukanya Pandey,Krisztina Szilágyi*

Main category: cs.DS

TL;DR: 与DSL、图处理、MLIR、编译器或HLS相关吗：与**图处理**相关，因为它涉及平面图的结构分析和图算法（面覆盖数问题）。
太长不读（tldr）：当输入是一个任意平面图（没有固定嵌入）时，“面覆盖数问题”以前没有多项式内核。本文首次通过在SPR-tree上自底向上构建内核的方法，解决了这一挑战，并提供了一个多项式内核。


<details>
  <summary>Details</summary>
Motivation: 现有的“面覆盖数问题”的多项式内核仅适用于输入是已给定固定嵌入的平面图（即平面图），而对于输入是任意平面图（即没有固定嵌入的平面图），寻找其多项式内核仍然是一个未解决的挑战。因此，本文旨在为非固定嵌入的平面图的“面覆盖数问题”提供第一个多项式内核。

Method: 作者通过建立一个自底向上的SPR-tree结构，并在构建过程中保持面覆盖的基本属性，从而克服了没有预定义面边界集的挑战，最终实现了没有固定嵌入的平面图的面覆盖数问题的多项式内核。

Result: 本文成功地为以任意平面图为输入的“面覆盖数问题”提供了第一个多项式内核。

Conclusion: 本文解决了“面覆盖数问题”在输入为任意平面图（而非固定的平面嵌入图）时，其是否具有多项式内核的问题，并成功地给出了一个多项式内核。这扩展了之前在固定嵌入上的已知结果。

Abstract: Given a planar graph, a subset of its vertices called terminals, and $k \in \mathbb{N}$, the Face Cover Number problem asks whether the terminals lie on the boundaries of at most $k$ faces of some embedding of the input graph. When a plane graph is given in the input, the problem is known to have a polynomial kernel~\cite{GarneroST17}. In this paper, we present the first polynomial kernel for Face Cover Number when the input is a planar graph (without a fixed embedding). Our approach overcomes the challenge of not having a predefined set of face boundaries by building a kernel bottom-up on an SPR-tree while preserving the essential properties of the face cover along the way.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [5] [A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems](https://arxiv.org/abs/2601.03992)
*Qi Wu,Chao Fang,Jiayuan Chen,Ye Lin,Yueqi Zhang,Yichuan Bai,Yuan Du,Li Du*

Main category: cs.DC

TL;DR: 该论文与编译器（广义上的模型优化和部署框架）相关，因为它专注于优化模型（MoE）在特定硬件（GPU-NDP系统）上的推理效率，涉及并行化、调度和资源管理。不过，与HLS和MLIR的关系不甚明确，与DSL和图处理的关系则没有提及。太长不读：本文提出了一个高效的MoE模型推理框架，用于解决在GPU-NDP系统上部署时面临的负载不平衡、GPU利用率不足和预取难题。通过利用张量并行、提出负载均衡调度算法和数据集无关的预取策略，该框架实现了相较于现有技术平均2.41倍的端到端延迟加速，显著提升了资源受限环境下的MoE推理效率。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE模型通过将模型容量与实际计算解耦从而有利于边缘部署，但其巨大的内存占用要求使用具备近数据处理（NDP）能力的GPU系统。然而，在GPU-NDP系统上部署MoE模型面临三大挑战：1) 由于非统一的专家选择和专家并行性导致的NDP单元间严重的负载不平衡。2) NDP单元内的专家计算过程中GPU利用率不足。3) 由于不可预测的专家激活模式，预取需要大量的数据预分析。

Method: 本文提出了一个高效的推理框架，包含三个关键优化：1) 利用张量并行性在多个NDP单元上同时划分和计算大型专家参数，以适应边缘低批次场景。2) 设计了负载均衡感知的调度算法，将专家计算分布到NDP单元和GPU，以最大化资源利用率。3) 采用了数据集无关的预取策略，主动加载频繁访问的专家，以最小化激活延迟。

Result: 实验结果表明，本文提出的框架使GPU-NDP系统在端到端延迟方面比现有最先进方法平均提高了2.41倍，最高达到2.56倍的加速，显著增强了MoE在资源受限环境中的推理效率。

Conclusion: 本文提出的框架通过利用张量并行、设计负载均衡调度算法和采用数据集无关的预取策略，显著提升了MoE模型在GPU-NDP系统上的推理效率，实现了平均2.41倍、最高2.56倍的端到端延迟加速，证明了其在资源受限边缘环境中的优越性。

Abstract: Mixture-of-Experts (MoE) models facilitate edge deployment by decoupling model capacity from active computation, yet their large memory footprint drives the need for GPU systems with near-data processing (NDP) capabilities that offload experts to dedicated processing units. However, deploying MoE models on such edge-based GPU-NDP systems faces three critical challenges: 1) severe load imbalance across NDP units due to non-uniform expert selection and expert parallelism, 2) insufficient GPU utilization during expert computation within NDP units, and 3) extensive data pre-profiling necessitated by unpredictable expert activation patterns for pre-fetching. To address these challenges, this paper proposes an efficient inference framework featuring three key optimizations. First, the underexplored tensor parallelism in MoE inference is exploited to partition and compute large expert parameters across multiple NDP units simultaneously towards edge low-batch scenarios. Second, a load-balancing-aware scheduling algorithm distributes expert computations across NDP units and GPU to maximize resource utilization. Third, a dataset-free pre-fetching strategy proactively loads frequently accessed experts to minimize activation delays. Experimental results show that our framework enables GPU-NDP systems to achieve 2.41x on average and up to 2.56x speedup in end-to-end latency compared to state-of-the-art approaches, significantly enhancing MoE inference efficiency in resource-constrained environments.

</details>


### [6] [Failure-Resilient and Carbon-Efficient Deployment of Microservices over the Cloud-Edge Continuum](https://arxiv.org/abs/2601.04123)
*Francisco Ponce,Simone Gazza,Andrea D'Iapico,Roberto Amadini,Antonio Brogi,Stefano Forti,Saverio Giallorenzo,Pierluigi Plebani,Davide Usai,Monica Vitali,Gianluigi Zavattaro,Jacopo Soldani*

Main category: cs.DC

TL;DR: 该论文与编译器、HLS、MLIR、DSL或图处理不直接相关。它关注的是微服务应用（MSA）在云边基础设施（Cloud-Edge Continuum）上的自动化部署优化。/ FREEDA工具链为微服务应用（MSA）在云边基础设施上的部署提供了一种自动化的、故障恢复且碳效率的解决方案，它能持续适应变化的环境以优化弹性、性能和可持续性，并已通过模拟和仿真场景验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在异构且动态的云边基础设施上部署基于微服务的应用（MSA）时，需要在故障恢复能力、性能和环境可持续性等相互冲突的目标之间取得平衡。

Method: FREEDA工具链采用持续适应部署配置的方法，以应对不断变化的运营条件、资源可用性和可持续性限制。它通过迁移服务、调整规格选择或重新平衡工作负载等方式，自主重新配置部署，并在实验套件中使用多样化的模拟和仿真场景进行验证。

Result: 实验结果表明，FREEDA工具链能够成功地在弹性、效率和环境影响之间实现最佳平衡。它通过自主重新配置部署（例如迁移服务、调整规格选择或重新平衡工作负载）来应对资源耗尽、节点故障和碳强度波动等挑战。

Conclusion: FREEDA工具链通过在云边基础设施上持续适配部署配置，实现了微服务应用（MSA）在弹性、性能和碳效率之间的优化平衡，并在各种具有挑战性的现实场景中得到了验证，表明它在自动化故障恢复和碳效率部署方面的有效性。

Abstract: Deploying microservice-based applications (MSAs) on heterogeneous and dynamic Cloud-Edge infrastructures requires balancing conflicting objectives, such as failure resilience, performance, and environmental sustainability. In this article, we introduce the FREEDA toolchain, designed to automate the failure-resilient and carbon-efficient deployment of MSAs over the Cloud-Edge Continuum.
  The FREEDA toolchain continuously adapts deployment configurations to changing operational conditions, resource availability, and sustainability constraints, aiming to maintain the MSA quality and service continuity while reducing carbon emissions. We also introduce an experimental suite using diverse simulated and emulated scenarios to validate the effectiveness of the toolchain against real-world challenges, including resource exhaustion, node failures, and carbon intensity fluctuations. The results demonstrate FREEDA's capability to autonomously reconfigure deployments by migrating services, adjusting flavour selections, or rebalancing workloads, successfully achieving an optimal balance among resilience, efficiency, and environmental impact.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [7] [Logic Programming with Extensible Types](https://arxiv.org/abs/2601.03836)
*Ivan Perez,Angel Herranz*

Main category: cs.PL

TL;DR: 该论文与DSL和编译器相关。

逻辑编程的声明性和简洁性未被其他编程范式广泛采用。本文提出了一种在支持静态类型的函数式编程语言（如Haskell）中整合逻辑编程的新方法，该方法通过结合可扩展类型、通用的统一算法和一个领域特定语言（DSL），在保持静态类型检查的同时，利用了函数式编程的优势。实验证明了该方法的实用性和有效性。


<details>
  <summary>Details</summary>
Motivation: 弥合逻辑编程语言（具有声明性和简洁性的优势）与其他编程范式和语言（尤其是支持静态类型的函数式编程语言）之间的鸿沟。目标是在不牺牲宿主语言的静态类型优势的同时，将逻辑编程的优点融入到现有的代码库中，并利用宿主语言（如Haskell）的多态性和高阶特性。

Method: 通过结合三种核心思想来实现：1. 使用可扩展类型（extensible types）技术，使得宿主语言（typed functional programming language）的值可以包含逻辑变量。2. 实现了一个适用于任何支持特定操作的数据结构的统一（unification）算法。3. 引入了一个领域特定语言（DSL）来定义和查询谓词（predicates）。

Result: 通过一系列示例展示了方法的有效性，并提供了辅助工具来简化用户符号，证明了所提出的方法不仅技术上可行，而且具有实用性。该方法已在Haskell语言中实现，并取得了非常好的效果。

Conclusion: 本文提出了一种在现有的、支持静态类型的函数式编程语言的代码库中整合逻辑编程的新方法，它在不牺牲静态类型优势的同时，利用了函数式编程如多态性和高阶等特性。通过结合可扩展类型、通用统一算法和一个领域特定语言，论文成功地展示了将声明性和简洁的逻辑编程引入到函数式编程环境中的可行性和实用性。他们的实现在Haskell中取得了很好的效果，证明了该方法的技术可行性和实用性。

Abstract: Logic programming languages present clear advantages in terms of declarativeness and conciseness. However, the ideas of logic programming have been met with resistance in other programming communities, and have not generally been adopted by other paradigms and languages. This paper proposes a novel way to incorporate logic programming in an existing codebase in a typed functional programming language. Our approach integrates with the host language without sacrificing static typing, and leverages strengths of typed functional programming such as polymorphism and higher-order. We do so by combining three ideas. First, we use the extensible types technique to allow values of the host language to contain logic variables. Second, we implement a unification algorithm that works for any data structure that supports certain operations.Third, we introduce a domain-specific language to define and query predicates. We demonstrate our proposal via a series of examples, and provide aids to make the notation convenient for users, showing that the proposed approach is not just technically possible but also practical. Our ideas have been implemented in the language Haskell with very good results.

</details>


### [8] [Inductive First-Order Formula Synthesis by ASP: A Case Study in Invariant Inference](https://arxiv.org/abs/2601.03854)
*Ziyi Yang,George Pîrlea,Ilya Sergey*

Main category: cs.PL

TL;DR: 该论文与编译器相关，具体来说是形式化方法和程序分析的一部分，用于不变量推理；该框架（FORCE）通过将现有的一阶逻辑（FOL）公式合成方法与答案集编程（ASP）相结合，并引入了一种名为“正交切片”的新技术来划分搜索空间和剪枝，显著加速了分布式系统不变量推理的最新算法。


<details>
  <summary>Details</summary>
Motivation: 统一并改进从示例中合成一阶逻辑（FOL）公式的现有方法，特别是为了推进过渡系统不变量推理的最新方法。

Method: 使用答案集编程（ASP）对现有的一阶逻辑公式体系统进行编码和分类。提出了一种新的公式枚举技术“正交切片”（orthogonal slices），将搜索空间划分为可管理的块，并在此基础上实现了两种增量式候选剪枝方法。将现有的一阶（FO）不变量合成技术与正交切片相结合，构建了框架FORCE。

Result: 所提出的框架FORCE显著加速了分布式系统不变量推理的最新算法。该方法有助于不同不变量推理框架的组合，从而实现新的优化。

Conclusion: 本文提出了一个基于正交切片的公式合成框架FORCE，它通过ASP实现了公式枚举和剪枝，显著加速了分布式系统不变量推理的最新算法，并促进了不同不变量推理框架的组合和优化。

Abstract: We present a framework for synthesising formulas in first-order logic (FOL) from examples, which unifies and advances state-of-the-art approaches for inference of transition system invariants. To do so, we study and categorise the existing methodologies, encoding techniques in their formula synthesis via answer set programming (ASP). Based on the derived categorisation, we propose orthogonal slices, a new technique for formula enumeration that partitions the search space into manageable chunks, enabling two approaches for incremental candidate pruning. Using a combination of existing techniques for first-order (FO) invariant synthesis and the orthogonal slices implemented in our framework FORCE, we significantly accelerate a state-of-the-art algorithm for distributed system invariant inference. We also show that our approach facilitates composition of different invariant inference frameworks, allowing for novel optimisations.

</details>


### [9] [Implementing Binary Search Trees in GP 2 (Extended Abstract)](https://arxiv.org/abs/2601.03897)
*Ziad Ismaili Alaoui,Detlef Plump*

Main category: cs.PL

TL;DR: 相关性：该论文与**图处理（Graph Processing）**相关，因为它在图编程语言GP 2中实现数据结构，使用了图转换规则。它也与**编译器（Compiler）**领域间接相关，因为图编程语言可以被视为一种高级抽象，其执行和优化与编译器技术有交叉。

太长不读：本文介绍了一种在基于规则的图编程语言GP 2中实现二叉搜索树（BST）的方法。利用GP 2的有根图转换规则，实现了插入、删除和查询操作，并论证其操作的最坏情况时间复杂度为O(n)，而平均情况下预期可达O(log n)，与命令式语言实现的BST性能相匹配。


<details>
  <summary>Details</summary>
Motivation: 主要动机是在基于规则的图编程语言GP 2中实现一种重要的数据结构——二叉搜索树（BST），并证明其性能（特别是时间复杂度）可以与命令式语言中的实现相媲美。

Method: 在GP 2中，使用有根图转换规则来实现二叉搜索树（BST），具体实现了插入（Insertion）、删除（Deletion）和查询（Query）操作。

Result: 在GP 2中成功实现了二叉搜索树（BST）的插入、删除和查询操作。研究者认为，这些操作的最坏情况运行时为O(n)，而平均情况运行时为O(log n)。这意味着在时间复杂度上，这种实现方式与命令式语言中的BST实现相匹配。

Conclusion: 本文成功地在基于规则的图编程语言GP 2中实现了二叉搜索树，并声称其最坏情况下的时间复杂度为O(n)，平均情况下为O(log n)，从而在时间复杂度上与命令式语言中的实现相匹配。这为在基于规则的图编程范式中处理和维护复杂数据结构，以及探讨其性能提供了案例。

Abstract: We present an approach to implement binary search trees in the rule-based graph programming language GP 2. Our implementation uses GP 2's rooted graph transformation rules to be fast and supports insertion, deletion and query operations. We argue that the worst-case runtime for each of the operations is O(n) for a tree with n nodes. In addition, we expect that, on average, the operations run in time O(log(n)). Hence the implementation would match the time complexity of binary search trees implementations in imperative languages.

</details>
