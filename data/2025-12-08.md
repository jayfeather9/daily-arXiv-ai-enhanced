<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 4]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.DS](#cs.DS) [Total: 2]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [NVLang: Unified Static Typing for Actor-Based Concurrency on the BEAM](https://arxiv.org/abs/2512.05224)
*Miguel de Oliveira Guerreiro*

Main category: cs.PL

TL;DR: 涉及领域：Compiler (NVLang 编译到 Core Erlang)。
总结：NVLang是一种静态类型的功能语言，旨在为基于Actor的系统（如Erlang/OTP）提供编译时的消息协议类型安全保证。它通过代数数据类型（ADTs）来编码Actor的消息协议，并引入了类型化的进程标识符（Pid[T]）和Future（Future[T]）。NVLang扩展了Hindley-Milner类型推断来跟踪消息协议，从而在保持简洁语法的同事，消除了运行时消息传递错误，并能无缝地与现有Erlang生态系统互操作。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Actor的系统（如Erlang/OTP）虽然具有极高的可靠性，擅长处理数百万并发连接，但在消息协议方面缺乏静态保证。进程之间通过发送任意消息并在运行时进行模式匹配，导致协议违规在生产环境中才会暴露，这可能导致生产故障。因此，需要一种方法来在编译时强制执行消息协议的类型安全。

Method: NVLang的核心方法是利用代数数据类型（ADTs）来自然地编码Actor的消息协议。每个Actor声明一个表示其消息词汇的求和类型（sum type），类型系统在编译时强制执行协议一致性。该语言引入了类型化的进程标识符（Pid[T]）和类型化的Future（Future[T]），以确保类型安全的消息传递和请求-回复模式。通过扩展Hindley-Milner类型推断来跟踪消息协议，NVLang可以在不牺牲动态类型替代方案的简洁语法的情况下，消除消息传递错误。 NVLang的实现编译到Core Erlang。

Result: NVLang是一种静态类型的功能语言，它为BEAM虚拟机带来了全面的类型安全，同时保留了Actor模型的简洁性和强大功。该语言通过在编译时强制执行消息协议的一致性，消除了整个类别的消息传递错误。形式化的类型系统和类型健全性（type soundness）证明草图表明，类型良好的NVLang程序不会发送违反Actor协议的消息。此外，NVLang实现了与现有Erlang生态系统的无缝互操作性。

Conclusion: NVLang通过形式化类型系统和证明保证了类型安全特性，并能编译为Core Erlang，实现与现有Erlang生态系统的互操作性。它展示了静态类型方法在保持Actor模型的简洁性和强大的同时，可以消除一类运行时错误。

Abstract: Actor-based systems like Erlang/OTP power critical infrastructure -- from telecommunications to messaging platforms--handling millions of concurrent connections with legendary reliability. Yet these systems lack static guarantees about message protocols: processes communicate by sending arbitrary messages that pattern-matched at runtime, deferring protocol violations to production failures.
  We present NVLang, a statically typed functional language that brings comprehensive type safety to the BEAM virtual machine while preserving actor model's simplicity and power. NVLang's central contribution that algebraic data types (ADTs) naturally encode actor message protocols: each actor declares the sum type representing its message vocabulary, and the type system enforces protocol conformance at compile time. We introduce typed process identifiers (Pid[T]) that encode the protocol an actor expects, and typed futures (Future[T]) that provide type-safe request-reply patterns.
  By extending Hindley-Milner type inference to track message protocols, NVLang eliminates an entire class of message-passing errors while maintaining clean syntax that rivals dynamically typed alternatives. Our implementation compiles to Core Erlang, enabling seamless interoperability with the existing Erlang ecosystem. We formalize the type system and provide proof sketches for type soundness, demonstrating that well-typed NVLang programs cannot send messages that violate actor protocols.

</details>


### [2] [Verified VCG and Verified Compiler for Dafny](https://arxiv.org/abs/2512.05262)
*Daniel Nezamabadi,Magnus O. Myreen,Yong Kiam Tan*

Main category: cs.PL

TL;DR: 相关领域：Compiler (编译器)。
太长不看摘要：Dafny 的编译器和验证器存在可靠性错误。本文提出了一个命令式 Dafny 子集的函数式大步语义，并在 HOL4 中机械化验证了一个基于此语义的验证条件生成器（VCG）和一个编译器。这使得经过验证的 Dafny 程序可以被编译成 CakeML（然后是机器码），同时形式化地保证了源程序的功能正确性。


<details>
  <summary>Details</summary>
Motivation: Dafny 是一种支持验证的编程语言，但其编译器和静态程序验证器都没有经过正确性证明，并且已发现存在可靠性错误（soundness bugs）。由于这些工具缺乏形式化的正确性保证，导致对使用 Dafny 验证得到的程序的信任度存在潜在问题。因此，有必要为 Dafny 工具开发具有形式化正确性保证的版本。

Method: 本文首先提出了一个命令式 Dafny 子集（包括相互递归方法调用、while 循环和数组）的函数式大步语义。然后，基于该语义，作者构建了一个经过验证的验证条件生成器（VCG）和一个经过验证的编译器。VCG 用于证明带注解 Dafny 程序的功能正确性，而编译器用于将经过验证的 Dafny 程序编译成 CakeML 程序，进而通过已验证的 CakeML 编译器生成可执行机器码。所有工作都在 HOL4 定理证明器中进行了机械化。

Result: 作者形式化了一个包含相互递归方法调用、while 循环和数组等重要特性的 Dafny 子集。基于此形式化，作者开发了一个经过验证的验证条件生成器（VCG）和一个经过验证的编译器。经过验证的 VCG 允许证明带注解 Dafny 程序的功能正确性。经过验证的编译器可以将经过验证的 Dafny 程序编译成 CakeML 程序，并最终通过已验证的 CakeML 编译器生成可执行机器码，整个过程（从源语言的功能正确性证明到机器码执行）都保持了功能正确性保证。这一工作已在 HOL4 定理证明器中进行了机械化。

Conclusion: 本文介绍了形式化 Dafny 一个重要子集的函数式大步语义，并基于此语义，构建了一个经过验证的验证条件生成器（VCG）和一个经过验证的编译器，为 Dafny 工具链提供了形式化的正确性保证。这项工作在 HOL4 定理证明器中进行了机械化，使得对经过验证的 Dafny 程序进行编译后，仍然可以通过 CakeML 编译器获得可执行的机器码，同时保持了源程序的功能正确性保证。

Abstract: Dafny is a verification-aware programming language that comes with a compiler and static program verifier. However, neither the compiler nor the verifier is proved correct; in fact, soundness bugs have been found in both tools. This paper shows that the aforementioned Dafny tools can be developed with foundational correctness guarantees. We present a functional big-step semantics for an imperative subset of Dafny and, based on this semantics, a verified verification condition generator (VCG) and a verified compiler for Dafny. The subset of Dafny we have formalized includes mutually recursive method calls, while loops, and arrays -- these language features are significant enough to cover challenging examples such as McCarthy's 91 function and array-based programs that are used when teaching Dafny. The verified VCG allows one to prove functional correctness of annotated Dafny programs, while the verified compiler can be used to compile verified Dafny programs to CakeML programs. From there, one can obtain executable machine code via the (already verified) CakeML compiler, all while provably maintaining the functional correctness guarantees that were proved for the source-level Dafny programs. Our work has been mechanized in the HOL4 theorem prover.

</details>


### [3] [Compiler-supported reduced precision and AoS-SoA transformations for heterogeneous hardware](https://arxiv.org/abs/2512.05516)
*Pawel K. Radtke,Tobias Weinzierl*

Main category: cs.PL

TL;DR: 关联：编译器（Compiler）、图处理（Graph Processing）、HLS（High-Level Synthesis）。
总结：本文评估了在基于 GPU 的粒子模拟代码中，应用 AoS-to-SoA 转换和减少精度数据布局的效果。研究动机在于 AoS 尽管是许多拉格朗日代码的首选，但 SoA 更适合 SIMT 架构；同时，不确定数据转换（格式和精度）以及 GPU 卸载应该在 CPU 端还是 GPU 端进行，尤其是在 CPU/GPU 共享内存的现代超级芯片上。为此，论文引入了编译器注解来帮助程序员协调这些转换，并与 GPU 卸载结合。实验结果表明，在 Nvidia G200 平台上获得了约 2.6 倍的加速，而 AMD MI300A 平台性能更稳定但加速较少，这表明基于编译器的转换技术对于广泛的拉格朗日代码具有潜在应用。


<details>
  <summary>Details</summary>
Motivation: 许多拉格朗日代码倾向于使用 AoS 存储格式，但研究假设 SoA 格式更适合 SIMT 架构的 GPU。当计算内核需要在加速器上运行时，使用低于 IEEE 精度的减少精度数据作为解决带宽瓶颈的方法，然而，不清楚 AoS 和精度转换应该在 CPU 上执行还是部署到 GPU 上。此外，在 CPU 和 GPU 共享（逻辑上）同一数据空间的现代超级芯片上，研究不确定是在计算前将数据流式传输到加速器上，还是让加速器按需转换数据（即逻辑上原地工作）更有利。因此，需要机制来促进这种转换并为程序员提供协调转换的选项。

Method: 研究通过引入编译器注解来促进 AoS-to-SoA 转换以及减少精度的数据布局，使其能够与 GPU 卸载相结合，允许程序员协调数据转换的执行位置（CPU 或 GPU），并将其应用于粒子模拟代码进行评估。

Result: 在 Nvidia G200 平台上，对于关注的计算内核，AoS-to-SoA 转换和减少精度数据布局的优化带来了约 2.6 倍的加速。AMD MI300A 平台表现出更稳定的性能，但获益较少。这项基于编译器的转换技术被假设可应用于多种拉格朗日代码及其他领域。

Conclusion: 该研究提出了编译器注解来促进 AoS-to-SoA 转换，并允许程序员在 GPU 卸载的同时协调这些转换。实验结果显示，在 Nvidia G200 平台上，对于某些计算内核，性能提升约为 2.6 倍，而在 AMD MI300A 平台上，性能提升较小，但性能更稳定。研究假设其基于编译器的技术适用于广泛的拉格朗日代码及其他领域，并建议在具有统一内存的现代超级芯片上，数据格式转换可以考虑在 GPU 上按需进行。

Abstract: This study evaluates AoS-to-SoA transformations over reduced-precision data layouts for a particle simulation code on several GPU platforms: We hypothesize that SoA fits particularly well to SIMT, while AoS is the preferred storage format for many Lagrangian codes. Reduced-precision (below IEEE accuracy) is an established tool to address bandwidth constraints, although it remains unclear whether AoS and precision conversions should execute on a CPU or be deployed to a GPU if the compute kernel itself must run on an accelerator. On modern superchips where CPUs and GPUs share (logically) one data space, it is also unclear whether it is advantageous to stream data to the accelerator prior to the calculation, or whether we should let the accelerator transform data on demand, i.e.~work in-place logically. We therefore introduce compiler annotations to facilitate such conversions and to give the programmer the option to orchestrate the conversions in combination with GPU offloading. For some of our compute kernels of interest, Nvidia's G200 platforms yield a speedup of around 2.6 while AMD's MI300A exhibits more robust performance yet profits less. We assume that our compiler-based techniques are applicable to a wide variety of Lagrangian codes and beyond.

</details>


### [4] [Compiling Away the Overhead of Race Detection](https://arxiv.org/abs/2512.05555)
*Alexey Paznikov,Andrey Kogutenko,Yaroslav Osipov,Michael Schwarz,Umang Mathur*

Main category: cs.PL

TL;DR: 该论文与编译器、图处理（间接涉及，因为静态分析和LLVM IR处理可以视为图结构上的分析）和MLIR（与编译器相关，虽然未直接提及）相关。与HLS和DSL不直接相关。

**TLDR 摘要:** 动态数据竞争检测器因冗余内存访问插桩导致开销大，限制了其应用。本文提出一个编译器集成（基于LLVM，集成到ThreadSanitizer）的静态分析方法，通过过程间分析消除对确定无竞争访问的插桩，并引入基于支配性的消除分析来排除报告重复等效竞争的检查点。实验结果显示，在保持检测完整性的前提下，实现了平均1.34倍、峰值2.5倍的加速，显著降低了数据竞争检测的运行时开销。该优化已被ThreadSanitizer接受。


<details>
  <summary>Details</summary>
Motivation: 动态数据竞争检测器（如ThreadSanitizer）因其高昂的运行时开销而限制了其应用，这种开销主要源于对内存访问的普遍插桩，其中很大一部分是冗余的。本文的动机在于通过静态、编译器集成的优化方法，识别并消除这些冗余插桩，从而显著降低动态数据竞争检测器的运行时成本。

Method: 本文提出了一个编译器集成的静态分析方法来消除冗余插桩。具体方法包括：1. 引入一套过程间静态分析，推理内存访问模式、同步和线程创建，以消除对确定无竞争访问的插桩，同时保证数据竞争检测器的完整性。2. 提出一种基于支配性的消除分析，识别并消除那些报告的竞争与先前已报告的等效竞争重复的检查点，通过限制每个等价类只报告至少一个代表性竞争来实现进一步的优化。3. 以上两种洞见在LLVM中实现为五个静态分析，并集成到ThreadSanitizer的插桩过程中。

Result: 所提出的优化方法在多样化的真实世界应用套件上的实验评估表明，它显著减少了竞争检测的开销。实现了平均1.34倍的几何平均加速比，在线程竞争激烈的情况下，峰值加速比达到2.5倍。该性能提升是在编译时间增加可忽略不计的情况下实现的，而且是全自动的，不会给开发人员带来额外负担。该优化已被ThreadSanitizer维护者接受并正在集成到上游代码中。

Conclusion: 本文提出了一种静态、编译器集成的优化方法，通过识别和消除冗余的内存访问插桩，显著降低了动态数据竞争检测器的运行时开销。实验结果表明，该方法在保持检测完整性的同时，实现了平均1.34倍、峰值2.5倍的加速效果。该优化已被ThreadSanitizer维护者接受并正在集成到上游代码中，证明了其有效性和实用性。

Abstract: Dynamic data race detectors are indispensable for flagging concurrency errors in software, but their high runtime overhead limits their adoption. This overhead stems primarily from pervasive instrumentation of memory accesses - a significant fraction of which is redundant. We addresses this inefficiency through a static, compiler-integrated approach that identifies and eliminates redundant instrumentation, drastically reducing the runtime cost of dynamic data race detectors. We introduce a suite of interprocedural static analyses reasoning about memory access patterns, synchronization, and thread creation to eliminate instrumentation for provably race-free accesses and show that the completeness properties of the data race detector are preserved. We further observe that many inserted checks flag a race if and only if a preceding check has already flagged an equivalent race for the same memory location - albeit potentially at a different access. We characterize this notion of equivalence and show that, when limiting reporting to at least one representative for each equivalence class, a further class of redundant checks can be eliminated. We identify such accesses using a novel dominance-based elimination analysis. Based on these two insights, we have implemented five static analyses within the LLVM, integrated with the instrumentation pass of the race detector ThreadSanitizer. Our experimental evaluation on a diverse suite of real-world applications demonstrates that our approach significantly reduces race detection overhead, achieving a geomean speedup of 1.34x, with peak speedups reaching 2.5x under high thread contention. This performance is achieved with a negligible increase in compilation time and, being fully automatic, places no additional burden on developers. Our optimizations have been accepted by the ThreadSanitizer maintainers and are in the process of being upstreamed.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [5] [FedGMR: Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity](https://arxiv.org/abs/2512.05372)
*Chengjie Ma,Seungeun Oh,Jihong Park,Seong-Lyun Kim*

Main category: cs.DC

TL;DR: 该论文与**机器学习（ML）**和**编译器**（涉及模型结构和优化）相关。
**太长不看版总结：**论文提出了 FedGMR，一种在异步和模型异构的联邦学习（FL）中，通过在训练过程中逐步增加带宽受限客户端（BCCs）子模型密度的方法。这解决了 BCCs 后期收敛慢和泛化差的问题。FedGMR 还包含一个掩码感知聚合规则和理论收敛性保证。实验证明，在高异构和非 IID 设置下，FedGMR 实现了更快的收敛和更高的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）在异构环境中，特别是面临带宽受限客户端（BCCs）时，效率低下。这些客户端的子模型（由于带宽限制）容量小，虽然初期学习快，但在后期会因为**欠参数化（under-parameterized）**而导致**收敛缓慢**和**泛化能力下降**，使得它们难以持续有效地参与训练。因此，需要一种机制来确保这些带宽受限的设备能够全程保持对全局模型的有效贡献。

Method: 核心方法是 FedGMR (Federated Learning with Gradual Model Restoration)，即异步和模型异构环境下具备的逐步模型恢复功能的联邦学习。

具体机制包括：
1. **逐步模型密度增加（Gradual Model Restoration, GMR）**：在训练过程中，逐渐增加带宽受限客户端（BCCs）的子模型密度，确保这些客户端在整个训练过程中保持高效的贡献。
2. **掩码感知聚合规则（Mask-aware Aggregation Rule）**：为异步异构联邦学习（MHFL）量身定制的聚合规则，用于处理和聚合不同密度的子模型。
3. **理论收敛性保证**：证明了聚合误差与客户端和轮次之间的平均子模型密度成正比，并证明了 GMR 能有效缩小这一差距，使其趋向于全模型 FL 的性能。

Result: 1. **性能提升**：FedGMR 实现了更快的收敛速度和更高的准确性。
2. **适用性**：尤其在**高异构性（high heterogeneity）**和**非独立同分布（non-IID）**设置下，性能优势更为显著。
3. **实验验证**：在 FEMNIST, CIFAR-10, 和 ImageNet-100 等多个数据集上验证了其有效性。
4. **理论支撑**：提供了收敛性保证，表明聚合误差随平均子模型密度变化，且 GMR 能够有效地减小误差，接近全模型 FL 的表现。

Conclusion: FedGMR 是一种在异步和模型异构环境下具备逐步模型恢复功能的联邦学习（FL）方法，它通过在训练过程中逐步增加带宽受限客户端的子模型密度，有效地解决了它们参与FL时面临的收敛慢和泛化能力下降的问题。除了提出 FedGMR，作者还设计了一种适用于异步 MHFL 的掩码感知聚合规则，并在理论上证明了其收敛性保证，展示了 GMR 如何有效地缩小与全模型 FL 之间的性能差距。实验结果表明，FedGMR 在高异构和非 IID 设置下，尤其在 FEMNIST、CIFAR-10 和 ImageNet-100 数据集上，实现了更快的收敛速度和更高的准确性。

Abstract: Federated learning (FL) holds strong potential for distributed machine learning, but in heterogeneous environments, Bandwidth-Constrained Clients (BCCs) often struggle to participate effectively due to limited communication capacity. Their small sub-models learn quickly at first but become under-parameterized in later stages, leading to slow convergence and degraded generalization. We propose FedGMR - Federated Learning with Gradual Model Restoration under Asynchrony and Model Heterogeneity. FedGMR progressively increases each client's sub-model density during training, enabling BCCs to remain effective contributors throughout the process. In addition, we develop a mask-aware aggregation rule tailored for asynchronous MHFL and provide convergence guarantees showing that aggregated error scales with the average sub-model density across clients and rounds, while GMR provably shrinks this gap toward full-model FL. Extensive experiments on FEMNIST, CIFAR-10, and ImageNet-100 demonstrate that FedGMR achieves faster convergence and higher accuracy, especially under high heterogeneity and non-IID settings.

</details>


### [6] [Are Bus-Mounted Edge Servers Feasible?](https://arxiv.org/abs/2512.05543)
*Xuezhi Li,Jiancong He,Ming Xie,Xuyang Chen,Le Chang,Li Jiang,Gui Gui*

Main category: cs.DC

TL;DR: 关联：都不相关。总结：本文研究了在车联网（IoV）中部署公交车载边缘服务器的可行性。与固定站点服务器（如RSU和基站）相比，公交车载边缘服务器能为系统提供计算弹性，更有效地应对时空变化的用户需求。作者利用上海的真实公交/出租车/电信数据集进行了覆盖范围分析，并建立了一个数学模型和设计了一个贪婪启发式算法，以在有限预算下选择最大化覆盖需求点的公交车。仿真结果验证了该方法在处理动态用户需求和现实约束下的有效性。最终得出结论：公交车载边缘服务器在城市车联网中是可行、有益且有价值的。


<details>
  <summary>Details</summary>
Motivation: 传统的路边单元（RSU）或基站的固定边缘服务器位置和容量是固定的，在处理时空用户动态方面效率低下。移动服务器（如公交车）有潜力为系统增加计算弹性。为了实现这一目标，本文研究了基于真实轨迹的公交车载边缘服务器的可行性。

Method: 1. 利用上海的公交/出租车/电信数据集，调查了公交车和基站的覆盖范围，证明了公交车载边缘服务器的巨大潜力。2. 建立了数学模型，并设计了一个简单的贪婪启发式算法来选择有限数量的公交车，以最大化对需求点（即用户）的覆盖范围。3. 进行了跟踪驱动的仿真，以验证所提出公交车选择算法的性能。

Result: 1. 研究结果表明，公交车覆盖了大量的地理区域和需求点，证明了公交车载边缘服务器的巨大潜力。2. 跟踪驱动的仿真结果表明，所提出的算法在服务器容量和购买数量等现实约束下，能有效地处理动态用户需求。

Conclusion: 公交车载边缘服务器对于城市车联网来说是可行、有益且有价值的。

Abstract: Placement of edge servers is the prerequisite of provisioning edge computing services for Internet of Vehicles (IoV). Fixed-site edge servers at Road Side Units (RSUs) or base stations are able to offer basic service coverage for end users, i.e., vehicles on road. However, the server locations and capacity are fixed after deployment, rendering their inefficiency in handling spationtemporal user dynamics. Mobile servers such as buses, on the other hand, have the potential of adding computation elasticity to such system. To this end, this paper studies the feasibility of bus-mounted edge servers based on real traces. First, we investigate the coverage of the buses and base stations using the Shanghai bus/taxi/Telecom datasets, which shows a great potential of bus-based edge servers as they cover a great portion of geographic area and demand points. Next, we build a mathematical model and design a simple greedy heuristic algorithm to select a limited number of buses that maximizes the coverage of demand points, i.e., with a limited purchase budget. We perform trace-driven simulations to verify the performance of the proposed bus selection algorithm. The results show that our approach effectively handles the dynamic user demand under realistic constraints such as server capacity and purchase quantity. Thus, we claim: bus-mounted edge servers for vehicular networks in urban areas are feasible, beneficial, and valuable.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [7] [Incorporating indel channels into average-case analysis of seed-chain-extend](https://arxiv.org/abs/2512.05247)
*Spencer Gibson,Yun William Yu*

Main category: cs.DS

TL;DR: 关联：图处理（线性间隙成本链通常可以用图算法解决）。这个工作将序列比对中 $k$-mer 种子启发式的理论分析从仅替换模型推广到包含插入和删除的模型。之前的研究证明了在仅替换通道下一个最优线性间隙成本链的预期可恢复性为 $1 - O\left(\frac{1}{\sqrt{m}}\right)$，但这个结果忽略了真实基因组数据中的插入和删除。本文通过引入新的数学工具来处理 indel 通道带来的相邻锚点的依赖性和部分正确的锚点这两个新问题，证明了在包含替换、插入和删除的总突变率 $θ_T < 0.159$ 时，最优链的预期可恢复性仍能达到 $\ge 1 - O\left(\frac{1}{\sqrt{m}}\right)$，同时给出了新的预期运行时间上界 $O(mn^{3.15 \cdot θ_T}\log n)$。


<details>
  <summary>Details</summary>
Motivation: 现有的最佳线性间隙成本链理论结果（\[Shaw and Yu]）仅适用于只包含替换的突变通道，并假设均匀随机的 $s_1$，但在包含插入和删除（indels）的实际基因组数据中，基于 $k$-mer 种子的 seed-chain-extend 启发式方法仍然有效。因此，本文的动机在于弥补理论与实践之间的差距，将理论推广到包含 indels 的更真实的突变模型。

Method: 通过引入新的数学工具来处理 indel 通道带来的两个新障碍：相邻锚点的依赖性和部分正确的锚点的存在，本文成功地将其先前的理论结果推广到了包含插入和删除（indels）的突变模型。

Result: 证明了在包含替换、插入和删除的突变通道下，当总突变率 $θ_T = θ_i + θ_d + θ_s$ 低于 $0.159$ 时，最优链的预期可恢复性为 $\ge 1 - O\left(\frac{1}{\sqrt{m}}\right)$，预期运行时间为 $O(mn^{3.15 \cdot θ_T}\log n)$。这成功地将先前的理论结果推广到了包含 indels 的情景。

Conclusion: 本文将先前关于最优线性间隙成本链可恢复性的理论结果推广到包含插入和删除（indels）的突变模型，证明了在总突变率低于 $0.159$ 的条件下，最优链的预期可恢复性可达 $\ge 1 - O\left(\frac{1}{\sqrt{m}}\right)$，预期运行时间为 $O(mn^{3.15 \cdot θ_T}\log n)$，从而缩小了理论与实践之间的差距。

Abstract: Given a sequence $s_1$ of $n$ letters drawn i.i.d. from an alphabet of size $σ$ and a mutated substring $s_2$ of length $m < n$, we often want to recover the mutation history that generated $s_2$ from $s_1$. Modern sequence aligners are widely used for this task, and many employ the seed-chain-extend heuristic with $k$-mer seeds. Previously, Shaw and Yu showed that optimal linear-gap cost chaining can produce a chain with $1 - O\left(\frac{1}{\sqrt{m}}\right)$ recoverability, the proportion of the mutation history that is recovered, in $O\left(mn^{2.43θ} \log n\right)$ expected time, where $θ< 0.206$ is the mutation rate under a substitution-only channel and $s_1$ is assumed to be uniformly random. However, a gap remains between theory and practice, since real genomic data includes insertions and deletions (indels), and yet seed-chain-extend remains effective. In this paper, we generalize those prior results by introducing mathematical machinery to deal with the two new obstacles introduced by indel channels: the dependence of neighboring anchors and the presence of anchors that are only partially correct. We are thus able
  to prove that the expected recoverability of an optimal chain is $\ge 1 - O\Bigl(\frac{1}{\sqrt{m}}\Bigr)$ and the expected runtime is $O(mn^{3.15 \cdot θ_T}\log n)$, when the total mutation rate given by the sum of the substitution, insertion, and deletion mutation rates ($θ_T = θ_i + θ_d + θ_s$) is less than $0.159$.

</details>


### [8] [Crude Approximation of Directed Minimum Cut and Arborescence Packing in Almost Linear Time](https://arxiv.org/abs/2512.05300)
*Yonggang Jiang,Yaowei Long,Thatchaphol Saranurak,Benyu Wang*

Main category: cs.DS

TL;DR: This paper is related to **Graph Processing (图处理)**, specifically the optimization problems on directed graphs (有向图上的优化问题), which are fundamental topics in **Compiler (编译器)** and **HLS (高层次综合)** for resource allocation and data flow analysis.
本文提出了近似计算有根最小割和最大发散树打包的准线性时间算法。对于一个节点数为 $n$、边数为 $m$、最小割值为 $k$ 的有向图，新的算法能在 $m^{1+o(1)}$ 时间内：a) 找到一个 $O(k \log^5 n)$ 的近似最小割；b) 以 $n^{o(1)}$ 拥塞度打包 $k$ 棵发散树。这些算法在速度上远超现有的精确算法，显著提高了图论基本问题的求解效率。


<details>
  <summary>Details</summary>
Motivation: 有根最小割（Rooted Minimum Cut）和最大发散树打包（Maximum Arborescence Packing）是图论中两个对偶且基础的问题。
传统求解这些问题的已知算法具有较高的超线性（super-linear）时间复杂度：
* 最小割的精确算法时间复杂度为 $\tilde{O}(mk)$ 或 $\tilde{O}(m^{1+o(1)}\min\{\sqrt{n},n/m^{1/3}\})$。
* 无拥塞发散树打包算法的时间复杂度为 $\tilde{O}(m \cdot \mathrm{poly}(k))$。
因此，研究的动机是开发出准线性时间（almost-linear-time）的近似算法，以显著提高大规模有向图处理的效率。

Method: 本文提出了两种准线性时间算法：
1. **近似 s-有根最小割算法**：在 $m^{1+o(1)}$ 时间内，计算一个大小至多为 $O(k\log^{5} n)$ 的 $s$-有根割，其中 $k$ 是 $s$-有根最小割值。此算法也适用于加权图。
2. **近似 s-有根发散树打包算法**：在 $m^{1+o(1)}$ 时间内，打包 $k$ 棵 $s$-有根发散树，拥塞度为 $n^{o(1)}$，从而证明 $s$-有根最小割至少为 $k / n^{o(1)}$。
这些算法与传统的、时间复杂度更高的精确算法相比，在效率上有显著提升。

Result: 本文提出的近似算法取得了以下成果：
1. **s-rooted minimum cut (s-有根最小割) 近似**：在 $m^{1+o(1)}$ 时间内，找到一个近似割，其大小最多是精确最小割 $k$ 的 $O(\log^5 n)$ 倍。
2. **s-rooted arborescence packing (s-有根发散树打包) 近似**：在 $m^{1+o(1)}$ 时间内，能够打包 $k$ 棵发散树，拥塞度为 $n^{o(1)}$，从而证明最小割的下界为 $k / n^{o(1)}$。
这些结果在运行时间上是准线性的（$m^{1+o(1)}$），显著优于此前的超线性精确算法。

Conclusion: 本文介绍了近似计算有根最小割和最大发散树打包的准线性时间算法，这是两个对偶问题。这些算法在处理有向图时，具有显著的效率优势，尤其是在最小割值较大时，其运行速度超越了现有精确算法。作者指出，这些算法为近似计算方法在处理图论中的基本问题提供了新的思路和重要进展。

Abstract: We give almost-linear-time algorithms for approximating rooted minimum cut and maximum arborescence packing in directed graphs, two problems that are dual to each other [Edm73]. More specifically, for an $n$-vertex, $m$-edge directed graph $G$ whose $s$-rooted minimum cut value is $k$, our first algorithm computes an $s$-rooted cut of size at most $O(k\log^{5} n)$ in $m^{1+o(1)}$ time, and our second algorithm packs $k$ $s$-rooted arborescences with $n^{o(1)}$ congestion in $m^{1+o(1)}$ time, certifying that the $s$-rooted minimum cut is at least $k / n^{o(1)}$. Our first algorithm also works for weighted graphs.
  Prior to our work, the fastest algorithms for computing the $s$-rooted minimum cut were exact but had super-linear running time: either $\tilde{O}(mk)$ [Gab91] or $\tilde{O}(m^{1+o(1)}\min\{\sqrt{n},n/m^{1/3}\})$ [CLN+22]. The fastest known algorithms for packing $s$-rooted arborescences had no congestion, but required $\tilde{O}(m \cdot \mathrm{poly}(k))$ time [BHKP08].

</details>
