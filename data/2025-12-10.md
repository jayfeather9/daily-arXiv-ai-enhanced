<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 9]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.AR](#cs.AR) [Total: 1]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Chopper: A Multi-Level GPU Characterization Tool & Derived Insights Into LLM Training Inefficiency](https://arxiv.org/abs/2512.08242)
*Marco Kurzynski,Shaizeen Aga,Di Wu*

Main category: cs.DC

TL;DR: 该论文与编译器相关，它研究了大型语言模型（LLMs）的训练效率问题。
TLDR: 现有的工作对多 GPU LLM 训练中的复杂交互作用缺乏充分表征，作者提出了 Chopper 框架，它能收集、对齐并可视化多粒度的 GPU 内核跟踪和硬件性能计数器。使用 Chopper，作者对 Llama 3 8B 在 FSDP 下于 AMD Instinct MI300X 节点上的训练进行了全面的端到端表征，揭示了多个瓶颈和行为，并发现频率开销（DVFS 效应）是理论性能与观察性能之间差距的最大贡献者。Chopper 为优化训练框架、改进电源管理策略和指导未来 GPU 架构与系统设计提供了见解。


<details>
  <summary>Details</summary>
Motivation: 现有的工作主要关注内核级性能或单 GPU 微基准测试，而多 GPU LLM 训练中通信、计算、内存行为和电源管理之间复杂的交互作用仍未得到充分表征。为了提高大型语言模型（LLMs）的训练效率，需要深入理解现代 GPU 系统在真实分布式训练工作负载下的行为。

Method: Chopper 框架收集、对齐并可视化了多粒度（从单个内核到操作、层、阶段、迭代和 GPU）的 GPU 内核跟踪和硬件性能计数器。使用 Chopper，作者对 Llama 3 8B 在 FSDP 下的训练过程进行了全面的端到端表征，实验平台为八块 GPU 的 AMD Instinct MI300X 节点。

Result: 分析揭示了几个以前未被充分探索的瓶颈和行为，例如内存确定性能够实现更高、更稳定的 GPU 和内存频率。识别出几个效率低下的来源，其中频率开销（DVFS 效应）是理论性能与观察性能之间差距的最大单一贡献者，超过了 MFMA 利用率损失、通信/计算重叠和内核启动开销的影响。

Conclusion: Chopper 是第一个在 AMD Instinct MI300X GPU 上对 LLM 训练进行全面的、多粒度的表征框架，为优化训练框架、改进电源管理策略以及指导未来的 GPU 架构和系统设计提供了可操作的见解。

Abstract: Training large language models (LLMs) efficiently requires a deep understanding of how modern GPU systems behave under real-world distributed training workloads. While prior work has focused primarily on kernel-level performance or single-GPU microbenchmarks, the complex interaction between communication, computation, memory behavior, and power management in multi-GPU LLM training remains poorly characterized. In this work, we introduce Chopper, a profiling and analysis framework that collects, aligns, and visualizes GPU kernel traces and hardware performance counters across multiple granularities (i.e., from individual kernels to operations, layers, phases, iterations, and GPUs). Using Chopper, we perform a comprehensive end-to-end characterization of Llama 3 8B training under fully sharded data parallelism (FSDP) on an eight-GPU AMD InstinctTM MI300X node. Our analysis reveals several previously underexplored bottlenecks and behaviors, such as memory determinism enabling higher, more stable GPU and memory frequencies. We identify several sources of inefficiencies, with frequency overhead (DVFS effects) being the single largest contributor to the gap between theoretical and observed performance, exceeding the impact of MFMA utilization loss, communication/computation overlap, and kernel launch overheads. Overall, Chopper provides the first holistic, multi-granularity characterization of LLM training on AMD InstinctTM MI300X GPUs, yielding actionable insights for optimizing training frameworks, improving power-management strategies, and guiding future GPU architecture and system design.

</details>


### [2] [Modeling the Potential of Message-Free Communication via CXL.mem](https://arxiv.org/abs/2512.08005)
*Stepan Vanecek,Matthew Turner,Manisha Gajbe,Matthew Wolf,Martin Schulz*

Main category: cs.DC

TL;DR: 该论文与编译器相关（因为它着重于性能分析和优化，这在编译器设计和运行时系统中是常见的，特别是针对特定硬件），与图处理和 MLIR 或 HLS 不直接相关。

太长不看摘要：HPC 系统中，CXL.mem 这种共享内存池技术为高效节点间通信带来新可能。该论文提出了一个评估工具链和扩展性能模型，通过分析 MPI 应用的数据访问模式和跨节点流量，以 MPI 调用为粒度，预测哪些数据传输能从 CXL.mem 中获益。该工具链扩展了 Mitos 工具来提取数据访问行为，并通过在 2D 热转移和 HPCG 上的验证，证明了其对集成 CXL.mem 进行有针对性优化的支持。


<details>
  <summary>Details</summary>
Motivation: 随着 HPC 系统中内存墙问题的日益突出，异构内存技术（如 CXL.mem）变得越来越重要。CXL.mem 特别之处在于其可实现附加到多个节点上的共享内存池，从而为高效的节点间通信提供了新机遇。因此，需要一个工具来评估和预测在消息传递通信中利用 CXL.mem 所能带来的潜在性能优势。

Method: 方法包括：1. 提出一个新的性能评估工具链和扩展性能模型，用于消息传递通信，预测使用 CXL.mem 进行数据交换的潜在性能优势。2. 分析 MPI 应用程序的数据访问模式，尤其是对 MPI 缓冲区的片上访问和跨节点 MPI 流量，以全面理解内存性能的影响。3. 将这些数据结合到扩展性能模型中，预测哪些数据传输可以通过 CXL.mem 获益。模型工作在每个 MPI 调用的粒度，从而识别具有最高潜在加速的 MPI 调用。4. 将内存跟踪采样工具 Mitos 进行扩展，用于提取数据访问行为。5. 后处理步骤自动分析原始数据，为每个独立的 MPI 调用提供性能模型。

Result: 1. 提出了用于消息传递通信的性能评估工具链和扩展性能模型，能够预测使用 CXL.mem 进行数据交换的潜在性能提升。2. 模型在每个 MPI 调用的粒度上工作，可以识别代码中具有最高潜在加速的 MPI 调用。3. 对两个示例应用程序（2D 热转移 miniapp 和 HPCG 基准测试）进行了模型验证，并演示了模型对通过集成 CXL.mem 进行有针对性优化的支持。

Conclusion: 该论文提出了一个将 CXL.mem 应用于 MPI 通信的性能评估工具链和扩展性能模型，旨在预测和识别可以从 CXL.mem 中受益的数据传输和 MPI 调用。通过对两个示例应用程序（2D 热转移 miniapp 和 HPCG 基准测试）的验证，证明了该模型对有针对性的优化，尤其是集成 CXL.mem 的支持。

Abstract: Heterogeneous memory technologies are increasingly important instruments in addressing the memory wall in HPC systems. While most are deployed in single node setups, CXL.mem is a technology that implements memories that can be attached to multiple nodes simultaneously, enabling shared memory pooling. This opens new possibilities, particularly for efficient inter-node communication.
  In this paper, we present a novel performance evaluation toolchain combined with an extended performance model for message-based communication, which can be used to predict potential performance benefits from using CXL.mem for data exchange. Our approach analyzes data access patterns of MPI applications: it analyzes on-node accesses to/from MPI buffers, as well as cross-node MPI traffic to gather a full understanding of the impact of memory performance. We combine this data in an extended performance model to predict which data transfers could benefit from direct CXL.mem implementations as compared to traditional MPI messages. Our model works on a per-MPI call granularity, allowing the identification and later optimizations of those MPI invocations in the code with the highest potential for speedup by using CXL.mem.
  For our toolchain, we extend the memory trace sampling tool Mitos and use it to extract data access behavior. In the post-processing step, the raw data is automatically analyzed to provide performance models for each individual MPI call. We validate the models on two sample applications -- a 2D heat transfer miniapp and the HPCG benchmark -- and use them to demonstrate their support for targeted optimizations by integrating CXL.mem.

</details>


### [3] [CapsuleFS A Multi-credential DataCapsule Filesystem](https://arxiv.org/abs/2512.08067)
*Qingyang Hu,Yucheng Huang,Manshi Yang*

Main category: cs.DC

TL;DR: This paper is related to **operating system/filesystem** and **edge computing**.
CapsuleFS (CFS) 是第一个在 POSIX 兼容的文件系统中集成多凭证功能的文件系统，它使用 DataCapsule 作为存储提供者，并在边缘计算的全球数据平面上构建。CFS 架构包含 DataCapsule 服务器、运行在 TEE 中的中间件（用于权限管理）和 POSIX 客户端组件。实验结果显示，CFS 具有高度的功能正确性，尽管读写性能适中，但适用于实际软件开发场景。


<details>
  <summary>Details</summary>
Motivation: 在 POSIX 兼容的文件系统框架内提供多凭证功能。具体来说，是为了解决在边缘计算环境中缺乏具有通用访问 API 的多凭证文件系统的问题，利用 DataCapsule 作为存储提供者。

Method: CapsuleFS (CFS) 的架构分为三个主要组成部分：
1. DataCapsule 服务器：负责在边缘存储、传播和复制 DataCapsule。
2. 中间件：在可信执行环境 (TEE) 中运行，负责执行和管理写入权限和请求。
3. 客户端组件：表现为 POSIX 兼容的文件系统，可在多种架构上运行。
该系统基于边缘计算领域的全球数据平面 (Global Data Plane) 构建，并使用 DataCapsule 作为存储提供者。

Result: 实验评估表明，CapsuleFS 保持了高度的功能正确性，尽管其读写性能相对适中。这使得 CFS 成为实际软件开发场景中可行的候选系统。

Conclusion: CapsuleFS (CFS) 首次将多凭证功能集成到 POSIX 兼容的文件系统中，解决了边缘计算环境中缺乏具有常见访问权限 API 的多凭证文件系统的问题。CFS 在功能正确性方面表现出色，使其适用于实际的软件开发场景，尽管其读写性能相对适中。未来的工作将侧重于增强其实用性。

Abstract: CapsuleFS (CFS) is the first filesystem to integrate multi-credential functionality within a POSIX-compliant framework, utilizing DataCapsule as the storage provider. This innovative system is established based on the Global Data Plane in the area of edge computing. Our comprehensive design and implementation of CFS successfully fulfill the objective of providing a multi-credential Common Access API. The architecture of CFS is methodically segmented into three integral components: Firstly, the DataCapsule server, tasked with the storage, dissemination, and replication of DataCapsules on the edge. Secondly, the middleware, a crucial element running in a Trusted Execution Environment responsible for the enforcement and management of write permissions and requests. Finally, the client component, which manifests as a POSIX-compliant filesystem, is adaptable and operational across many architectures. Experimental evaluations of CFS reveal that, while its read and write performances are comparatively modest, it upholds a high degree of functional correctness. This attribute distinctly positions CFS as a viable candidate for application in real-world software development scenarios. The paper also delineates potential future enhancements, aimed at augmenting the practicality of CFS in the landscape of software development.

</details>


### [4] [Synergizing Monetization, Orchestration, and Semantics in Computing Continuum](https://arxiv.org/abs/2512.08288)
*Chinmaya Kumar Dehury,Lauri Lovén,Praveen Kumar Donta,Ilir Murturi,Schahram Dustdar*

Main category: cs.DC

TL;DR: 该论文与编译器（orchestration/编排，可以视为一种形式的调度或编译）、图处理（语义互操作性，可能涉及到图数据库或知识图谱的存储和处理）有关。这是一个关于 HERMES 框架的介绍，该框架旨在解决超分布式应用在可扩展性、互操作性和信任方面的挑战。HERMES 通过智能编排异构资源、数据服务变现和语义互操作性，创建了一个开放、无缝、安全的计算连续体环境，为新一代分布式应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 应对工业界对跨越云到边缘（cloud to the edge）的超分布式应用不断增长的需求，而现有解决方案在可扩展性、互操作性和信任方面存在固有局限性。

Method: HERMES (Heterogeneous Computing Continuum with Resource Monetization, Orchestration, and Semantic) 框架通过建立一个开放、无缝、安全的环境，实现资源的智能编排、数据和服务的分布式市场化变现、以及通过语义互操作性共享知识，来连接和利用异构计算连续体中的数据。

Result: 提出了 HERMES 框架，它通过智能编排异构资源（从云服务器到微小边缘设备）、在分布式市场中实现数据和服务的变现，以及通过语义互操作性共享知识，来转换计算连续体中的连接性和数据利用，最终实现更高效、可信、自主的新一代分布式应用。

Conclusion: HERMES 为新一代分布式应用奠定了基础，这些应用在智能制造、交通和农业等领域可以更高效、可信、自主地运行和管理跨越云到边缘的异构计算资源和数据。

Abstract: Industry demands are growing for hyper-distributed applications that span from the cloud to the edge in domains such as smart manufacturing, transportation, and agriculture. Yet today's solutions struggle to meet these demands due to inherent limitations in scalability, interoperability, and trust. In this article, we introduce HERMES (Heterogeneous Computing Continuum with Resource Monetization, Orchestration, and Semantic) - a novel framework designed to transform connectivity and data utilization across the computing continuum. HERMES establishes an open, seamless, and secure environment where resources, from cloud servers to tiny edge devices, can be orchestrated intelligently, data and services can be monetized in a distributed marketplace, and knowledge is shared through semantic interoperability. By bridging these key facets, HERMES lays a foundation for a new generation of distributed applications that are more efficient, trustworthy, and autonomous.

</details>


### [5] [Emulation of Complex Matrix Multiplication based on the Chinese Remainder Theorem](https://arxiv.org/abs/2512.08321)
*Yuki Uchino,Qianxiang Ma,Toshiyuki Imamura,Katsuhisa Ozaki,Patrick Lars Gutsche*

Main category: cs.DC

TL;DR: 涉及领域：编译器/硬件加速（通过利用低精度硬件特性）。
总结：该研究基于 Ozaki-II 方案，提出了在 INT8 矩阵引擎上高性能仿真单精度和双精度复数矩阵乘法的方法，并在 NVIDIA B200 GPU 上实现了相比原生 cuBLAS 复数矩阵乘法显著的 4.0x–6.5x 加速，同时提供了速度和精度上的灵活权衡，使其有潜力成为通用算法。


<details>
  <summary>Details</summary>
Motivation: 现代计算架构中低精度矩阵乘法单元具有远高于高精度单元的吞吐量。受此趋势启发，研究人员对使用低精度硬件仿真高精度矩阵乘法产生了浓厚兴趣。Ozaki-II 方案为矩阵乘法仿真提供了一个通用框架。现有的研究已成功应用于实数矩阵乘法。本文旨在将此研究路线扩展到单精度和双精度复数矩阵乘法。

Method: 本文基于 Ozaki-II 方案，提出了在 INT8 矩阵引擎上进行单精度和双精度复数矩阵乘法的高性能仿真方法。该方法通过利用低精度硬件的高吞吐量来模拟高精度运算。

Result: 在 NVIDIA B200 GPU 上，对于足够大的问题规模，所提出的方法相对于 cuBLAS 的原生单精度和双精度复数矩阵乘法程序，分别实现了 4.0x–5.6x 和 4.4x–6.5x 的加速。此外，该方法允许在可接受较低精度时实现更高速度，或在计算时间小幅增加时提供比标准程序更高的精度。

Conclusion: 本文提出的基于 Ozaki-II 方案的单精度和双精度复数矩阵乘法仿真方法在 NVIDIA B200 GPU 上，对于足够大的问题规模，相对于 cuBLAS 的原生复数矩阵乘法实现了显著的加速，并提供了灵活性，允许用户在速度和精度之间进行权衡。这表明该方法有潜力成为广泛应用的默认算法。

Abstract: Modern computing architectures feature low-precision matrix multiplication units that achieve substantially higher throughput than their high-precision counterparts. Motivated by this architectural trend, the emulation of high-precision matrix multiplication using low-precision hardware has attracted significant interest in the high-performance computing community. Ozaki, Uchino, and Imamura introduced the Ozaki-II scheme as a general framework for emulating matrix multiplication. Building on this framework, Uchino, Ozaki, and Imamura developed high-performance and power-efficient techniques for emulating single- and double-precision real matrix multiplication on INT8 matrix engines. Extending this line of research, the present study proposes high-performance emulation methods for single- and double-precision complex matrix multiplication on INT8 matrix engines, based on the Ozaki-II scheme. On an NVIDIA B200 GPU, the proposed methods achieve 4.0x--5.6x and 4.4x--6.5x speedups over the native single- and double-precision complex matrix multiplication routines from cuBLAS, respectively, for sufficiently large problem sizes. When lower accuracy than that of the standard routine is acceptable, the proposed methods can operate at even higher speed. Conversely, with only a modest increase in computation time, they can also deliver higher accuracy than the standard routines. These properties suggest that the proposed approach has the potential to serve as a default algorithm across a wide range of applications.

</details>


### [6] [Magneton: Optimizing Energy Efficiency of ML Systems via Differential Energy Debugging](https://arxiv.org/abs/2512.08365)
*Yi Pan,Wenbo Qian,Dedong Xie,Ruiyan Hu,Yigong Hu,Baris Kasikci*

Main category: cs.DC

TL;DR: 该论文与编译器（软件设计导致的能效问题）、MLIR（与ML框架优化相关）和图处理（ML框架中的操作符图）相关。其与这些方面的联系是因为作者关注于解决ML系统软件层面的能耗低效问题，这涉及到对ML框架（如操作符级别）的优化和诊断，而ML框架的优化经常涉及到编译器技术（如MLIR）。

**TL;DR:** 机器学习系统的训练和部署能耗巨大，但现有的能效优化侧重于硬件，忽略了由糟糕软件设计导致的能量浪费，开发者缺乏检测工具。本文提出了一种新的方法——**微分能量调试**，并基于此设计了**Magneton**能量分析工具。Magneton通过在操作符级别比较相似ML系统的能量消耗差异，自动定位能耗过高的代码和配置。将Magneton应用于9个流行的ML系统（包括LLM推理、通用框架和图像生成），成功发现并诊断了16个已知案例，并新增发现了8个未知软件能耗低效案例（其中7个已得到开发者确认），验证了该方法和工具的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的ML模型训练和部署能耗巨大，且优化工作主要集中在硬件能效上。作者认为，一个显著但被忽视的低效来源是软件能量浪费，这通常由不佳的软件设计（如冗余或设计不佳的操作）引起，这些浪费在广泛使用的ML框架和应用中存在，但开发者缺乏可见性和工具来检测和诊断它们。本文的动机在于解决这一软件层面的能耗低效问题。

Method: 本文提出了一种新的方法——微分能量调试（Differential Energy Debugging），其核心思想是利用相似ML系统在实现相同功能时能量消耗差异巨大的现象。基于此，作者设计并实现了一个名为Magneton的能量分析工具（energy profiler）。Magneton能够在操作符级别比较相似ML系统之间的能量消耗，并自动定位导致过度能耗的代码区域和配置选择。

Result: 所提出的工具Magneton被应用于9个流行的ML系统，涵盖LLM推理、通用ML框架和图像生成。它成功地检测和诊断了16个已知的软件能量低效案例，并进一步发现了8个此前未知的案例。这8个新发现的案例中有7个已得到开发者的确认，验证了该方法的有效性和工具的实用性。

Conclusion: Magneton在9个流行的ML系统（包括LLM推理、通用ML框架和图像生成）上的应用有效地发现并诊断了16个已知的软件能效低下案例，并进一步发现了8个此前未知的案例，其中7个已得到开发者的确认。这有力地证明了微分能量调试方法的有效性和Magneton工具的实用性，为ML系统软件能量优化提供了一个有力的工具。未来的工作可以基于此工具和方法，进一步扩展到其他类型的软件系统，促进软件能效的普遍提高。

Abstract: The training and deployment of machine learning (ML) models have become extremely energy-intensive. While existing optimization efforts focus primarily on hardware energy efficiency, a significant but overlooked source of inefficiency is software energy waste caused by poor software design. This often includes redundant or poorly designed operations that consume more energy without improving performance. These inefficiencies arise in widely used ML frameworks and applications, yet developers often lack the visibility and tools to detect and diagnose them.
  We propose differential energy debugging, a novel approach that leverages the observation that competing ML systems often implement similar functionality with vastly different energy consumption. Building on this insight, we design and implement Magneton, an energy profiler that compares energy consumption between similar ML systems at the operator level and automatically pinpoints code regions and configuration choices responsible for excessive energy use. Applied to 9 popular ML systems spanning LLM inference, general ML frameworks, and image generation, Magneton detects and diagnoses 16 known cases of software energy inefficiency and further discovers 8 previously unknown cases, 7 of which have been confirmed by developers.

</details>


### [7] [Basic Lock Algorithms in Lightweight Thread Environments](https://arxiv.org/abs/2512.08563)
*Taras Skazhenik,Nikolai Korobenikov,Andrei Churbanov,Anton Malakhov,Vitaly Aksenov*

Main category: cs.DC

TL;DR: 该论文与编译器、DSL、图处理、MLIR、HLS 均不相关。
**TLDR:** 传统的操作系统线程锁（如互斥锁）不适用于低开销的轻量级线程（协程），因为可能导致死锁。本文研究了轻量级线程的锁设计，提出了修改版的 TTAS 和 MCS 锁，并强调了轻量级线程的“让出”（yielding）和“休眠”（sleeping）两种上下文切换机制的重要性。为了在不同轻量级线程库中取得性能平衡，作者推荐了一种称为 **cohort lock** 的混合锁机制，它结合了 MCS 锁的高性能和 TTAS 锁的普适性，能在不同设定下提供稳定的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的并发数据结构（特别是互斥锁）是为操作系统（OS）线程设计的，但它们不适用于轻量级线程（如协程或异步调用）。轻量级线程具有启动和上下文切换开销低的优点，但需要手动调用上下文切换才能实现并行性。将传统的互斥锁实现用于轻量级线程可能会导致死锁，且不同的轻量级线程库需要不同的锁实现。因此，需要研究和设计适用于轻量级线程环境的互斥锁。

Method: 作者修改了 TTAS 和 MCS 锁，使其适用于轻量级线程。他们演示了轻量级线程的两种上下文切换机制（yielding 和 sleeping）的重要性。为了在不同库中取得平衡性能，作者推荐了一种称为 cohort lock 的锁机制，它结合了 TTAS 和 MCS 的优点，通过多个带有一个公共 TTAS 锁的 MCS 队列实现。

Result: 传统的 OS 线程互斥锁实现在轻量级线程环境中可能导致死锁。轻量级线程环境下的互斥锁设计必须考虑其两种上下文切换机制：yielding 和 sleeping。作者提出了修改后的 TTAS 和 MCS 锁，并推荐使用 cohort lock，该锁结合了 MCS 和 TTAS 的优势，在不同的轻量级线程库和设置中都能提供一个良好的性能平衡。

Conclusion: 本文研究了针对轻量级线程的互斥锁设计，提出了一种结合 TTAS 和 MCS 优点的改进型队列锁（cohort lock），该锁在不同的轻量级线程库和设置下均能实现较好的性能平衡。

Abstract: Traditionally, multithreaded data structures have been designed for access by the threads of Operating Systems (OS). However, implementations for access by programmable alternatives known as lightweight threads (also referred to as asynchronous calls or coroutines) have not been thoroughly studied. The main advantage of lightweight threads is their significantly lower overhead during launch and context switching. However, this comes at a cost: to achieve proper parallelism, context switches must be manually invoked in the code; without these switches, new lightweight threads will never be executed.
  In this paper, we focus on the simplest multithreaded data structure: a mutex (also known as a lock). We demonstrate that original implementations for OS threads cannot be used effectively in this new context due to the potential for deadlocks. Furthermore, correctness is not the only concern. In certain languages, such as C++, there are various lightweight thread libraries, each with different implementations and interfaces, which necessitate distinct lock implementations.
  In this work, we present a modification of TTAS and MCS locks for the use from lightweight threads and demonstrate that the two context switch mechanisms of lightweight threads, yielding and sleeping, are crucial. However, the performance of TTAS and MCS may differ significantly depending on the settings. If one wants to have a lock that works well for any library, we suggest using the cohort lock, which strikes a balance between MCS and TTAS by utilizing several MCS queues with a common TTAS.

</details>


### [8] [Model-based Testing of Practical Distributed Systems in Actor Model](https://arxiv.org/abs/2512.08698)
*Ilya Kokorin,Evgeny Chernatskiy,Vitaly Aksenov*

Main category: cs.DC

TL;DR: 该论文与DSL、图处理、MLIR、编译器、HLS均**不相关**。
**TLDR:** 分布式系统的正确实现充满挑战，尽管有经过验证的规范，但实现与规范之间仍存在差距。本文提出了一种高效的、基于模型检测的测试方法，通过将系统模型解释为有限状态自动机，可以为采用Actor模型的分布式系统生成详尽的测试套件，从而弥合实现与规范的差距。该方法无需修改代码或执行环境。文中以一个基于Viewstamped Replication的复制算法的实现验证为例，证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 分布式系统的设计和实现极具挑战性，尽管通常有经过模型检测的形式化规范，但规范与实际实现之间仍存在差距，不能保证实现没有bug。为了弥合这一差距，确保实现的正确性，本文旨在利用基于模型的测试方法生成详尽的测试套件。

Method: 本文提出了一种高效的方法，用于为采用Actor模型的分布式系统生成详尽的、覆盖所有可能状态和转换的测试套件。该方法基于模型检测，将系统模型解释为有限状态自动机来生成测试用例，而且不需要对现有代码或分布式系统执行环境进行任何修改。

Result: 通过将系统模型解释为有限状态自动机，本文的方法能够为分布式系统（特别是采用Actor模型的系统）生成一个详尽的测试套件，从而验证实现。文中以对一个基于Viewstamped Replication的复制算法实现进行验证为例，证明了该方法的有效性。

Conclusion: 本文提出的方法通过模型检测为分布式系统生成了详尽的测试套件，显著地弥合了形式化规范与实际实现之间的差距，提高了分布式系统实现的正确性和可靠性。这种不侵入代码和执行环境的测试方法具有很高的实用价值。

Abstract: Designing and implementing distributed systems correctly can be quite challenging. Although these systems are often accompanied by formal specifications that are verified using model-checking techniques, a gap still exists between the implementation and its formal specification: there is no guarantee that the implementation is free of bugs.
  To bridge this gap, we can use model-based testing. Specifically, if the model of the system can be interpreted as a finite-state automaton, we can generate an exhaustive test suite for the implementation that covers all possible states and transitions.
  In this paper, we discuss how to efficiently generate such a test suite for distributed systems written in the actor model. Importantly, our approach does not require any modifications to the code or interfering with the distributed system execution environment. As an example, we verified an implementation of a replication algorithm based on Viewstamped Replication, which is used in a real-world system.

</details>


### [9] [Spatio-Temporal Shifting to Reduce Carbon, Water, and Land-Use Footprints of Cloud Workloads](https://arxiv.org/abs/2512.08725)
*Giulio Attenni,Youssef Moawad,Novella Bartolini,Lauritz Thamsen*

Main category: cs.DC

TL;DR: 此论文与DSL、图形处理、MLIR、编译器或HLS无关。

Too Long; Didn't Read (TLDR):
该研究通过对AWS和Azure等云服务商的真实数据和工作负载进行模拟分析，发现**空间和时间上的云工作负载迁移**可以大幅减少能源相关应用的环境足迹（碳、水和土地使用）。其中，**空间迁移**效果最显著，降幅可达20%到85%；**时间迁移**提供额外增益。结合使用效果最佳，且该策略对电网预测误差和季节变化具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前云计算环境对环境造成了显著的碳排放、水资源消耗和土地使用，因此需要探索创新的方法来减轻这些环境足迹。该研究的动机是调查空间和时间上的云工作负载迁移策略在减少云工作负载环境影响方面的潜力。

Method: 研究使用了来自多个云服务提供商（AWS和Azure）的真实世界数据和针对不同应用（大数据分析和FaaS）的工作负载跟踪数据进行模拟研究。通过模拟评估了空间迁移、时间迁移以及两者结合对环境足迹（碳、水、土地使用）的影响。

Result: 模拟结果显示：
1. **空间迁移（Spatial shifting）**可以显著降低碳足迹、水足迹和土地使用足迹，降幅在20%到85%之间（取决于场景和优化标准）。
2. **时间迁移（Temporal shifting）**也能减少足迹，但效果不如空间迁移。
3. **两者结合**能带来最大的整体减排效果，主要由空间迁移驱动，时间调整提供了额外的增量效益。
4. **敏感性分析**表明，这种迁移策略对电网构成数据预测误差和不同季节变化具有鲁棒性。

Conclusion: 该研究通过模拟分析表明，空间和时间上的云工作负载迁移对减少碳足迹、水足迹和土地使用足迹具有显著潜力。空间迁移效果最为显著，时间迁移提供额外增益。这种迁移策略对于电网构成数据预测误差和季节变化具有鲁棒性。

Abstract: In this paper, we investigate the potential of spatial and temporal cloud workload shifting to reduce carbon, water, and land-use footprints. Specifically, we perform a simulation study using real-world data from multiple cloud providers (AWS and Azure) and workload traces for different applications (big data analytics and FaaS). Our simulation results indicate that spatial shifting can substantially lower carbon, water, and land use footprints, with observed reductions ranging from 20% to 85%, depending on the scenario and optimization criteria. Temporal shifting also decreases the footprint, though to a lesser extent. When applied together, the two strategies yield the greatest overall reduction, driven mainly by spatial shifting with temporal adjustments providing an additional, incremental benefit. Sensitivity analysis demonstrates that such shifting is robust to prediction errors in grid mix data and to variations across different seasons.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [10] [The Bichromatic Two-Center Problem on Graphs](https://arxiv.org/abs/2512.08111)
*Qi Sun,Jingru Zhang*

Main category: cs.DS

TL;DR: 该论文与图处理相关。**太长不看版：** 本文研究了图上的（加权）双色两中心问题，目标是找到两个中心点并分配成对的顶点到不同中心以最小化最大距离。本文首次提出了解决该问题的一般无向图（$O(m^2n\log n\log mn)$）、树（$O(n\log n)$）和无权树（$O(n)$）的有效算法。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于研究图上的（加权）双色两中心问题，该问题在图论和优化领域尚未得到充分研究，特别是关于树图的情况。目标是找到最小化分配给两个中心的顶点最大距离的方法。

Method: 本文首先提出了一种解决带有距离矩阵的无向图问题的 $O(m^2n\log n\log mn)$ 算法。接着，针对树结构，提出了一种 $O(n\log n)$-time 的算法。最后，对于无权树版本，提出了一种线性时间 $O(n)$ 的方法。

Result: 本文提出的算法及其时间复杂度如下：（1）对于带有距离矩阵的无向图，给出了一个 $O(m^2n\log n\log mn)$ 算法；（2）对于树，给出了一个 $O(n\log n)$ 时间算法；（3）对于无权树，给出了一个线性时间 $O(n)$ 方法。这些结果首次在图上对该问题进行了有效解决。

Conclusion: 本文研究了图上的双色两中心问题，并提出了针对不同图结构的有效算法，填补了该问题在图上研究的空白。研究结果包括了解决一般图、树和无权树版本的算法及其时间复杂度。

Abstract: In this paper, we study the (weighted) bichromatic two-center problem on graphs. The input consists of a graph $G$ of $n$ (weighted) vertices and $m$ edges, and a set $\mathcal{P}$ of pairs of distinct vertices, where no vertex appears in more than one pair. The problem aims to find two points (i.e., centers) on $G$ by assigning vertices of each pair to different centers so as to minimize the maximum (weighted) distance of vertices to their assigned centers (so that the graph can be bi-colored with this goal). To the best of our knowledge, this problem has not been studied on graphs, including tree graphs. In this paper, we propose an $O(m^2n\log n\log mn)$ algorithm for solving the problem on an undirected graph provided with the distance matrix, an $O(n\log n)$-time algorithm for the problem on trees, and a linear-time approach for the unweighted tree version.

</details>


### [11] [A tight example for approximation ratio 5 for covering small cuts by the primal-dual method](https://arxiv.org/abs/2512.08350)
*Zeev Nutov*

Main category: cs.DS

TL;DR: This content has not passed the compliance test and has been hidden.


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决 Simmons 提出的关于 Williamson、Goemans、Mihail 和 Vazirani 原始对偶算法在小割集覆盖问题上的近似比 $5$ 是否紧确的问题。精确确定该算法的性能界限对算法分析和未来改进至关重要。

Method: 作者通过构造一个具体的、能够使得原始对偶算法的解与最优解的比值任意接近 $5$ 的例子来证明其结果。这个方法的重点在于设计一个具有挑战性的图结构，该结构能够暴露算法的弱点。

Result: 作者提供了一个例子，在这个例子中，原始对偶算法产生的解与最优解的比值可以任意接近 $5$。这证实了 Williamson 等人的算法在小割集覆盖问题上的近似比 $5$ 是紧确的。

Conclusion: 本文证明了 Williamson 等人的原始对偶算法在小割集覆盖（Small Cuts Cover）问题上的近似比 $5$ 是紧的。这意味着该算法对于这个问题不能获得比 $5$ 更好的理论最坏情况近似比。

Abstract: In the Small Cuts Cover problem we seek to cover by a min-cost edge-set the set family of cuts of size/capacity $<k$ of a graph. Recently, Simmons showed that the primal-dual algorithm of Williamson, Goemans, Mihail, and Vazirani achieves approximation ratio $5$ for this problem, and asked whether this bound is tight. We will answer this question positively, by providing an example in which the ratio between the solution produced by the primal-dual algorithm and the optimum is arbitrarily close to $5$.

</details>


### [12] [A Distribution Testing Approach to Clustering Distributions](https://arxiv.org/abs/2512.08376)
*Gunjan Kumar,Yash Pote,Jonathan Scarlett*

Main category: cs.DS

TL;DR: Paper relation: The paper is not related to DSL, graph processing, MLIR, compiler, or HLS.

TLDR: The paper studies a fundamental distribution clustering problem where $k$ distributions are secretly divided into two groups, each with the same distribution, and the two group distributions are $\varepsilon$-far apart in total variation. The goal is to recover the partition. The authors establish tight upper and lower bounds on the sample complexity for two core cases: one cluster's distribution is known, and both are unknown. The bounds precisely characterize the dependence on all parameters ($n$: domain size, $k$: number of distributions, $r$: size of one cluster, $\varepsilon$: distance) up to an $O(\log k)$ factor.


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于研究一个基本的统计和机器学习问题——分布聚类（或假设检验）。具体来说，作者关注的是一个特定的隐式划分问题：将 $k$ 个分布划分为两个内部相似且彼此 $\varepsilon$-远的组。理解在这种设置下恢复隐藏划分所需的最小样本数（即样本复杂度）是至关重要的，这为设计高效的聚类算法提供了理论指导和性能基准。

Method: 作者通过建立样本复杂度的上界和下界来研究分布聚类问题。对于上界，可能使用了有效的聚类算法和样本分配策略来最小化所需的总样本数。对于下界，作者采用了信息论或统计学中的工具（如Fano's不等式或基于假设检验的方法）来证明任何成功的恢复算法至少需要特定数量的样本。通过比较上下界，作者成功地刻画了样本复杂度对所有参数（$n, k, r, \varepsilon$）的依赖关系。

Result: 本文为隐式分布聚类问题（将 $k$ 个分布划分为两个 $\varepsilon$-远簇）的样本复杂度建立了上界和下界。这些界限针对两种情况：（1）一个簇的分布已知，（2）两个簇的分布都未知。研究结果精确地描述了样本复杂度对域大小 $n$、分布数量 $k$、其中一个簇的大小 $r$ 以及距离 $\varepsilon$ 的依赖关系。此外，作者证明了这些上下界在所有参数制度下（除了 $O(\log k)$ 的因子）达到了紧性。

Conclusion: 本文研究了隐式分布聚类问题，目标是根据 $\varepsilon$-远（总变差距离）的两个簇分布，恢复对 $k$ 个分布的隐藏划分。作者为两种基本情况（一个簇分布已知和两个簇分布都未知）确定了样本复杂度的上下界。这些界限精确地刻画了样本复杂度对域大小 $n$、分布数量 $k$、其中一个簇的大小 $r$ 以及距离 $\varepsilon$ 的依赖关系，并在所有情况下（除了 $O(\log k)$ 因子外）达到了紧性。研究结果为分布聚类问题的样本需求提供了理论基础。

Abstract: We study the following distribution clustering problem: Given a hidden partition of $k$ distributions into two groups, such that the distributions within each group are the same, and the two distributions associated with the two clusters are $\varepsilon$-far in total variation, the goal is to recover the partition. We establish upper and lower bounds on the sample complexity for two fundamental cases: (1) when one of the cluster's distributions is known, and (2) when both are unknown. Our upper and lower bounds characterize the sample complexity's dependence on the domain size $n$, number of distributions $k$, size $r$ of one of the clusters, and distance $\varepsilon$. In particular, we achieve tightness with respect to $(n,k,r,\varepsilon)$ (up to an $O(\log k)$ factor) for all regimes.

</details>


### [13] [Finding All Bounded-Length Simple Cycles in a Directed Graphs - Revisited](https://arxiv.org/abs/2512.08392)
*Frank Bauernöppel,Jörg-Rüdiger Sack*

Main category: cs.DS

TL;DR: 关联：图处理（Graph processing）。总结：本文分析了 Gupta 和 Suzumura（2021年）提出的有向图枚举所有有界长度简单环的算法，通过具体的反例证明该算法会遗漏某些有效环，并详细指出了其证明中的逻辑漏洞。作者随后提出了一个修正后的公式来解决这些问题，同时保持了原算法所宣称的 $O((c + 1) \cdot k \cdot (n + e))$ 理想计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 原有的 Gupta 和 Suzumura 提出的有界长度简单环枚举算法存在缺陷，无法枚举所有有效环。进行修正的目的是为了确保算法的正确性，并保持其可接受的计算复杂度。

Method: 1. 提出具体的有向图反例，证明原算法无法枚举某些有效的简单环。2. 通过反例进行详细分析，找出原算法证明中存在的逻辑漏洞。3. 提出修正后的公式，以解决现有问题。

Result: 证明了 Gupta 和 Suzumura 于 2021 年提出的有向图枚举所有有界长度简单环的算法存在错误。提出了修正后的公式，它纠正了原算法的错误，并在理论上保持了 $O((c + 1) \cdot k \cdot (n + e))$ 的计算复杂度。

Conclusion: 本文通过具体的反例及其详细分析，指出了 Gupta 和 Suzumura 提出的有向图枚举所有有界长度简单环算法中的错误。更重要的是，作者提出了一种修正后的公式，解决了现有问题，同时保持了算法的计算复杂度仍为 $O((c + 1) \cdot k \cdot (n + e))$，其中 $c$ 是最大长度为 $k$ 的简单环数量，$n$ 和 $e$ 分别是图的节点和边数量。

Abstract: In 2021, Gupta and Suzumura proposed a novel algorithm for enumerating all bounded-length simple cycles in directed graphs. In this work, we present concrete examples demonstrating that the proposed algorithm fails to enumerate certain valid cycles. Via these examples, we perform a detailed analysis pinpointing the specific points at which the proofs exhibit logical gaps. Furthermore, we propose a corrected formulation that resolves these issues while preserving the desirable property that the algorithm's computational complexity remains $O((c + 1) \cdot k \cdot (n + e))$ where $c$ is the number of simple cycles of a specified maximum length $k$, and $n$ and $e$ the number of graph nodes and edges respectively.

</details>


### [14] [Weighted $k$-Path and Other Problems in Almost $O^*(2^k)$ Deterministic Time via Dynamic Representative Sets](https://arxiv.org/abs/2512.08583)
*Jesper Nederlof*

Main category: cs.DS

TL;DR: 涉及领域：图处理（Graph Processing，因为涉及 $k$-路径问题）。
太长不看摘要：本文提出了一个名为“动态代表集”的新数据结构，用于高效维护集合族并支持特定的组合查询。通过 $2^{k+O(\sqrt{k}\log^2k)}n \log n$ 预处理后，所有操作只需 $2^{k+O(\sqrt{k}\log^2k)}\log n$ 时间。该数据结构的一个关键应用是将加权有向 $k$-路径问题的确定性算法时间复杂度提升至 $2^{k+O(\sqrt{k}\log^2k)}(n+m)\log n$，这一结果部分解决了参数化复杂度领域中一个长期存在的开放问题。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于解决参数化复杂度（Parameterized Complexity）中的核心问题——特别是加权有向 $k$-路径问题（Weighted Directed $k$-Path），这是该领域的一个主要开放问题。作者旨在设计一个通用的数据结构（即动态代表集），该结构能够高效地支持集合族的动态更新和特定的组合查询（如不相交子集查询），并将其应用于如 $k$-路径等经典算法问题，以期提供比现有工作更优的性能改进。

Method: 本文的核心方法是提出并设计了动态代表集（Dynamic Representative Set）这一数据结构，用于维护 $n$ 个元素子集族 $\mathcal{F}$ 的表示。该数据结构支持：
1. **更新操作**：两个集合族的并集、元素卷积。
2. **查询操作**：给定集合 $B$，查询是否存在大小至多为 $k-|B|$ 且与 $B$ 不相交的集合 $A \in \mathcal{F}$。
通过 $2^{k+O(\sqrt{k}\log^2k)}n \log n$ 的预处理时间，所有操作的查询时间复杂度为 $2^{k+O(\sqrt{k}\log^2k)}\log n$。
作者随后将这一数据结构应用于加权有向 $k$-路径（Weighted Directed $k$-Path）问题，设计了一个确定性算法，时间复杂度为 $2^{k+O(\sqrt{k}\log^2k)}(n+m)\log n$。

Result: 1. **数据结构**：提出了动态代表集（Dynamic Representative Set），在 $2^{k+O(\sqrt{k}\log^2k)}n \log n$ 预处理时间后，更新和查询操作的时间复杂度为 $2^{k+O(\sqrt{k}\log^2k)}\log n$。
2. **应用**：将该数据结构应用于加权有向 $k$-路径问题。
3. **算法改进**：提供了一个确定性的算法，能在 $2^{k+O(\sqrt{k}\log^2k)}(n+m)\log n$ 时间内（在 $word$ RAM 模型下，权重适合单个 $word$）求解 $n$ 顶点图中的最小边长度 $k$ 顶点路径。
4. **影响**：除了低阶项 $2^{O(\sqrt{k}\log^2k)} $ 外，该结果回答了参数化复杂度领域中一个长期被提出的主要开放问题，显著超越了现有成果。

Conclusion: 本文提出了一个名为“动态代表集”的数据结构，该结构在参数化复杂度、动态维护和组合查询方面有着广泛的应用。具体而言，它在加权有向 $k$-路径问题上提供了 $2^{k+O(\sqrt{k}\log^2k)}(n+m)\log n$ 时间的确定性算法，显著改善了现有结果，并部分解决了该领域的一个主要开放问题。

Abstract: We present a data structure that we call a Dynamic Representative Set. In its most basic form, it is given two parameters $0< k < n$ and allows us to maintain a representation of a family $\mathcal{F}$ of subsets of $\{1,\ldots,n\}$. It supports basic update operations (unioning of two families, element convolution) and a query operation that determines for a set $B \subseteq \{1,\ldots,n\}$ whether there is a set $A \in \mathcal{F}$ of size at most $k-|B|$ such that $A$ and $B$ are disjoint. After $2^{k+O(\sqrt{k}\log^2k)}n \log n$ preprocessing time, all operations use $2^{k+O(\sqrt{k}\log^2k)}\log n$ time.
  Our data structure has many algorithmic consequences that improve over previous works. One application is a deterministic algorithm for the Weighted Directed $k$-Path problem, one of the central problems in parameterized complexity. Our algorithm takes as input an $n$-vertex directed graph $G=(V,E)$ with edge lengths and an integer $k$, and it outputs the minimum edge length of a path on $k$ vertices in $2^{k+O(\sqrt{k}\log^2k)}(n+m)\log n$ time (in the word RAM model where weights fit into a single word). Modulo the lower order term $2^{O(\sqrt{k}\log^2k)}$, this answers a question that has been repeatedly posed as a major open problem in the field.

</details>


### [15] [Fast exact algorithms via the Matrix Tree Theorem](https://arxiv.org/abs/2512.08600)
*V. Arvind,Srijan Chakraborty,Samir Datta,Asif Khan*

Main category: cs.DS

TL;DR: This paper is related to graph processing and compiler (in the context of analyzing algorithms that might be used in optimization, although not directly an optimization implementation). For graph processing, the paper explicitly deals with Hamiltonian paths, perfect matchings, graph partitioning (k-stars), and maximum matchings in bipartite and general graphs.
The paper devises simple and similar algorithms for Hamiltonian paths in undirected and directed bipartite graphs using the Matrix-Tree theorem and sieving with roots of unity. This framework is then used for counting perfect matchings, counting k-star partitions (achieving improved running time $O^*((1+ε_k)^n)$ as $k \rightarrow \infty$), and counting maximum matchings via Björklund's algorithm and Gallai-Edmonds theorem.


<details>
  <summary>Details</summary>
Motivation: 现有的无向和有向二分图哈密顿路径的精确算法是已知的，但它们优雅但复杂，且彼此不同。本文的动机是设计**简单、相似且具有相同上界**的算法来解决这些问题，并希望将这种统一的框架应用于图论中的其他计数问题，例如完美匹配、图划分和最大匹配计数等。

Method: 1. 为无向和有向二分图的哈密顿路径计数设计了简单且相似的算法，这些算法使用Matrix-Tree定理和单位根筛选技术（sieving using roots of unity）。
2. 使用基于哈密顿路径算法的框架，提出了计算二分图完美匹配数（即计算$\{0,1\}$-permanent）的替代算法，其运行时间与Ryser算法相似。
3. 利用该方法的灵活性，计算了将图划分为$k$-星（k-star）的方式数量，并在$k \rightarrow \infty$时，运行时间上取得了显著改善。
4. 结合Björklund的算法和Gallai-Edmonds分解定理，计算了一般图的最大匹配计数。

Result: 1. 提出了计算无向和有向二分图哈密顿路径的快速精确算法，这些算法基于Matrix-Tree定理和单位根筛选，既简单又相似，且与现有算法具有相同的上界。
2. 成功地将所提出的框架应用于二分图完美匹配的计数，得到了与Ryser算法运行时间相似的替代算法。
3. 展示了该方法的灵活性，通过计算图的$k$-星划分数量，实现了运行时间的显著提升，即$O^*((1+ε_k)^n)$，其中$ε_k \rightarrow 0$ 当 $k \rightarrow \infty$。
4. 结合Björklund的算法和Gallai-Edmonds分解定理，证明了最大匹配的计数可以在$O^*(2^ν)$时间内计算，其中$ν$是最大匹配的大小。
5. 所有提出的算法都只需要多项式空间。

Conclusion: 本文提出的算法基于Matrix-Tree定理和单位根的筛选（sieving using roots of unity），为二分图和有向二分图的哈密顿路径计数提供了简化且统一的方法，并成功应用于完美匹配计数、k-星划分计数和最大匹配计数等问题。其核心优势在于算法的简洁性、统一性和在特定场景（如k-星划分）下运行时间的显著提升。所有算法均在多项式空间内运行。

Abstract: Fast exact algorithms are known for Hamiltonian paths in undirected and directed bipartite graphs through elegant though involved algorithms that are quite different from each other. We devise algorithms that are simple and similar to each other while having the same upper bounds. The common features of these algorithms is the use of the Matrix-Tree theorem and sieving using roots of unity.
  Next, we use the framework to provide alternative algorithms to count perfect matchings in bipartite graphs on $n$ vertices, i.e., computing the $\{0,1\}$-permanent of a square $n/2 \times n/2$ matrix which runs in a time similar to Ryser.
  We demonstrate the flexibility of our method by counting the number of ways to vertex partition the graph into $k$-stars (a $k$-star consist of a tree with a root having $k-1$ children that are all leaves). Interestingly, our running time improves to $O^*((1+ε_k)^n)$ with $ε_k \rightarrow 0$ as $k \rightarrow \infty$.
  As an aside, making use of Björklund's algorithm for exact counting perfect matchings in general graphs, we show that the count of maximum matchings can be computed in time $O^*(2^ν)$ where $ν$ is the size of a maximum matching. The crucial ingredient here is the famous Gallai-Edmonds decomposition theorem.
  All our algorithms run in polynomial space.

</details>


### [16] [Parallel Batch Dynamic Vertex Coloring in $O(\log Δ)$ Amortized Update Time](https://arxiv.org/abs/2512.08742)
*Chase Hutton,Adam Melrod*

Main category: cs.DS

TL;DR: 该论文与图处理（顶点着色）相关。
本文首次提出了一种用于维护适当 $(Δ+ 1)$ 顶点着色的并行批处理动态算法。该方法基于一种新的顺序动态算法，实现了 $O(\log Δ)$ 的预期分摊更新时间，并且对于大小为 $b$ 的批处理更新，具有 $O(\operatorname{polylog} b + \operatorname{polylog} n)$ 的高概率并行跨度。


<details>
  <summary>Details</summary>
Motivation: 需要一种高效的、支持并行批处理更新的算法来持续维护图的适当 $(Δ+ 1)$ 顶点着色。

Method: 提出了一种新的顺序动态算法，该算法受到 Bhattacharya 等人工作的启发。然后，在此基础上设计了第一个并行批处理动态算法，用于维护适当的 $(Δ+ 1)$ 顶点着色。

Result: 所提出的随机算法实现了 $O(\log Δ)$ 的预期分摊更新时间。对于任意 $b$ 个更新组成的批处理，算法具有 $O(\operatorname{polylog} b + \operatorname{polylog} n)$ 的高概率并行跨度。

Conclusion: 本文首次提出了维护适当 $(Δ+ 1)$ 顶点着色的并行批处理动态算法，并基于新的顺序动态算法，实现了对批处理更新的高效并行处理。

Abstract: We present the first parallel batch-dynamic algorithm for maintaining a proper $(Δ+ 1)$-vertex coloring. Our approach builds on a new sequential dynamic algorithm inspired by the work of Bhattacharya et al. (SODA'18). The resulting randomized algorithm achieves $O(\log Δ)$ expected amortized update time and, for any batch of $b$ updates, has parallel span $O(\operatorname{polylog} b + \operatorname{polylog} n)$ with high probability.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [17] [NysX: An Accurate and Energy-Efficient FPGA Accelerator for Hyperdimensional Graph Classification at the Edge](https://arxiv.org/abs/2512.08089)
*Jebacyril Arockiaraj,Dhruv Parikh,Viktor Prasanna*

Main category: cs.AR

TL;DR: 该论文与**图处理**（图分类）、**编译器/HLS**（FPGA加速器、流式架构、静态负载平衡）相关。

**TLDR:** 本文提出了NysX，是首个针对基于Nyström核近似的超维计算（HDC）图分类的端到端FPGA加速器，用于解决边缘设备上加速面临的四大挑战（样本冗余、内存限制、码本查找开销和SpMV负载不平衡）。NysX通过集成混合地标选择策略、流式Nyström投影矩阵架构、最小完美哈希查找引擎和稀疏感知SpMV引擎等优化技术，在AMD ZCU104 FPGA上实现了相较于优化CPU基线6.85倍的速度提升和169倍的能效提升，同时平均提高了3.4%的分类准确性。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上实现实时、高能效的图分类推理对许多应用至关重要。超维计算（HDC）因其低精度、高维向量编码和简单的操作，适用于资源受限的边缘平台。最近的工作通过Nyström核近似提高了HDC在图分类中的准确性。然而，对这种方法进行边缘加速面临以下几个挑战：
1. **样本冗余：** 通过均匀采样选择的地标（landmark）样本存在冗余。
2. **内存限制：** 在有限的片上内存下存储Nyström投影矩阵。
3. **查找开销：** 昂贵且容易引发竞争的码本查找。
4. **负载不平衡：** $\text{SpMV}$（稀疏矩阵向量乘法）中不规则的稀疏性导致负载不平衡。

为了解决这些挑战，作者提出了NysX。

Method: 作者提出了NysX，第一个用于基于Nyström的HDC图分类的端到端FPGA加速器。NysX集成了四个关键优化措施：
1. **混合地标选择（Hybrid Landmark Selection）：** 结合均匀采样（uniform sampling）和行列式点过程（DPPs）来减少冗余并提高准确性。
2. **Nyström投影矩阵的流式架构（Streaming Architecture）：** 最大化外部内存带宽利用率，解决内存限制问题。
3. **最小完美哈希查找引擎（Minimal-Perfect-Hash Lookup Engine）：** 实现$O(1)$复杂度、低片上内存开销的键到索引映射，解决昂贵的码本查找问题。
4. **稀疏感知SpMV引擎（Sparsity-aware SpMV Engines）：** 具有静态负载平衡功能，解决不规则稀疏性导致的负载不平衡问题。

这些优化措施共同实现了在资源受限平台上实时、节能的推理。

Result: NysX在AMD Zynq UltraScale+ (ZCU104) FPGA上实现并进行了评估。结果显示：
1. **速度提升：** 相较于优化的CPU基线，获得 $6.85\times$ 的加速；相较于优化的GPU基线，获得 $4.32\times$ 的加速。
2. **能效提升：** 相较于优化的CPU基线，能效提升 $169\times$；相较于优化的GPU基线，能效提升 $314\times$。
3. **准确性提高：** 在TUDataset基准测试中，平均分类准确性提高了 $3.4\%$。

这些结果证明了NysX能够在资源受限的平台上实现实时、节能的推理，并显著优于现有的 CPU/GPU 优化方案。

Conclusion: NysX是第一个针对基于Nyström的HDC图分类的端到端FPGA加速器。通过混合地标选择、流式Nyström投影矩阵架构、最小完美哈希查找引擎和稀疏感知SpMV引擎，NysX在边缘设备上实现了实时、节能的图分类推理，相较于优化的CPU和GPU基线，在速度和能效上取得了显著提升，并同时提高了分类准确性。这一成果为在资源受限的边缘平台上部署先进的图分类模型提供了可行且高效的解决方案。

Abstract: Real-time, energy-efficient inference on edge devices is essential for graph classification across a range of applications. Hyperdimensional Computing (HDC) is a brain-inspired computing paradigm that encodes input features into low-precision, high-dimensional vectors with simple element-wise operations, making it well-suited for resource-constrained edge platforms. Recent work enhances HDC accuracy for graph classification via Nyström kernel approximations. Edge acceleration of such methods faces several challenges: (i) redundancy among (landmark) samples selected via uniform sampling, (ii) storing the Nyström projection matrix under limited on-chip memory, (iii) expensive, contention-prone codebook lookups, and (iv) load imbalance due to irregular sparsity in SpMV. To address these challenges, we propose NysX, the first end-to-end FPGA accelerator for Nyström-based HDC graph classification at the edge. NysX integrates four key optimizations: (i) a hybrid landmark selection strategy combining uniform sampling with determinantal point processes (DPPs) to reduce redundancy while improving accuracy; (ii) a streaming architecture for Nyström projection matrix maximizing external memory bandwidth utilization; (iii) a minimal-perfect-hash lookup engine enabling $O(1)$ key-to-index mapping with low on-chip memory overhead; and (iv) sparsity-aware SpMV engines with static load balancing. Together, these innovations enable real-time, energy-efficient inference on resource-constrained platforms. Implemented on an AMD Zynq UltraScale+ (ZCU104) FPGA, NysX achieves $6.85\times$ ($4.32\times$) speedup and $169\times$ ($314\times$) energy efficiency gains over optimized CPU (GPU) baselines, while improving classification accuracy by $3.4\%$ on average across TUDataset benchmarks, a widely used standard for graph classification.

</details>
