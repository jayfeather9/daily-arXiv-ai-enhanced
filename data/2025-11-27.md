<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 2]
- [cs.AR](#cs.AR) [Total: 3]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.DC](#cs.DC) [Total: 5]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Optimism in Equality Saturation](https://arxiv.org/abs/2511.20782)
*Russel Arbore,Alvin Cheung,Max Willsey*

Main category: cs.PL

TL;DR: 该论文与编译器相关。

**太长不看（TLDR）:** 等价性饱和（ES）优化技术现有的 e-class 分析在处理 SSA 形式的循环程序时不够精确。本文提出了一个基于抽象解释的统一算法，可以在 ES 过程中精确分析循环，从而实现乐观分析和非破坏性重写。在一个 SSA 程序抽象解释器原型上的实验表明，该方法在简单程序分析上比 Clang 和 GCC 更精确。


<details>
  <summary>Details</summary>
Motivation: 现有的等价性饱和（Equality Saturation）技术所采用的 e-class 分析是悲观的（pessimistic），这导致它在分析循环程序（如 SSA 形式的程序）时效率低下或不精确。因此，需要一个更精确、能够处理循环的分析方法。

Method: 提出了一种抽象解释算法，用于在等价性饱和过程中精确分析程序中的循环（如 SSA 形式中的程序）。该方法为乐观分析和非破坏性重写提供了一个统一的算法。并通过设计 SSA 新的语义，实现了一个针对 SSA 程序的抽象解释器原型。

Result: 所提出的抽象解释器原型，在分析简单的示例程序时，表现出比 Clang 和 GCC 更高的精确度。

Conclusion: 本文提出了一种抽象解释算法，能够精确分析等价性饱和（Equality Saturation, ES）过程中的循环结构。这使得乐观分析和非破坏性重写得以统一。通过为 SSA 程序设计新的语义以及实现抽象解释原型，展示了在简单程序上比 Clang 和 GCC 更精确的分析效果。

Abstract: Equality saturation is a technique for program optimization based on non-destructive rewriting and a form of program analysis called e-class analysis. The current form of e-class analysis is pessimistic and therefore ineffective at analyzing cyclic programs, such as those in SSA form. We propose an abstract interpretation algorithm that can precisely analyze cycles during equality saturation. This results in a unified algorithm for optimistic analysis and non-destructive rewriting. We instantiate this approach on a prototype abstract interpreter for SSA programs using a new semantics of SSA. Our prototype can analyze simple example programs more precisely than clang and gcc.

</details>


### [2] [Towards Computational UIP in Cubical Agda](https://arxiv.org/abs/2511.21209)
*Yee-Jian Tan,Andreas Nuyts,Dominique Devriese*

Main category: cs.PL

TL;DR: 关联领域：DSL（否），图处理（否），MLIR（否），编译器（否），HLS（否）。本文属于**类型论/证明助手/编程语言理论**领域。
太长不看（TLDR）：本文讨论了如何在 Cubical Agda 中构建一个实用且简化的高阶同伦类型理论（"h-Set Cubical Type Theory"）。其目标是保留 Cubical Type Theory 的优势（如 QITs 和功能外延性），但通过移除 Univalence 公理（移除 Glue Types）并假设同一性证明的唯一性（UIP）来消除 HoTT 中复杂的无限层级等式。目前在 Cubical Agda 中实现 UIP 的方式要么破坏规范性，要么过于繁琐。因此，本文分析了不同的 UIP 公式化和计算规则，并实现了一个不包含 Glue 的 Cubical Agda 变体，以此为 Agda 未来自动实现 UIP 并得到一个规范的 h-Set Cubical Type Theory 做准备。


<details>
  <summary>Details</summary>
Motivation: Cubical Type Theory（如 Cubical Agda 中实现）具有优于内涵 Martin-Löf Type Theory 的优点，例如商归纳类型（QITs）和可证明的功能外延性（Functional Extensionality）。然而，高阶同伦类型理论（HoTT）的无限层级等式（infinite hierarchy of equalities）使其形式化变得难以操作。本文的动机在于，QITs 和功能外延性在等式层级被截断到同伦集合（h-Sets），即假设“同一性证明的唯一性”（UIP）并移除 Univalence 公理时，仍然得以保留。因此，研究人员希望构建一个“h-Set Cubical Type Theory”，它既保留了 Cubical Type Theory 的实用特性，又避免了高阶等式带来的复杂性，从而得到一个更易于使用的类型系统。目前在 Cubical Agda 中实现这一点的方式并不理想，需要一个更具规范性的自动实现方法。

Method: 本文通过理论分析和原型实现的方法来研究 h-Set Cubical Type Theory 在 Cubical Agda 中的实现。具体方法包括：1. 理论分析：分析 Cubical Type Theory、Univalence、Glue Types、UIP 和 h-Sets 之间的关系。2. 探讨实现策略：分析当前在 Cubical Agda 中实现 h-Set Cubical Type Theory 的两种不理想方式（直接公设 UIP 或手动证明每个类型上的 UIP）。3. 深入研究 UIP 公式化：详细分析不同的 UIP 公式化及其计算规则，评估其在 Cubical Agda 中实现的适用性。4. 实施准备工作：实现了一个不包含 Glue 的 Cubical Agda 变体，该变体与公设 UIP 兼容，为未来自动实现 UIP 打下基础。

Result: 本文详细分析了不同 UIP 公式化及其计算规则在 Cubical Agda 中实现的适用性。研究结果表明，通过移除 Glue Types 并假设 UIP，可以构建一个“h-Set Cubical Type Theory”，该理论保留了功能外延性（Functional Extensionality）和商归纳类型（QITs）。此外，作者还实现了一个不包含 Glue 的 Cubical Agda 变体，这使其与公设的 UIP 兼容，并为 Cubical Agda 未来自动实现 UIP 铺平了道路，从而解决了当前手动证明 UIP 的繁琐问题。虽然没有直接提出最终的自动实现方案，但为实现目标提供了坚实的理论和实践基础。

Conclusion: 本文分析了如何在 Cubical Agda 中实现 h-Set Cubical Type Theory。通过移除 Glued Types（从而移除了 Univalence）并在类型上进行 Set 截断（即假设 UIP），研究者旨在构建一个既保留功能外延性（Functional Extensionality）和商归纳类型（QITs）等优点，又避免无限层级等式复杂性的“h-Set Cubical Type Theory”。文章详细探讨了不同的 UIP 公式化及其计算规则在 Cubical Agda 中的实现可行性，并基于一个不包含 Glue 的 Cubical Agda 变体，为未来在 Agda 中自动实现 UIP 奠定了基础。目的是在保留 Cubical Type Theory 实用优势的同时，获得一个更具规范性和操作性的类型系统。

Abstract: Some advantages of Cubical Type Theory, as implemented by Cubical Agda, over intensional Martin-Löf Type Theory include Quotient Inductive Types (QITs), which exist as instances of Higher Inductive Types, and functional extensionality, which is provable in Cubical Type Theory. However, HoTT features an infinite hierarchy of equalities that may become unwieldy in formalisations. Fortunately, QITs and functional extensionality are both preserved even if the equality levels of Cubical Type Theory are truncated to only homotopical Sets (h-Sets). In other words, removing the univalence axiom from Cubical Type Theory and instead postulating a conflicting axiom: the Uniqueness of Identity Proofs (UIP) postulate. Since univalence is proved in Cubical Type Theory from the so-called Glue Types, therefore, it is known that one can first remove the Glue Types (thus removing univalence) and then set-truncate all equalities (essentially assuming UIP), à la XTT. The result is a "h-Set Cubical Type Theory" that retains features such as functional extensionality and QITs.
  However, in Cubical Agda, there are currently only two unsatisfying ways to achieve h-Set Cubical Type Theory. The first is to give up on the canonicity of the theory and simply postulate the UIP axiom, while the second way is to use a standard result stating "type formers preserve h-levels" to manually prove UIP for every defined type. The latter is, however, laborious work best suited for an automatic implementation by the proof assistant. In this project, we analyse formulations of UIP and detail their computation rules for Cubical Agda, and evaluate their suitability for implementation. We also implement a variant of Cubical Agda without Glue, which is already compatible with postulated UIP, in anticipation of a future implementation of UIP in Cubical Agda.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [3] [Bombyx: OpenCilk Compilation for FPGA Hardware Acceleration](https://arxiv.org/abs/2511.21346)
*Mohamed Shahawy,Julien de Castelnau,Paolo Ienne*

Main category: cs.AR

TL;DR: 与 DSL、图处理、MLIR、编译器、HLS 相关。
- **编译器关系**: Bombyx 是一个将 OpenCilk 程序转换为 Cilk-1 IR 的编译器工具链。
- **HLS 关系**: 编译器生成可综合的 PE 目标，专为 Vitis HLS 等 HLS 工具设计。

Too long; didn't read: 本文提出了 Bombyx 编译器工具链，旨在将面向 CPU 的 OpenCilk TLP 程序高效地映射到 FPGA 空间架构。Bombyx 采用 Cilk-1 风格的显式延续传递模型来避免硬件上下文切换，更匹配 FPGA 的流式特性。它支持生成兼容 OpenCilk 运行时的代码，以及用于 HLS 工具（如 Vitis HLS）的可综合 PE。此外，通过解耦的访问-执行优化，Bombyx 实现了高性能 PE 的自动生成，提升了内存-计算重叠和整体吞吐量。


<details>
  <summary>Details</summary>
Motivation: - **背景**: 任务级并行（TLP）在软件中广泛应用，但近年来的系统开始探索在 FPGA 上实现 TLP 的架构支持，通常利用高等级综合（HLS）创建处理单元（PE）。
- **挑战**: 现有的 OpenCilk 等 CPU 导向的 TLP 模型的隐式任务模型在硬件中需要昂贵的上下文切换，不适合 FPGA 的空间架构和流式特性。
- **目标**: 设计一个编译器工具链，能够高效地将面向 CPU 的 TLP 应用（如 OpenCilk 程序）映射到 FPGA，并解决隐式任务模型带来的硬件效率问题。

Method: - **编译器工具链 Bombyx**: 将 OpenCilk 程序转换为 Cilk-1 风格的中间表示（IR）。
- **Cilk-1 风格的显式延续传递模型**: 区别于 OpenCilk 的隐式任务模型，该模型避免了昂贵的硬件上下文切换，更符合 FPGA 的流式特性。
- **多重编译目标**:
    - 一个是与 OpenCilk 兼容的运行时，用于使用 OpenCilk 后端执行 Cilk-1 风格的代码。
    - 另一个是可综合的处理单元（PE）生成器，专为 Vitis HLS 等 HLS 工具设计。
- **解耦的访问-执行优化（Decoupled Access-Execute Optimization）**: 自动生成高性能 PE，以改善内存与计算的重叠（memory-compute overlap）和整体吞吐量。

Result: - 成功开发了名为 Bombyx 的编译器工具链，能够将 OpenCilk 程序降级到 Cilk-1 风格的中间表示。
- Bombyx 支持生成 Cilk-1 风格代码，既可以在 OpenCilk 兼容运行时上运行，也可以生成可综合的 PE，用于 Vitis HLS 等 HLS 工具。
- 引入了解耦的访问-执行优化，**自动生成了高性能的 PE**，显著提高了内存与计算的重叠和整体吞吐量。

Conclusion: Bombyx 作为一个编译器工具链，成功地将面向 CPU 的 OpenCilk TLP 程序映射到基于 FPGA 的空间架构上，通过采用 Cilk-1 风格的显式延续传递模型和解耦的访问-执行优化，生成了高效且可综合的 PE。它证明了 Cilk-1 模型更适合 FPGA 的流式特性，为在 FPGA 上实现高性能的 TLP 应用提供了新的途径。

Abstract: Task-level parallelism (TLP) is a widely used approach in software where independent tasks are dynamically created and scheduled at runtime. Recent systems have explored architectural support for TLP on field-programmable gate arrays (FPGAs), often leveraging high-level synthesis (HLS) to create processing elements (PEs). In this paper, we present Bombyx, a compiler toolchain that lowers OpenCilk programs into a Cilk-1-inspired intermediate representation, enabling efficient mapping of CPU-oriented TLP applications to spatial architectures on FPGAs. Unlike OpenCilk's implicit task model, which requires costly context switching in hardware, Cilk-1 adopts explicit continuation-passing - a model that better aligns with the streaming nature of FPGAs. Bombyx supports multiple compilation targets: one is an OpenCilk-compatible runtime for executing Cilk-1-style code using the OpenCilk backend, and another is a synthesizable PE generator designed for HLS tools like Vitis HLS. Additionally, we introduce a decoupled access-execute optimization that enables automatic generation of high-performance PEs, improving memory-compute overlap and overall throughput.

</details>


### [4] [A Jammer-Resilient 2.87 mm$^2$ 1.28 MS/s 310 mW Multi-Antenna Synchronization ASIC in 65 nm](https://arxiv.org/abs/2511.21451)
*Flurin Arquint,Oscar Castañeda,Gian Marti,Christoph Studer*

Main category: cs.AR

TL;DR: 与DSL或图处理或MLIR或编译器或HLS均不相关。
这篇论文介绍了首个用于抗干扰多天线时间同步的ASIC实现，该ASIC集成了利用多天线处理来缓解同步信号干扰攻击的算法。该设计支持单天线发射机和16天线接收机间的同步，能对抗多达两个发射天线的智能干扰源。该65纳米ASIC的核心面积为2.87 mm$^2$，功耗310 mW，采样率为1.28 MS/s。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是解决时间同步信号容易受到干扰攻击的问题，特别是在存在智能干扰源的情况下，并首次提出并实现了基于多天线处理的抗干扰时间同步算法的ASIC硬件实现。

Method: 该论文实现了一个ASIC（专用集成电路），它集成了最近提出的使用多天线处理来减轻对同步信号的干扰攻击的算法。该设计支持单天线发射机和16天线接收机之间的同步，并能对抗高达两个发射天线的智能干扰源。

Result: 该ASIC使用65纳米工艺制造，核心面积为2.87 mm$^2$，功耗为310 mW，支持的采样率为1.28 MS/s。该芯片成功实现了抗干扰的多天线时间同步，能够减轻具有多达两个发射天线的智能干扰源的攻击。

Conclusion: 该论文介绍了首个抗干扰多天线时间同步ASIC的实现，验证了所提算法在硬件中的有效性，并展示了在65纳米工艺下的具体性能指标。

Abstract: We present the first ASIC implementation of jammer-resilient multi-antenna time synchronization. The ASIC implements a recent algorithm that mitigates jamming attacks on synchronization signals using multi-antenna processing. Our design supports synchronization between a single-antenna transmitter and a 16-antenna receiver while mitigating smart jammers with up to two transmit antennas. The fabricated 65 nm ASIC has a core area of 2.87 mm$^2$, consumes a power of 310 mW, and supports a sampling rate of 1.28 mega-samples per second (MS/s).

</details>


### [5] [A 0.32 mm$^2$ 100 Mb/s 223 mW ASIC in 22FDX for Joint Jammer Mitigation, Channel Estimation, and SIMO Data Detection](https://arxiv.org/abs/2511.21461)
*Jonas Elmiger,Fabian Stuber,Oscar Castañeda,Gian Marti,Christoph Studer*

Main category: cs.AR

TL;DR: 该论文与 DSL、图处理、MLIR、编译器或 HLS **均不相关**。
该论文介绍了首个单输入多输出（SIMO）接收机 ASIC，该芯片实现了名为 MAED 的同步干扰缓解、信道估计和数据检测算法。MAED 通过非线性优化和空间滤波来抵抗智能干扰，以实现最先进的错误率性能。该 ASIC 采用 22 nm FD-SOI 工艺制造，支持八个接收天线，核心面积为 0.32 mm$^2$，实现了 100 Mb/s 的吞吐量和 223 mW 的功耗。与现有技术相比，该设计在每用户吞吐量上提高了 3 倍，在面积效率上提高了 4.5 倍。


<details>
  <summary>Details</summary>
Motivation: 在存在智能干扰的情况下，需要一个能够联合执行干扰缓解、信道估计和数据检测的高性能接收机。这促使研究人员提出并实现了一种能有效应对干扰，同时保持高错误率性能的先进算法及其硬件实现。该论文的目标是首次实现一个能联合执行这些关键功能的 SIMO 接收机 ASIC。

Method: 本文设计并制造了一个单输入多输出（SIMO）接收机专用集成电路（ASIC）。该 ASIC 实现了名为“siMultaneous mitigAtion, Estimation, and Detection (MAED)”的先进算法。MAED 算法通过一个统一了干扰估计与置零、信道估计和数据检测的非线性优化问题，使用空间滤波技术来减轻智能干扰的影响。该设计支持八个接收天线，能够减轻智能干扰和弹幕式干扰。

Result: 所设计的 ASIC 采用 22 nm FD-SOI 工艺制造，核心面积为 0.32 mm$^2$。该芯片实现了 100 Mb/s 的吞吐量，功耗为 223 mW。与现有最先进的抗干扰检测器相比，该 ASIC 实现了 3 倍的每用户吞吐量提升和 4.5 倍的面积效率提升，并在干扰环境下获得了最先进的错误率性能。

Conclusion: 本文介绍了首个实现 MAED 算法的 SIMO 接收机 ASIC，该芯片在 22 nm FD-SOI 工艺下制造，核心面积小，吞吐量达到 100 Mb/s，功耗为 223 mW。其性能优于现有技术，在每用户吞吐量上提高了 3 倍，在面积效率上提高了 4.5 倍。这表明 MAED 算法及其 ASIC 实现是应对智能和弹幕式干扰的高效解决方案。

Abstract: We present the first single-input multiple-output (SIMO) receiver ASIC that jointly performs jammer mitigation, channel estimation, and data detection. The ASIC implements a recent algorithm called siMultaneous mitigAtion, Estimation, and Detection (MAED). MAED mitigates smart jammers via spatial filtering using a nonlinear optimization problem that unifies jammer estimation and nulling, channel estimation, and data detection to achieve state-of-the-art error-rate performance under jamming. The design supports eight receive antennas and enables mitigation of smart jammers as well as of barrage jammers. The ASIC is fabricated in 22 nm FD-SOI, has a core area of 0.32 mm$^2$, and achieves a throughput of 100 Mb/s at 223 mW, thus delivering 3$\times$ higher per-user throughput and 4.5$\times$ higher area efficiency than the state-of-the-art jammer-resilient detector.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [6] [Quadratic-Time Algorithm for the Maximum-Weight $(k, \ell)$-Sparse Subgraph Problem](https://arxiv.org/abs/2511.20882)
*Bence Deák,Péter Madarasi*

Main category: cs.DS

TL;DR: 该论文不涉及 DSL、图处理、MLIR、编译器或 HLS。
这篇论文解决了计算最大权重 $(k, \ell)$-稀疏子图的算法问题。现有的方法是 $O(nm)$ 时间，而先前声称的 $O(n^2 + m)$ 算法被证明是基于错误分析的。作者提出了第一个正确的时间复杂度为 $O(n^2 + m)$ 的算法，它结合了高效数据结构和精细分析。这一新的二次时间算法加速了刚性理论中几个关键问题的解决，如计算最小权重冗余刚性和全局刚性子图。


<details>
  <summary>Details</summary>
Motivation: 最大权重 $(k, \ell)$-稀疏子图是组合优化和刚性理论中的一个关键算法问题。虽然已有的方法提供了 $O(nm)$ 的解决方案，但先前提出的 $O(n^2 + m)$ 方法被证明是基于不正确分析的，因此实现这一二次时间界限的问题仍然悬而未决。作者的动机是肯定地回答这个问题，并**首次**提出一个正确且时间复杂度为 $O(n^2 + m)$ 的算法。

Method: 本文通过结合高效的数据结构和精密的分析，提出了第一个时间复杂度为 $O(n^2 + m)$ 的算法来计算最大权重 $(k, \ell)$-稀疏子图。

Result: 本文提出了第一个 $O(n^2 + m)$ 时间复杂度算法来计算最大权重 $(k, \ell)$-稀疏子图。该二次时间算法比现有 $O(nm)$ 的方法更快，并加速了刚性理论中几个关键问题的解决，包括计算最小权重冗余刚性和全局刚性子图、列举非交叉最小刚性框架和识别运动学关节。

Conclusion: 本文提出了第一个时间复杂度为 $O(n^2 + m)$ 的最大权重 $(k, \ell)$-稀疏子图算法，解决了该二次时间界限是否可达的问题。这一突破性的算法组合了高效的数据结构和精密的分析。这一更快的算法能加速解决刚性理论中的几个关键问题，包括计算最小权重冗余刚性和全局刚性子图、列举非交叉最小刚性框架以及识别运动学关节等。

Abstract: The family of $(k, \ell)$-sparse graphs, introduced by Lorea, plays a central role in combinatorial optimization and has a wide range of applications, particularly in rigidity theory. A key algorithmic challenge is to compute a maximum-weight $(k, \ell)$-sparse subgraph of a given edge-weighted graph. Although prior approaches have long provided an $O(nm)$-time solution, a previously proposed $O(n^2 + m)$ method was based on an incorrect analysis, leaving open whether this bound is achievable.
  We answer this question affirmatively by presenting the first $O(n^2 + m)$-time algorithm for computing a maximum-weight $(k, \ell)$-sparse subgraph, which combines an efficient data structure with a refined analysis. This quadratic-time algorithm enables faster solutions to key problems in rigidity theory, including computing minimum-weight redundantly rigid and globally rigid subgraphs. Further applications include enumerating non-crossing minimally rigid frameworks and recognizing kinematic joints. Our implementation of the proposed algorithm is publicly available online.

</details>


### [7] [Sublinear Time Low-Rank Approximation of Hankel Matrices](https://arxiv.org/abs/2511.21418)
*Michael Kapralov,Cameron Musco,Kshiteej Sheth*

Main category: cs.DS

TL;DR: DSL, graph processing, MLIR, compiler,或 HLS 均不相关。
这篇论文解决了PSD Hankel矩阵的低秩近似问题。已知的理论结果表明这类矩阵是近似低秩的。本文首次提出了一个在**亚线性时间**$O(\polylog(n, 1/\varepsilon))$内运行的算法，计算出匹配理论误差界限的低秩Hankel近似的因式分解表示。该算法是鲁棒的，可以处理噪声输入。实现这一目标的关键包括证明结构保持的Hankel近似存在性（作为AAK定理的有限维类比），以及使用基于采样的通用岭杠杆分数界方法来利用Hankel矩阵的Vandermonde结构。


<details>
  <summary>Details</summary>
Motivation: Hankel 矩阵因其高结构性，在计算数学、工程和理论计算机科学中都有重要应用。已知的理论结果（Beckermann 和 Townsend 的定理）表明，正半定（PSD）Hankel 矩阵总是近似低秩的，即对于任意 $\varepsilon>0$，最佳秩 $k$ 逼近 $H_k$ 满足 $\|H-H_k\|_F \leq \varepsilon\|H\|_F$，其中 $k = O(\log n \log(1/\varepsilon))$。这一特性使得 PSD Hankel 矩阵成为低秩近似算法的理想目标。然而，到目前为止，还没有在亚线性时间内运行的低秩近似算法。因此，本文的动机是设计第一个在亚线性时间 $\polylog(n, 1/\varepsilon)$ 内运行，并匹配甚至改进现有理论低秩界限的算法。此外，还需要确保算法对噪声具有鲁棒性。

Method: 本文的算法基于采样方法，利用了 Hankel 矩阵的 Vandermonde 结构，并依赖于 Vandermonde 矩阵的通用岭杠杆分数界（ridge leverage score bounds）。在算法实现之前，作者首先证明了一个结构保持（structure-preserving）的存在性定理，即存在一个秩为 $k$ 的 **Hankel** 逼近 $H$ 达到了 Beckermann 和 Townsend 的误差界限，这可以看作是 AAK 定理的有限维模拟。新的算法在多对数时间 $O(\polylog(n, 1/\varepsilon))$ 内运行，提供了 Hankel 矩阵 $\widehat{H}$ 的因式分解表示，其秩为 $O(\log n \log(1/\varepsilon))$，误差保证为 $\|H-\widehat{H}\|_F \leq O(\|E\|_F) + \varepsilon\|H\|_F$（在存在噪声 $E$ 的情况下）。

Result: 本文取得了以下主要结果：
1. **结构保持的存在性结果：** 证明了存在一个秩为 $k=O(\log n \log(1/\varepsilon))$ 的 **Hankel** 矩阵近似 $\widehat{H}$，其逼近误差与 Beckermann 和 Townsend 的误差界限 $\|H-H_k\|_F \leq \varepsilon\|H\|_F$ 相匹配。这提供了 Hankel 矩阵低秩逼近的结构保持性，是 AAK 定理的有限维类比。
2. **亚线性时间算法：** 首次提出了一个在亚线性时间 $O(\polylog(n, 1/\varepsilon))$ 内对 PSD Hankel 矩阵进行低秩近似的算法。该算法计算出一个秩为 $O(\log n \log(1/\varepsilon))$ 的 Hankel 矩阵 $\widehat{H}$ 的因式分解表示，其误差保证 $\|H-\widehat{H}\|_F \leq O(1) \cdot \varepsilon\|H\|_F$ 匹配了 Beckermann 和 Townsend 的界限（常数因子）。
3. **鲁棒性：** 证明了该算法具有鲁棒性。当输入矩阵为 $H+E$（其中 $E$ 是任意非 Hankel 噪声矩阵）时，算法得到的近似 $\widehat{H}$ 的误差为 $\|H - \widehat{H}\|_F \leq O(\|E\|_F) + \varepsilon\|H\|_F$，即误差可以分解为与噪声成比例的部分以及与理想近似误差相近的部分。

Conclusion: 本文提出了一种在亚线性时间内对正半定（PSD）Hankel矩阵进行低秩近似的算法。该算法以多对数时间复杂度 $O(\polylog(n, 1/\varepsilon))$ 运行，可以计算出一个低秩 $O(\log n \log(1/\varepsilon))$ 的 Hankel 矩阵 $\widehat{H}$ 的因式分解表示，其近似误差与 Beckermann 和 Townsend 的经典结果相匹配。该算法还具有鲁棒性，能够处理任意非 Hankel 噪声矩阵 $E$ 的输入。此外，本文还证明了结构保持的低秩 Hankel 逼近的存在性，其误差界与 Beckermann-Townsend 的结果相匹配，这是 AAK 定理的有限维模拟。通过利用 Hankel 矩阵的 Vandermonde 结构和基于采样的通用岭杠杆分数界，实现了亚线性时间算法。

Abstract: Hankel matrices are an important class of highly-structured matrices, arising across computational mathematics, engineering, and theoretical computer science. It is well-known that positive semidefinite (PSD) Hankel matrices are always approximately low-rank. In particular, a celebrated result of Beckermann and Townsend shows that, for any PSD Hankel matrix $H \in \mathbb{R}^{n \times n}$ and any $ε> 0$, letting $H_k$ be the best rank-$k$ approximation of $H$, $\|H-H_k\|_F \leq ε\|H\|_F$ for $k = O(\log n \log(1/ε))$. As such, PSD Hankel matrices are natural targets for low-rank approximation algorithms. We give the first such algorithm that runs in \emph{sublinear time}. In particular, we show how to compute, in $\polylog(n, 1/ε)$ time, a factored representation of a rank-$O(\log n \log(1/ε))$ Hankel matrix $\widehat{H}$ matching the error guarantee of Beckermann and Townsend up to constant factors. We further show that our algorithm is \emph{robust} -- given input $H+E$ where $E \in \mathbb{R}^{n \times n}$ is an arbitrary non-Hankel noise matrix, we obtain error $\|H - \widehat{H}\|_F \leq O(\|E\|_F) + ε\|H\|_F$. Towards this algorithmic result, our first contribution is a \emph{structure-preserving} existence result - we show that there exists a rank-$k$ \emph{Hankel} approximation to $H$ matching the error bound of Beckermann and Townsend. Our result can be interpreted as a finite-dimensional analog of the widely applicable AAK theorem, which shows that the optimal low-rank approximation of an infinite Hankel operator is itself Hankel. Armed with our existence result, and leveraging the well-known Vandermonde structure of Hankel matrices, we achieve our sublinear time algorithm using a sampling-based approach that relies on universal ridge leverage score bounds for Vandermonde matrices.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [8] [Assessing Redundancy Strategies to Improve Availability in Virtualized System Architectures](https://arxiv.org/abs/2511.20780)
*Alison Silva,Gustavo Callou*

Main category: cs.DC

TL;DR: Paper is not related to DSL, graph processing, MLIR, compiler, or HLS.
Too long; didn't read: The paper presents a methodology using Stochastic Petri Nets (SPNs) to analyze the availability of Nextcloud file servers hosted in a private cloud environment (Apache CloudStack). By modeling and comparing four architectural configurations (baseline, host redundancy, VM redundancy, and combined redundancy), the study finds that a combination of host and VM-level redundancy significantly improves availability and reduces expected downtime, offering a method to support infrastructure design decisions.


<details>
  <summary>Details</summary>
Motivation: 随着云计算存储平台的普及，特别是对于寻求公共云替代方案的组织而言，系统可靠性成为一项至关重要的要求。在私有云环境中，评估和提高文件服务器等关键系统的可用性是至关重要的。本文的动机在于提出一个分析私有云存储平台（如使用Apache CloudStack部署的Nextcloud）可用性的方法，并通过评估不同的冗余策略来指导基础设施的设计，以提高系统的可靠性。

Method: 本文采用建模方法，特别是随机Petri网（SPNs）来分析一个基于Apache CloudStack私有云环境下的Nextcloud文件服务器的可用性。研究建模并评估了四种不同的架构配置：基准配置、主机级冗余、虚拟机（VM）冗余以及主机和VM双重冗余的组合。通过对比这些配置下的可用性指标和预期停机时间，来评估不同冗余策略的效果。

Result: 研究结果表明，在四种建筑配置中，同时采用主机级冗余和虚拟机（VM）级冗余的配置能显著提高系统的可用性，并大幅减少预期的停机时间。这证明了冗余策略对于增强私有云文件服务器可用性的有效性。所提出的基于SPNs的分析方法为评估私有云可用性及支持基础设施设计决策提供了有效工具。

Conclusion: 本文提出了一种通过随机Petri网（SPNs）评估私有云环境中文件服务器（Nextcloud）可用性的方法，特别是通过评估不同的冗余策略对系统可用性和预期停机时间的影响。研究结果表明，主机级和虚拟机级冗余的组合能显著提高系统可用性并减少预期停机时间。这种方法为评估私有云可用性提供了支持基础设施设计决策的工具。

Abstract: Cloud-based storage platforms are becoming more common in both academic and business settings due to their flexible access to data and support for collaborative functionalities. As reliability becomes a vital requirement, particularly for organizations looking for alternatives to public cloud services, assessing the dependability of these systems is crucial. This paper presents a methodology for analyzing the availability of a file server (Nextcloud) hosted in a private cloud environment using Apache CloudStack. The analysis is based on a modeling approach through Stochastic Petri Nets (SPNs) that allows the evaluation of different redundancy strategies to enhance the availability of such systems. Four architectural configurations were modeled, including the baseline, host-level redundancy, virtual machine (VM) redundancy, and a combination of both. The results show that redundancy at both the host and VM levels significantly improves availability and reduces expected downtime. The proposed approach provides a method to evaluate the availability of a private cloud and support infrastructure design decisions.

</details>


### [9] [A Dynamic PD-Disaggregation Architecture for Maximizing Goodput in LLM Inference Serving](https://arxiv.org/abs/2511.20982)
*Junhan Liao,Minxian Xu,Wanyi Zheng,Yan Wang,Kejiang Ye,Rajkumar Buyya,Chengzhong Xu*

Main category: cs.DC

TL;DR: 该论文与图处理（graph processing）相关。
太长不读摘要：该研究针对大型语言模型（LLM）推理中预填充（prefill）和解码（decoding）阶段解耦部署导致的生产者-消费者失衡问题，提出了一种动态 LLM 推理系统 DOPD (Dynamic Optimal Prefill/Decoding)。DOPD 通过实时监控负载动态调整预填充/解码（P/D）实例的分配比例，结合适当的请求调度策略，有效解决了资源不平衡和混合长度请求下的资源分配不匹配问题。实验结果表明，DOPD 在 goodput、P90 Time-to-First-Token (TTFT) 和 P90 Time-per-Output-Token (TPOT) 方面均优于现有的聚合式和分离式方法，并能在使用更少额外资源的情况下实现超过 99% 的 SLO 达成。


<details>
  <summary>Details</summary>
Motivation: 当代的 LLM 为了满足严格的服务水平目标（SLOs）将预填充（prefill）和解码（decoding）阶段解耦并放置在不同的 GPU 上以减轻各自的瓶颈。然而，LLM 工作负载的异构性导致在这种分离式架构中，两种实例类型之间存在生产者-消费者失衡问题。

Method: DOPD 通过实时负载监控来动态调整实例分配，以实现最佳的预填充到解码（P/D）比率。此外，它还结合了一个适当的请求调度策略来解决高并发下混合长度请求导致的资源分配不匹配问题。DOPD 的动态 P/D 调整技术还基于历史负载进行主动重新配置。

Result: 与 vLLM 和 DistServe 相比，DOPD 将总体系统 goodput 提高了多达 1.5 倍，将 P90 TTFT 降低了多达 67.5%，将 P90 TPOT 降低了多达 22.8%。此外，DOPD 的动态 P/D 调整技术基于历史负载执行主动重新配置，在动用更少额外资源的情况下实现了超过 99% 的 SLO 达成。

Conclusion: DOPD通过采用动态调整预填充/解码（P/D）比率和适当的请求调度策略，有效解决了 LLM 推理过程中的生产者-消费者失衡和资源分配不匹配问题，与现有方法相比，显著提高了系统吞吐量、TTFT 和 TPOT，并在使用更少额外资源的情况下实现超过 99% 的 SLO 达成。

Abstract: To meet strict Service-Level Objectives (SLOs),contemporary Large Language Models (LLMs) decouple the prefill and decoding stages and place them on separate GPUs to mitigate the distinct bottlenecks inherent to each phase. However, the heterogeneity of LLM workloads causes producerconsumer imbalance between the two instance types in such disaggregated architecture. To address this problem, we propose DOPD (Dynamic Optimal Prefill/Decoding), a dynamic LLM inference system that adjusts instance allocations to achieve an optimal prefill-to-decoding (P/D) ratio based on real-time load monitoring. Combined with an appropriate request-scheduling policy, DOPD effectively resolves imbalances between prefill and decoding instances and mitigates resource allocation mismatches due to mixed-length requests under high concurrency. Experimental evaluations show that, compared with vLLM and DistServe (representative aggregation-based and disaggregationbased approaches), DOPD improves overall system goodput by up to 1.5X, decreases P90 time-to-first-token (TTFT) by up to 67.5%, and decreases P90 time-per-output-token (TPOT) by up to 22.8%. Furthermore, our dynamic P/D adjustment technique performs proactive reconfiguration based on historical load, achieving over 99% SLOs attainment while using less additional resources.

</details>


### [10] [Automated Dynamic AI Inference Scaling on HPC-Infrastructure: Integrating Kubernetes, Slurm and vLLM](https://arxiv.org/abs/2511.21413)
*Tim Trappen,Robert Keßler,Roland Pabel,Viktor Achter,Stefan Wesner*

Main category: cs.DC

TL;DR: 该论文与图处理无关；它与编译器、HLS、DSL、MLIR 无直接关联。该论文与 AI/LLM 的高性能计算（HPC）基础设施和部署相关。

太长不看摘要：由于传统的 HPC 模式难以适应同步、面向用户的动态 AI (LLMs) 负载需求，本文提出了一种解决方案，通过在 RAMSES 超算上集成 vLLM、Slurm 和 Kubernetes，实现 LLM 的高效服务。初步基准测试表明，该架构能有效扩展至 1000 个并发请求，且端到端延迟开销仅约 500 毫秒。


<details>
  <summary>Details</summary>
Motivation: 随着对人工智能推理需求的增长，尤其是在高等教育领域，利用现有高性能计算（HPC）基础设施的需求增加。然而，经典的 HPC 运营模式不适应同步、面向用户的动态 AI 应用工作负载（如 LLMs）的需求。

Method: 通过在 RAMSES 超算上集成 vLLM（用于高效 LLM 推理）、Slurm（作为 HPC 资源管理器）和 Kubernetes（用于容器化和动态调度）来构建 LLM 服务架构。

Result: 初步基准测试显示，所提出的架构可以有效地扩展以处理 100、500 和 1000 个并发请求，并且在端到端延迟方面仅产生大约 500 毫秒的开销。

Conclusion: 本文提出了一个在 RAMSES 超算上集成 vLLM、Slurm 和 Kubernetes 的解决方案，以高效地服务同步、面向用户的动态 AI 应用（特别是 LLMs），初步基准测试表明该架构具有良好的可扩展性和较低的延迟开销。

Abstract: Due to rising demands for Artificial Inteligence (AI) inference, especially in higher education, novel solutions utilising existing infrastructure are emerging. The utilisation of High-Performance Computing (HPC) has become a prevalent approach for the implementation of such solutions. However, the classical operating model of HPC does not adapt well to the requirements of synchronous, user-facing dynamic AI application workloads. In this paper, we propose our solution that serves LLMs by integrating vLLM, Slurm and Kubernetes on the supercomputer \textit{RAMSES}. The initial benchmark indicates that the proposed architecture scales efficiently for 100, 500 and 1000 concurrent requests, incurring only an overhead of approximately 500 ms in terms of end-to-end latency.

</details>


### [11] [MemFine: Memory-Aware Fine-Grained Scheduling for MoE Training](https://arxiv.org/abs/2511.21431)
*Lu Zhao,Rong Shi,Shaoqing Zhang,Yueqiang Chen,Baoguo He,Hongfeng Sun,Ziqing Yin,Shangchao Su,Zhiyan Cui,Liang Dong,Xiyuan Li,Lingbin Wang,Jianwei He,Jiesong Ma,Weikang Huang,Jianglei Tong,Dongdong Gao,Jian Zhang,Hong Tian*

Main category: cs.DC

TL;DR: 相关：Compiler（调度优化和内存管理属于编译器/运行时优化范畴）。
总结：大规模MoE模型训练面临动态路由引起的负载不平衡所导致的严重内存瓶颈。MemFine提出了一种内存感知的细粒度调度（fine-grained scheduling）框架，它将计算分解为可管理的块并采用分块重计算策略，并通过理论模型动态优化以平衡内存和吞吐量。实验证明MemFine能显著降低激活内存（48.03%）并提高吞吐量（4.42%），从而在内存受限的GPU上实现稳定的大规模MoE训练。


<details>
  <summary>Details</summary>
Motivation: 大规模 MoE 模型训练中，动态 Token 路由导致了严重的负载不平衡，进而引发了关键的内存瓶颈。这导致在内存容量有限的 GPU 上发生内存溢出，限制了模型的扩展性。现有的负载均衡方法（如限制专家容量）虽然可以缓解问题，但会损害模型精度，并且在内存受限的硬件上效果不佳。

Method: MemFine 是一种内存感知的细粒度调度框架，它将 token 分布和专家计算分解为可管理的“块”（chunks）。通过采用分块重计算（chunked recomputation）策略，并结合一个理论内存模型进行动态优化，以平衡内存效率和吞吐量。

Result: MemFine 实验证明相比于基于完全重计算（full recomputation）的基线方法，能够减少激活内存使用量达 48.03%，并提高吞吐量 4.42%。这使得 MemFine 能够在内存有限的 GPU 上实现稳定的大规模 MoE 训练。

Conclusion: MemFine 通过在 MoE 训练中采用内存感知的细粒度调度框架和分块重计算策略，成功解决了大规模 MoE 模型训练中因动态路由导致的负载不平衡及其引发的内存瓶颈问题。它实现了更高的内存效率和更好的吞吐量，使模型能够在内存受限的 GPU 上稳定、高效地训练。

Abstract: The training of large-scale Mixture of Experts (MoE) models faces a critical memory bottleneck due to severe load imbalance caused by dynamic token routing. This imbalance leads to memory overflow on GPUs with limited capacity, constraining model scalability. Existing load balancing methods, which cap expert capacity, compromise model accuracy and fail on memory-constrained hardware. To address this, we propose MemFine, a memory-aware fine-grained scheduling framework for MoE training. MemFine decomposes the token distribution and expert computation into manageable chunks and employs a chunked recomputation strategy, dynamically optimized through a theoretical memory model to balance memory efficiency and throughput. Experiments demonstrate that MemFine reduces activation memory by 48.03% and improves throughput by 4.42% compared to full recomputation-based baselines, enabling stable large-scale MoE training on memory-limited GPUs.

</details>


### [12] [Modeling the Effect of Data Redundancy on Speedup in MLFMA Near-Field Computation](https://arxiv.org/abs/2511.21535)
*Morteza Sadeghi*

Main category: cs.DC

TL;DR: 该论文与图处理（Multilevel Fast Multipole Algorithm, MLFMA 涉及一种树形结构和近场/远场交互，与图算法的划分和交互有相似之处）有关。

**太长不读摘要（TLDR）：**
MLFMA（多级快速多极算法）中的 P2P（近场）算子在 GPU 上由于内存局部性差而成为性能瓶颈。本文通过引入数据冗余来改善空间局部性，提出了一个结合数据量和访问分散性的局部性分析模型来预测性能趋势。在规则结构的电磁求解器和不规则分布的恒星动力学代码上的验证显示，该方法使内核获得了高达 7 倍的加速。然而，由于数据冗余带来的重构开销，端到端应用加速比受限于 1.04 倍。模型被证明能可靠地捕捉性能趋势。该工作证明了数据冗余可以提高 GPU 上 P2P 算子的性能，但局部性收益必须超过数据移动成本。


<details>
  <summary>Details</summary>
Motivation: MLFMA 中的近场（P2P）算子在 GPU 上存在性能瓶颈，主要原因是内存局部性差。作者希望通过一种方法来提高空间局部性，从而改善 P2P 算子在 GPU 上的性能。

Method: 本文提出了通过引入数据冗余来提高 P2P 算子空间局部性，以减少内存访问分散性。同时，提出了一种基于局部性度量的分析模型，该模型结合数据量和访问分散性来预测加速比趋势。在电磁求解器（DBIM-MLFMA）和恒星动力学代码（PhotoNs-2.0）两个基于 MLFMA 的应用上验证了该方法。

Result: 实验结果表明，由于缓存行为的改善，P2P 算子内核实现了高达 7 倍的加速。但是，数据量的增加导致数据重构开销增加，使得端到端应用程序加速比受限于 1.04 倍。所提出的局部性模型能可靠地捕捉不同问题规模和密度下的性能趋势。

Conclusion: 本文证明了通过引入数据冗余，可以改善 MLFMA 中 P2P 算子在 GPU 上的空间局部性，从而提高性能，前提是局部性带来的收益大于额外的数据移动成本。所提出的局部性分析模型虽然不能精确预测绝对加速比，但能可靠地捕捉性能趋势。该技术可被注入到现有实现中。

Abstract: The near-field (P2P) operator in the Multilevel Fast Multipole Algorithm (MLFMA) is a performance bottleneck on GPUs due to poor memory locality. This work introduces data redundancy to improve spatial locality by reducing memory access dispersion. For validation of results, we propose an analytical model based on a Locality metric that combines data volume and access dispersion to predict speedup trends without hardware-specific profiling. The approach is validated on two MLFMA-based applications: an electromagnetic solver (DBIM-MLFMA) with regular structure, and a stellar dynamics code (PhotoNs-2.0) with irregular particle distribution. Results show up to 7X kernel speedup due to improved cache behavior. However, increased data volume raises overheads in data restructuring, limiting end-to-end application speedup to 1.04X. While the model cannot precisely predict absolute speedups, it reliably captures performance trends across different problem sizes and densities. The technique is injectable into existing implementations with minimal code changes. This work demonstrates that data redundancy can enhance GPU performance for P2P operator, provided locality gains outweigh data movement costs.

</details>
