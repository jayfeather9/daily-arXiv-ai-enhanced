<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 6]
- [cs.AR](#cs.AR) [Total: 4]
- [cs.DS](#cs.DS) [Total: 12]
- [cs.DC](#cs.DC) [Total: 9]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [Expanding Specification Capabilities of a Gradual Verifier with Pure Functions](https://arxiv.org/abs/2511.22075)
*Doruk Alp Mutlu*

Main category: cs.PL

TL;DR: 该论文与编译器、DSL、图处理或HLS不直接相关。论文内容涉及程序验证，特别是渐进式验证（Gradual Verification）。渐进式验证可以被视为一种软件验证技术，它可以与编译器优化、DSL或HLS中的验证阶段相关联，但该论文的重点是验证器本身和其规约语言的扩展。
TLDR: 渐进式验证 Gradual C0 验证器在复杂表达式方面的规约能力有限。本文通过引入纯函数结构，扩展了 Gradual C0 的设计，解决了在不精确规约下纯函数公理化的技术挑战，从而提高了规约能力并简化了观察者方法的编码。


<details>
  <summary>Details</summary>
Motivation: Gradual C0是唯一一个基于符号执行的实用渐进式验证器，它支持递归堆数据结构。尽管有人努力提高其规约语言的表达能力，但Gradual C0的规约语言在处理复杂表达方面的能力仍然有限。作者的动机是希望通过在Gradual C0中引入纯函数（一种许多静态验证工具支持的常见结构）来扩展Gradual C0的规约设计，以提高规约能力并简化观察者方法的编码。

Method: 作者提出了一种将纯函数结构体扩展到Gradual C0设计中的方法。这种方法解决了在不精确规约下纯函数公理化的技术挑战，从而提高了Gradual C0的规约能力，并简化了观察者方法的编码。

Result: 作者成功地在Gradual C0中加入了纯函数这一常见结构，从而扩展了Gradual C0的规约能力，并使观察者方法更容易编码。本文的方法解决了处理带有不精确规约的纯函数公理化相关的技术挑战。

Conclusion: 本文成功地将纯函数结构体扩展到了Gradual C0设计中，解决了在不精确规约下纯函数公理化面临的技术挑战。这一扩展提高了Gradual C0的规约能力，并使观察者方法更容易编码。

Abstract: Gradual verification soundly combines static checking and dynamic checking to provide an incremental approach for software verification. With gradual verification, programs can be partially specified first, and then the full specification of a program can be achieved in incremental steps. The first and only practicable gradual verifier based on symbolic execution, Gradual C0, supports recursive heap data structures. Despite recent efforts to improve the expressivity of Gradual C0's specification language, Gradual C0's specification language is still limited in its capabilities for complex expressions. This work explores an extension to Gradual C0's design with a common construct supported by many static verification tools, pure functions, which both extend the specification capabilities of Gradual C0 and increase the ease of encoding observer methods in Gradual C0. Our approach addresses the technical challenges related to the axiomatisation of pure functions with imprecise specifications.

</details>


### [2] [On Circuit Description Languages, Indexed Monads, and Resource Analysis](https://arxiv.org/abs/2511.22419)
*Ken Sakayori,Andrea Colledan,Ugo Dal Lago*

Main category: cs.PL

TL;DR: 该论文与编译器、DSL（Proto-Quipper 演算族）相关，与图处理、MLIR、HLS 无直接关联。/ 该论文引入了一个基于单子的指称语义模型，用于 Proto-Quipper 演算族（Quipper 语言的理想化形式）。该模型通过单子分离了项的归约值和作为副作用产生的量子电路。通过引入“电路代数”的新概念，该模型为支持量化电路属性（如大小）保证的丰富作用效应类型系统提供了语义验证基础。


<details>
  <summary>Details</summary>
Motivation: Proto-Quipper 演算族（Quipper 编程语言的理想化版本）需要一种能够清晰分离计算结果值和作为副作用生成的量子电路的语义模型。该模型需要支持对丰富的类型系统进行指称解释和验证，尤其是需要控制和保证所产生量子电路（如大小）的量化性质。

Method: 使用基于单子（Monad）的指称语义模型（Denotational Model）来对 Proto-Quipper 演算族进行建模。该方法分离了项的归约值和作为副作用产生的电路，并通过引入“电路代数”（Circuit Algebra）来支持对电路大小等量化性质的控制和保证。

Result: 提出了一个基于单子的指称模型，并证明其对于 Proto-Quipper 演算族是充分的。该模型允许在语义上分离值和作为副作用产生的电路。通过引入“电路代数”的新概念，该框架能够支持**作用效应类型系统**（effect typing），保证即使在存在优化的前提下，也能对产生的电路的量化性质（如尺寸）进行控制和验证。

Conclusion: 本文成功地建立了一个单子化的解释模型，并证明其对于 Proto-Quipper 演算族的充分性。通过电路代数的概念，该模型为 Quipper 语言提供了一种新的、支持丰富类型系统的语义验证框架，特别是在保证产生电路的量化性质方面。

Abstract: In this paper, a monad-based denotational model is introduced and shown adequate for the Proto-Quipper family of calculi, themselves being idealized versions of the Quipper programming language. The use of a monadic approach allows us to separate the value to which a term reduces from the circuit that the term itself produces as a side effect. In turn, this enables the denotational interpretation and validation of rich type systems in which the size of the produced circuit can be controlled. Notably, the proposed semantic framework, through the novel concept of circuit algebra, suggests forms of effect typing guaranteeing quantitative properties about the resulting circuit, even in presence of optimizations.

</details>


### [3] [A Synthetic Reconstruction of Multiparty Session Types (with Appendix)](https://arxiv.org/abs/2511.22692)
*David Castro-Perez,Francisco Ferreira,Sung-Shik Jongmans*

Main category: cs.PL

TL;DR: The paper is related to compiler based on the concurrent system (Multiparty session types, MPST) verification.
本文介绍了一种新的多方会话类型（MPST）验证方法，称为“合成方法”，它通过引入一个直接针对全局协议规范（LTS）验证每个进程的类型系统，实现了表达能力和组合性的兼得，避免了对局部类型和投影的需求，并成功处理了传统组合技术难以验证的复杂协议。


<details>
  <summary>Details</summary>
Motivation: 现有的多方会话类型（MPST）验证方法存在困难的权衡：传统的基于投影的技术具有组合性，但表达能力有限；而最近的依赖非组合式、全局系统模型检查的技术具有更高的表达能力，但可伸缩性较差。本文的动机是引入一种新的MPST方法，以实现表达能力和组合性的兼得。

Method: 本文引入了一种称为“合成方法”的新型多方会话类型（MPST）方法。其关键创新在于设计了一个类型系统，该系统可以直接针对全局协议规范（通常表示为带标签的转换系统LTS，全局类型是其特例）验证每个进程。这种方法避免了传统方法中对中间局部类型和投影的需求。作者通过形式化和机械化（在Agda中）以及开发原型实现（作为VS Code扩展）来展示和验证他们的框架。

Result: 本文提出的合成方法具有表达能力强和组合性良好的特点，并成功支持了MPST文献中传统组合技术难以处理的具有挑战性的协议基准。作者还泛化了类型系统，表明它可以针对任何“表现良好”的LTS进行验证，即便这些协议无法用标准全局类型语法表达。整个框架已在Agda中形式化和机械化，并开发了VS Code的原型实现。

Conclusion: 本文介绍了合成方法，这是一种新的MPST验证方法。它的核心是引入了一个类型系统，可以直接针对全局协议规范（通用LTS）验证每个进程，从而避免了对中间局部类型和投影的需求。这种方法在概念上更简单，但支持了传统组合技术难以处理的复杂协议。作者还对类型系统进行了泛化，使其能够针对任何“表现良好”的LTS进行验证。整个框架在Agda中进行了形式化和机械化，并通过VS Code扩展实现了原型。

Abstract: Multiparty session types (MPST) provide a rigorous foundation for verifying the safety and liveness of concurrent systems. However, existing approaches often force a difficult trade-off: classical, projection-based techniques are compositional but limited in expressiveness, while more recent techniques achieve higher expressiveness by relying on non-compositional, whole-system model checking, which scales poorly.
  This paper introduces a new approach to MPST that delivers both expressiveness and compositionality, called the synthetic approach. Our key innovation is a type system that verifies each process directly against a global protocol specification, represented as a labelled transition system (LTS) in general, with global types as a special case. This approach uniquely avoids the need for intermediate local types and projection.
  We demonstrate that our approach, while conceptually simpler, supports a benchmark of challenging protocols that were previously beyond the reach of compositional techniques in the MPST literature. We generalise our type system, showing that it can validate processes against any specification that constitutes a "well-behaved" LTS, supporting protocols not expressible with the standard global type syntax. The entire framework, including all theorems and many examples, has been formalised and mechanised in Agda, and we have developed a prototype implementation as an extension to VS Code.

</details>


### [4] [All for One and One for All: Program Logics for Exploiting Internal Determinism in Parallel Programs](https://arxiv.org/abs/2511.23283)
*Alexandre Moine,Sam Westrick,Joseph Tassarotti*

Main category: cs.PL

TL;DR: 该论文与编译器相关，涉及程序验证和类型系统。本文提出了Angelic逻辑和Musketeer分离逻辑，以简化对内部确定性并行程序的形式化验证。通过定义“调度无关安全性”属性，Angelic逻辑允许只验证程序的单个顺序执行即可证明其在所有并行执行顺序下的安全，并通过Musketeer逻辑证明了MiniDet类型系统的soundness，确保了其下的程序可以使用Angelic逻辑进行验证。


<details>
  <summary>Details</summary>
Motivation: 并行程序的非确定性（Nondeterminism）使得编写和推理变得困难。内部确定性（Internally Deterministic）并行编程技术虽然提高了可推理性，但缺乏相应的验证框架来利用这一特性，从而简化对内部确定性并行程序的正式推理。

Method: 本文定义了“调度无关安全性”来捕获内部确定性程序的本质，并提出了Musketeer分离逻辑来证明程序满足这一特性。然后，提出了Angelic逻辑，它利用调度无关安全性，允许通过只验证一个顺序执行来完成对并行程序的验证。最后通过Musketeer逻辑证明了MiniDet类型系统的soundness，从而将Angelic逻辑应用于所有符合该类型系统的程序。所有结果都使用Rocq在Iris分离逻辑框架中进行了形式化验证。

Result: 提出了“调度无关安全性”（Schedule-Independent Safety）这一属性，它表明对于满足该属性的程序，只需验证一个终止执行的安全性，即可证明其在所有执行顺序下的安全性。基于此，开发了Musketeer分离逻辑用于证明程序满足调度无关安全性，并提出了Angelic逻辑用于利用这一特性，通过验证单一顺序执行来验证并行程序的安全性。同时，使用Musketeer证明了MiniDet类型系统的 soundness，从而使得该系统下的任意良类型程序都可以应用Angelic逻辑进行简化验证。所有结果都已在Rocq中，使用Iris分离逻辑框架进行了形式化验证。

Conclusion: 本文介绍了Angelic逻辑，它利用“调度无关安全性”简化了对内部确定性并行程序的验证。Angelics允许通过验证程序的单个顺序执行来证明其在所有执行顺序下的安全性。进一步，通过Musketeer逻辑证明了MiniDet类型系统的 soundness，从而提供了一种可验证的内部确定性编程方法，所有这些工作都在Iris分离逻辑框架下使用Rocq进行了形式化验证。

Abstract: Nondeterminism makes parallel programs challenging to write and reason about. To avoid these challenges, researchers have developed techniques for internally deterministic parallel programming, in which the steps of a parallel computation proceed in a deterministic way. Internal determinism is useful because it lets a programmer reason about a program as if it executed in a sequential order. However, no verification framework exists to exploit this property and simplify formal reasoning about internally deterministic programs.
  To capture the essence of why internally deterministic programs should be easier to reason about, this paper defines a property called schedule-independent safety. A program satisfies schedule-independent safety, if, to show that the program is safe across all orderings, it suffices to show that one terminating execution of the program is safe. We then present a separation logic called Musketeer for proving that a program satisfies schedule-independent safety. Once a parallel program has been shown to satisfy schedule-independent safety, we can verify it with a new logic called Angelic, which allows one to dynamically select and verify just one sequential ordering of the program.
  Using Musketeer, we prove the soundness of MiniDet, an affine type system for enforcing internal determinism. MiniDet supports several core algorithmic primitives for internally deterministic programming that have been identified in the research literature, including a deterministic version of a concurrent hash set. Because any syntactically well-typed MiniDet program satisfies schedule-independent safety, we can apply Angelic to verify such programs.
  All results in this paper have been verified in Rocq using the Iris separation logic framework.

</details>


### [5] [TypeDis: A Type System for Disentanglement](https://arxiv.org/abs/2511.23358)
*Alexandre Moine,Stephanie Balzer,Alex Xu,Sam Westrick*

Main category: cs.PL

TL;DR: 该论文与编译器和形式化验证相关。首先，该论文关注并行程序的“非纠缠性”（disentanglement），这是MaPLe编译器和运行时系统中的一个关键运行时属性，用于快速的自动内存管理（如任务局部垃圾回收）。其次，该论文旨在通过开发一个类型系统（TypeDis）来取代现有的基于程序逻辑（DisLog/DisLog2）的手动验证方法，从而实现自动静态验证，这属于形式化验证和编程语言理论的范畴，与编译器设计紧密相关。太长不看：Disentanglement是并行程序中实现高效自动内存管理的关键属性，但其验证工作量大。本文提出了TypeDis类型系统，它通过在类型中加入时间戳并引入子计时机制，实现了对并行程序非纠缠性的自动静态验证。TypeDis的可靠性在Rocq证明助手中得到机械化证明，极大地减轻了程序员的验证负担。


<details>
  <summary>Details</summary>
Motivation: 并行程序的“非纠缠性”（Disentanglement）是一种运行时属性，可以保证并行任务的内存分配互不影响，从而实现高效的自动内存管理（如无同步的任务局部垃圾回收）。然而，非纠缠性是一种底层属性，难以被程序员推理。现有的静态验证方法DisLog（DisLog2的前身）是一种基于分离逻辑的程序逻辑，虽然功能完备，但需要专业的知识和大量的针对每个程序的证明工作，验证成本高昂。因此，本文旨在通过自动验证的方法，即设计一个类型系统，来减轻程序员的验证负担。

Method: 本文提出了一种名为TypeDis的类型系统，该系统灵感来源于区域类型（region types），通过在类型上标注时间戳（timestamp）来识别分配该数据的任务。TypeDis支持同构递归类型（iso-recursive types）以及类型和时间戳上的多态性。关键机制包括允许时间戳在类型检查过程中在汇合点（join points）和通过“子计时”（subtiming）形式的子类型化进行更改。本文使用DisLog2（DisLog的改进版本）在Rocq证明助手中机械化验证了TypeDis的可靠性和示例。

Result: 本文设计并实现了一个名为TypeDis的类型系统，它能够确保任何“类型良好”（well-typed）的程序都是“非纠缠的”（disentangled）。TypeDis通过在类型中添加时间戳来实现这一目标，时间戳指明了分配该数据的任务。该类型系统支持复杂的特性，如同构递归类型和多态性。它还引入了创新的机制，如在程序汇合点和通过子类型化（subtiming）来改变时间戳。TypeDis及其功能的可靠性通过Rocq证明助手中基于改进后的DisLog2进行机械化验证得到了证明。

Conclusion: 本文提出了一种名为TypeDis的类型系统，用于自动验证并行程序的“非纠缠性”（disentanglement）。TypeDis通过类型系统取代了复杂的手动证明过程，显著降低了程序员的验证负担。TypeDis的完备性和示例均在Rocq证明助手中进行了机械化验证，证明了其作为一种实用且强大的自动化验证工具的有效性。

Abstract: Disentanglement is a runtime property of parallel programs guaranteeing that parallel tasks remain oblivious to each other's allocations. As demonstrated in the MaPLe compiler and run-time system, disentanglement can be exploited for fast automatic memory management, especially task-local garbage collection with no synchronization between parallel tasks. However, as a low-level property, disentanglement can be difficult to reason about for programmers. The only means of statically verifying disentanglement so far has been DisLog, an Iris-fueled variant of separation logic, mechanized in the Rocq proof assistant. DisLog is a fully-featured program logic, allowing for proof of functional correctness as well as verification of disentanglement. Yet its employment requires significant expertise and per-program proof effort.
  This paper explores the route of automatic verification via a type system, ensuring that any well-typed program is disentangled and lifting the burden of carrying out manual proofs from the programmer. It contributes TypeDis, a type system inspired by region types, where each type is annotated with a timestamp, identifying the task that allocated it. TypeDis supports iso-recursive types as well as polymorphism over both types and timestamps. Crucially, timestamps are allowed to change during type-checking, at join points as well as via a form of subtyping, dubbed subtiming. The paper illustrates TypeDis and its features on a range of examples. The soundness of TypeDis and the examples are mechanized in the Rocq proof assistant, using an improved version of DisLog, dubbed DisLog2.

</details>


### [6] [RapunSL: Untangling Quantum Computing with Separation, Linear Combination and Mixing](https://arxiv.org/abs/2511.23472)
*Yusuke Matsushita,Kengo Hirata,Ryo Wakizaka,Emanuele D'Osualdo*

Main category: cs.PL

TL;DR: 与DSL、图处理、MLIR、编译器、HLS无关。

Too Long; Didn't Read (TL;DR) 概要：量子分离逻辑（QSL）是一个提高量子程序演绎推理可扩展性的工具。本文提出了一种新的量子分离逻辑 RapunSL，引入了基底局部性（basis-locality）和结果局部性（outcome-locality）这两个独特的量子域局部性概念，并引入线性组合（linear combination）和混合（mixing）两种连接词。RapunSL 能够可靠地将叠加态和测量引起的混合态的推理简化为纯态推理，从而显著提高了量子程序推理的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的量子分离逻辑（QSL）虽然有效，但需要进一步提高量子程序演绎推理的可扩展性。具体来说，需要找到一种有效的方法来处理量子程序中的叠加态和测量引起的混合态，从而显著提高推理的效率和可扩展性。

Method: 引入了两种独特的量子域局部性概念：基底局部性（basis-locality）和结果局部性（outcome-locality）。在此基础上，构建了新的量子分离逻辑 RapunSL，并引入了两个新的连接词：线性组合（linear combination）和混合（mixing）。这些连接词与分离概念相结合，以实现叠加态和混合态到纯态的简化推理。

Result: 构建了一种新的量子分离逻辑 RapunSL，它能够可靠地将叠加态的推理简化为纯态推理（基底局部性），并将由测量产生的混合态的推理简化为纯态推理（结果局部性）。通过引入线性组合和混合连接词，实现了推理可扩展性的显著改进，并在多个具有挑战性的案例研究中得到了验证。

Conclusion: 我们提出了一种新的量子分离逻辑 RapunSL，它通过引入基底局部性和结果局部性，以及线性组合和混合两种连接词，能够更高效地处理量子程序中的叠加态和测量引起的混合态。这种方法在可扩展性方面取得了显著改进，并在挑战性的案例研究中得到了验证。

Abstract: Quantum Separation Logic (QSL) has been proposed as an effective tool to improve the scalability of deductive reasoning for quantum programs. In QSL, separation is interpreted as disentanglement, and the frame rule brings a notion of entanglement-local specification (one that only talks about the qubits entangled with those acted upon by the program). In this paper, we identify two notions of locality unique to the quantum domain, and we construct a novel quantum separation logic, RapunSL, which is able to soundly reduce reasoning about superposition states to reasoning about pure states (basis-locality), and reasoning about mixed states arising from measurement to reasoning about pure states (outcome-locality). To do so, we introduce two connectives, linear combination and mixing, which together with separation provide a dramatic improvement in the scalability of reasoning, as we demonstrate on a series of challenging case studies.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [7] [Aquas: Enhancing Domain Specialization through Holistic Hardware-Software Co-Optimization based on MLIR](https://arxiv.org/abs/2511.22267)
*Yuyang Zou,Youwei Xiao,Yansong Xu,Chenyun Yin,Yuhao Luo,Yitian Sun,Ruifan Xu,Renze Chen,Yun Liang*

Main category: cs.AR

TL;DR: 涉及领域：编译器（compiler），MLIR（MLIR），指令集处理器设计/硬件综合（ASIP/HLS）。
总结：本文提出了 Aquas，一个基于 MLIR 的软硬件协同设计框架，用于优化 RISC-V ASIP 的性能。它在硬件层面引入了突发 DMA 引擎和先进的 HLS 优化来实现快速内存访问，并在编译器层面采用了基于 e-graph 的可重定向方法和新颖的匹配引擎。实验结果表明，Aquas 在实际工作负载上实现了高达 9.27 倍的性能加速。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 RISC-V 架构的 ASIPs（Application-Specific Instruction-Set Processors，应用专用指令集处理器）受限于开源生态中刚性的编译器支持和受限的硬件综合能力，导致性能表现不佳。因此，本文的动机是建立一个全面的软硬件协同设计框架（Aquas），以克服这些性能限制，最大化 ASIP 的专用化潜力。

Method: 本文提出了 Aquas 框架，这是一个基于 MLIR 的软硬件协同设计框架，旨在解决现有 RISC-V ASIP 框架的性能瓶颈。在硬件方面，Aquas 通过引入突发 DMA 引擎实现快速内存访问，并采用先进的高级综合（HLS）优化来增强 ASIP 综合。在软件/编译器方面，它提出了一种基于 E-graph 的可重定向方法，并结合新颖的匹配引擎来实现高效的指令匹配，从而为 ASIP 提供更灵活和高性能的编译器支持。

Result: 所提出的 Aquas 框架在真实世界的工作负载（包括点云处理和大型语言模型（LLM）推理）上进行了评估。评估结果显示，Aquas 实现了高达 9.27 倍的加速比，证明了其在提高 RISC-V ASIP 性能方面的显著效果。

Conclusion: Aquas 框架通过 MLIR 实现了硬件和软件的协同设计，引入了突发 DMA 引擎和先进的 HLS 优化，显著提高了 RISC-V ASIP 的性能。在编译器方面，采纳了基于 e-graph 的可重定向方法和新颖的匹配引擎，确保了高效的指令匹配。最终，它在实际工作负载（如点云处理和 LLM 推理）上实现了高达 9.27 倍的加速比，证明了其在 RISC-V ASIP 设计中的优越性和潜力。

Abstract: Application-Specific Instruction-Set Processors (ASIPs) built on the RISC-V architecture offer specialization opportunities for various applications. However, existing frameworks from the open-source RISC-V ecosystem suffer from limited performance due to restricted hardware synthesis and rigid compiler support. To address these challenges, we introduce Aquas, a holistic hardware-software co-design framework built upon MLIR. Aquas enhances ASIP synthesis with fast memory access capability via a burst DMA engine and advanced high-level synthesis (HLS) optimizations. On the compiler side, we propose an e-graph based retargetable approach with a novel matching engine for efficient instruction matching. Evaluation demonstrates up to 9.27x speedup on real-world workloads, including point cloud processing and LLM inference.

</details>


### [8] [3RSeT: Read Disturbance Rate Reduction in STT-MRAM Caches by Selective Tag Comparison](https://arxiv.org/abs/2511.22551)
*Elham Cheshmikhani,Hamed Farbeh,Hossein Asad*

Main category: cs.AR

TL;DR: 相关性：该论文与 **compiler** (编译器) 和 **HLS** (高级综合) **不相关**，与 **DSL** (特定领域语言) 和 **graph processing** (图处理) **不相关**，与 **MLIR** (多级中间表示) **不相关**，但与 **compiler** 优化的底层硬件，即 **cache memory** (如优化缓存访问、可靠性和能效) 相关。

TLDR: STT-MRAM 缓存因读操作中的位翻转（读干扰错误）面临可靠性挑战，特别是所有标签同时访问进行并行比较的问题。本文提出一个低成本方案 **3RSeT**，通过使用标签的低有效位来选择性地禁用不可能命中的标签，从而减少标签读取。实验证明 3RSeT 将读干扰率降低 **71.8%**，MTTF 提升 **3.6倍**，能耗降低 **62.1%**，且性能无损，面积开销小于 **0.4%**。


<details>
  <summary>Details</summary>
Motivation: STT-MRAM因其低泄漏功耗、高密度、抗辐射和非易失性，被认为是最有希望取代SRAM用于片上缓存存储器的技术。然而，STT-MRAM缓存面临的一个严重可靠性挑战是读操作期间发生的非预期位翻转，即 **读干扰错误**。以往的工作未解决的一个主要读干扰源是缓存组中为进行并行比较而同时访问所有标签。本文的动机是论证高频次的标签阵列读取会极大地增加读干扰率，并提出一种低成本方案来解决这一问题。

Method: 本文主要方法是提出了一种名为 **3RSeT (Read Disturbance Rate Reduction in STT-MRAM Caches by Selective Tag Comparison)** 的方案。该方案通过在每次访问请求中利用标签的低有效位（low significant bits of the tags），主动禁用那些没有命中可能性的标签，从而消除很大一部分标签读取操作，减少读干扰率。

Result: 实验评估使用gem5全系统周期精确模拟器进行。结果显示，3RSeT方案能够：
*   将标签阵列中的读干扰率降低 **71.8%**。
*   将平均故障间隔时间（MTTF）提高 **3.6倍**。
*   将能耗降低 **62.1%**。
*   在不影响性能的前提下，新增的面积开销低于 **0.4%**。

Conclusion: 该论文提出了一种名为“基于选择性标签比较的STT-MRAM缓存中读干扰率降低”（3RSeT）的低成本方案，通过在每次访问请求中利用标签的低有效位来选择性地禁用不可能命中的标签，从而显著减少了标签读取操作，有效降低了读干扰错误率。实验结果证明3RSeT方案在显著提升可靠性和降低能耗的同时，保持了性能且仅有极小的面积开销。

Abstract: Recent development in memory technologies has introduced Spin-Transfer Torque Magnetic RAM (STT-MRAM) as the most promising replacement for SRAMs in on-chip cache memories. Besides its lower leakage power, higher density, immunity to radiation-induced particles, and non-volatility, an unintentional bit flip during read operation, referred to as read disturbance error, is a severe reliability challenge in STT-MRAM caches. One major source of read disturbance error in STT-MRAM caches is simultaneous accesses to all tags for parallel comparison operation in a cache set, which has not been addressed in previous work. This paper first demonstrates that high read accesses to tag array extremely increase the read disturbance rate and then proposes a low-cost scheme, so-called Read Disturbance Rate Reduction in STT-MRAM Caches by Selective Tag Comparison (3RSeT), to reduce the error rate by eliminating a significant portion of tag reads. 3RSeT proactively disables the tags that have no chance for hit, using low significant bits of the tags on each access request. Our evaluations using gem5 full-system cycle-accurate simulator show that 3RSeT reduces the read disturbance rate in the tag array by 71.8%, which results in 3.6x improvement in Mean Time To Failure (MTTF). In addition, the energy consumption is reduced by 62.1% without compromising performance and with less than 0.4% area overhead.

</details>


### [9] [The Immutable Tensor Architecture: A Pure Dataflow Approach for Secure, Energy-Efficient AI Inference](https://arxiv.org/abs/2511.22889)
*Fang Li*

Main category: cs.AR

TL;DR: 该论文与编译器和硬件设计相关。

太长不看版：为了解决LLMs在边缘设备部署时的“内存墙”问题（即获取模型权重所需的巨大带宽和能耗），本文提出了“不可变张量架构”（ITA）。ITA将模型权重视为ASIC（成熟节点如28nm/40nm）的物理电路拓扑，直接编码到金属互连和逻辑中，从而完全消除了内存层级。这种“分裂大脑”设计（CPU处理动态KV-cache，ITA ASIC作为无状态ROM嵌入的数据流引擎）极大地降低了能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: LLMs在消费级边缘设备上的部署受限于“内存墙”问题——每次生成Token时，从DRAM获取数GB模型权重所需的巨大带宽和能耗成本。当前的GPU和NPU将模型权重视为可修改的软件数据，为保持通用可编程性而牺牲了巨大的能耗。

Method: 提出“不可变张量架构”（Immutable Tensor Architecture，ITA），将模型权重视为物理电路拓扑而非可变软件数据。通过在成熟节点（28nm/40nm）ASIC的金属互连和逻辑中直接编码参数，达到完全消除内存层级的目的。实现了“分裂大脑”（Split-Brain）系统设计，由Host CPU管理动态的KV-cache等操作，而ITA ASIC作为无状态、ROM嵌入的数据流引擎。

Result: ITA作为一种无状态、ROM嵌入的数据流引擎，彻底消除了内存层级，从而解决了内存墙问题。与传统的内存-计算分离架构相比，ITA在边缘部署LLMs时实现了极低的能耗和延迟。

Conclusion: ITA提出了一种内存-计算融合的新范式，通过将模型权重直接编码为ASIC的物理电路拓扑，从而彻底消除内存墙问题，为LLMs在边缘设备上的部署提供了一种能效极高且延迟极低的解决方案。

Abstract: The deployment of Large Language Models (LLMs) on consumer edge devices is throttled by the "Memory Wall" -- the prohibitive bandwidth and energy cost of fetching gigabytes of model weights from DRAM for every token generated. Current architectures (GPUs, NPUs) treat model weights as mutable software data, incurring massive energy penalties to maintain general-purpose programmability. We propose The Immutable Tensor Architecture (ITA), a paradigm shift that treats model weights not as data, but as physical circuit topology. By encoding parameters directly into the metal interconnects and logic of mature-node ASICs (28nm/40nm), ITA eliminates the memory hierarchy entirely. We present a "Split-Brain" system design where a host CPU manages dynamic KV-cache operations while the ITA ASIC acts as a stateless, ROM-embedded dataflow engine.

</details>


### [10] [Cohet: A CXL-Driven Coherent Heterogeneous Computing Framework with Hardware-Calibrated Full-System Simulation](https://arxiv.org/abs/2511.23011)
*Yanjing Wang,Lizhou Wu,Sunfeng Gao,Yibo Tang,Junhui Luo,Zicong Wang,Yang Ou,Dezun Dong,Nong Xiao,Mingche Lai*

Main category: cs.AR

TL;DR: 该论文与编译器、DSL、图处理或MLIR无关，但与底层系统（如互连标准CXL）和编译器/运行时环境非常相关。
该论文是关于Cohet，这是第一个CXL驱动的相干异构计算框架。CXL解决了传统PCIe互连中细粒度交互效率低和编程模型复杂的问题。Cohet解耦了CPU和XPU的计算与内存资源，形成一个统一且相干的内存池，并为两者提供标准的内存分配接口。研究人员还开发了一个名为SimCXL的全系统周期级模拟器，并经过校准（平均误差3%）。评估显示，CXL.cache相比DMA在延迟上降低68%，带宽提高了14.4倍。在远程原子操作（RAO）和远程过程调用（RPC）的应用中，基于CXL的Cohet相比PCIe-NIC实现了显著的加速（RAO加速5.5至40.2倍，RPC平均加速1.86倍）。


<details>
  <summary>Details</summary>
Motivation: 传统的基于PCIe互连的异构计算系统存在细粒度主机-设备交互效率低下和编程模型复杂的问题。近年来兴起的CXL（Compute Express Link）等缓存相干互连标准有望从根本上改变CPU与XPU的协作计算模式。然而，由于缺乏可用的CXL平台、不成熟的软件/硬件生态系统以及不明确的应用前景，相关研究受到阻碍。本文的动机是克服这些障碍，探索CXL驱动相干异构计算的潜力。

Method: 本文提出了Cohet框架，它解耦了计算和内存资源，形成统一的、相干的内存池，并通过标准的malloc/mmap接口为CPU和XPU计算线程提供内存分配和管理。为促进研究，本文还设计并实现了一个全系统周期级模拟器SimCXL，该模拟器能够对所有CXL子协议和设备类型进行建模，并经过真实CXL测试平台校准。Cohet的有效性通过测试远程原子操作（RAO）和远程过程调用（RPC）两个“杀手级应用”来评估，并与传统的PCIe-NIC设计进行了性能比较。

Result: 本文提出的SimCXL模拟器经过校准，平均模拟误差为3%。评估结果显示，与缓存行粒度的DMA传输相比，CXL.cache将延迟降低了68%，带宽提高了14.4倍。基于Cohet框架的评估表明，与PCIe-NIC设计相比，CXL-NIC在远程原子操作（RAO）卸载方面实现了5.5到40.2倍的加速，在远程过程调用（RPC）的（反）序列化卸载方面平均实现了1.86倍的加速。

Conclusion: 本文提出了CXL驱动的相干异构计算框架Cohet，并开发了全系统周期级模拟器SimCXL。Cohet通过解耦计算和内存资源，形成统一且相干的内存池，并为CPU和XPU提供标准内存分配接口，从而简化编程模型并提高细粒度交互的效率。实验结果表明，Cohet在远程原子操作（RAO）和远程过程调用（RPC）等应用中取得了显著的性能提升，突显了CXL在高性能异构计算中的巨大潜力。

Abstract: Conventional heterogeneous computing systems built on PCIe interconnects suffer from inefficient fine-grained host-device interactions and complex programming models. In recent years, many proprietary and open cache-coherent interconnect standards have emerged, among which compute express link (CXL) prevails in the open-standard domain after acquiring several competing solutions. Although CXL-based coherent heterogeneous computing holds the potential to fundamentally transform the collaborative computing mode of CPUs and XPUs, research in this direction remains hampered by the scarcity of available CXL-supported platforms, immature software/hardware ecosystems, and unclear application prospects. This paper presents Cohet, the first CXL-driven coherent heterogeneous computing framework. Cohet decouples the compute and memory resources to form unbiased CPU and XPU pools which share a single unified and coherent memory pool. It exposes a standard malloc/mmap interface to both CPU and XPU compute threads, leaving the OS dealing with smart memory allocation and management of heterogeneous resources. To facilitate Cohet research, we also present a full-system cycle-level simulator named SimCXL, which is capable of modeling all CXL sub-protocols and device types. SimCXL has been rigorously calibrated against a real CXL testbed with various CXL memory and accelerators, showing an average simulation error of 3%. Our evaluation reveals that CXL.cache reduces latency by 68% and increases bandwidth by 14.4x compared to DMA transfers at cacheline granularity. Building upon these insights, we demonstrate the benefits of Cohet with two killer apps, which are remote atomic operation (RAO) and remote procedure call (RPC). Compared to PCIe-NIC design, CXL-NIC achieves a 5.5 to 40.2x speedup for RAO offloading and an average speedup of 1.86x for RPC (de)serialization offloading.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [11] [A Combinatorial Characterization of Constant Mixing Time](https://arxiv.org/abs/2511.21868)
*Lap Chi Lau,Raymond Liu*

Main category: cs.DS

TL;DR: 本文与DSL、图处理、MLIR、编译器、HLS等均不直接相关，但它属于**图处理 (Graph Processing)** 领域中的图理论和算法研究范畴。
本文为具有常数混合时间的图提供了一个基于小集合二分密度的组合特征。该条件比传统的谱半径条件弱，但比小集合顶点扩展条件强，从而提供了一个新的、适度的特性来表征图的快速混合时间。


<details>
  <summary>Details</summary>
Motivation: 经典的谱图论可以刻画具有对数混合时间的图，但本文的动机在于寻找**具有常数混合时间图的组合特征化**，这是一个更强的混合时间属性。

Method: 本文提出了一种基于**小集合二分密度**条件的图的组合特征化方法来刻画具有常数混合时间的图。该方法通过一个比谱半径条件弱，但比小集合顶点扩展条件强的中间性质完成了特征化。

Result: 本文的结果是提供了一个**具有常数混合时间图的组合特征化**，该特征化基于**小集合二分密度**条件。该条件比接近最优谱半径的条件弱，但比接近最优小集合顶点扩展的条件强。

Conclusion: 本文将具有常数混合时间的图的组合特征化呈现出来，它基于小集合二分密度条件，该条件比拥有接近最优谱半径的条件弱，但比拥有接近最优小集合顶点扩展的条件强。这意味着小集合二分密度是刻画具有快速混合时间图的一个关键且适中的性质。

Abstract: Classical spectral graph theory characterizes graphs with logarithmic mixing time. In this work, we present a combinatorial characterization of graphs with constant mixing time. The combinatorial characterization is based on the small-set bipartite density condition, which is weaker than having near-optimal spectral radius and is stronger than having near-optimal small-set vertex expansion.

</details>


### [12] [Differential privacy from axioms](https://arxiv.org/abs/2511.21876)
*Guy Blanc,William Pires,Toniann Pitassi*

Main category: cs.DS

TL;DR: 关联领域：否。
太长不看：尽管普遍存在寻求放松差分隐私（DP）以实现更高效率和更广泛应用任务的动机，本文的核心结论是，任何合理的、满足“非平凡可组合性”的隐私度量，在样本复杂度多项式因子内，都等同于DP。作者通过确定四个核心公理（预处理不变性、禁止公然非隐私、强可组合性、线性可扩展性）来证明这一等价性，并进一步证明这些公理是最小的，从而巩固了DP作为隐私安全黄金标准的地位。


<details>
  <summary>Details</summary>
Motivation: 差分隐私（DP）是目前在理论和实践中事实上的隐私标准，但它要求严格，需防范最坏情况下的强攻击，例如攻击者已知数据集中除一个点外所有信息的场景。这种严格性促使许多研究探索DP的平均情况放松是否更容易满足。本文的作者旨在提出一个更根本的问题：是否存在替代的、较弱的隐私概念，它们既能保证一定程度的基本隐私，又能以更高的效率和/或适用于更广泛的任务集来实现隐私？如果存在，这些概念是否仍然具有实际意义？

Method: 作者采取了公理化方法来证明其主要结果。他们确定了四个核心公理：预处理不变性、禁止公然非隐私、强可组合性、以及线性可扩展性。然后，他们证明了任何满足这四个公理的隐私度量都必须等同于差分隐私（DP），差异仅在于样本复杂度上的多项式因子。最后，他们通过展示移除任何一个公理都会导致不合理解释行为的隐私度量，来证明这些公理的最小性。

Result: 主要结果表明，对于任何合理的、满足非平凡可组合性的隐私度量，答案是否定的：即使在统计设置中，它也等同于差分隐私（DP），最多在样本复杂度上相差一个多项式因子。这是通过确定四个核心公理（预处理不变性、禁止公然非隐私、强可组合性、线性可扩展性）来证明的。满足这些公理的任何隐私度量都必须等价于DP。此外，作者还证明了这四个公理是最小的，移除任何一个公理都会导致行为异常（即不合理）的隐私度量。

Conclusion: 这篇论文的核心结论是，即使在统计环境中，任何满足“非平凡可组合性”的合理隐私度量都等同于差分隐私（DP），最多只有样本复杂度上的多项式因子差异。作者通过确定四个核心公理（预处理不变性、禁止公然非隐私、强可组合性、线性可扩展性）来证明，任何满足这些公理的隐私度量都必须等效于DP。此外，作者还证明了这些公理是最小的，缺少任何一个公理都会导致行为异常的隐私度量。这有力地支持了DP作为隐私领域黄金标准的地位。

Abstract: Differential privacy (DP) is the de facto notion of privacy both in theory and in practice. However, despite its popularity, DP imposes strict requirements which guard against strong worst-case scenarios. For example, it guards against seemingly unrealistic scenarios where an attacker has full information about all but one point in the data set, and still nothing can be learned about the remaining point. While preventing such a strong attack is desirable, many works have explored whether average-case relaxations of DP are easier to satisfy [HWR13,WLF16,BF16,LWX23].
  In this work, we are motivated by the question of whether alternate, weaker notions of privacy are possible: can a weakened privacy notion still guarantee some basic level of privacy, and on the other hand, achieve privacy more efficiently and/or for a substantially broader set of tasks? Our main result shows the answer is no: even in the statistical setting, any reasonable measure of privacy satisfying nontrivial composition is equivalent to DP. To prove this, we identify a core set of four axioms or desiderata: pre-processing invariance, prohibition of blatant non-privacy, strong composition, and linear scalability. Our main theorem shows that any privacy measure satisfying our axioms is equivalent to DP, up to polynomial factors in sample complexity. We complement this result by showing our axioms are minimal: removing any one of our axioms enables ill-behaved measures of privacy.

</details>


### [13] [Identifying all snarls and superbubbles in linear-time, via a unified SPQR-tree framework](https://arxiv.org/abs/2511.21919)
*Francisco Sena,Aleksandr Politov,Corentin Moumard,Manuel Cáceres,Sebastian Schmidt,Juha Harviainen,Alexandru I. Tomescu*

Main category: cs.DS

TL;DR: This paper is related to **graph processing** and may be related to **compiler** (if the graph processing is part of a compiler pipeline, e.g., for optimization). The part related to graph processing is the use of graph structures (snarls, superbubbles) and the SPQR tree decomposition to efficiently find these structures in a pangenome graph.
The paper presents the first linear-time algorithm for identifying all "snarls" and a new linear-time algorithm for "superbubbles" in pangenome graphs. These bubble-like structures are crucial for pangenomic tasks. The approach uses a unified framework based on the observation that these structures are separated by two vertices (a 2-separator), utilizing the SPQR tree decomposition to guide the search. The new implementation, "BubbleFinder," significantly outperforms existing tools like `vg` (up to 2x faster for snarls) and `BubbleGun` (up to 50x faster for superbubbles) on various pangenomic datasets.


<details>
  <summary>Details</summary>
Motivation: Snarls 和 superbubbles 是泛基因组分析中捕获变异位点的基本分解结构（类似气泡的结构），它们支撑着计算泛基因组学中的关键任务，如结构变异基因分型、距离索引、单倍型采样和变异注释。然而，snarls的数量可能是图大小的二次方，自 2018 年推出以来，一直没有在线性时间内识别所有 snarls 的工作。此外，虽然已知如何在线性时间内找到 superbubbles，但这是一个高度专业的解决方案，是经过一系列长期研究才实现的。因此，需要一个更高效、更统一的算法来寻找这些关键结构。

Method: 作者提出了一种新的算法，用于线性时间识别所有 snarls。该算法基于 snarls 的新表示，其大小与输入图的大小呈线性关系，并且可以在线性时间内计算。该算法基于一个统一的框架，该框架也提供了一个新的线性时间算法来寻找 superbubbles。作者观察到所有这些结构（除了易于计算的情况）都被图的其余部分通过两个顶点隔开，即它们的端点是基础无向图的一个 2-分隔符。基于此，作者利用了著名的 SPQR 树分解（它编码了所有 2-分隔符）来指导遍历，从而高效地找到这些类似气泡的结构。作者在 C++ 中实现了这些算法（名为 BubbleFinder），并在各种泛基因组数据集上进行了评估。

Result: 作者提出的算法在各种泛基因组数据集上进行了评估，结果表明，其算法优于或与现有方法处于同一水平。在计算 snarls 时，作者的算法比 vg 快两倍，同时识别了所有 snarls。在计算 superbubbles 时，作者的算法比 BubbleGun 快 50 倍。作者的 SPQR 树框架为泛基因组学中的类似气泡结构提供了统一的视角，并为高效寻找其他类似气泡结构提供了模板。

Conclusion: 本文作者提出了第一个在线性时间内识别所有 snarl 的算法，同时提供了一个新的统一框架，该框架也提供了一个新的线性时间算法来寻找 superbubbles。作者通过实现和在泛基因组数据集上的评估，证明了新算法在效率上优于现有方法，特别是 snarls 算法比 vg 快两倍，superbubbles 算法比 BubbleGun 快 50 倍。作者认为 SPQR 树框架为泛基因组学中的类似气泡结构提供了统一的视角和高效寻找其他类似气泡结构的模板。

Abstract: Snarls and superbubbles are fundamental pangenome decompositions capturing variant sites. These bubble-like structures underpin key tasks in computational pangenomics, including structural-variant genotyping, distance indexing, haplotype sampling, and variant annotation. Snarls can be quadratically-many in the size of the graph, and since their introduction in 2018 with the vg toolkit, there has been no work on identifying all snarls in linear time. Moreover, while it is known how to find superbubbles in linear time, this result is a highly specialized solution only achieved after a long series of papers.
  We present the first algorithm identifying all snarls in linear time. This is based on a new representation of all snarls, of size linear in the input graph size, and which can be computed in linear time. Our algorithm is based on a unified framework that also provides a new linear-time algorithm for finding superbubbles. An observation behind our results is that all such structures are separated from the rest of the graph by two vertices (except for cases which are trivially computable), i.e. their endpoints are a 2-separator of the underlying undirected graph. Based on this, we employ the well-known SPQR tree decomposition, which encodes all 2-separators, to guide a traversal that finds the bubble-like structures efficiently.
  We implemented our algorithms in C++ (available at https://github.com/algbio/BubbleFinder) and evaluated them on various pangenomic datasets. Our algorithms outcompete or they are on the same level of existing methods. For snarls, we are up to two times faster than vg, while identifying all snarls. When computing superbubbles, we are up to 50 times faster than BubbleGun. Our SPQR tree framework provides a unifying perspective on bubble-like structures in pangenomics, together with a template for finding other bubble-like structures efficiently.

</details>


### [14] [MagnifierSketch: Quantile Estimation Centered at One Point](https://arxiv.org/abs/2511.22070)
*Jiarui Guo,Qiushi Lyu,Yuhan Wu,Haoyu Li,Zhaoqian Yao,Yuqi Dong,Xiaolin Wang,Bin Cui,Tong Yang*

Main category: cs.DS

TL;DR: This paper is related to graph processing (data stream processing can be considered a form of graph processing if the data flow is modeled as a stream graph, though here it's primarily data stream/database processing, it also relates to *compiler* (as RocksDB is a database system, and database systems often involve compiler techniques for query optimization though not directly mentioned) and is not primarily related to DSL or MLIR or HLS. / 本文与图处理（数据流处理可以视为一种图处理形式，尽管本文主要关注数据流/数据库处理，它也涉及到*编译器*（因为RocksDB是一个数据库系统，数据库系统通常涉及用于查询优化的编译器技术，尽管没有直接提及））相关，但主要不涉及DSL、MLIR或HLS。本文提出了MagnifierSketch，一种用于数据流模型中高精度点分位数估计的算法，特别针对每键估计的单个预定义分位数（如尾延迟测量）。MagnifierSketch采用Value Focus、Distribution Calibration和Double Filtration技术，经证明是无偏的，并且在单键和每键场景下的平均误差显著优于现有技术，同时具有令人满意的吞吐量，并已在RocksDB数据库中实现以减少查询延迟。


<details>
  <summary>Details</summary>
Motivation: 现有分位数估计算法并非专门为以单个点为中心的每键估计设计，导致在处理数据流中键值对的每键分位数估计（尤其是预定义的单个分位数如0.95或0.99分位数）时，精度不高，且吞吐量不能满足高速数据流的要求。

Method: 提出了MagnifierSketch算法，专注于点分位数估计。其核心技术包括Value Focus、Distribution Calibration和Double Filtration。通过严格的数学推导证明了MagnifierSketch的无偏性，并分析了其空间和时间复杂度。在RocksDB数据库中实现了MagnifierSketch以减少分位数查询延迟。

Result: MagnifierSketch的平均误差（AE）在单键和每键场景下都显著低于现有技术。它能够有效地支持高精度、高吞吐量的点分位数估计，并被成功应用于RocksDB数据库中以减少查询延迟。

Conclusion: MagnifierSketch在单键和每键的点分位数估计中，其平均误差（AE）显著低于现有技术。它被集成到RocksDB数据库中，以减少分位数查询延迟。MagnifierSketch是无偏的，并且具有明确的空间和时间复杂度。

Abstract: In this paper, we take into consideration quantile estimation in data stream models, where every item in the data stream is a key-value pair. Researchers sometimes aim to estimate per-key quantiles (i.e. quantile estimation for every distinct key), and some popular use cases, such as tail latency measurement, recline on a predefined single quantile (e.g. 0.95- or 0.99- quantile) rather than demanding arbitrary quantile estimation. However, existing algorithms are not specially designed for per-key estimation centered at one point. They cannot achieve high accuracy in our problem setting, and their throughput are not satisfactory to handle high-speed items in data streams. To solve this problem, we propose MagnifierSketch for point-quantile estimation. MagnifierSketch supports both single-key and per-key quantile estimation, and its key techniques are named Value Focus, Distribution Calibration and Double Filtration. We provide strict mathematical derivations to prove the unbiasedness of MagnifierSketch and show its space and time complexity. Our experimental results show that the Average Error (AE) of MagnifierSketch is significantly lower than the state-of-the-art in both single-key and per-key situations. We also implement MagnifierSketch on RocksDB database to reduce quantile query latency in real databases. All related codes of MagnifierSketch are open-sourced and available at GitHub.

</details>


### [15] [How fast are algorithms reducing the demands on memory? A survey of progress in space complexity](https://arxiv.org/abs/2511.22084)
*Hayden Rome,Jayson Lynch,Jeffery Li,Chirag Falor,Neil Thompson*

Main category: cs.DS

TL;DR: 该论文与DSL或图处理或MLIR或编译器或HLS不直接相关，但与**编译器**在算法选择和优化方面可能有间接关联。

本文首次对算法进步如何改善内存使用（空间复杂度）进行了广泛调查，分析了118个重要算法问题的800多种算法。研究结果表明，由于“内存墙”问题，空间复杂度的重要性显著提高，甚至在大型问题中，算法的空间复杂度改进在20%的案例中超越了DRAM访问速度的硬件进步。论文还发现算法中时间/空间复杂度之间存在帕累托前沿的权衡，强调了在选择算法时需要全面考虑。


<details>
  <summary>Details</summary>
Motivation: 传统的算法研究主要关注处理器需要多少操作（时间复杂度），但对于许多问题，运行时和能耗主要由内存访问决定。随着内存访问成为性能瓶颈（“内存墙”）的日益突出，研究算法进展对内存使用（空间复杂度）的改善变得至关重要。因此，本文旨在首次对算法进步在空间复杂度方面的改进进行广泛的调查和分析。

Method: 本文通过对计算机科学中118个最重要算法问题及其涉及的800多种算法进行分析和综述，调查了算法进步如何改善内存使用（空间复杂度）。并通过对比算法的空间复杂度改进和硬件（DRAM访问速度）进步，来量化算法进步的重要性。同时，本文还观察和分析了算法中时间复杂度与空间复杂度之间的权力制衡关系。

Result: 研究结果表明，空间复杂度近年来变得越来越重要。在20%的案例中，对于大型问题（n=10亿），算法的空间复杂度改进超越了DRAM访问速度的硬件进步，这表明在最小化内存访问延迟方面，算法进步起到了比硬件进步更大的作用。此外，越来越多的算法出现了帕累托前沿，即获得更好的渐近时间复杂度需要以更差的渐近空间复杂度为代价，反之亦然，这迫使编程者需要在多种算法中进行权衡选择。

Conclusion: 这篇论文首次对算法进展如何改善内存使用（空间复杂度）进行了广泛的调查。研究结果表明，近年来，随着内存访问瓶颈（“内存墙”）问题的日益突出，空间复杂度的重要性显著提高。在20%的案例中，算法的空间复杂度改进对于大型问题（n=10亿）的影响甚至超过了DRAM访问速度的硬件进步。此外，论文发现，算法中时间复杂度和空间复杂度之间存在越来越多的帕累托前沿，这种权衡意味着程序员在选择算法时需要考虑多种选择。作者提供了一个参考资料库（algorithm-wiki.csail.mit.edu），以帮助理论家和实践者更好地理解这些权衡。

Abstract: Algorithm research focuses primarily on how many operations processors need to do (time complexity). But for many problems, both the runtime and energy used are dominated by memory accesses. In this paper, we present the first broad survey of how algorithmic progress has improved memory usage (space complexity). We analyze 118 of the most important algorithm problems in computer science, reviewing the 800+ algorithms used to solve them.
  Our results show that space complexity has become much more important in recent years as worries have arisen about memory access bottle-necking performance (the ``memory wall''). In 20% of cases we find that space complexity improvements for large problems (n=1 billion) outpaced improvements in DRAM access speed, suggesting that for these problems algorithmic progress played a larger role than hardware progress in minimizing memory access delays. Increasingly, we also see the emergence of algorithmic Pareto frontiers, where getting better asymptotic time complexity for a problem requires getting worse asymptotic space complexity, and vice-versa. This tension implies that programmers will increasingly need to consider multiple algorithmic options to understand which is best for their particular problem. To help theorists and practitioners alike consider these trade-offs, we have created a reference for them at https://algorithm-wiki.csail.mit.edu.

</details>


### [16] [Balancing Two-Dimensional Straight-Line Programs](https://arxiv.org/abs/2511.22212)
*Itai Boneh,Estéban Gabory,Paweł Gawrychowski,Adam Górkiewicz*

Main category: cs.DS

TL;DR: 该论文与编译器前端的字符串压缩和数据结构优化相关，特别是在处理二维数据结构和数据压缩方面的随机访问性能优化。
**TLDR:**

本文研究了二维字符串的直连程序（SLP）中的随机访问问题。一维字符串可以实现$\mathcal{O}(g)$大小和$\mathcal{O}(\log N)$访问时间。而对于二维字符串，本文证明了一个否定的下界结果：任何对数深度平衡的2D SLP会使得其尺寸增大到$Ω(g\cdot N/\log^{3}N)$。然而，通过引入一种广义模型——“带孔的2D SLP”，本文利用已有的平衡定理，成功构建了一个大小为$\mathcal{O}(g)$、支持$\mathcal{O}(\log N)$时间随机访问的结构，从而解决了二维压缩数据随机访问的效率问题。


<details>
  <summary>Details</summary>
Motivation: 一维字符串的直连程序（SLP）已经证明可以构建一个$\mathcal{O}(g)$大小的结构，并在$\mathcal{O}(\log N)$时间内提供随机访问，这通过构建一个等价的$\mathcal{O}(g)$大小和$\mathcal{O}(\log N)$深度的SLP实现。本文的动机是探索这个结果是否可以推广到二维字符串，即是否可以为二维字符串的$2D$ SLP构建一个尺寸大致相同且深度较小的等价结构，以支持高效的随机访问。

Method: 本文通过构造一个无限族的二维字符串，并证明任何描述相同字符串的对数深度的二维SLP必须具有较大的$Ω(g\cdot N/\log^{3}N)$尺寸，从而得出了一个否定的下界结果。作为补充，提出了一个尺寸为$\mathcal{O}(g\cdot N)$的上界构造。随后，引入了“带孔的2D SLP”的泛化定义，并应用已知的平衡定理证明了可以构建一个尺寸适中且访问时间高效的随机访问结构。

Result: 本文的主要结果是：1. 否定的下界结果：存在一个无限族的$N\times N$二维字符串，由大小为$g$的2D SLP描述，但任何描述相同字符串的$\mathcal{O}(\log N)$深度的2D SLP，其尺寸必须为$Ω(g\cdot N/\log^{3}N)$。这表明一维字符串的平衡结果不能直接推广到二维。2. 上界结果：可以构造一个尺寸为$\mathcal{O}(g\cdot N)$的2D SLP。3. 积极的结果：引入了“带孔的2D SLP”（2D SLP with holes）的泛化模型，并证明了对于一个大小为$g$的2D SLP，可以构造一个尺寸为$\mathcal{O}(g)$、支持$\mathcal{O}(\log N)$时间随机访问的“带孔的2D SLP”结构。4. 进一步优化：可以扩展该结构至$\mathcal{O}(g \log^εN)$的尺寸，以提供$\mathcal{O}(\log N/\log \log N)$的随机访问时间。

Conclusion: 本文研究了如何为二维字符串的直连程序（SLP）构建一个数据结构，以支持字符的随机访问。研究得出了一个重要的否定的下界结果，即对于二维字符串，以对数深度平衡的SLP会带来很大的尺寸代价。然而，通过引入“带孔的2D SLP”这一广义模型，研究证明了可以构建一个大小为$\mathcal{O}(g)$的结构，在$\mathcal{O}(\log N)$时间内支持随机访问，从而为二维数据压缩结构中的随机访问问题提供了一个有效而紧凑的解决方案。

Abstract: We consider building, given a straight-line program (SLP) consisting of $g$ productions deriving a two-dimensional string $T$ of size $N\times N$, a structure capable of providing random access to any character of $T$. For one-dimensional strings, it is now known how to build a structure of size $\mathcal{O}(g)$ that provides random access in $\mathcal{O}(\log N)$ time. In fact, it is known that this can be obtained by building an equivalent SLP of size $\mathcal{O}(g)$ and depth $\mathcal{O}(\log N)$ [Ganardi, Jeż, Lohrey, JACM 2021]. We consider the analogous question for two-dimensional strings: can we build an equivalent SLP of roughly the same size and small depth?
  We show that the answer is negative: there exists an infinite family of two-dimensional strings of size $N\times N$ described by a 2D SLP of size $g$ such that any 2D SLP describing the same string of depth $\mathcal{O}(\log N)$ must be of size $Ω(g\cdot N/\log^{3}N)$. We complement this with an upper bound showing how to construct such a 2D SLP of size $\mathcal{O}(g\cdot N)$. Next, we observe that one can naturally define a generalization of 2D SLP, which we call 2D SLP with holes. We show that a known general balancing theorem by [Ganardi, Jeż, Lohrey, JACM 2021] immediately implies that, given a 2D SLP of size $g$ deriving a string of size $N\times N$, we can construct a 2D SLP with holes of depth $\mathcal{O}(\log N)$ and size $\mathcal{O}(g)$. This allows us to conclude that there is a structure of size $\mathcal{O}(g)$ providing random access in $\mathcal{O}(\log N)$ time for such a 2D SLP. Further, this can be extended (analogously as for a 1D SLP) to obtain a structure of size $\mathcal{O}(g \log^εN)$ providing random access in $\mathcal{O}(\log N/\log \log N)$ time, for any $ε>0$.

</details>


### [17] [Improved exploration of temporal graphs](https://arxiv.org/abs/2511.22604)
*Paul Bastide,Carla Groenland,Lukas Michel,Clément Rambaud*

Main category: cs.DS

TL;DR: 该论文与图处理（Graph Processing）相关，具体是时间图（Temporal Graph）上的时间探索问题。生成一个TLDR摘要：时间图探索问题旨在找到访问所有顶点的最短步数。先前对于基础图连通且有界最大度的最好上界是$\mathcal{O}(n^{7/4})$。本文通过引入平均时间最大度$D$的概念，将这个上限显著改进到$\mathcal{O}(n^{3/2} \sqrt{\log n})$。更普遍地，作者证明当所有时间步的图连通时，存在一个长度上限为$\mathcal{O}(n^{3/2} \sqrt{D \log n})$的时间探索。这是第一个在基础图具有有界平均度时给出次平方上界的结果，统一并改进了包括平面图在内的特殊情况下的界限。


<details>
  <summary>Details</summary>
Motivation: 研究时间图（Temporal Graph）上的“时间探索问题”（Temporal Exploration Problem），该问题旨在找到访问所有顶点的最短步数序列。对于基础图连通且有界最大度的基本情况，已有的最好上界是$\mathcal{O}(n^{7/4})$。作者的动机是显著改进这一基本情况下的上界，并为更普遍的情况（如基础图有界平均度）找到次平方（subquadratic）的上界。

Method: 通过引入和利用“平均时间最大度”（$D$）这一新概念，作者建立了一个更通用的定理：如果每个图$G_t$都是连通的，则存在一个长度为$\mathcal{O}(n^{3/2} \sqrt{D \log n})$的时间探索。这个通用结果通过选择特定的$D$值来得到针对不同场景的改进上界，包括将有界最大度情况下的上界从$\mathcal{O}(n^{7/4})$改进到$\mathcal{O}(n^{3/2} \sqrt{\log n})$。

Result: 主要结果是将有界最大度图的最短时间探索长度的上界从$\mathcal{O}(n^{7/4})$改进到$\mathcal{O}(n^{3/2} \sqrt{\log n})$。更强和更通用的结果是，如果所有$G_t$是连通的，并且平均时间最大度为$D$，则存在一个长度为$\mathcal{O}(n^{3/2} \sqrt{D \log n})$的时间探索。此结果在$D=o(n/\log n)$时是次平方的，并首次对有界平均度的情况给出了次平方上界，同时统一改进了平面图和有界树宽图等特殊情况下的最好界限。

Conclusion: 这篇论文显著改进了在所有时间步图$G_t$都连通且具有有界最大度的情况下，最短时间探索的长度上限，从之前的$\mathcal{O}(n^{7/4})$降低到$\mathcal{O}(n^{3/2} \sqrt{\log n})$。更普遍地，作者提出了一个更通用的结果，利用平均时间最大度$D$，证明了当$G_t$连通时，存在一个长度上限为$\mathcal{O}(n^{3/2} \sqrt{D \log n})$的时间探索。这首次在基础图具有有界平均度的情况下给出了次平方的上界，并统一改进了基础图是平面图或具有有界树宽等特殊情况下的最好界限。

Abstract: A temporal graph $G$ is a sequence $(G_t)_{t \in I}$ of graphs on the same vertex set of size $n$. The \emph{temporal exploration problem} asks for the length of the shortest sequence of vertices that starts at a given vertex, visits every vertex, and at each time step $t$ either stays at the current vertex or moves to an adjacent vertex in $G_t$. Bounds on the length of a shortest temporal exploration have been investigated extensively. Perhaps the most fundamental case is when each graph $G_t$ is connected and has bounded maximum degree. In this setting, Erlebach, Kammer, Luo, Sajenko, and Spooner [ICALP 2019] showed that there exists an exploration of $G$ in $\mathcal{O}(n^{7/4})$ time steps. We significantly improve this bound by showing that $\mathcal{O}(n^{3/2} \sqrt{\log n})$ time steps suffice.
  In fact, we deduce this result from a much more general statement. Let the \emph{average temporal maximum degree} $D$ of $G$ be the average of $\max_{t \in I} d_{G_t}(v)$ over all vertices $v \in V(G)$, where $d_{G_t}(v)$ denotes the degree of $v$ in $G_t$. If each graph $G_t$ is connected, we show that there exists an exploration of $G$ in $\mathcal{O}(n^{3/2} \sqrt{D \log n})$ time steps. In particular, this gives the first subquadratic upper bound when the underlying graph has bounded average degree. As a special case, this also improves the previous best bounds when the underlying graph is planar or has bounded treewidth and provides a unified approach for all of these settings. Our bound is subquadratic already when $D=o(n/\log n)$.

</details>


### [18] [Spanning Trees with a Small Vertex Cover: the Complexity on Specific Graph Classes](https://arxiv.org/abs/2511.22912)
*Toranosuke Kokai,Akira Suzuki,Takahiro Suzuki,Yuma Tamura,Xiao Zhou*

Main category: cs.DS

TL;DR: 该论文与 DSL、图处理、MLIR、编译器或 HLS 无关。
**太长不看（TLDR）:** 本论文研究了最小覆盖生成树（MCST）问题，该问题是确定一个图 $G$ 是否存在一个顶点覆盖至多为 $k$ 的生成树。论文证明了在直径至多为 2 或 $P_5$-free 图上 MCST 与支配集问题的等价性（难解性），并证明了其在最大度为 4 的双平面图和单位圆盘图上的 NP-完全性，解决了先前研究中的开放问题。此外，论文还提出了针对以团宽度为参数的 MCST 问题的 FPT 算法，以及针对区间图的线性时间算法。


<details>
  <summary>Details</summary>
Motivation: 在算法理论中，关于具有理想性质的生成树的研究是一个重要的方向。本文的动机是研究最小覆盖生成树（MCST）问题的复杂性，即给定一个图 $G$ 和一个正整数 $k$，确定 $G$ 是否存在一个顶点覆盖至多为 $k$ 的生成树。该问题先前已有研究，但仍存在未解决的复杂性问题，其主要目标是填补现有研究的空白，明晰 MCST 问题在各种图类上的可解性和难解性。

Method: 本文通过理论分析和归约证明的方法来分析 MCST 问题的复杂性。通过揭示 MCST 与支配集问题在特定图类（直径至多为 2 或 $P_5$-free 图）上的等价性来证明其难解性。通过归约证明了 MCST 在双平面图（最大度为 4）和单位圆盘图上的 NP-完全性。此外，本文还应用了 FPT 算法以及针对特定图类（区间图）的线性时间算法来证明其可解性。

Result: 本文得出了以下主要结果：1. 揭示了 MCST 问题与支配集问题在直径至多为 2 的图或 $P_5$-free 图上的等价性，这表明了在这些图类上的难解性，同时也为几个 $P_5$-free 图的子类的可解性提供了依据。2. 证明了 MCST 在最大度为 4 的双平面图和单位圆盘图上是 NP-完全的。这些结果解决了先前研究中提出的开放问题。3. 提出了一个以团宽度为参数的 MCST 问题的 FPT 算法。4. 提出了一个针对区间图的线性时间算法。

Conclusion: 本文研究了最小覆盖生成树（MCST）问题，证明了其在直径至多为 2 的图或 $P_5$-free 图上的等价性以及在双平面图（最大度为 4）和单位圆盘图上的 NP-完全性。这些结果解决了先前研究中提出的开放问题。此外，本文还提出了针对以团宽度为参数的 MCST 问题的 FPT 算法以及针对区间图的线性时间算法，表明了在更严格的图类上的可解性。

Abstract: In the context of algorithm theory, various studies have been conducted on spanning trees with desirable properties. In this paper, we consider the \textsc{Minimum Cover Spanning Tree} problem (MCST for short). Given a graph $G$ and a positive integer $k$, the problem determines whether $G$ has a spanning tree with a vertex cover of size at most $k$. We reveal the equivalence between \mcst\ and the \textsc{Dominating Set} problem when $G$ is of diameter at most~$2$ or $P_5$-free. This provides the intractability for these graphs and the tractability for several subclasses of $P_5$-free graphs. We also show that \mcst\ is NP-complete for bipartite planar graphs of maximum degree~$4$ and unit disk graphs. These hardness results resolve open questions posed in prior research. Finally, we present an FPT algorithm for {\mcst} parameterized by clique-width and a linear-time algorithm for interval graphs.

</details>


### [19] [Towards an algebraic approach to the reconfiguration CSP](https://arxiv.org/abs/2511.22914)
*Kei Kimura*

Main category: cs.DS

TL;DR: 关联领域：图处理（Graph Homomorphisms/Recoloring）。
太长不看（TLDR）：可重构约束满足问题（RCSP）询问一个 CSP 实例的两个解是否可以通过一系列中间解相互转换，每次只改变一个变量的赋值。针对 RCSP 的复杂性分析，本文提出了一种新颖的代数方法，该方法不使用传统的全运算，而是引入了偏代数（partial operations）来捕获涉及等式约束的归约。这种偏代数的视角有助于将布尔域的复杂性结果扩展到更一般的设置，并证明了其在识别可处理 RCSP 实例方面的通用性。


<details>
  <summary>Details</summary>
Motivation: 约束满足问题（CSP）的可重构变体（RCSP）已经引起了理论计算机科学界日益增长的兴趣。当变量域是布尔域时，其计算复杂性取决于允许的约束类型，表现出二分法。本文的动机是希望**将复杂性结果从布尔域推广到更一般的设置**，并识别可处理的 RCSP 实例。

Method: 本文提出了一种新颖的代数方法来分析 RCSP 的复杂性，这与传统的基于全运算的方法不同，该框架采用了**偏代数（partial operations）**来捕获涉及等式约束的归约。

Result: 本文表明，偏代数的方法有助于将复杂性结果从布尔域扩展到更一般的设置，并证明了偏代数在识别可处理的 RCSP 实例方面的通用性（versatility）。

Conclusion: 本文将偏代数（partial operations）引入到可重构约束满足问题（RCSP）的复杂性分析中，并证明了偏代数视角在识别可处理的 RCSP 实例方面的通用性。

Abstract: This paper investigates the reconfiguration variant of the Constraint Satisfaction Problem (CSP), referred to as the Reconfiguration CSP (RCSP). Given a CSP instance and two of its solutions, RCSP asks whether one solution can be transformed into the other via a sequence of intermediate solutions, each differing by the assignment of a single variable. RCSP has attracted growing interest in theoretical computer science, and when the variable domain is Boolean, the computational complexity of RCSP exhibits a dichotomy depending on the allowed constraint types. A notable special case is the reconfiguration of graph homomorphisms -- also known as graph recoloring -- which has been studied using topological methods. We propose a novel algebraic approach to RCSP, inspired by techniques used in classical CSP complexity analysis. Unlike traditional methods based on total operations, our framework employs partial operations to capture a reduction involving equality constraints. This perspective facilitates the extension of complexity results from Boolean domains to more general settings, demonstrating the versatility of partial operations in identifying tractable RCSP instances.

</details>


### [20] [Solution Discovery for Vertex Cover, Independent Set, Dominating Set, and Feedback Vertex Set](https://arxiv.org/abs/2511.23012)
*Rin Saito,Anouk Sommer,Tatsuhiro Suga,Takahiro Suzuki,Yuma Tamura*

Main category: cs.DS

TL;DR: 该论文与 DSL 或图处理或 MLIR 或编译器或 HLS 无关。该论文研究图上若干基本顶点子集问题的解发现问题的计算复杂度。作者提供了关于团宽度的 XP 算法、特定图类（弦图、直径为 2 的图）上的 NP 完备性、另一特定图类（分裂图）上的多项式时间可解性，并为反馈顶点集发现提供了一个 FPT 算法。


<details>
  <summary>Details</summary>
Motivation: 图形搜索中解发现问题研究的是在一个图的顶点上给定 $k$ 个令牌的初始放置，询问是否可以通过少量修改将其转换为一个可行解。本文旨在研究几个基本图顶点子集问题（顶点覆盖发现、独立集发现、支配集发现和反馈顶点集发现）的解发现问题的计算复杂度，以理解它们在不同图结构下的难度边界。

Method: 本文通过理论分析和算法设计来研究问题。具体方法包括：1. 针对团宽度参数设计 XP 算法（针对所有四个问题）。2. 证明某些图类（弦图和直径为 2 的图）上的 NP 完备性（针对 VC 发现、IS 发现、FVS 发现）。3. 证明在另一类图（分裂图）上的多项式时间可解性（针对 VC 发现、IS 发现、FVS 发现）。4. 设计以令牌数 k 为参数的 FPT 算法（针对 FVS 发现）。

Result: 本文得出了以下主要结果：1. 所有四个解发现问题（VC 发现、IS 发现、DS 发现和 FVS 发现）在以图的团宽度为参数时，都存在 XP 算法。2. 顶点覆盖发现、独立集发现和反馈顶点集发现问题在弦图和直径为 2 的图上是 NP 完备的。3. 顶点覆盖发现、独立集发现和反馈顶点集发现问题在分裂图上是可以在多项式时间内解决的。4. 为反馈顶点集发现问题设计了一个以令牌数量为参数的 FPT 算法。

Conclusion: 本文研究了图上若干基本顶点子集问题的解发现问题的计算复杂度。对于团宽度有界的图，这些问题的解发现都存在 XP 算法。然而，对于无界团宽度的图，例如弦图和直径为 2 的图，其中的三个问题（顶点覆盖发现、独立集发现和反馈顶点集发现）被证明是 NP 完备的。相比之下，在分裂图上，所有这三个问题都可以在多项式时间内解决。此外，还为反馈顶点集发现问题设计了以令牌数量为参数的 FPT 算法。

Abstract: In the solution discovery problem for a search problem on graphs, we are given an initial placement of $k$ tokens on the vertices of a graph and asked whether this placement can be transformed into a feasible solution by applying a small number of modifications. In this paper, we study the computational complexity of solution discovery for several fundamental vertex-subset problems on graphs, namely Vertex Cover Discovery, Independent Set Discovery, Dominating Set Discovery, and Feedback Vertex Set Discovery. We first present XP algorithms for all four problems parameterized by clique-width. We then prove that Vertex Cover Discovery, Independent Set Discovery, and Feedback Vertex Set Discovery are NP-complete for chordal graphs and graphs of diameter 2, which have unbounded clique-width. In contrast to these hardness results, we show that all three problems can be solved in polynomial time on split graphs. Furthermore, we design an FPT algorithm for Feedback Vertex Set Discovery parameterized by the number of tokens.

</details>


### [21] [Improved and Parameterized Algorithms for Online Multi-level Aggregation: A Memory-based Approach](https://arxiv.org/abs/2511.23211)
*Alexander Turoczy,Young-San Lin*

Main category: cs.DS

TL;DR: 关联领域：图处理 (Graph Processing)——问题定义在具有顶点权重的树上。
总括：本文研究在线多级聚合问题（MLAP-D），在该问题中，树的顶点上的请求随时间到达并带有截止日期，目标是找到最小化总成本的聚合服务方案。作者提出了一个简单的新框架，在此基础上提出了两种改进的参数化在线算法：一个是 $e(D+1)$-竞争算法（$D$ 为树的深度），另一个是首个以优于深度 $D$ 的精细参数“毛毛虫维度 $H$”为参数的 $e(4H+2)$-竞争算法。当 $H$ 显著小于 $D$ 或 $\log |V|$ 时，该算法的竞争比优于现有技术，特别适用于毛毛虫图等结构简单的树类。


<details>
  <summary>Details</summary>
Motivation: 在线多级聚合问题（MLAP-D）是一个重要的在线优化问题，涉及最小化在给定截止日期内服务所有请求的总成本。现有最先进的在线算法，如 $6(D+1)$-竞争算法（$D$ 为树的深度）和 $O(\log |V|)$-竞争算法（$|V|$ 为顶点数），其竞争比依赖于深度或顶点数。作者的目标是找到一个更优的或基于更精细参数的在线算法。特别是，作者希望找到第一个基于比深度更好的参数的在线算法，并设计一个适用于任意树结构的简单框架。

Method: 本文提出了一个适用于任意树结构的新颖、简单的在线算法框架，用以解决 MLAP-D 问题。在此框架下，基于两种不同的参数（树的深度 $D$ 和毛毛虫维度 $H$），本文导出了两种参数化竞争算法：
1. $e(D+1)$-竞争算法：以树的深度 $D$ 为参数。
2. $e(4H+2)$-竞争算法：以树的毛毛虫维度 $H$ 为参数。
该框架避免了以往将问题简化为特定结构树的步骤，并直接在具有任意结构的树上应用。

Result: 本文取得了两个主要结果：
1. 提出了一个 $e(D+1)$-竞争算法，其中 $D$ 是树的深度。
2. 提出了一个 $e(4H+2)$-竞争算法，其中 $H$ 是树的毛毛虫维度。毛毛虫维度 $H$ 满足 $H \le D$ 且 $H \le \log_2 |V|$。对于线图、毛毛虫图和龙虾图等简单但丰富的树类， $H$ 保持不变（分别为 1、2 和 3）。
与现有最先进算法（$6(D+1)$-竞争和 $O(\log |V|)$-竞争）相比，当 $H = o(\min\{D,\log_2 |V|\})$ 时，本文提出的框架具有更好的竞争比。这是首个以优于深度（$D$）的衡量标准（$H$）为参数的在线算法。作者的框架是简单且直接适用于任何结构树的。

Conclusion: 本文研究了带截止日期的在线多级聚合问题（MLAP-D），提出了两种改进的参数化在线算法：一是 $e(D+1)$-竞争算法（$D$ 为树的深度），与现有最佳算法 $6(D+1)$ 相当，但框架更简单。二是 $e(4H+2)$-竞争算法（$H$ 为毛毛虫维度），这是首个基于比深度更好的参数（$H$）的在线算法，且 $H$ 对于一些特定结构的树是常数，因此在这些情况下具有更好的竞争比。这项工作为 MLAP-D 问题的在线求解提供了更简单、更有效的框架，特别是在毛毛虫维度较小时，性能优于现有技术。

Abstract: We study the online multi-level aggregation problem with deadlines (MLAP-D) introduced by Bienkowski et al. (ESA 2016, OR 2020). In this problem, requests arrive over time at the vertices of a given vertex-weighted tree, and each request has a deadline that it must be served by. The cost of serving a request equals the cost of a path from the root to the vertex where the request resides. Instead of serving each request individually, requests can be aggregated and served by transmitting a subtree from the root that spans the vertices on which the requests reside, to potentially be more cost-effective. The aggregated cost is the weight of the transmission subtree. The goal of MLAP-D is to find an aggregation solution that minimizes the total cost while serving all requests.
  We present improved and parameterized algorithms for MLAP-D. Our result is twofold. First, we present an $e(D+1)$-competitive algorithm where $D$ is the depth of the tree. Second, we present an $e(4H+2)$-competitive algorithm where $H$ is the caterpillar dimension of the tree. Here, $H \le D$ and $H \le \log_2 |V|$ where $|V|$ is the number of vertices in the given tree. The caterpillar dimension remains constant for rich but simple classes of trees, such as line graphs ($H=1$), caterpillar graphs ($H=2$), and lobster graphs ($H=3$). To the best of our knowledge, this is the first online algorithm parameterized on a measure better than depth. The state-of-the-art online algorithms are $6(D+1)$-competitive by Buchbinder, Feldman, Naor, and Talmon (SODA 2017) and $O(\log |V|)$-competitive by Azar and Touitou (FOCS 2020). Our framework outperforms the state-of-the-art ratios when $H = o(\min\{D,\log_2 |V|\})$. Our simple framework directly applies to trees with any structure and differs from the previous frameworks that reduce the problem to trees with specific structures.

</details>


### [22] [Homomorphism Testing with Resilience to Online Manipulations](https://arxiv.org/abs/2511.23363)
*Esty Kelman,Uri Meir,Debanuj Nayak,Sofya Raskhodnikova*

Main category: cs.DS

TL;DR: 该论文与图处理、MLIR、编译器或HLS无关，但与DSL（领域特定语言）的**性质测试**和**代数结构验证**有关，这在程序验证和编译优化中有应用。
这份摘要启动了在线操纵模型下“抗操纵”群同态测试的研究。作者提出了一个最优的 $\mathsf{Random\ Signs\ Test}$，它使用 $O(1/\varepsilon+\log t)$ 次查询，并将经典的线性度测试推广到一般群，以抵抗对手在查询响应中擦除或损坏数据的行为，从而在对抗性环境中恢复了标准性质测试模型的 $O(1/\varepsilon)$ 最优查询界限。


<details>
  <summary>Details</summary>
Motivation: 经典的代数性质测试（如线性度或群同态）假定对输入函数拥有无限制、无噪声的访问权限，这在对抗性或动态环境中并不成立。先前的工作引入了“在线操纵模型”，其中对手可以根据测试器过去的查询，随时擦除或损坏查询响应。本文的动机是希望在这种更具挑战性的在线操纵模型下，首次研究和开发用于“群同态”的操纵弹性测试器，以确保在数据访问受限或被恶意修改的环境中仍然能够可靠地验证代数结构。

Method: 作者提出了一个最优的“抗操纵”群同态测试器，称为 $\mathsf{Random\ Signs\ Test}$。该方法的关键在于通过引入更多的随机性，将先前的抗操纵线性测试器（适用于 $\mathbb{F}_2^n\to \mathbb{F}_2$）推广到了一般群域和群余域。具体来说，新测试器不是对随机元素的和验证同态条件，而是使用随机元素的加减法，并为每个元素随机选择一个符号。这种技术使得测试器对在线操纵模型下的恶意擦除或损坏具有鲁棒性。

Result: 主要结果是一个针对在线模型中群同态测试的**最优**测试器，查询次数为 $O(1/\varepsilon+\log t)$，其中 $\varepsilon$ 是距离参数，$t$ 是对手在每个查询中可以擦除或损坏的函数值数量。这个结果恢复了经典性质测试模型中群同态测试的 $O(1/\varepsilon)$ 最优界限（由 Ben-Or 等人获得），但使用了不同的测试器。此外，该工作对关键群族获得了改进的特定于群的查询界限。

Conclusion: 本文启动了对在线模型中“抗操纵”群同态测试的研究，并给出了一个最优的测试器。这个测试器在保持了经典性质测试模型中$O(1/\varepsilon)$最优查询次数的基础上，仅增加了对操纵能力的最小依赖，即$O(\log t)$。所提出的 $\mathsf{Random\ Signs\ Test}$ 通过引入额外的随机性（使用随机符号对随机元素的加减法）将现有的抗操纵线性测试器推广到了一般群域和群余域，这不仅是一个理论上的突破，也为未来在动态或对抗性环境中进行性质测试提供了新的视角和实用工具。

Abstract: A central challenge in property testing is verifying algebraic structure with minimal access to data. A landmark result addressing this challenge, the linearity test of Blum, Luby, and Rubinfeld (JCSS `93), spurred a rich body of work on testing algebraic properties such as linearity and its generalizations to low-degree polynomials and group homomorphisms. However, classical tests for these properties assume unrestricted, noise-free access to the input function--an assumption that breaks down in adversarial or dynamic settings. To address this, Kalemaj, Raskhodnikova, and Varma (Theory of Computing `23) introduced the online manipulation model, where an adversary may erase or corrupt query responses over time, based on the tester's past queries.
  We initiate the study of {manipulation-resilient} testing for {group homomorphism} in this online model. Our main result is an {optimal} tester that makes $O(1/\varepsilon+\log t)$ queries, where $\varepsilon$ is the distance parameter and $t$ is the number of function values the adversary can erase or corrupt per query. Our result recovers the celebrated $O(1/\varepsilon)$ bound by Ben-Or, Coppersmith, Luby, and Rubinfeld (Random Struct.\ Algorithms `08) for homomorphism testing in the standard property testing model, albeit with a different tester. Our tester, $\mathsf{Random\ Signs\ Test}$, {lifts} known manipulation-resilient linearity testers for $\mathbb{F}_2^n\to \mathbb{F}_2$ to general group domains and codomains by introducing more randomness: instead of verifying the homomorphism condition for a sum of random elements, it uses additions and subtractions of random elements, randomly selecting a sign for each element. We also obtain improved group-specific query bounds for key families of groups.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [23] [A Sustainable and Reward Incentivized High-Performance Cluster Computing for Artificial Intelligence: A Novel Bayesian-Time-Decay Trust Mechanism in Blockchain](https://arxiv.org/abs/2511.21844)
*Murat Yaslioglu*

Main category: cs.DC

TL;DR: 该论文与编译器、DSL、HLS、MLIR、图处理无关。
该论文提出了一种新的区块链框架，将高性能集群计算与智能算法结合，通过改进的工作量证明（PoW）机制、动态信任评级和统计抽签系统，旨在提高智能算法开发和实现的可持续性、效率和广泛参与度。


<details>
  <summary>Details</summary>
Motivation: 当前高性能计算和智能算法的发展对计算能力要求高，导致能源消耗大，可能排斥计算系统较弱的参与者。因此，迫切需要一种更具包容性、可扩展性和生态友好性的方法来开发和实现智能算法，以实现可持续发展。

Method: 提出了一种将高性能集群计算与智能算法无缝融合到区块链基础设施中的新框架。核心方法包括：1. 引入一种进化的工作量证明（PoW）共识过程，将计算努力与区块生产奖励直接关联，确保资源最佳利用和广泛参与。2. 采用动态“信任评级”系统，根据准确的区块验证记录演变，用以决定节点被选为区块生成的可能性。3. 建议采用统计学上的“抽签”系统，为计算能力较弱的节点提供参与区块创建的机会。

Result: 该框架通过结合区块链技术，特别是引入了改进的PoW机制、动态信任评级和统计抽签系统，成功构建了一个既能提升智能算法效率和可持续性，又能激励广泛参与和公平资源分配的系统。它确保了资源的优化使用，并为真实的、精准的贡献提供奖励，同时为计算能力较弱的节点提供了参与机会。

Conclusion: 本文提出了一种结合高性能集群计算、智能算法和区块链的新框架。其核心优势在于引入了进化的工作量证明机制和动态信任评级系统，旨在提高智能算法开发和实现的效率、可扩展性和可持续性，同时促进更广泛的参与和更公平的资源分配。

Abstract: In an age where sustainability is of paramount importance, the significance of both high-performance computing and intelligent algorithms cannot be understated. Yet, these domains often demand hefty computational power, translating to substantial energy usage and potentially sidelining less robust computing systems. It's evident that we need an approach that is more encompassing, scalable, and eco-friendly for intelligent algorithm development and implementation. The strategy we present in this paper offers a compelling answer to these issues. We unveil a fresh framework that seamlessly melds high-performance cluster computing with intelligent algorithms, all within a blockchain infrastructure. This promotes both efficiency and a broad-based participation. At its core, our design integrates an evolved proof-of-work consensus process, which links computational efforts directly to rewards for producing blocks. This ensures both optimal resource use and participation from a wide spectrum of computational capacities. Additionally, our approach incorporates a dynamic 'trust rating' that evolves based on a track record of accurate block validations. This rating determines the likelihood of a node being chosen for block generation, creating a merit-based system that recognizes and rewards genuine and precise contributions. To level the playing field further, we suggest a statistical 'draw' system, allowing even less powerful nodes a chance to be part of the block creation process.

</details>


### [24] [Equivalence and Separation between Heard-Of and Asynchronous Message-Passing Models](https://arxiv.org/abs/2511.21859)
*Hagit Attiya,Armando Castañeda,Dhrubajyoti Ghosh,Thomas Nowak*

Main category: cs.DC

TL;DR: 该论文与分布式系统、并发计算相关，不直接涉及DSL、图处理、MLIR、编译器或HLS。

**TL;DR:** 本文重新审视了异步消息传递模型 ($\operatorname{AMP}_f$) 和 Heard-Of 模型 ($\operatorname{HO}_f$) 之间的关系。研究发现，在 $n > 2f$ 的条件下，对于无色任务，两者是等价的；但对于有色任务，仅在 $f=1$ 时等价。这种分离是由于 $\operatorname{HO}_f$ 中“静默”进程的存在。研究结论表明，基于轮次的抽象的表达能力限制是结构性的，而非概率性的，精确地界定了基于轮次的抽象何时能捕获异步计算，何时不能。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是重新审视和精确界定异步消息传递模型 $\operatorname{AMP}_f$（允许最多 $f$ 个崩溃故障）和 Heard-Of 模型 $\operatorname{HO}_f$（允许最多 $f$ 个消息遗漏）这两种基本分布式计算模型之间的表达能力和关系。目的是确定基于轮次的抽象（如 $\operatorname{HO}_f$）在多大程度上能够准确地捕获异步计算的本质（如 $\operatorname{AMP}_f$）。

Method: 本文通过 $\operatorname{AMP}_f$ 和 $\operatorname{HO}_f$ 之间的双向模拟以及引入一个捕获“静默”概念的中间模型来证明其结果。此外，研究还扩展到针对非自适应对手的随机协议，以分析概率因素的作用。

Result: 在 $n > 2f$ 的条件下，对于无色任务（colorless tasks），$\operatorname{AMP}_f$ 和 $\operatorname{HO}_f$ 模型在可解性上是等价的。对于有色任务（colored tasks），只有当 $f = 1$（且 $n > 2$）时，这两种模型才等价。当 $f$ 更大时，由于 $\operatorname{HO}_f$ 模型中存在“静默”（silenced）进程，可能导致不兼容的决策，从而造成模型分离。这些结果进一步扩展到针对非自适应对手的随机协议，表明这种表达能力的限制是结构性的，而非概率性的。

Conclusion: 本文通过引入“静默”进程的概念，证明了在 $n > 2f$ 的条件下，异步消息传递模型 $\operatorname{AMP}_f$ 和 Heard-Of 模型 $\operatorname{HO}_f$ 在无色任务的可解性上是等价的，但在有色任务上仅在 $f=1$（且 $n > 2$）时等价。研究结果表明了基于轮次的抽象在何种情况下可以捕获异步计算，在何种情况下不能，揭示了这两种分布式计算模型之间表达能力的精确界限。

Abstract: We revisit the relationship between two fundamental models of distributed computation: the asynchronous message-passing model with up to $f$ crash failures ($\operatorname{AMP}_f$) and the Heard-Of model with up to $f$ message omissions ($\operatorname{HO}_f$). We show that for $n > 2f$, the two models are equivalent with respect to the solvability of colorless tasks, and that for colored tasks the equivalence holds only when $f = 1$ (and $n > 2$). The separation for larger $f$ arises from the presence of silenced processes in $\operatorname{HO}_f$, which may lead to incompatible decisions. The proofs proceed through bidirectional simulations between $\operatorname{AMP}_f$ and $\operatorname{HO}_f$ via an intermediate model that captures this notion of silencing. The results extend to randomized protocols against a non-adaptive adversary, indicating that the expressive limits of canonical rounds are structural rather than probabilistic. Together, these results delineate precisely where round-based abstractions capture asynchronous computation, and where they do not.

</details>


### [25] [OOCO: Latency-disaggregated Architecture for Online-Offline Co-locate LLM Serving](https://arxiv.org/abs/2511.21862)
*Siyu Wu,Zihan Tang,Yuting Zeng,Hui Chen,Guiguang Ding,Tongxuan Liu,Ke Zhang,Hailong Yang*

Main category: cs.DC

TL;DR: This paper is related to graph processing or compiler because it discusses resource allocation and scheduling problems in LLM inference serving, which is related to compiler and optimization. The paper addresses the severe load imbalance issue when co-locating online and offline LLM workloads in Prefill/Decode disaggregated systems. It proposes a latency-constraint disaggregated architecture separating resources into latency-strict and latency-relaxed pools, along with a bottleneck-based scheduler guided by a Roofline model and a fast preemption mechanism, improving offline throughput by up to 3x while maintaining online SLOs.


<details>
  <summary>Details</summary>
Motivation: 将在线服务和成本敏感的离线工作负载共同部署在共享服务实例上，可以提高资源利用率。然而，在现有分离系统（Prefill/Decode, P/D）中直接应用会导致严重的负载不平衡问题，因为请求组合的波动会改变固有的 P/D 比例。现有动态调整技术难以跟上在线服务的突发流量模式。

Method: 本文提出了一种延迟约束的分离架构，将集群资源分为延迟严格和延迟宽松的资源池。为了充分利用这种灵活性，提出了（1）一个由基于Roofline的性能模型指导的基于性能瓶颈的调度器；（2）一个严格执行在线请求服务质量目标（SLOs）的快速抢占机制。

Result: 该方法相比现有的离线系统方法，在保持在线请求服务质量目标（SLOs）的同时，将离线吞吐量提高了高达3倍。

Conclusion: 本文提出了一种延迟约束的分离架构，将集群资源分为延迟严格和延迟宽松的资源池，并提出了基于性能瓶颈的调度器及快速抢占机制。实验证明，该方法在保持在线服务质量目标（SLOs）的同时，将离线吞吐量提高了高达3倍。

Abstract: Large Language Models (LLMs) are increasingly deployed in both latency-sensitive online services and cost-sensitive offline workloads. Co-locating these workloads on shared serving instances can improve resource utilization, but directly applying this approach to Prefill/Decode (P/D) disaggregated systems introduces severe load imbalance, as fluctuating request mixes alter the intrinsic P/D ratio. Existing dynamic adjustment techniques cannot keep up with the bursty traffic patterns of online services.
  We propose a latency-constraint disaggregated architecture, which separates cluster resources into latency-strict and latency-relaxed pools based on task latency requirements. This design enables flexible placement of offline decode tasks, mitigating P/D imbalance while preserving online performance. To fully exploit this flexibility, we propose (1) a bottleneck-based scheduler guided by a Roofline-based performance model for performance bottleneck based scheduling, and (2) a fast preemption mechanism that strictly enforces Service Level Objectives (SLOs) for online requests.
  Experiments on real-world traces show that compared to existing offline system approaches, our method improves offline throughput by up to 3x, while maintaining online request SLOs.

</details>


### [26] [Clock2Q+: A Simple and Efficient Replacement Algorithm for Metadata Cache in VMware vSAN](https://arxiv.org/abs/2511.21958)
*Yiyan Zhai,Bintang Dwi Marthen,Sarath Balivada,Vamsi Sudhakar Bojji,Eric Knauft,Jitender Rohilla,Jiaqi Zuo,Quanxing Liu,Maxime Austruy,Wenguang Wang,Juncheng Yang*

Main category: cs.DC

TL;DR: 该论文与编译器和HLS无关，但与**DSL**（因为缓存替换算法是系统软件组成的一部分，影响**存储系统的设计**，可以理解为领域特定优化）和**图处理**无关。其核心贡献聚焦于**存储系统的缓存替换算法**。这篇论文提出了一种新的缓存替换算法Clock2Q+，专门针对元数据缓存中固有的相关引用问题。Clock2Q+在S3-FIFO的三队列结构基础上引入了“相关性窗口”来避免误将相关引用识别为热块。实验证明，Clock2Q+在元数据跟踪上比S3-FIFO的未命中率降低高达28.5%，并且在数据跟踪上也有出色表现。该算法已在VMware的vSAN和VDFS中实现，具有低开销和高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 缓存替换算法是存储系统中的关键组成部分。本文的动机在于，元数据缓存固有地表现出“相关引用”（correlated references），即使对应的数据访问不具有相关性。这种相关引用的存在性降低了现有缓存替换算法的有效性，因为这些引用经常被错误地归类为热块，从而占用缓存空间。因此，需要设计一种专门针对元数据缓存特性优化的替换算法。

Method: 本文提出了一种新的缓存替换算法Clock2Q+，专门为元数据缓存设计。Clock2Q+基于三队列结构（类似于S3-FIFO），但在小FIFO队列中引入了一个“相关性窗口”（correlation window），在其中的块不设置引用位。这种简单改进可以有效地处理元数据独有的相关引用问题。作者通过在元数据和数据跟踪上的实验，将Clock2Q+与S3-FIFO等现有最先进的替换算法进行比较。

Result: Clock2Q+算法在元数据跟踪上的性能优于最先进的替换算法。与次优算法S3-FIFO相比，Clock2Q+实现了高达28.5%的未命中率降低。Clock2Q+同样在数据跟踪上表现优于现有的最先进算法。该算法具有大规模存储系统所需的关键属性：在缓存命中时具有低CPU开销、低内存开销，能有效扩展到多个CPU，并且易于调整和实现。Clock2Q+已在vSAN和VDFS（VMware by Broadcom的两个旗舰存储产品）中实现。

Conclusion: Clock2Q+是一种新的缓存替换算法，它通过引入相关性窗口来有效处理元数据缓存中固有的相关引用。在元数据跟踪上，Clock2Q+的未命中率比最先进的算法降低了高达28.5%，同时在数据跟踪上表现也优于现有算法。Clock2Q+具有大规模存储系统所需的低开销、高效率和易于实现等关键特性。

Abstract: Cache replacement algorithms are critical building blocks of storage systems. This paper examines the characteristics of metadata caches and argues that they inherently exhibit correlated references, even when the corresponding data accesses do not contain correlated references. The presence of correlated references reduces the effectiveness of cache replacement algorithms because these references are often mistakenly categorized as hot blocks. Clock2Q+ is specifically designed for metadata caches and has been implemented in vSAN and VDFS, two flagship storage products of VMware by Broadcom. Similar to S3-FIFO, Clock2Q+ uses three queues; however, Clock2Q+ introduces a correlation window in the Small FIFO queue, where blocks in this window do not set the reference bit. This simple enhancement allows Clock2Q+ to outperform state-of-the-art replacement algorithms. Compared to S3-FIFO, the second-best performing algorithm, Clock2Q+ achieves up to a 28.5% lower miss ratio on metadata traces. Clock2Q+ possesses the essential properties required for large-scale storage systems: it has low CPU overhead on cache hits, low memory overhead, scales efficiently to multiple CPUs, and is both easy to tune and implement. Additionally, Clock2Q+ outperforms state-of-the-art cache replacement algorithms on data traces as well.

</details>


### [27] [An Empirical Study of Cross-Language Interoperability in Replicated Data Systems](https://arxiv.org/abs/2511.22010)
*Provakar Mondal,Eli Tilevich*

Main category: cs.DC

TL;DR: 该论文与分布式系统、编译器和编程语言相关。
在现代分布式系统中，数据复制库 (RDLs) 的集成在多语言环境中面临挑战，因为它们通常只支持单一语言或特定的绑定。这项工作旨在通过比较外部函数接口 (FFI) 和通用数据格式 (CDF) 这两种集成策略，来理解 RDL 在多语言环境中的软件质量和性能特性。实证研究结果显示，CDF 在软件质量、延迟、内存消耗和吞吐量方面优于 FFI。研究人员进一步通过基于 CDF 的 RDL 验证了其发现，该 RDL 支持混合不同类型的语言，并具有插件可扩展性，从而为设计多语言复制数据系统中的 RDL 提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统在多个执行站点之间复制数据，并且业务需求和资源限制通常需要在副本站点之间混合使用不同的语言。为了促进复制数据的管理，现代软件工程实践集成了提供数据读写访问并确保其同步的专用复制数据库（RDLs）。现有 RDLs 在多语言环境中集成需要专用代码，但其软件质量和性能特性了解甚少。我们的目标是弥合这一知识鸿沟，以了解多语言环境中 RDL 集成的软件质量和性能特性。

Method: 我们对在多语言复制数据系统背景下集成 RDLs 的两种关键策略进行了实证研究：外部函数接口（FFI）和通用数据格式（CDF）；我们测量和比较了它们各自的软件度量和性能，以了解它们在这项任务中的适用性。

Result: 我们的结果表明，采用 CDF 进行跨语言交互在软件质量、延迟、内存消耗和吞吐量方面具有优势。我们通过以下方式进一步验证了我们的发现：(1) 创建了一个基于 CDF 的 RDL，用于混合编译型、解释型和托管型语言；(2) 使用插件可扩展性增强我们的 RDL，该可扩展性支持以单一语言添加功能，同时保持在多语言环境中的集成。

Conclusion: 现代分布式系统正在利用多种语言，我们的研究结果为设计多语言复制数据系统中的 RDLs 提供了新的见解。

Abstract: BACKGROUND: Modern distributed systems replicate data across multiple execution sites. Business requirements and resource constraints often necessitate mixing different languages across replica sites. To facilitate the management of replicated data, modern software engineering practices integrate special-purpose replicated data libraries (RDLs) that provide read-write access to the data and ensure its synchronization. Irrespective of the implementation languages, an RDL typically uses a single language or offers bindings to a designated one. Hence, integrating existing RDLs in multilingual environments requires special-purpose code, whose software quality and performance characteristics are poorly understood.
  AIMS: We aim to bridge this knowledge gap to understand the software quality and performance characteristics of RDL integration in multilingual environments.
  METHOD: We conduct an empirical study of two key strategies for integrating RDLs in the context of multilingual replicated data systems: foreign-function interface (FFI) and a common data format (CDF); we measure and compare their respective software metrics and performance to understand their suitability for the task at hand.
  RESULTS: Our results reveal that adopting CDF for cross-language interaction offers software quality, latency, memory consumption, and throughput advantages. We further validate our findings by (1) creating a CDF-based RDL for mixing compiled, interpreted, and managed languages; and (2) enhancing our RDL with plug-in extensibility that enables adding functionality in a single language while maintaining integration within a multilingual environment.
  CONCLUSIONS: With modern distributed systems utilizing multiple languages, our findings provide novel insights for designing RDLs in multilingual replicated data systems.

</details>


### [28] [PAT: Accelerating LLM Decoding via Prefix-Aware Attention with Resource Efficient Multi-Tile Kernel](https://arxiv.org/abs/2511.22333)
*Jinjun Yi,Zhixin Zhao,Yitao Hu,Ke Yan,Weiwei Sun,Hao Wang,Laiping Zhao,Yuhao Zhang,Wenxin Li,Keqiu Li*

Main category: cs.DC

TL;DR: 与DSL、图处理、MLIR、编译器、HLS相关的部分：编译器（LLM注意力的内核优化属于编译器/系统软件对特定硬件算子的性能优化范畴）。过长摘要，不想阅读：本论文提出了PAT（Prefix-Aware Attention），一个针对LLM解码的、可即插即用的注意力内核优化实现。PAT利用实际工作负载中普遍存在的共享前缀，采用“打包-转发-合并”范式，以减少内存访问和提高计算单元效率。实验证明，PAT显著降低了注意力延迟（平均67.4%）和TPOT（13.6%-83.4%），优于现有最先进的内核。


<details>
  <summary>Details</summary>
Motivation: 现有的注意力实现未能充分利用实际LLM工作负载中存在的、大量的、具有层次结构的共享前缀（例如，系统提示、工具/模板、RAG），导致反复加载共享前缀的KV缓存，从而加剧了内存带宽压力，并使内存受限的解码注意力停滞不前。具体问题包括：“one-query-per-CTA”的执行方式重复加载共享前缀的KV缓存，以及“one-size-fits-all”的分块策略导致片上资源闲置并加剧了KV长度不均匀时的“气泡”问题。作者旨在通过提出PAT来解决这些问题。

Method: 这篇论文介绍了一种名为PAT（Prefix-Aware Attention）的注意力内核实现，用于LLM解码，该方法采用“打包-转发-合并”（pack-forward-merge）的执行范式。具体来说，PAT通过共享前缀对查询进行打包，以减少重复的内存访问；运行定制的多瓦片（multi-tile）内核以提高资源效率，同时应用实用的多流转发和KV分割来减少资源“气泡”（bubbles）；最终的合并步骤则以可忽略的开销执行在线的Softmax计算。PAT作为一个可即插即用的插件在vLLM中实现。

Result: 在真实和合成工作负载上的评估结果表明，在相同的配置下，PAT平均将注意力延迟降低了67.4%，并将TPOT（Time to next token）降低了13.6%到83.4%，性能优于当前最先进的注意力内核。

Conclusion: PAT是一种高效的、可即插即用的LLM解码注意力内核实现，它通过利用实际工作负载中普遍存在的共享前缀来显著减轻服务压力，为LLM服务的性能提升提供了一个有效的解决方案。

Abstract: LLM serving is increasingly dominated by decode attention, which is a memory-bound operation due to massive KV cache loading from global memory. Meanwhile, real-world workloads exhibit substantial, hierarchical shared prefixes across requests (e.g., system prompts, tools/templates, RAG). Existing attention implementations fail to fully exploit prefix sharing: *one-query-per-CTA* execution repeatedly loads shared prefix KV cache, while *one-size-fits-all* tiling leaves on-chip resources idle and exacerbates bubbles for uneven KV lengths. These choices amplify memory bandwidth pressure and stall memory-bound decode attention.
  This paper introduces PAT, a prefix-aware attention kernel implementation for LLM decoding that organizes execution with a pack-forward-merge paradigm. PAT packs queries by shared prefix to reduce repeated memory accesses, runs a customized multi-tile kernel to achieve high resource efficiency. It further applies practical multi-stream forwarding and KV splitting to reduce resource bubbles. The final merge performs online softmax with negligible overhead. We implement PAT as an off-the-shelf plugin for vLLM. Evaluation on both real-world and synthetic workloads shows that PAT reduces attention latency by 67.4% on average and TPOT by 13.6-83.4% under the same configurations against state-of-the-art attention kernels.

</details>


### [29] [OmniInfer: System-Wide Acceleration Techniques for Optimizing LLM Serving Throughput and Latency](https://arxiv.org/abs/2511.22481)
*Jun Wang,Yunxiang Yao,Wenwei Kuang,Runze Mao,Zhenhao Sun,Zhuang Tao,Ziyang Zhang,Dengyu Li,Jiajun Chen,Zhili Wang,Kai Cui,Congzhi Cai,Longwen Lan,Ken Zhang*

Main category: cs.DC

TL;DR: This paper is related to compiler because it is a system-level acceleration framework designed to maximize end-to-end serving efficiency for large language models, involving fine-grained optimization and scheduling which are core concerns of compilers for performance optimization and resource management in complex systems.
OmniInfer是一个统一的LLM服务加速框架，通过集成OmniPlacement（专家调度）、OmniAttn（稀疏注意力加速）和OmniProxy（去聚合请求调度），在vLLM基础上实现自适应资源去聚合和高效稀疏利用，以解决LLM服务中的计算密集、延迟和吞吐量挑战，实验证明其在昇腾 910C集群上能显著提高吞吐量（616 QPM）并大幅减少TPOT和TTFT。



<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在现代AI应用中占据重要地位，但因计算密集、严格的延迟限制和吞吐量瓶颈，对大规模服务系统提出了严峻的挑战。该研究的动机是设计一个统一的系统级加速框架，以最大化端到端的服务效率。

Method: OmniInfer通过其集成的三个核心组件实现系统级加速：1. OmniPlacement：负责负载感知（load-aware）的MoE（Mixture-of-Experts）调度。2. OmniAttn：用于稀疏注意力（sparse attention）的加速。3. OmniProxy：进行去聚合感知（disaggregation-aware）的请求调度。OmniInfer建立在vLLM的基础上，通过自适应资源去聚合、高效稀疏性利用以及跨预填充（prefill）和解码（decode）阶段的全局协调，实现系统范围内的性能提升。

Result: 在由10个昇腾 910C组成的集群、使用DeepSeek-R1模型进行的评估中，OmniInfer实现了616 QPM（Queries Per Minute）的吞吐量。 unified framework（统一框架）将TPOT（Time Per Output Token）降低了36\%。叠加使用OmniProxy后，TTFT（Time To First Token）进一步减少了38\%。

Conclusion: OmniInfer是一个统一的系统级加速框架，它通过细粒度优化专家放置、缓存压缩和调度，显著提升了LLM的服务效率。在10节点昇腾 910C集群上，OmniInfer在DeepSeek-R1模型上的表现验证了其有效性，实现了616 QPM的吞吐量，并大幅降低了TPOT和TTFT。该框架的代码已开源。

Abstract: Large Language Models drive a wide range of modern AI applications but impose substantial challenges on large-scale serving systems due to intensive computation, strict latency constraints, and throughput bottlenecks. We introduce OmniInfer, a unified system-level acceleration framework designed to maximize end-to-end serving efficiency through fine-grained optimization of expert placement, cache compression, and scheduling. OmniInfer integrates three complementary components: OmniPlacement for load-aware Mixture-of-Experts scheduling, OmniAttn for sparse attention acceleration, and OmniProxy for disaggregation-aware request scheduling. Built atop vLLM, OmniInfer delivers system-wide performance gains through adaptive resource disaggregation, efficient sparsity exploitation, and global coordination across prefill and decode phases. Evaluated on DeepSeek-R1 within a 10-node Ascend 910C cluster, OmniInfer achieves 616 QPM, where the unified framework reduces TPOT by 36\%, and the superimposition of OmniProxy further slashes TTFT by 38\%. The project is open-sourced at [this https URL](https://gitee.com/omniai/omniinfer).

</details>


### [30] [Accelerating mesh-based Monte Carlo simulations using contemporary graphics ray-tracing hardware](https://arxiv.org/abs/2511.22779)
*Shijie Yan,Douglas Dwyer,David R. Kaeli,Qianqian Fang*

Main category: cs.DC

TL;DR: 相关：编译器（利用GPU硬件加速的光线追踪核心，涉及编译优化和硬件特性利用）。 总结：蒙特卡洛（MC）方法是光与组织相互作用建模的黄金标准，其中基于网格的MC（MMC）提供了更高的精度。然而，MMC的性能受限于频繁光线-边界相交测试的计算成本。本文提出了RT-MMC算法，利用现代GPU上的光线追踪核心（RT-cores）进行硬件加速光线遍历和相交，解决了这一瓶颈。RT-MMC基于NVIDIA OptiX平台实现，将图形光线追踪扩展到浊媒体中的体素光线追踪，简化了工作流并消除了复杂的网格生成需求。结果显示，RT-MMC与传统软件MMC算法一致，但在不同GPU架构上实现了1.5倍至4.5倍的加速，显著提升了MMC的实用性。这一迁移到硬件光线追踪的方法简化了MMC模拟，并为生物光子学应用带来了显著的速度提升。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛（MC）方法因其准确性而被认为是光与组织相互作用建模的黄金标准。基于网格的MC（MMC）通过使用四面体网格模型为复杂的组织结构提供了更高的精度。尽管在图形处理单元（GPU）上取得了显著的加速，但MMC的性能仍然受到频繁的光线-边界相交测试的计算成本的阻碍。

Method: 提出了一种高度加速的MMC算法，称为RT-MMC，它利用现代GPU上光线追踪核心（RT-cores）提供的硬件加速光线遍历和相交能力。RT-MMC是使用NVIDIA的OptiX平台实现的，它将图形光线追踪管道扩展到浊媒体中的体素光线追踪，消除了具有挑战性的四面体网格生成的需求，同时通过硬件加速实现了显著的速度提升。它还固有地支持宽场光源，无需复杂的网格重构。

Result: RT-MMC算法与传统软件光线追踪MMC算法取得了良好的一致性，同时在不同的GPU架构上实现了1.5倍至4.5倍的加速。这些性能提升显著增强了MMC在常规模拟中的实用性。

Conclusion: 蒙特卡洛（MC）模拟工作流程从软件光线追踪向硬件光线追踪的迁移，不仅极大地简化了MMC的模拟工作流程，而且带来了显著的加速，随着光线追踪硬件的普及，这种加速预计将进一步提升。在定量MMC仿真中采用图形光线追踪管道，能够利用新兴的硬件资源，并有利于广泛的生物光子学应用。

Abstract: Significance: Monte Carlo (MC) methods are the gold-standard for modeling light-tissue interactions due to their accuracy. Mesh-based MC (MMC) offers enhanced precision for complex tissue structures using tetrahedral mesh models. Despite significant speedups achieved on graphics processing units (GPUs), MMC performance remains hindered by the computational cost of frequent ray-boundary intersection tests.
  Aim: We propose a highly accelerated MMC algorithm, RT-MMC, that leverages the hardware-accelerated ray traversal and intersection capabilities of ray-tracing cores (RT-cores) on modern GPUs.
  Approach: Implemented using NVIDIA's OptiX platform, RT-MMC extends graphics ray-tracing pipelines towards volumetric ray-tracing in turbid media, eliminating the need for challenging tetrahedral mesh generation while delivering significant speed improvements through hardware acceleration. It also intrinsically supports wide-field sources without complex mesh retesselation.
  Results: RT-MMC demonstrates excellent agreement with traditional software-ray-tracing MMC algorithms while achieving 1.5x to 4.5x speedups across multiple GPU architectures. These performance gains significantly enhance the practicality of MMC for routine simulations.
  Conclusion: Migration from software- to hardware-based ray-tracing not only greatly simplifies MMC simulation workflows, but also results in significant speedups that are expected to increase further as ray-tracing hardware rapidly gains adoption. Adoption of graphics ray-tracing pipelines in quantitative MMC simulations enables leveraging of emerging hardware resources and benefits a wide range of biophotonics applications.

</details>


### [31] [Serving Heterogeneous LoRA Adapters in Distributed LLM Inference Systems](https://arxiv.org/abs/2511.22880)
*Shashwat Jaiswal,Shrikara Arun,Anjaly Parayil,Ankur Mallick,Spyros Mastorakis,Alind Khare,Chloi Alverti,Renee St Amant,Chetan Bansal,Victor Rühle,Josep Torrellas*

Main category: cs.DC

TL;DR: 涉及到的领域是编译器、图处理、MLIR、编译器或HLS中的编译器部分，因为LoRA Serve的核心是关于高效地服务（部署）模型，这属于深度学习系统的部署优化，它可能会在运行时进行指令优化，但最直接涉及的是深度学习系统架构和优化。鉴于其优化目标和技术（服务系统、调度、加速），它更倾向于高性能计算/系统优化，与编译器技术有交叉但不是核心。TLDR: LoRA已成为大语言模型参数高效微调的事实标准。然而，在大规模生产环境中，现有服务系统没有考虑LoRA适配器秩的异构性，导致性能严重倾斜和GPU资源浪费。本文提出了LoRAServe，一个工作负载感知的动态适配器放置和路由框架，通过动态重新平衡适配器和利用GPU Direct RDMA，显著提高了吞吐量，降低了延迟，并在保持服务水平目标的同时，将所需GPU数量减少了高达50%。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA服务系统在共同批量处理异构适配器时，没有考虑到适配器秩（大小）的可变性，导致严重的性能倾斜，最终需要增加GPU数量以满足服务水平目标（SLOs）。现有的优化忽略了这种异构性，使得GPU资源未得到充分利用。

Method: LoRAServe是一个工作负载感知的动态适配器放置和路由框架，旨在管理LoRA服务中的秩（大小）多样性。它通过动态地重新平衡GPU上的适配器和利用GPU Direct RDMA进行远程访问，以最大化吞吐量并最小化尾部延迟。

Result: 与现有最先进的系统相比，LoRAServe在保持SLO约束下，吞吐量提高了2倍，TTFT（Time to First Token）降低了9倍，同时使用的GPU数量最多减少了50%。

Conclusion: LoRAServe通过工作负载感知的动态适配器放置和路由，有效地解决了LoRA服务中适配器秩（大小）异构性带来的性能挑战。实验结果表明，LoRAServe在提高吞吐量、减少延迟和节省硬件资源方面，显著优于现有最先进的系统。

Abstract: Low-Rank Adaptation (LoRA) has become the de facto method for parameter-efficient fine-tuning of large language models (LLMs), enabling rapid adaptation to diverse domains. In production, LoRA-based models are served at scale, creating multi-tenant environments with hundreds of adapters sharing a base model. However, state-of-the-art serving systems co-batch heterogeneous adapters without accounting for rank (size) variability, leading to severe performance skew, which ultimately requires adding more GPUs to satisfy service-level objectives (SLOs). Existing optimizations, focused on loading, caching, and kernel execution, ignore this heterogeneity, leaving GPU resources underutilized. We present LoRAServe, a workload-aware dynamic adapter placement and routing framework designed to tame rank diversity in LoRA serving. By dynamically rebalancing adapters across GPUs and leveraging GPU Direct RDMA for remote access, LoRAServe maximizes throughput and minimizes tail latency under real-world workload drift. Evaluations on production traces from Company X show that LoRAServe elicits up to 2$\times$ higher throughput, up to 9$\times$ lower TTFT, while using up to 50% fewer GPUs under SLO constraints compared to state-of-the-art systems.

</details>
