{"id": "2512.22435", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22435", "abs": "https://arxiv.org/abs/2512.22435", "authors": ["Zining Wang", "Jian Gao", "Weimin Fu", "Xiaolong Guo", "Xuan Zhang"], "title": "AnalogSAGE: Self-evolving Analog Design Multi-Agents with Stratified Memory and Grounded Experience", "comment": null, "summary": "Analog circuit design remains a knowledge- and experience-intensive process that relies heavily on human intuition for topology generation and device parameter tuning. Existing LLM-based approaches typically depend on prompt-driven netlist generation or predefined topology templates, limiting their ability to satisfy complex specification requirements. We propose AnalogSAGE, an open-source self-evolving multi-agent framework that coordinates three-stage agent explorations through four stratified memory layers, enabling iterative refinement with simulation-grounded feedback. To support reproducibility and generality, we release the source code. Our benchmark spans ten specification-driven operational amplifier design problems of varying difficulty, enabling quantitative and cross-task comparison under identical conditions. Evaluated under the open-source SKY130 PDK with ngspice, AnalogSAGE achieves a 10$\\times$ overall pass rate, a 48$\\times$ Pass@1, and a 4$\\times$ reduction in parameter search space compared with existing frameworks, demonstrating that stratified memory and grounded reasoning substantially enhance the reliability and autonomy of analog design automation in practice.", "AI": {"tldr": "\u5426\uff0c\u672c\u8bba\u6587\u5185\u5bb9\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u4e0d\u76f4\u63a5\u76f8\u5173\u3002\u672c\u6587\u5173\u6ce8\u4e8e\u4f7f\u7528\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548cLLM\u6280\u672f\u8fdb\u884c**\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u81ea\u52a8\u5316**\u3002\n\u592a\u957f\u4e0d\u770b\uff1a\u672c\u6587\u63d0\u51fa\u4e86AnalogSAGE\uff0c\u4e00\u4e2a\u5f00\u6e90\u7684\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u81ea\u52a8\u5316\u3002\u5b83\u901a\u8fc7\u4e09\u9636\u6bb5\u667a\u80fd\u4f53\u63a2\u7d22\u548c\u56db\u5c42\u5206\u5c42\u5185\u5b58\uff0c\u5e76\u7ed3\u5408\u4eff\u771f\u53cd\u9988\uff0c\u5b9e\u73b0\u4e86\u8fed\u4ee3\u4f18\u5316\u3002\u5728\u8fd0\u7b97\u653e\u5927\u5668\u8bbe\u8ba1\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAnalogSAGE\u76f8\u8f83\u4e8e\u73b0\u6709\u6846\u67b6\u5c06\u6574\u4f53\u901a\u8fc7\u7387\u63d0\u9ad8\u4e8610\u500d\uff0cPass@1\u63d0\u9ad8\u4e8648\u500d\uff0c\u5e76\u5c06\u53c2\u6570\u641c\u7d22\u7a7a\u95f4\u51cf\u5c11\u4e864\u500d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bbe\u8ba1\u7684\u53ef\u9760\u6027\u548c\u81ea\u4e3b\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u4e25\u91cd\u4f9d\u8d56\u4eba\u5de5\u7ecf\u9a8c\u548c\u76f4\u89c9\uff0c\u662f\u4e00\u4e2a\u77e5\u8bc6\u5bc6\u96c6\u578b\u7684\u8fc7\u7a0b\u3002\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u53d7\u9650\u4e8e\u63d0\u793a\u9a71\u52a8\u7684\u7f51\u8868\u751f\u6210\u6216\u9884\u5b9a\u4e49\u7684\u62d3\u6251\u6a21\u677f\uff0c\u96be\u4ee5\u6ee1\u8db3\u590d\u6742\u7684\u89c4\u683c\u8981\u6c42\u3002AnalogSAGE\u7684\u52a8\u673a\u5728\u4e8e\uff0c\u901a\u8fc7\u63d0\u51fa\u4e00\u4e2a\u81ea\u8fdb\u5316\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u548c\u5206\u5c42\u5185\u5b58\u7ec4\u7ec7\uff0c\u663e\u8457\u63d0\u9ad8\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u53ef\u9760\u6027\u3001\u901a\u7528\u6027\u548c\u81ea\u4e3b\u6027\uff0c\u5e76\u51cf\u5c11\u53c2\u6570\u641c\u7d22\u7a7a\u95f4\u3002", "method": "AnalogSAGE\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u534f\u8c03\u4e09\u9636\u6bb5\u7684\u667a\u80fd\u4f53\u63a2\u7d22\u8fc7\u7a0b\u548c\u5229\u7528\u56db\u4e2a\u5206\u5c42\u7684\u5185\u5b58\u5c42\u6765\u8fdb\u884c\u8fed\u4ee3\u4f18\u5316\u3002\u8be5\u6846\u67b6\u4f7f\u7528\u57fa\u4e8e\u4eff\u771f\u7684\u53cd\u9988\uff08\u5982\u901a\u8fc7ngspice\u5bf9SKY130 PDK\uff09\u6765\u6301\u7eed\u6539\u8fdb\u8bbe\u8ba1\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. **\u4e09\u9636\u6bb5\u667a\u80fd\u4f53\u63a2\u7d22**\uff1a\u63a8\u52a8\u8bbe\u8ba1\u8fc7\u7a0b\u7684\u8fed\u4ee3 refinement\u30022. **\u56db\u5c42\u5206\u5c42\u5185\u5b58**\uff1a\u7528\u4e8e\u7ec4\u7ec7\u548c\u7ba1\u7406\u8bbe\u8ba1\u8fc7\u7a0b\u4e2d\u79ef\u7d2f\u7684\u77e5\u8bc6\u548c\u53cd\u9988\u30023. **\u57fa\u4e8e\u4eff\u771f\u7684\u53cd\u9988\u56de\u8def**\uff1a\u786e\u4fdd\u8bbe\u8ba1\u662f\u57fa\u4e8e\u5b9e\u9645\u7269\u7406\u6027\u80fd\u8fdb\u884c\u9a8c\u8bc1\u548c\u8c03\u6574\u7684\u3002", "result": "AnalogSAGE\u5728\u5305\u542b\u5341\u4e2a\u4e0d\u540c\u96be\u5ea6\u7684\u8fd0\u7b97\u653e\u5927\u5668\u8bbe\u8ba1\u95ee\u9898\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u6846\u67b6\uff0c\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1a1. **\u6574\u4f53\u901a\u8fc7\u7387**\uff1a\u63d0\u9ad8\u4e8610\u500d\u30022. **Pass@1**\uff08\u9996\u6b21\u5c1d\u8bd5\u7684\u901a\u8fc7\u7387\uff09\uff1a\u63d0\u9ad8\u4e8648\u500d\u30023. **\u53c2\u6570\u641c\u7d22\u7a7a\u95f4**\uff1a\u51cf\u5c11\u4e864\u500d\u3002\u8fd9\u4e9b\u7ed3\u679c\u57fa\u4e8e\u5f00\u6e90\u7684SKY130 PDK\u548cngspice\u4eff\u771f\u5668\u83b7\u5f97\uff0c\u8bc1\u660e\u4e86\u5206\u5c42\u5185\u5b58\u548c\u57fa\u4e8e\u53cd\u9988\u7684\u63a8\u7406\u5728\u5b9e\u8df5\u4e2d\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u62df\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u53ef\u9760\u6027\u548c\u81ea\u4e3b\u6027\u3002", "conclusion": "AnalogSAGE\u6846\u67b6\u901a\u8fc7\u5176\u81ea\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u63a2\u7d22\u548c\u5206\u5c42\u5185\u5b58\u7ec4\u7ec7\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3001\u53ef\u9760\u6027\u548c\u81ea\u4e3b\u6027\u3002\u5b83\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u590d\u6742\u7684\u7535\u8def\u8bbe\u8ba1\u6311\u6218\u3002"}}
{"id": "2512.23062", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.23062", "abs": "https://arxiv.org/abs/2512.23062", "authors": ["Soham Pramanik", "Vimal William", "Arnab Raha", "Debayan Das", "Amitava Mukherjee", "Janet L. Paluh"], "title": "TYTAN: Taylor-series based Non-Linear Activation Engine for Deep Learning Accelerators", "comment": null, "summary": "The rapid advancement in AI architectures and the proliferation of AI-enabled systems have intensified the need for domain-specific architectures that enhance both the acceleration and energy efficiency of AI inference, particularly at the edge. This need arises from the significant resource constraints-such as computational cost and energy consumption-associated with deploying AI algorithms, which involve intensive mathematical operations across multiple layers. High-power-consuming operations, including General Matrix Multiplications (GEMMs) and activation functions, can be optimized to address these challenges. Optimization strategies for AI at the edge include algorithmic approaches like quantization and pruning, as well as hardware methodologies such as domain-specific accelerators. This paper proposes TYTAN: TaYlor-series based non-linear acTivAtion eNgine, which explores the development of a Generalized Non-linear Approximation Engine (G-NAE). TYTAN targets the acceleration of non-linear activation functions while minimizing power consumption. The TYTAN integrates a re-configurable hardware design with a specialized algorithm that dynamically estimates the necessary approximation for each activation function, aimed at achieving minimal deviation from baseline accuracy. The proposed system is validated through performance evaluations with state-of-the-art AI architectures, including Convolutional Neural Networks (CNNs) and Transformers. Results from system-level simulations using Silvaco's FreePDK45 process node demonstrate TYTAN's capability to operate at a clock frequency >950 MHz, showcasing its effectiveness in supporting accelerated, energy-efficient AI inference at the edge, which is ~2 times performance improvement, with ~56% power reduction and ~35 times lower area compared to the baseline open-source NVIDIA Deep Learning Accelerator (NVDLA) implementation.", "AI": {"tldr": "\u672c\u6587\u4e0e DSL \u65e0\u5173\uff0c\u4e0e\u56fe\u5904\u7406\u65e0\u5173\uff0c\u4e0e MLIR \u65e0\u5173\u3002\u5b83\u4e0e\u7f16\u8bd1\u5668\u548c HLS \u6709\u95f4\u63a5\u5173\u8054\uff0c\u56e0\u4e3a\u5b83\u6d89\u53ca\u7279\u5b9a\u786c\u4ef6\u52a0\u901f\u5668\u7684\u8bbe\u8ba1\u548c\u4f18\u5316\uff0c\u8fd9\u901a\u5e38\u9700\u8981\u4f7f\u7528\u7f16\u8bd1\u5668\u540e\u7aef\u6216 HLS \u5de5\u5177\u94fe\u8fdb\u884c\u5b9e\u73b0\u3002\n\u672c\u6587\u63d0\u51fa\u4e86 TYTAN\uff0c\u4e00\u4e2a\u57fa\u4e8e\u6cf0\u52d2\u7ea7\u6570\u548c\u901a\u7528\u975e\u7ebf\u6027\u8fd1\u4f3c\u5f15\u64ce\uff08G-NAE\uff09\u7684\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u4e13\u4e3a\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684 AI \u63a8\u7406\u52a0\u901f\u975e\u7ebf\u6027\u6fc0\u6d3b\u51fd\u6570\u5e76\u6700\u5c0f\u5316\u529f\u8017\u3002TYTAN \u96c6\u6210\u4e86\u53ef\u91cd\u6784\u786c\u4ef6\u548c\u52a8\u6001\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u65e8\u5728\u5b9e\u73b0\u6700\u5c0f\u7cbe\u5ea6\u504f\u5dee\u3002\u7cfb\u7edf\u7ea7\u4eff\u771f\u8868\u660e\uff0c\u4e0e\u57fa\u7ebf NVDLA \u76f8\u6bd4\uff0cTYTAN \u5728 45nm \u5de5\u827a\u8282\u70b9\u4e0a\u5b9e\u73b0\u4e86\u7ea6 2 \u500d\u7684\u6027\u80fd\u63d0\u5347\u3001\u7ea6 56% \u7684\u529f\u8017\u964d\u4f4e\u548c\u7ea6 35 \u500d\u7684\u9762\u79ef\u51cf\u5c0f\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u52a0\u901f\u548c\u8282\u80fd\u8fb9\u7f18 AI \u63a8\u7406\u4e2d\u7684\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u968f\u7740 AI \u67b6\u6784\u7684\u5feb\u901f\u53d1\u5c55\u548c AI \u7cfb\u7edf\u7684\u666e\u53ca\uff0c\u7279\u522b\u662f\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\uff0c\u5bf9\u65e2\u80fd\u63d0\u9ad8 AI \u63a8\u7406\u52a0\u901f\u53c8\u8282\u80fd\u7684\u9886\u57df\u7279\u5b9a\u67b6\u6784\u7684\u9700\u6c42\u65e5\u76ca\u589e\u52a0\u3002\u90e8\u7f72 AI \u7b97\u6cd5\u9762\u4e34\u663e\u8457\u7684\u8d44\u6e90\u9650\u5236\uff0c\u5982\u8ba1\u7b97\u6210\u672c\u548c\u80fd\u8017\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u5927\u91cf\u6570\u5b66\u8fd0\u7b97\uff08\u5982\u901a\u7528\u77e9\u9635\u4e58\u6cd5 GEMM \u548c\u6fc0\u6d3b\u51fd\u6570\uff09\u7684\u573a\u666f\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4f18\u5316\u8fd9\u4e9b\u9ad8\u529f\u8017\u7684\u64cd\u4f5c\uff0c\u4ee5\u5e94\u5bf9\u8fb9\u7f18\u90e8\u7f72 AI \u7684\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a TYTAN\uff08\u57fa\u4e8e\u6cf0\u52d2\u7ea7\u6570\u7684\u975e\u7ebf\u6027\u6fc0\u6d3b\u5f15\u64ce\uff09\u7684\u901a\u7528\u975e\u7ebf\u6027\u8fd1\u4f3c\u5f15\u64ce\uff08G-NAE\uff09\u3002TYTAN \u7ed3\u5408\u4e86\u53ef\u91cd\u6784\u786c\u4ef6\u8bbe\u8ba1\u548c\u4e13\u7528\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u80fd\u591f\u52a8\u6001\u4f30\u8ba1\u6bcf\u4e2a\u6fc0\u6d3b\u51fd\u6570\u6240\u9700\u7684\u8fd1\u4f3c\u503c\uff0c\u4ee5\u6700\u5c0f\u5316\u4e0e\u57fa\u7ebf\u7cbe\u5ea6\u7684\u504f\u5dee\u3002\u8be5\u7cfb\u7edf\u901a\u8fc7\u4f7f\u7528\u6700\u5148\u8fdb\u7684 AI \u67b6\u6784\uff08\u5305\u62ec CNN \u548c Transformer\uff09\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u548c\u7cfb\u7edf\u7ea7\u4eff\u771f\u6765\u9a8c\u8bc1\uff0c\u4eff\u771f\u57fa\u4e8e Silvaco \u7684 FreePDK45 \u5de5\u827a\u8282\u70b9\u3002", "result": "\u7cfb\u7edf\u7ea7\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8e Silvaco \u7684 FreePDK45 \u5de5\u827a\u8282\u70b9\uff0cTYTAN \u80fd\u591f\u4ee5\u5927\u4e8e 950 MHz \u7684\u65f6\u949f\u9891\u7387\u8fd0\u884c\u3002\u4e0e\u57fa\u7ebf\u5f00\u6e90 NVIDIA \u6df1\u5ea6\u5b66\u4e60\u52a0\u901f\u5668\uff08NVDLA\uff09\u5b9e\u65bd\u76f8\u6bd4\uff0cTYTAN \u5728\u8fb9\u7f18 AI \u63a8\u7406\u65b9\u9762\u5b9e\u73b0\u4e86\u7ea6 2 \u500d\u7684\u6027\u80fd\u63d0\u5347\u3001\u7ea6 56% \u7684\u529f\u8017\u964d\u4f4e\u548c\u7ea6 35 \u500d\u7684\u9762\u79ef\u51cf\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6700\u5c0f\u7684\u7cbe\u5ea6\u504f\u5dee\u3002\u8fd9\u4e9b\u7ed3\u679c\u8bc1\u660e\u4e86\u5176\u5728\u52a0\u901f\u3001\u8282\u80fd\u7684\u8fb9\u7f18 AI \u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "TYTAN \u901a\u8fc7\u5c06\u53ef\u91cd\u6784\u786c\u4ef6\u8bbe\u8ba1\u4e0e\u52a8\u6001\u4f30\u8ba1\u6240\u9700\u8fd1\u4f3c\u503c\u7684\u4e13\u7528\u7b97\u6cd5\u76f8\u7ed3\u5408\uff0c\u6210\u529f\u5728\u8fb9\u7f18 AI \u63a8\u7406\u4e2d\u5b9e\u73b0\u4e86\u6fc0\u6d3b\u51fd\u6570\u7684\u52a0\u901f\u548c\u529f\u8017\u6700\u5c0f\u5316\u3002\u4e0e\u57fa\u7ebf NVDLA \u5b9e\u65bd\u76f8\u6bd4\uff0cTYTAN \u5b9e\u73b0\u4e86\u7ea6 2 \u500d\u7684\u6027\u80fd\u63d0\u5347\u3001\u7ea6 56% \u7684\u529f\u8017\u964d\u4f4e\u548c\u7ea6 35 \u500d\u7684\u9762\u79ef\u51cf\u5c0f\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u52a0\u901f\u3001\u8282\u80fd\u7684\u8fb9\u7f18 AI \u63a8\u7406\u65b9\u9762\u7684\u6709\u6548\u6027\u548c\u524d\u666f\u3002"}}
{"id": "2512.22125", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22125", "abs": "https://arxiv.org/abs/2512.22125", "authors": ["Jithin VG", "Ditto PS"], "title": "GPU-Virt-Bench: A Comprehensive Benchmarking Framework for Software-Based GPU Virtualization Systems", "comment": null, "summary": "The proliferation of GPU-accelerated workloads, particularly in artificial intelligence and large language model (LLM) inference, has created unprecedented demand for efficient GPU resource sharing in cloud and container environments. While NVIDIA's Multi-Instance GPU (MIG) technology provides hardware-level isolation, its availability is limited to high-end datacenter GPUs. Software-based virtualization solutions such as HAMi-core and BUD-FCSP offer alternatives for broader GPU families but lack standardized evaluation methodologies. We present GPU-Virt-Bench, a comprehensive benchmarking framework that evaluates GPU virtualization systems across 56 performance metrics organized into 10 categories. Our framework measures overhead, isolation quality, LLM-specific performance, memory bandwidth, cache behavior, PCIe throughput, multi-GPU communication, scheduling efficiency, memory fragmentation, and error recovery. GPU-Virt-Bench enables systematic comparison between software virtualization approaches and ideal MIG behavior, providing actionable insights for practitioners deploying GPU resources in multi-tenant environments. We demonstrate the framework's utility through evaluation of HAMi-core, BUD-FCSP, and simulated MIG baselines, revealing performance characteristics critical for production deployment decisions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL\u3001\u56fe\u5904\u7406\u3001MLIR \u6216 HLS **\u4e0d\u76f8\u5173**\u3002\n**\u592a\u957f\u4e0d\u770b (TLDR) \u6458\u8981:** \u968f\u7740 AI/LLM \u5de5\u4f5c\u8d1f\u8f7d\u7684\u9700\u6c42\u589e\u957f\uff0c\u9ad8\u6548\u7684 GPU \u8d44\u6e90\u5171\u4eab\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8f6f\u4ef6 GPU \u865a\u62df\u5316\u65b9\u6848\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u3002\u672c\u6587\u63d0\u51fa\u4e86 GPU-Virt-Bench\uff0c\u4e00\u4e2a\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7 10 \u4e2a\u7c7b\u522b 56 \u4e2a\u6307\u6807\uff08\u5305\u62ec LLM \u6027\u80fd\u3001\u9694\u79bb\u3001\u8c03\u5ea6\u7b49\uff09\u7cfb\u7edf\u6027\u8bc4\u4f30 GPU \u865a\u62df\u5316\u7cfb\u7edf\uff08\u5982 HAMi-core \u548c BUD-FCSP\uff09\uff0c\u5e76\u4e0e MIG \u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e3a\u591a\u79df\u6237\u73af\u5883\u4e0b\u7684\u90e8\u7f72\u63d0\u4f9b\u5173\u952e\u7684\u6027\u80fd\u6d1e\u5bdf\u548c\u51b3\u7b56\u4f9d\u636e\u3002", "motivation": "\u968f\u7740 GPU \u52a0\u901f\u7684\u5de5\u4f5c\u8d1f\u8f7d\uff08\u5c24\u5176\u662f AI \u548c LLM \u63a8\u7406\uff09\u7684\u666e\u53ca\uff0c\u5bf9\u4e91\u548c\u5bb9\u5668\u73af\u5883\u4e2d\u9ad8\u6548 GPU \u8d44\u6e90\u5171\u4eab\u7684\u9700\u6c42\u7a7a\u524d\u9ad8\u6da8\u3002\u867d\u7136 NVIDIA \u7684 MIG \u6280\u672f\u63d0\u4f9b\u4e86\u786c\u4ef6\u9694\u79bb\uff0c\u4f46\u4ec5\u9650\u4e8e\u9ad8\u7aef\u6570\u636e\u4e2d\u5fc3 GPU\u3002\u73b0\u6709\u7684\u8f6f\u4ef6\u865a\u62df\u5316\u89e3\u51b3\u65b9\u6848\uff08\u5982 HAMi-core \u548c BUD-FCSP\uff09\u7f3a\u4e4f\u6807\u51c6\u5316\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4f7f\u5f97\u65e0\u6cd5\u7cfb\u7edf\u5730\u6bd4\u8f83\u548c\u8bc4\u4f30\u8fd9\u4e9b\u89e3\u51b3\u65b9\u6848\u7684\u6027\u80fd\u548c\u9002\u7528\u6027\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a GPU-Virt-Bench \u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u8de8\u8d8a 10 \u4e2a\u7c7b\u522b\u3001\u5171\u8ba1 56 \u4e2a\u6027\u80fd\u6307\u6807\u6765\u8bc4\u4f30 GPU \u865a\u62df\u5316\u7cfb\u7edf\uff0c\u8fd9\u4e9b\u6307\u6807\u5305\u62ec\u5f00\u9500\u3001\u9694\u79bb\u8d28\u91cf\u3001LLM \u7279\u5b9a\u6027\u80fd\u3001\u5185\u5b58\u5e26\u5bbd\u3001\u7f13\u5b58\u884c\u4e3a\u3001PCIe \u541e\u5410\u91cf\u3001\u591a GPU \u901a\u4fe1\u3001\u8c03\u5ea6\u6548\u7387\u3001\u5185\u5b58\u788e\u7247\u548c\u9519\u8bef\u6062\u590d\u3002\u4f5c\u8005\u4f7f\u7528\u8be5\u6846\u67b6\u6765\u8bc4\u4f30 HAMi-core\u3001BUD-FCSP \u4ee5\u53ca\u6a21\u62df\u7684 MIG \u57fa\u7ebf\u3002", "result": "\u4f5c\u8005\u63d0\u51fa\u4e86 GPU-Virt-Bench \u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b83\u5bf9 HAMi-core\u3001BUD-FCSP \u548c\u6a21\u62df\u7684 MIG \u57fa\u7ebf\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u8bc4\u4f30\u7ed3\u679c\u63ed\u793a\u4e86\u8fd9\u4e9b\u865a\u62df\u5316\u89e3\u51b3\u65b9\u6848\u5728\u751f\u4ea7\u90e8\u7f72\u51b3\u7b56\u4e2d\u81f3\u5173\u91cd\u8981\u7684\u6027\u80fd\u7279\u5f81\uff0c\u8bc1\u5b9e\u4e86\u8be5\u6846\u67b6\u5bf9\u4e8e\u5728\u591a\u79df\u6237\u73af\u5883\u4e2d\u90e8\u7f72 GPU \u8d44\u6e90\u7684\u4ece\u4e1a\u8005\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "GPU-Virt-Bench\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7cfb\u7edf\u3001\u5168\u9762\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30 GPU \u865a\u62df\u5316\u89e3\u51b3\u65b9\u6848\uff08\u5982 HAMi-core \u548c BUD-FCSP\uff09\uff0c\u5e76\u901a\u8fc7\u5c06\u5176\u7ed3\u679c\u4e0e\u7406\u60f3\u7684 MIG \u57fa\u7ebf\u8fdb\u884c\u6bd4\u8f83\uff0c\u4e3a\u5728\u591a\u79df\u6237\u73af\u5883\u4e2d\u90e8\u7f72 GPU \u8d44\u6e90\u7684\u5b9e\u9645\u51b3\u7b56\u63d0\u4f9b\u4e86\u5173\u952e\u7684\u6027\u80fd\u6d1e\u5bdf\u3002\u8fd9\u9879\u5de5\u4f5c\u5f25\u8865\u4e86 GPU \u865a\u62df\u5316\u7cfb\u7edf\u7f3a\u4e4f\u6807\u51c6\u5316\u8bc4\u4f30\u65b9\u6cd5\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.22383", "categories": ["cs.PL", "cs.LO", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.22383", "abs": "https://arxiv.org/abs/2512.22383", "authors": ["Mingsheng Ying"], "title": "Symbolic Specification and Reasoning for Quantum Data and Operations", "comment": null, "summary": "In quantum information and computation research, symbolic methods have been widely used for human specification and reasoning about quantum states and operations. At the same time, they are essential for ensuring the scalability and efficiency of automated reasoning and verification tools for quantum algorithms and programs. However, a formal theory for symbolic specification and reasoning about quantum data and operations is still lacking, which significantly limits the practical applicability of automated verification techniques in quantum computing.\n  In this paper, we present a general logical framework, called Symbolic Operator Logic $\\mathbf{SOL}$, which enables symbolic specification and reasoning about quantum data and operations. Within this framework, a classical first-order logical language is embedded into a language of formal operators used to specify quantum data and operations, including their recursive definitions. This embedding allows reasoning about their properties modulo a chosen theory of the underlying classical data (e.g., Boolean algebra or group theory), thereby leveraging existing automated verification tools developed for classical computing. It should be emphasised that this embedding of classical first-order logic into $\\mathbf{SOL}$ is precisely what makes the symbolic method possible.\n  We envision that this framework can provide a conceptual foundation for the formal verification and automated theorem proving of quantum computation and information in proof assistants such as Lean, Coq, and related systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\u90e8\u5206\uff1a\u7406\u8bba\u57fa\u7840\u3001\u903b\u8f91\u6846\u67b6\u3001\u5f62\u5f0f\u5316\u9a8c\u8bc1\u3002\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7b26\u53f7\u7b97\u5b50\u903b\u8f91$\\mathbf{SOL}$\u7684\u901a\u7528\u903b\u8f91\u6846\u67b6\uff0c\u7528\u4e8e\u91cf\u5b50\u6570\u636e\u548c\u64cd\u4f5c\u7684\u7b26\u53f7\u5316\u89c4\u8303\u548c\u63a8\u7406\u3002$\\mathbf{SOL}$\u5c06\u7ecf\u5178\u4e00\u9636\u903b\u8f91\u5d4c\u5165\u5230\u5f62\u5f0f\u7b97\u5b50\u8bed\u8a00\u4e2d\uff0c\u5141\u8bb8\u5728\u7ecf\u5178\u6570\u636e\uff08\u5982\u5e03\u5c14\u4ee3\u6570\uff09\u7684\u7406\u8bba\u4e0b\u8fdb\u884c\u63a8\u7406\uff0c\u4ece\u800c\u80fd\u5229\u7528\u73b0\u6709\u7684\u7ecf\u5178\u8ba1\u7b97\u81ea\u52a8\u5316\u9a8c\u8bc1\u5de5\u5177\u3002\u8be5\u6846\u67b6\u65e8\u5728\u4e3a\u91cf\u5b50\u8ba1\u7b97\u548c\u4fe1\u606f\u7684\u6b63\u5f0f\u9a8c\u8bc1\u548c\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\u3002", "motivation": "\u5728\u91cf\u5b50\u4fe1\u606f\u548c\u8ba1\u7b97\u7814\u7a76\u4e2d\uff0c\u7b26\u53f7\u65b9\u6cd5\u5728\u4eba\u5de5\u89c4\u8303\u548c\u63a8\u7406\u91cf\u5b50\u6001\u548c\u64cd\u4f5c\u65b9\u9762\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5bf9\u4e8e\u91cf\u5b50\u7b97\u6cd5\u548c\u7a0b\u5e8f\u7684\u81ea\u52a8\u5316\u63a8\u7406\u548c\u9a8c\u8bc1\u5de5\u5177\u7684\u89c4\u6a21\u5316\u548c\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u5173\u4e8e\u91cf\u5b50\u6570\u636e\u548c\u64cd\u4f5c\u7684\u7b26\u53f7\u5316\u89c4\u8303\u548c\u63a8\u7406\u7684\u6b63\u5f0f\u7406\u8bba\uff0c\u8fd9\u6781\u5927\u5730\u9650\u5236\u4e86\u81ea\u52a8\u5316\u9a8c\u8bc1\u6280\u672f\u5728\u91cf\u5b50\u8ba1\u7b97\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u903b\u8f91\u6846\u67b6\u2014\u2014\u7b26\u53f7\u7b97\u5b50\u903b\u8f91$\\mathbf{SOL}$\uff0c\u4ee5\u5b9e\u73b0\u5bf9\u91cf\u5b50\u6570\u636e\u548c\u64cd\u4f5c\u7684\u7b26\u53f7\u5316\u89c4\u8303\u548c\u63a8\u7406\u3002\u8be5\u6846\u67b6\u7684\u5173\u952e\u5728\u4e8e\u5c06\u7ecf\u5178\u4e00\u9636\u903b\u8f91\u8bed\u8a00\u5d4c\u5165\u5230\u7528\u4e8e\u89c4\u8303\u91cf\u5b50\u6570\u636e\u548c\u64cd\u4f5c\u7684\u5f62\u5f0f\u7b97\u5b50\u8bed\u8a00\u4e2d\uff0c\u5305\u62ec\u5b83\u4eec\u7684\u9012\u5f52\u5b9a\u4e49\u3002\u8fd9\u79cd\u5d4c\u5165\u5141\u8bb8\u5728\u57fa\u7840\u7ecf\u5178\u6570\u636e\uff08\u5982\u5e03\u5c14\u4ee3\u6570\u6216\u7fa4\u8bba\uff09\u7684\u9009\u5b9a\u7406\u8bba\u4e0b\u8fdb\u884c\u5c5e\u6027\u63a8\u7406\uff0c\u4ece\u800c\u53ef\u4ee5\u5229\u7528\u73b0\u6709\u4e3a\u7ecf\u5178\u8ba1\u7b97\u5f00\u53d1\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u5de5\u5177\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86$\\mathbf{SOL}$\u7b26\u53f7\u7b97\u5b50\u903b\u8f91\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u5c06\u7ecf\u5178\u4e00\u9636\u903b\u8f91\u5d4c\u5165\u5230\u5f62\u5f0f\u7b97\u5b50\u8bed\u8a00\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5bf9\u91cf\u5b50\u6570\u636e\u548c\u64cd\u4f5c\u7684\u7b26\u53f7\u5316\u89c4\u8303\u548c\u63a8\u7406\uff0c\u5305\u62ec\u5b83\u4eec\u7684\u9012\u5f52\u5b9a\u4e49\u3002\u8fd9\u79cd\u5d4c\u5165\u4f7f\u5f97\u53ef\u4ee5\u5bf9\u91cf\u5b50\u6570\u636e\u7684\u5c5e\u6027\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u4e14\u80fd\u591f\u5229\u7528\u73b0\u6709\u9488\u5bf9\u7ecf\u5178\u8ba1\u7b97\u5f00\u53d1\u7684\u81ea\u52a8\u5316\u9a8c\u8bc1\u5de5\u5177\uff0c\u4ece\u800c\u4f7f\u5f97\u7b26\u53f7\u65b9\u6cd5\u6210\u4e3a\u53ef\u80fd\u3002\u8be5\u6846\u67b6\u4e3a\u8bc1\u660e\u52a9\u624b\u4e2d\u7684\u91cf\u5b50\u8ba1\u7b97\u548c\u4fe1\u606f\u7684\u6b63\u5f0f\u9a8c\u8bc1\u548c\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u4e86\u6982\u5ff5\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a$\\mathbf{SOL}$\u7684\u7b26\u53f7\u7b97\u5b50\u903b\u8f91\u5f62\u5f0f\u5316\u6846\u67b6\uff0c\u65e8\u5728\u4e3a\u91cf\u5b50\u8ba1\u7b97\u548c\u4fe1\u606f\u7684\u7406\u8bba\u9a8c\u8bc1\u548c\u81ea\u52a8\u5316\u5b9a\u7406\u8bc1\u660e\u63d0\u4f9b\u6982\u5ff5\u57fa\u7840\u3002\u901a\u8fc7\u5c06\u7ecf\u5178\u4e00\u9636\u903b\u8f91\u5d4c\u5165\u5230\u5f62\u5f0f\u7b97\u5b50\u8bed\u8a00\u4e2d\uff0c$\\mathbf{SOL}$\u4f7f\u5f97\u5bf9\u91cf\u5b50\u6570\u636e\u548c\u64cd\u4f5c\u7684\u5c5e\u6027\u8fdb\u884c\u63a8\u7406\u6210\u4e3a\u53ef\u80fd\uff0c\u5e76\u4e14\u53ef\u4ee5\u5229\u7528\u73b0\u6709\u7684\u7ecf\u5178\u8ba1\u7b97\u81ea\u52a8\u9a8c\u8bc1\u5de5\u5177\u3002\u4f5c\u8005\u8bbe\u60f3\u8be5\u6846\u67b6\u53ef\u5e94\u7528\u4e8eLean\u3001Coq\u7b49\u8bc1\u660e\u52a9\u624b\u3002"}}
{"id": "2512.22137", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.22137", "abs": "https://arxiv.org/abs/2512.22137", "authors": ["Jiangwen Dong", "Jiayu Li", "Wanyu Lin"], "title": "HybridFlow: Adaptive Task Scheduling for Fast and Token-Efficient LLM Inference in Edge-Cloud Collaboration", "comment": null, "summary": "Large language models (LLMs) exhibit impressive reasoning and problem-solving abilities, yet their substantial inference latency and token consumption pose major challenges for real-time deployment on resource-limited edge devices. Recent efforts toward edge-cloud collaboration have attempted to mitigate this issue, but most existing methods adopt coarse-grained task allocation strategies-assigning entire queries either to the edge or the cloud. Such rigid partitioning fails to exploit fine-grained reasoning parallelism and often leads to redundant computation and inefficient resource utilization. To this end, we propose HybridFlow, a resource-adaptive inference framework that enables fast and token-efficient collaborative reasoning between edge and cloud LLMs. HybridFlow operates in two stages: (1) task decomposition and parallel execution, which dynamically splits a complex query into interdependent subtasks that can execute as soon as their dependencies are resolved; and (2) resource-aware subtask routing, where a learned router adaptively assigns each subtask to the edge or cloud model according to predicted utility gains and real-time budget states. Comprehensive evaluations on GPQA, MMLU-Pro, AIME, and LiveBench-Reasoning demonstrate that HybridFlow effectively reduces end-to-end inference time and overall token usage while maintaining competitive accuracy.", "AI": {"tldr": "\u76f8\u5173\uff1a\u4e0d\u6d89\u53caDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS\u3002\u5b83\u4e0e**\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u90e8\u7f72\u548c\u8fb9\u7f18\u8ba1\u7b97**\u76f8\u5173\u3002\u6458\u8981\u8fc7\u957f\uff0c\u6ca1\u7a7a\u770b\uff1aHybridFlow\u662f\u4e00\u4e2a\u8d44\u6e90\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u590d\u6742\u67e5\u8be2\u5206\u89e3\u4e3a\u5e76\u884c\u5b50\u4efb\u52a1\u5e76\u6839\u636e\u8d44\u6e90\u548c\u6548\u7528\u667a\u80fd\u5730\u8def\u7531\u5230\u8fb9\u7f18\u6216\u4e91\u7aefLLM\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u4e86LLM\u7684\u63a8\u7406\u5ef6\u8fdf\u548c\u4ee3\u5e01\u6d88\u8017\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8fb9\u7f18-\u4e91\u534f\u540c\u63a8\u7406\u7684\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u5ef6\u8fdf\u548c\u4ee3\u5e01\u6d88\u8017\u963b\u788d\u4e86\u5176\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5b9e\u65f6\u90e8\u7f72\u3002\u73b0\u6709\u7684\u8fb9\u7f18-\u4e91\u534f\u4f5c\u65b9\u6cd5\u5927\u591a\u91c7\u7528\u7c97\u7c92\u5ea6\u7684\u4efb\u52a1\u5206\u914d\u7b56\u7565\uff0c\u672a\u80fd\u5229\u7528\u7ec6\u7c92\u5ea6\u7684\u63a8\u7406\u5e76\u884c\u6027\uff0c\u5bfc\u81f4\u5197\u4f59\u8ba1\u7b97\u548c\u4f4e\u6548\u7684\u8d44\u6e90\u5229\u7528\u3002", "method": "HybridFlow\u5206\u4e24\u9636\u6bb5\u8fdb\u884c\uff1a1. \u4efb\u52a1\u5206\u89e3\u548c\u5e76\u884c\u6267\u884c\uff1a\u5c06\u590d\u6742\u67e5\u8be2\u52a8\u6001\u62c6\u5206\u4e3a\u76f8\u4e92\u4f9d\u8d56\u7684\u5b50\u4efb\u52a1\uff0c\u4e00\u65e6\u4f9d\u8d56\u5173\u7cfb\u89e3\u51b3\u5373\u53ef\u6267\u884c\u30022. \u8d44\u6e90\u611f\u77e5\u5b50\u4efb\u52a1\u8def\u7531\uff1a\u5b66\u4e60\u5230\u7684\u8def\u7531\u5668\u6839\u636e\u9884\u6d4b\u7684\u6548\u7528\u589e\u76ca\u548c\u5b9e\u65f6\u9884\u7b97\u72b6\u6001\uff0c\u81ea\u9002\u5e94\u5730\u5c06\u6bcf\u4e2a\u5b50\u4efb\u52a1\u5206\u914d\u7ed9\u8fb9\u7f18\u6216\u4e91\u6a21\u578b\u3002", "result": "\u5728GPQA\u3001MMLU-Pro\u3001AIME\u548cLiveBench-Reasoning\u4e0a\u7684\u7efc\u5408\u8bc4\u4f30\u8868\u660e\uff0cHybridFlow\u5728\u4fdd\u6301\u7ade\u4e89\u6027\u51c6\u786e\u7387\u7684\u540c\u65f6\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u7aef\u5230\u7aef\u63a8\u7406\u65f6\u95f4\uff08End-to-End Inference Time\uff09\u548c\u603b\u4ee3\u5e01\u4f7f\u7528\u91cf\uff08Overall Token Usage\uff09\u3002", "conclusion": "HybridFlow\u662f\u4e00\u79cd\u8d44\u6e90\u81ea\u9002\u5e94\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u4efb\u52a1\u5206\u89e3\u548c\u8d44\u6e90\u611f\u77e5\u7684\u5b50\u4efb\u52a1\u8def\u7531\uff0c\u5b9e\u73b0\u4e86\u8fb9\u7f18\u548c\u4e91\u7aef\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e4b\u95f4\u7684\u5feb\u901f\u3001\u4ee3\u5e01\u9ad8\u6548\u7684\u534f\u540c\u63a8\u7406\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u7aef\u5230\u7aef\u63a8\u7406\u65f6\u95f4\u548c\u4ee3\u5e01\u4f7f\u7528\u91cf\u7684\u540c\u65f6\u4fdd\u6301\u4e86\u7ade\u4e89\u529b\u3002"}}
{"id": "2512.22729", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.22729", "abs": "https://arxiv.org/abs/2512.22729", "authors": ["Amir Azarmehr", "Soheil Behnezhad", "Shane Ferrante", "Mohammad Saneian"], "title": "Half-Approximating Maximum Dicut in the Streaming Setting", "comment": null, "summary": "We study streaming algorithms for the maximum directed cut problem. The edges of an $n$-vertex directed graph arrive one by one in an arbitrary order, and the goal is to estimate the value of the maximum directed cut using a single pass and small space. With $O(n)$ space, a $(1-\\varepsilon)$-approximation can be trivially obtained for any fixed $\\varepsilon > 0$ using additive cut sparsifiers. The question that has attracted significant attention in the literature is the best approximation achievable by algorithms that use truly sublinear (i.e., $n^{1-\u03a9(1)}$) space.\n  A lower bound of Kapralov and Krachun (STOC'20) implies .5-approximation is the best one can hope for. The current best algorithm for general graphs obtains a .485-approximation due to the work of Saxena, Singer, Sudan, and Velusamy (FOCS'23). The same authors later obtained a $(1/2-\\varepsilon)$-approximation, assuming that the graph is constant-degree (SODA'25).\n  In this paper, we show that for any $\\varepsilon > 0$, a $(1/2-\\varepsilon)$-approximation of maximum dicut value can be obtained with $n^{1-\u03a9_\\varepsilon(1)}$ space in *general graphs*. This shows that the lower bound of Kapralov and Krachun is generally tight, settling the approximation complexity of this fundamental problem. The key to our result is a careful analysis of how correlation propagates among high- and low-degree vertices, when simulating a suitable local algorithm.", "AI": {"tldr": "This paper is related to graph processing and algorithms. The paper studies streaming algorithms for the maximum directed cut problem. It presents a $(1/2-\\varepsilon)$-approximation algorithm with $n^{1-\\Omega_\\varepsilon(1)}$ space for general graphs, which is a tight result against a known $0.5$ lower bound, settling the approximation complexity for this fundamental problem.", "motivation": "\u6700\u5927\u6709\u5411\u5272\u95ee\u9898\uff08maximum directed cut problem\uff09\u5728\u6d41\u5f0f\u7b97\u6cd5\u548c\u5b50\u7ebf\u6027\u7a7a\u95f4\u7ea6\u675f\u4e0b\u7684\u8fd1\u4f3c\u6027\u80fd\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u7814\u7a76\u65b9\u5411\u3002\u73b0\u6709\u7814\u7a76\u5728 $O(n)$ \u7a7a\u95f4\u4e0b\u53ef\u4ee5\u8fbe\u5230 $(1-\\varepsilon)$-\u8fd1\u4f3c\uff0c\u4f46\u5bf9\u4e8e\u771f\u6b63\u6b21\u7ebf\u6027\u7a7a\u95f4\uff08$n^{1-\u03a9(1)}$\uff09\u7684\u6700\u4f73\u8fd1\u4f3c\u7387\u4ecd\u4e0d\u660e\u786e\u3002Kapralov \u548c Krachun \u7684\u4e0b\u754c\u8868\u660e $0.5$ \u8fd1\u4f3c\u662f\u6700\u597d\u7684\u671f\u671b\u503c\uff0c\u4f46\u73b0\u6709\u7684\u6700\u597d\u7ed3\u679c\u662f $0.485$\uff08\u4e00\u822c\u56fe\uff09\u548c $(1/2-\\varepsilon)$\uff08\u5e38\u6570\u5ea6\u56fe\uff09\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u5e0c\u671b\u5728\u4e00\u822c\u56fe\u548c\u771f\u6b63\u6b21\u7ebf\u6027\u7a7a\u95f4\u4e0b\uff0c\u901a\u8fc7\u6d41\u5f0f\u7b97\u6cd5\u8fbe\u5230 $(1/2-\\varepsilon)$ \u8fd1\u4f3c\uff0c\u4ece\u800c\u89e3\u51b3\u8be5\u95ee\u9898\u7684\u8fd1\u4f3c\u590d\u6742\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u5f0f\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u4e00\u822c\u56fe\u4e0a\u83b7\u5f97\u6700\u5927\u6709\u5411\u5272\u503c\u7684 $(1/2-\\varepsilon)$-\u8fd1\u4f3c\u3002\u8be5\u7b97\u6cd5\u4f7f\u7528\u4e86 $n^{1-\u03a9_\\varepsilon(1)}$ \u7a7a\u95f4\uff0c\u5e76\u4e14\u5176\u5173\u952e\u5728\u4e8e\u5bf9\u6a21\u62df\u7684\u5c40\u90e8\u7b97\u6cd5\u4e2d\u9ad8\u3001\u4f4e\u5ea6\u9876\u70b9\u4e4b\u95f4\u76f8\u5173\u6027\u4f20\u64ad\u7684\u7ec6\u81f4\u5206\u6790\u3002", "result": "\u672c\u6587\u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u610f $\\varepsilon > 0$\uff0c\u5728\u4e00\u822c\u56fe\u4e0a\uff0c\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 $n^{1-\u03a9_\\varepsilon(1)}$ \u7a7a\u95f4\u7684\u6d41\u5f0f\u7b97\u6cd5\uff0c\u83b7\u5f97\u6700\u5927\u6709\u5411\u5272\u503c\u7684 $(1/2-\\varepsilon)$-\u8fd1\u4f3c\u3002\u8fd9\u4e00\u7ed3\u679c\u8868\u660e Kapralov \u548c Krachun \u7684\u4e0b\u754c\u662f\u4e00\u822c\u7d27\u7684\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u8fd9\u4e00\u57fa\u7840\u95ee\u9898\u7684\u8fd1\u4f3c\u590d\u6742\u6027\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u6700\u5927\u6709\u5411\u5272\u95ee\u9898\u5728\u6d41\u5f0f\u7b97\u6cd5\u4e2d\u7684\u8fd1\u4f3c\u6027\u80fd\uff0c\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u5177\u6709 $n^{1-\u03a9_\\varepsilon(1)}$ \u7a7a\u95f4\u590d\u6742\u5ea6\u7684 $(1/2-\\varepsilon)$-\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u8be5\u95ee\u9898\u7684\u8fd1\u4f3c\u590d\u6742\u6027\uff0c\u8bc1\u660e\u4e86 Kapralov \u548c Krachun \u7684\u4e0b\u754c\u662f\u7d27\u7684\u3002\u8be5\u65b9\u6cd5\u7684\u5173\u952e\u5728\u4e8e\u5206\u6790\u5c40\u90e8\u7b97\u6cd5\u4e2d\u9ad8\u3001\u4f4e\u5ea6\u9876\u70b9\u4e4b\u95f4\u76f8\u5173\u6027\u4f20\u64ad\u3002"}}
{"id": "2512.22390", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.22390", "abs": "https://arxiv.org/abs/2512.22390", "authors": ["Yuze Li", "Srinivasan Ramachandra Sharma", "Charitha Saumya", "Ali R. Butt", "Kirshanthan Sundararajah"], "title": "Eliminate Branches by Melding IR Instructions", "comment": null, "summary": "Branch mispredictions cause catastrophic performance penalties in modern processors, leading to performance loss. While hardware predictors and profile-guided techniques exist, data-dependent branches with irregular patterns remain challenging. Traditional if-conversion eliminates branches via software predication but faces limitations on architectures like x86. It often fails on paths containing memory instructions or incurs excessive instruction overhead by fully speculating large branch bodies.\n  This paper presents Melding IR Instructions (MERIT), a compiler transformation that eliminates branches by aligning and melding similar operations from divergent paths at the IR instruction level. By observing that divergent paths often perform structurally similar operations with different operands, MERIT adapts sequence alignment to discover merging opportunities and employs safe operand-level guarding to ensure semantic correctness without hardware predication. Implemented as an LLVM pass and evaluated on 102 programs from four benchmark suites, MERIT achieves a geometric mean speedup of 10.9% with peak improvements of 32x compared to hardware branch predictor, demonstrating the effectiveness with reduced static instruction overhead.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u4e13\u6ce8\u4e8e\u4e00\u79cd\u540d\u4e3aMERIT\u7684\u7f16\u8bd1\u5668\u8f6c\u6362\uff0c\u65e8\u5728\u4f18\u5316\u7a0b\u5e8f\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u4e0eLLVM\uff08\u4e00\u4e2a\u8457\u540d\u7684\u7f16\u8bd1\u5668\u57fa\u7840\u8bbe\u65bd\uff09\u76f8\u5173\u3002\u5b83\u4e0e\u56fe\u5904\u7406\u548cHLS\u65e0\u5173\u3002\n\u592a\u957f\u4e0d\u770b\u7248\uff1a\u5206\u652f\u9884\u6d4b\u9519\u8bef\u662f\u73b0\u4ee3\u5904\u7406\u5668\u7684\u4e3b\u8981\u6027\u80fd\u74f6\u9888\uff0c\u4f20\u7edf\u7684\u5206\u652f\u6d88\u9664\u6280\u672f\u5982if-conversion\u5b58\u5728\u9650\u5236\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7f16\u8bd1\u5668\u8f6c\u6362\u65b9\u6cd5MERIT\uff08\u878d\u5408IR\u6307\u4ee4\uff09\uff0c\u901a\u8fc7\u5728IR\u7ea7\u522b\u5bf9\u9f50\u548c\u878d\u5408\u76f8\u4f3c\u64cd\u4f5c\u6765\u6d88\u9664\u6570\u636e\u76f8\u5173\u5206\u652f\uff0c\u5e76\u4f7f\u7528\u64cd\u4f5c\u6570\u7ea7\u522b\u7684\u4fdd\u62a4\u6765\u4fdd\u6301\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u4ece\u800c\u907f\u514d\u4e86\u786c\u4ef6\u9884\u8a00\u3002MERIT\u4f5c\u4e3aLLVM pass\u5b9e\u73b0\uff0c\u5e76\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u9ad8\u8fbe32\u500d\u7684\u5cf0\u503c\u52a0\u901f\uff0c\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\u8fbe\u523010.9%\uff0c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u73b0\u4ee3\u5904\u7406\u5668\u4e2d\uff0c\u5206\u652f\u9884\u6d4b\u9519\u8bef\u4f1a\u5bfc\u81f4\u6027\u80fd\u707e\u96be\u6027\u4e0b\u964d\u3002\u5c3d\u7ba1\u5b58\u5728\u786c\u4ef6\u9884\u6d4b\u5668\u548c\u5256\u9762\u6307\u5bfc\u6280\u672f\uff0c\u4f46\u5177\u6709\u4e0d\u89c4\u5219\u6a21\u5f0f\u7684\u6570\u636e\u76f8\u5173\u5206\u652f\u4ecd\u7136\u96be\u4ee5\u5904\u7406\u3002\u4f20\u7edf\u7684if-conversion\u901a\u8fc7\u8f6f\u4ef6\u9884\u8a00\u6d88\u9664\u5206\u652f\uff0c\u4f46\u5728x86\u7b49\u67b6\u6784\u4e0a\u9762\u4e34\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u5305\u542b\u5185\u5b58\u6307\u4ee4\u7684\u8def\u5f84\u4e0a\u6216\u5728\u5b8c\u6574\u63a8\u6d4b\u5927\u578b\u5206\u652f\u4f53\u65f6\u4f1a\u5f15\u5165\u8fc7\u591a\u7684\u6307\u4ee4\u5f00\u9500\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Melding IR Instructions (MERIT)\uff08\u878d\u5408IR\u6307\u4ee4\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u7f16\u8bd1\u5668\u8f6c\u6362\uff0c\u901a\u8fc7\u5728IR\u6307\u4ee4\u7ea7\u522b\u5bf9\u9f50\u548c\u878d\u5408\u6765\u81ea\u4e0d\u540c\u8def\u5f84\u7684\u76f8\u4f3c\u64cd\u4f5c\u6765\u6d88\u9664\u5206\u652f\u3002\u5b83\u501f\u9274\u4e86\u5e8f\u5217\u6bd4\u5bf9\u7684\u601d\u60f3\u6765\u53d1\u73b0\u878d\u5408\u673a\u4f1a\uff0c\u5e76\u91c7\u7528\u5b89\u5168\u7684\u64cd\u4f5c\u6570\u7ea7\u522b\u4fdd\u62a4\u6765\u786e\u4fdd\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u4ece\u800c\u907f\u514d\u4e86\u5bf9\u786c\u4ef6\u9884\u8a00\u7684\u652f\u6301\u3002\u8be5\u65b9\u6cd5\u4f5c\u4e3aLLVM\u7684\u4e00\u4e2apass\u5b9e\u73b0\u3002", "result": "MERIT\u5728LLVM\u4e2d\u5b9e\u73b0\u4e3a\u4e00\u4e2apass\uff0c\u5e76\u5728\u6765\u81ea\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u7684102\u4e2a\u7a0b\u5e8f\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002\u4e0e\u786c\u4ef6\u5206\u652f\u9884\u6d4b\u5668\u76f8\u6bd4\uff0cMERIT\u5b9e\u73b0\u4e8610.9%\u7684\u51e0\u4f55\u5e73\u5747\u52a0\u901f\u6bd4\uff0c\u5cf0\u503c\u6539\u8fdb\u8fbe\u523032\u500d\u3002\u540c\u65f6\uff0c\u5b83\u8fd8\u51cf\u5c11\u4e86\u9759\u6001\u6307\u4ee4\u5f00\u9500\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "MERIT\u662f\u4e00\u79cd\u7f16\u8bd1\u5668\u8f6c\u6362\uff0c\u901a\u8fc7\u5728IR\u6307\u4ee4\u7ea7\u522b\u5bf9\u9f50\u548c\u878d\u5408\u6765\u81ea\u4e0d\u540c\u8def\u5f84\u7684\u76f8\u4f3c\u64cd\u4f5c\u6765\u6d88\u9664\u5206\u652f\u3002\u5b83\u6539\u8fdb\u4e86\u4f20\u7edfif-conversion\u7684\u9650\u5236\uff0c\u901a\u8fc7\u5b89\u5168\u7684\u64cd\u4f5c\u6570\u7ea7\u522b\u4fdd\u62a4\u6765\u786e\u4fdd\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u4ece\u800c\u907f\u514d\u4e86\u786c\u4ef6\u9884\u8a00\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMERIT\u6bd4\u786c\u4ef6\u5206\u652f\u9884\u6d4b\u5668\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\uff0c\u8bc1\u5b9e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2512.22975", "categories": ["cs.DS", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.22975", "abs": "https://arxiv.org/abs/2512.22975", "authors": ["Flavia Bonomo-Braberman", "Eric Brandwein", "Ignasi Sau"], "title": "Computing parameters that generalize interval graphs using restricted modular partitions", "comment": "28 pages, 7 figures, 3 appendices", "summary": "Recently, Lafond and Luo [MFCS 2023] defined the $\\mathcal{G}$-modular cardinality of a graph $G$ as the minimum size of a partition of $V(G)$ into modules that belong to a graph class $\\mathcal{G}$. We analyze the complexity of calculating parameters that generalize interval graphs when parameterized by the $\\mathcal{G}$-modular cardinality, where $\\mathcal{G}$ corresponds either to the class of interval graphs or to the union of complete graphs. Namely, we analyze the complexity of computing the thinness and the simultaneous interval number of a graph.\n  We present a linear kernel for the Thinness problem parameterized by the interval-modular cardinality and an FPT algorithm for Simultaneous Interval Number when parameterized by the cluster-modular cardinality plus the solution size. The interval-modular cardinality of a graph is not greater than the cluster-modular cardinality, which in turn generalizes the neighborhood diversity and the twin-cover number. Thus, our results imply a linear kernel for Thinness when parameterized by the neighborhood diversity of the input graph, FPT algorithms for Thinness when parameterized by the twin-cover number and vertex cover number, and FPT algorithms for Simultaneous Interval Number when parameterized by the neighborhood diversity plus the solution size, twin-cover number, and vertex cover number. To the best of our knowledge, prior to our work no parameterized algorithms (FPT or XP) for computing the thinness or the simultaneous interval number were known.\n  On the negative side, we observe that Thinness and Simultaneous Interval Number parameterized by treewidth, pathwidth, bandwidth, (linear) mim-width, clique-width, modular-width, or even the thinness or simultaneous interval number themselves, admit no polynomial kernels assuming NP $\\not\\subseteq$ coNP/poly.", "AI": {"tldr": "\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u76f8\u5173\u6027\uff1a\u672c\u6587\u4e0e**\u56fe\u5904\u7406**\u76f8\u5173\u3002\u5b83\u5206\u6790\u4e86\u56fe\u8bba\u4e2d\u4e24\u4e2a\u53c2\u6570\uff08\u8584\u5ea6 Thinness \u548c\u540c\u6b65\u533a\u95f4\u6570 Simultaneous Interval Number\uff09\u5728\u53c2\u6570\u5316\u590d\u6742\u5ea6\u7406\u8bba\u4e0b\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7279\u522b\u662f\u5229\u7528\u4e86\u56fe\u7684\u6a21\u5757\u5316\u5206\u533a\u6982\u5ff5\u3002\n\n\u592a\u957f\u4e0d\u770b\u7248\uff1a\u672c\u6587\u5229\u7528\u65b0\u7684\u56fe\u53c2\u6570\u2014\u2014$\\mathcal{G}$-\u6a21\u5757\u5316\u57fa\u6570\uff08\u7279\u522b\u662f\u533a\u95f4\u6a21\u5757\u5316\u548c\u805a\u7c7b\u6a21\u5757\u5316\u57fa\u6570\uff09\uff0c\u4e3a\u8ba1\u7b97\u56fe\u7684**\u8584\u5ea6**\u548c**\u540c\u6b65\u533a\u95f4\u6570**\u8fd9\u4e24\u4e2a\u5e7f\u4e49\u533a\u95f4\u56fe\u53c2\u6570\u63d0\u4f9b\u4e86**\u7ebf\u6027\u6838**\u548c**FPT \u7b97\u6cd5**\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u53c2\u6570\u5316\u7b97\u6cd5\u7684\u7a7a\u767d\u3002\u540c\u65f6\u8bc1\u660e\u4e86\u8fd9\u4e9b\u95ee\u9898\u5728\u8bb8\u591a\u4f20\u7edf\u7684\u56fe\u5bbd\u5ea6\u53c2\u6570\u5316\u4e0b\u4e0d\u5177\u6709\u591a\u9879\u5f0f\u6838\u3002", "motivation": "\u8fd1\u5e74\u6709\u7814\u7a76\u8005\u5b9a\u4e49\u4e86\u56fe\u7684 $\\mathcal{G}$-\u6a21\u5757\u5316\u57fa\u6570\uff0c\u5b83\u91cf\u5316\u4e86\u56fe\u53ef\u4ee5\u88ab\u5212\u5206\u4e3a\u5c5e\u4e8e\u7279\u5b9a\u56fe\u7c7b $\\mathcal{G}$ \u7684\u6a21\u5757\uff08modules\uff09\u7684\u6700\u5c0f\u6570\u91cf\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\uff1a\n1. **\u63a2\u7d22\u65b0\u7684\u53c2\u6570\u5316\u7ef4\u5ea6\uff1a** \u5c06 $\\mathcal{G}$-\u6a21\u5757\u5316\u57fa\u6570\u4f5c\u4e3a\u53c2\u6570\uff0c\u4ee5\u6b64\u6765\u5206\u6790\u8ba1\u7b97\u5e7f\u4e49\u533a\u95f4\u56fe\u6027\u8d28\uff08\u5982\u8584\u5ea6 Thinness \u548c\u540c\u6b65\u533a\u95f4\u6570 Simultaneous Interval Number\uff09\u7684\u590d\u6742\u6027\u3002\n2. **\u89e3\u51b3\u73b0\u6709\u7a7a\u767d\uff1a** \u5728\u672c\u6587\u5de5\u4f5c\u4e4b\u524d\uff0c\u636e\u4f5c\u8005\u6240\u77e5\uff0c\u5bf9\u4e8e\u8ba1\u7b97\u8584\u5ea6\u6216\u540c\u6b65\u533a\u95f4\u6570\u7684\u53c2\u6570\u5316\u7b97\u6cd5\uff08\u65e0\u8bba\u662f FPT \u8fd8\u662f XP\uff09\u90fd\u662f\u672a\u77e5\u7684\u3002\n3. **\u8fde\u63a5\u5df2\u77e5\u7684\u53c2\u6570\uff1a** $\\mathcal{G}$-\u6a21\u5757\u5316\u57fa\u6570\u53ef\u4ee5\u63a8\u5e7f\u90bb\u57df\u591a\u6837\u6027\u548c\u5b6a\u751f\u8986\u76d6\u6570\uff0c\u56e0\u6b64\u5229\u7528\u65b0\u7684\u53c2\u6570\u53ef\u4ee5\u81ea\u7136\u5730\u4e3a\u8fd9\u4e9b\u5df2\u77e5\u7684\u3001\u66f4\u53d7\u5173\u6ce8\u7684\u53c2\u6570\u63d0\u4f9b\u7b97\u6cd5\u7ed3\u679c\u3002", "method": "\u672c\u6587\u91c7\u7528\u53c2\u6570\u5316\u590d\u6742\u5ea6\u7406\u8bba\u7684\u65b9\u6cd5\u6765\u5206\u6790\u95ee\u9898\u590d\u6742\u5ea6\u3002\u5177\u4f53\u505a\u6cd5\u662f\uff1a\n1. **\u5b9a\u4e49\u548c\u5229\u7528\u65b0\u7684\u53c2\u6570\uff1a** \u4f7f\u7528 Lafond \u548c Luo \u5b9a\u4e49\u7684 $\\mathcal{G}$-\u6a21\u5757\u5316\u57fa\u6570\uff0c\u5176\u4e2d $\\mathcal{G}$ \u5206\u522b\u53d6\u533a\u95f4\u56fe\u7c7b\uff08Interval-Modular Cardinality\uff09\u6216\u5b8c\u5168\u56fe\u7684\u5e76\u96c6\uff08Cluster-Modular Cardinality\uff09\u4f5c\u4e3a\u53c2\u6570\u3002\n2. **\u7b97\u6cd5\u8bbe\u8ba1\uff1a** \u9488\u5bf9 Thinness \u95ee\u9898\uff0c\u8bc1\u660e\u4e86\u4e00\u4e2a\u4ee5\u533a\u95f4\u6a21\u5757\u5316\u57fa\u6570\u4e3a\u53c2\u6570\u7684\u7ebf\u6027\u6838\uff08Linear Kernel\uff09\u3002\u9488\u5bf9 Simultaneous Interval Number \u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ee5\u805a\u7c7b\u6a21\u5757\u5316\u57fa\u6570\u52a0\u4e0a\u89e3\u96c6\u5927\u5c0f\u4e3a\u53c2\u6570\u7684 FPT \u7b97\u6cd5\u3002\n3. **\u63a8\u5bfc\u548c\u63a8\u5e7f\uff1a** \u5229\u7528\u6a21\u5757\u5316\u57fa\u6570\u4e0e\u90bb\u57df\u591a\u6837\u6027\uff08neighborhood diversity\uff09\u3001\u5b6a\u751f\u8986\u76d6\u6570\uff08twin-cover number\uff09\u548c\u9876\u70b9\u8986\u76d6\u6570\uff08vertex cover number\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c06\u4e3b\u8981\u7ed3\u679c\u63a8\u5e7f\u5230\u8fd9\u4e9b\u66f4\u5e7f\u4e3a\u4eba\u77e5\u7684\u53c2\u6570\u4e0a\u3002\n4. **\u8d1f\u9762\u7ed3\u679c\u5206\u6790\uff1a** \u8bc1\u660e\u4e86 Thinness \u548c Simultaneous Interval Number \u5728\u8bb8\u591a\u7ecf\u5178\u56fe\u5bbd\u5ea6\u53c2\u6570\uff08\u5982 Treewidth, Pathwidth, Clique-Width \u7b49\uff09\u53c2\u6570\u5316\u4e0b\uff0c\u5728\u6807\u51c6\u590d\u6742\u5ea6\u5047\u8bbe\u4e0b\uff08NP $\\not\\subseteq$ coNP/poly\uff09\u4e0d\u5177\u6709\u591a\u9879\u5f0f\u6838\u3002", "result": "\u672c\u6587\u53d6\u5f97\u4e86\u4ee5\u4e0b\u4e3b\u8981\u7ed3\u679c\uff1a\n1. **Thinness \u7ebf\u6027\u6838\uff1a** \u9488\u5bf9\u4ee5\u533a\u95f4\u6a21\u5757\u5316\u57fa\u6570\u53c2\u6570\u5316\u7684 Thinness \u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ebf\u6027\u6838\uff08Linear Kernel\uff09\u3002\n2. **Thinness \u63a8\u5e7f\u7ed3\u679c\uff1a** \u8fd9\u4e00\u7ebf\u6027\u6838\u7ed3\u679c\u76f4\u63a5\u5bfc\u51fa\u4e86\u5728\u4ee5\u90bb\u57df\u591a\u6837\u6027\u4e3a\u53c2\u6570\u7684 Thinness \u95ee\u9898\u7684\u7ebf\u6027\u6838\uff1b\u540c\u65f6\u63a8\u5bfc\u51fa\u4e86\u4ee5\u5b6a\u751f\u8986\u76d6\u6570\u548c\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u7684 Thinness \u95ee\u9898\u7684 FPT \u7b97\u6cd5\u3002\n3. **Simultaneous Interval Number FPT \u7b97\u6cd5\uff1a** \u9488\u5bf9\u4ee5\u805a\u7c7b\u6a21\u5757\u5316\u57fa\u6570\u52a0\u4e0a\u89e3\u96c6\u5927\u5c0f\u4e3a\u53c2\u6570\u7684 Simultaneous Interval Number \u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a FPT \u7b97\u6cd5\u3002\n4. **Simultaneous Interval Number \u63a8\u5e7f\u7ed3\u679c\uff1a** \u5bfc\u51fa\u4e86\u4ee5\u90bb\u57df\u591a\u6837\u6027\u52a0\u89e3\u96c6\u5927\u5c0f\u3001\u5b6a\u751f\u8986\u76d6\u6570\u548c\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u7684 Simultaneous Interval Number \u95ee\u9898\u7684 FPT \u7b97\u6cd5\u3002\n5. **\u8d1f\u9762\u7ed3\u679c\uff08\u975e\u591a\u9879\u5f0f\u6838\uff09\uff1a** \u8bc1\u660e\u4e86 Thinness \u548c Simultaneous Interval Number \u5728\u8bb8\u591a\u7ecf\u5178\u5bbd\u5ea6\u53c2\u6570\uff08\u5982 Treewidth, Pathwidth, Bandwidth, Clique-Width, Modular-Width \u7b49\uff09\u53c2\u6570\u5316\u4e0b\uff0c\u5728\u6807\u51c6\u5047\u8bbe\u4e0b\u4e0d\u5177\u6709\u591a\u9879\u5f0f\u6838\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u5f53\u56fe $G$ \u4ee5 $\\mathcal{G}$-\u6a21\u5757\u5316\u57fa\u6570\u53c2\u6570\u5316\u65f6\uff0c\u8ba1\u7b97\u56fe\u7684\u201c\u8584\u5ea6\u201d\uff08Thinness\uff09\u548c\u201c\u540c\u6b65\u533a\u95f4\u6570\u201d\uff08Simultaneous Interval Number\uff09\u8fd9\u4e24\u4e2a\u5e7f\u4e49\u533a\u95f4\u56fe\u53c2\u6570\u7684\u590d\u6742\u6027\u3002\u4e3b\u8981\u7ed3\u8bba\u662f\uff1a\u5728\u53c2\u6570\u5316\u590d\u6742\u5ea6\u7406\u8bba\u7684\u6846\u67b6\u4e0b\uff0c\u901a\u8fc7\u5f15\u5165 $\\mathcal{G}$-\u6a21\u5757\u5316\u57fa\u6570\u4f5c\u4e3a\u53c2\u6570\uff0c\u672c\u6587\u4e3a Thinness \u548c Simultaneous Interval Number \u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u3001\u65b0\u7684\u53c2\u6570\u5316\u7b97\u6cd5\u548c\u6838\u5fc3\u5316\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5229\u7528\u4e86\u533a\u95f4\u6a21\u5757\u5316\u57fa\u6570\u548c\u805a\u7c7b\u6a21\u5757\u5316\u57fa\u6570\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u6307\u51fa\u4e86\u8fd9\u4e9b\u95ee\u9898\u5728\u8bb8\u591a\u7ecf\u5178\u5bbd\u5ea6\u53c2\u6570\uff08\u5982\u6811\u5bbd\u3001\u8def\u5f84\u5bbd\u7b49\uff09\u53c2\u6570\u5316\u4e0b\u4e0d\u5177\u6709\u591a\u9879\u5f0f\u6838\u3002\u8fd9\u4e9b\u7ed3\u679c\u586b\u8865\u4e86\u8be5\u9886\u57df\u5728\u53c2\u6570\u5316\u7b97\u6cd5\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.22417", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.22417", "abs": "https://arxiv.org/abs/2512.22417", "authors": ["Vasileios Koutavas", "Yu-Yang Lin", "Nikos Tzevelekos"], "title": "A Bounded Game Semantics Checker for Precise Smart Contract Analysis", "comment": "21 pages, 2 figures, 4 tables", "summary": "We present a new approach to finding smart contract vulnerabilities that is precise (no false positives up to our EVM-Yul interpreter), bounded-complete, and, when instrumented with domain knowledge, scales to real-world contracts. Our method is based on game semantics, modelling computation as an interaction between a contract and its environment, reducing reasoning about unknown or malicious external contracts to trace enumeration. We implement this in a tool we refer to as YulToolkit, a bounded game-semantics checker for Yul, the intermediate language of Solidity. By exploring only feasible interactions, YulToolkit avoids over-approximation, and by relying on the theory of game semantics it achieves bounded completeness. To make exploration tractable, YulToolkit supports instrumentation written in Solidity and propagated to Yul, comparable in effort to creating a test harness. Unlike tests, however, our technique explores all admissible traces within the chosen parameters and bounds. We evaluate YulToolkit on three real-world incidents: The DAO, PredyPool, and Lendf.Me, as well as benchmark contracts. In all cases, YulToolkit detects the known vulnerabilities (producing a violation-triggering trace), and after applying fixes, reports no further violations within bounds. These results show that bounded game semantics exploration is an effective and precise addition to the smart contract analysis toolbox, particularly for vulnerabilities such as reentrancy that are hard to detect precisely in real code.", "AI": {"tldr": "The paper is related to compiler and DSL. The compiler part is related to the intermediate language Yul and the tool YulToolkit which works with the intermediate language. The DSL part is related to smart contract analysis (Solidity and Yul). / This paper presents YulToolkit, a precise and bounded-complete smart contract vulnerability finder based on game semantics, which models computation as an interaction between the contract and its environment. By exploring only feasible interactions within bounds, YulToolkit avoids over-approximation and detects vulnerabilities like reentrancy on real-world incidents (The DAO, PredyPool, and Lendf.Me) effectively, demonstrating its value as a precise addition to the smart contract analysis toolbox.", "motivation": "\u667a\u80fd\u5408\u7ea6\u7684\u6f0f\u6d1e\u68c0\u6d4b\u9700\u8981\u4e00\u79cd\u65e2\u7cbe\u786e\uff08\u907f\u514d\u8bef\u62a5\uff09\u53c8\u5177\u6709\u53ef\u6269\u5c55\u6027\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u7684\u5408\u7ea6\u590d\u6742\u6027\u3002\u7279\u522b\u662f\u5bf9\u4e8e\u50cf\u91cd\u5165\u6027\u8fd9\u6837\u7684\u6f0f\u6d1e\uff0c\u5728\u5b9e\u9645\u4ee3\u7801\u4e2d\u7cbe\u786e\u68c0\u6d4b\u975e\u5e38\u56f0\u96be\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u53ef\u80fd\u9762\u4e34\u8fc7\u5ea6\u8fd1\u4f3c\u6216\u7f3a\u4e4f\u7cbe\u786e\u6027\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u57fa\u4e8e\u4e25\u683c\u7406\u8bba\u57fa\u7840\uff08\u5982\u535a\u5f08\u8bed\u4e49\uff09\u3001\u80fd\u591f\u5b9e\u73b0\u6709\u9650\u5b8c\u5907\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u7cbe\u786e\u63a2\u7d22\u548c\u9886\u57df\u77e5\u8bc6\u7684\u8f85\u52a9\uff0c\u6709\u6548\u68c0\u6d4b\u6f0f\u6d1e\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u535a\u5f08\u8bed\u4e49\uff08Game Semantics\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u5c06\u8ba1\u7b97\u5efa\u6a21\u4e3a\u5408\u7ea6\u4e0e\u5176\u73af\u5883\u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u5e76\u5c06\u5bf9\u672a\u77e5\u6216\u6076\u610f\u5916\u90e8\u5408\u7ea6\u7684\u63a8\u7406\u7b80\u5316\u4e3a\u8e2a\u8ff9\u679a\u4e3e\u3002\u8be5\u65b9\u6cd5\u5728\u540d\u4e3a YulToolkit \u7684\u5de5\u5177\u4e2d\u5b9e\u73b0\uff0c\u8fd9\u662f\u4e00\u4e2a\u9488\u5bf9 Solidity \u4e2d\u95f4\u8bed\u8a00 Yul \u7684\u6709\u9650\u535a\u5f08\u8bed\u4e49\u68c0\u67e5\u5668\u3002YulToolkit \u901a\u8fc7\u4ec5\u63a2\u7d22\u53ef\u884c\u7684\u4ea4\u4e92\uff0c\u907f\u514d\u4e86\u8fc7\u5ea6\u8fd1\u4f3c\uff0c\u5e76\u4f9d\u9760\u535a\u5f08\u8bed\u4e49\u7684\u7406\u8bba\u5b9e\u73b0\u4e86\u6709\u9650\u5b8c\u5907\u6027\u3002\u4e3a\u4e86\u4f7f\u63a2\u7d22\u6613\u4e8e\u5904\u7406\uff0cYulToolkit \u652f\u6301\u4f7f\u7528 Solidity \u7f16\u5199\u7684\u4e14\u80fd\u4f20\u64ad\u5230 Yul \u7684\u5de5\u5177\u5316\uff08Instrumentation\uff09\uff0c\u5176\u5de5\u4f5c\u91cf\u7c7b\u4f3c\u4e8e\u521b\u5efa\u6d4b\u8bd5\u5de5\u5177\u3002\u7136\u800c\uff0c\u4e0e\u6d4b\u8bd5\u4e0d\u540c\u7684\u662f\uff0c\u8be5\u6280\u672f\u63a2\u7d22\u4e86\u6240\u9009\u53c2\u6570\u548c\u754c\u9650\u5185\u7684\u6240\u6709\u53ef\u63a5\u53d7\u8e2a\u8ff9\u3002", "result": "YulToolkit \u5728\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u5b89\u5168\u4e8b\u4ef6\uff08The DAO\u3001PredyPool \u548c Lendf.Me\uff09\u4ee5\u53ca\u57fa\u51c6\u5408\u7ea6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u5728\u6240\u6709\u60c5\u51b5\u4e0b\uff0cYulToolkit \u90fd\u6210\u529f\u68c0\u6d4b\u5230\u4e86\u5df2\u77e5\u7684\u6f0f\u6d1e\uff08\u5e76\u751f\u6210\u4e86\u89e6\u53d1\u8fdd\u89c4\u7684\u8e2a\u8ff9\uff09\uff0c\u5e76\u4e14\u5728\u5e94\u7528\u4fee\u590d\u540e\uff0c\u5728\u9650\u5b9a\u7684\u8303\u56f4\u5185\u6ca1\u6709\u62a5\u544a\u8fdb\u4e00\u6b65\u7684\u8fdd\u89c4\u3002\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e\uff0c\u6709\u9650\u535a\u5f08\u8bed\u4e49\u63a2\u7d22\u662f\u667a\u80fd\u5408\u7ea6\u5206\u6790\u5de5\u5177\u7bb1\u4e2d\u4e00\u79cd\u6709\u6548\u4e14\u7cbe\u786e\u7684\u8865\u5145\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5728\u5b9e\u9645\u4ee3\u7801\u4e2d\u96be\u4ee5\u7cbe\u786e\u68c0\u6d4b\u7684\u91cd\u5165\u6027\u7b49\u6f0f\u6d1e\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u535a\u5f08\u8bed\u4e49\u7684\u6709\u9650\u63a2\u7d22\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u4e14\u7cbe\u786e\u7684\u667a\u80fd\u5408\u7ea6\u5206\u6790\u5de5\u5177\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u7cbe\u786e\u68c0\u6d4b\u8bf8\u5982\u91cd\u5165\u6027\u7b49\u96be\u4ee5\u53d1\u73b0\u7684\u6f0f\u6d1e\u3002\u5176\u5728\u5b9e\u9645\u6848\u4f8b\u4e2d\u7684\u6210\u529f\u5e94\u7528\uff0c\u8868\u660e\u4e86\u8be5\u65b9\u6cd5\u4f5c\u4e3a\u667a\u80fd\u5408\u7ea6\u5206\u6790\u5de5\u5177\u7bb1\u7684\u91cd\u8981\u8865\u5145\u4ef7\u503c\uff0c\u5177\u6709\u9ad8\u6027\u80fd\u548c\u9ad8\u7cbe\u786e\u6027\u3002"}}
{"id": "2512.22142", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22142", "abs": "https://arxiv.org/abs/2512.22142", "authors": ["Leyang Xue", "Meghana Madhyastha", "Myungjin Lee", "Amos Storkey", "Randal Burns", "Mahesh K. Marina"], "title": "On Harnessing Idle Compute at the Edge for Foundation Model Training", "comment": "Extended abstract version of this paper appeared in ACM MobiCom 2025", "summary": "The ecosystem behind foundation model development today is highly centralized and limited to large-scale cloud data center operators: training foundation models is costly, needing immense compute resources. Decentralized foundation model training across edge devices, leveraging their spare compute, promises a democratized alternative. However, existing edge-training approaches fall short: they struggle to match cloud-based training performance, exhibit limited scalability with model size, exceed device memory capacity, and have prohibitive communication overhead. They also fail to satisfactorily handle device heterogeneity and dynamism.\n  We introduce a new paradigm, Cleave, which finely partitions training operations through a novel selective hybrid tensor parallelism method. Together with a parameter server centric training framework, Cleave copes with device memory limits and avoids communication bottlenecks, thereby enabling efficient training of large models on par with the cloud. Further, with a cost optimization model to guide device selection and training workload distribution, Cleave effectively accounts for device heterogeneity and churn.\n  Our evaluations show that Cleave matches cloud-based GPU training by scaling efficiently to larger models and thousands of devices, supporting up to 8x more devices than baseline edge-training approaches. It outperforms state-of-the-art edge training methods by up to a factor of 10 in per-batch training time and efficiently handles device failures, achieving at least 100x faster recovery than prior methods.", "AI": {"tldr": "\u6d89\u53ca\u9886\u57df\uff1a\u7f16\u8bd1\u5668/\u7f16\u8bd1\u6280\u672f\uff1b\u56fe\u5904\u7406\uff1bMLIR\uff1bHLS\uff1bDSL\n\u8fd9\u662f\u4e00\u7bc7\u5173\u4e8e\u53bb\u4e2d\u5fc3\u5316\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\u7684\u8bba\u6587\uff0c\u5b83\u901a\u8fc7\u5f15\u5165 Cleave \u8303\u5f0f\u6765\u89e3\u51b3\u73b0\u6709\u8fb9\u7f18\u8bad\u7ec3\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002Cleave \u91c7\u7528\u9009\u62e9\u6027\u6df7\u5408\u5f20\u91cf\u5e76\u884c\u65b9\u6cd5\u548c\u53c2\u6570\u670d\u52a1\u5668\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4e91\u7aef\u76f8\u5f53\u7684\u8bad\u7ec3\u6027\u80fd\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u53ef\u6269\u5c55\u6027\u548c\u5bb9\u9519\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u7840\u6a21\u578b\u5f00\u53d1\u751f\u6001\u7cfb\u7edf\u9ad8\u5ea6\u96c6\u4e2d\u4e14\u9650\u4e8e\u5927\u578b\u4e91\u6570\u636e\u4e2d\u5fc3\u8fd0\u8425\u5546\uff0c\u8bad\u7ec3\u6210\u672c\u9ad8\u6602\u3002\u53bb\u4e2d\u5fc3\u5316\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\u5229\u7528\u8fb9\u7f18\u8bbe\u5907\u7684\u7a7a\u95f2\u8ba1\u7b97\u8d44\u6e90\u53ef\u4ee5\u63d0\u4f9b\u4e00\u79cd\u6c11\u4e3b\u5316\u7684\u66ff\u4ee3\u65b9\u6848\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u8fb9\u7f18\u8bad\u7ec3\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u4e0e\u4e91\u7aef\u8bad\u7ec3\u4e0d\u5339\u914d\u3001\u6a21\u578b\u89c4\u6a21\u53ef\u6269\u5c55\u6027\u6709\u9650\u3001\u8d85\u51fa\u8bbe\u5907\u5185\u5b58\u5bb9\u91cf\u3001\u901a\u4fe1\u5f00\u9500\u5927\u4ee5\u53ca\u96be\u4ee5\u4ee4\u4eba\u6ee1\u610f\u5730\u5904\u7406\u8bbe\u5907\u5f02\u6784\u6027\u548c\u52a8\u6001\u6027\u7b49\u7f3a\u70b9\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Cleave \u7684\u65b0\u8303\u5f0f\uff0c\u5b83\u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u9009\u62e9\u6027\u6df7\u5408\u5f20\u91cf\u5e76\u884c\u65b9\u6cd5\u6765\u7cbe\u7ec6\u5730\u5212\u5206\u8bad\u7ec3\u64cd\u4f5c\u3002\u7ed3\u5408\u4e00\u4e2a\u4ee5\u53c2\u6570\u670d\u52a1\u5668\u4e3a\u4e2d\u5fc3\u7684\u8bad\u7ec3\u6846\u67b6\uff0cCleave \u89e3\u51b3\u4e86\u8bbe\u5907\u5185\u5b58\u9650\u5236\u5e76\u907f\u514d\u4e86\u901a\u4fe1\u74f6\u9888\u3002\u6b64\u5916\uff0cCleave \u4f7f\u7528\u6210\u672c\u4f18\u5316\u6a21\u578b\u6765\u6307\u5bfc\u8bbe\u5907\u9009\u62e9\u548c\u8bad\u7ec3\u5de5\u4f5c\u8d1f\u8f7d\u5206\u914d\uff0c\u4ee5\u6709\u6548\u5e94\u5bf9\u8bbe\u5907\u7684\u5f02\u6784\u6027\u548c\u52a8\u6001\u6027\uff08\u6d41\u5931\uff09\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cCleave \u5728\u6548\u7387\u4e0a\u4e0e\u57fa\u4e8e\u4e91\u7684 GPU \u8bad\u7ec3\u76f8\u5f53\uff0c\u80fd\u591f\u6709\u6548\u5730\u6269\u5c55\u5230\u66f4\u5927\u7684\u6a21\u578b\u548c\u6570\u5343\u4e2a\u8bbe\u5907\uff0c\u652f\u6301\u7684\u8bbe\u5907\u6570\u91cf\u662f\u57fa\u7ebf\u8fb9\u7f18\u8bad\u7ec3\u65b9\u6cd5\u7684 8 \u500d\u3002Cleave \u7684\u6bcf\u6279\u8bad\u7ec3\u65f6\u95f4\u6bd4\u6700\u5148\u8fdb\u7684\u8fb9\u7f18\u8bad\u7ec3\u65b9\u6cd5\u5feb 10 \u500d\uff0c\u5e76\u4e14\u80fd\u6709\u6548\u5904\u7406\u8bbe\u5907\u6545\u969c\uff0c\u6062\u590d\u901f\u5ea6\u6bd4\u5148\u524d\u7684\u65b9\u6cd5\u5feb\u81f3\u5c11 100 \u500d\u3002", "conclusion": "Cleave \u901a\u8fc7\u4e00\u79cd\u65b0\u9896\u7684\u9009\u62e9\u6027\u6df7\u5408\u5f20\u91cf\u5e76\u884c\u65b9\u6cd5\u548c\u4ee5\u53c2\u6570\u670d\u52a1\u5668\u4e3a\u4e2d\u5fc3\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u53bb\u4e2d\u5fc3\u5316\u57fa\u7840\u6a21\u578b\u8bad\u7ec3\uff0c\u80fd\u591f\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8bad\u7ec3\u5927\u578b\u6a21\u578b\uff0c\u6027\u80fd\u4e0e\u4e91\u7aef\u76f8\u5f53\u3002\u5b83\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8fb9\u7f18\u8bad\u7ec3\u7684\u5c40\u9650\u6027\uff0c\u5982\u6027\u80fd\u4f4e\u4e0b\u3001\u53ef\u6269\u5c55\u6027\u5dee\u3001\u5185\u5b58\u9650\u5236\u3001\u901a\u4fe1\u5f00\u9500\u5927\u4ee5\u53ca\u8bbe\u5907\u5f02\u6784\u6027\u548c\u52a8\u6001\u6027\u95ee\u9898\u3002"}}
{"id": "2512.23314", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.23314", "abs": "https://arxiv.org/abs/2512.23314", "authors": ["Robert Clausecker", "Florian Kurpicz", "Etienne Palanga"], "title": "Practical Parallel Block Tree Construction: First Results", "comment": null, "summary": "The block tree [Belazzougui et al., J. Comput. Syst. Sci. '21] is a compressed representation of a length-$n$ text that supports access, rank, and select queries while requiring only $O(z\\log\\frac{n}{z})$ words of space, where $z$ is the number of Lempel-Ziv factors of the text. In other words, its space-requirements are asymptotically similar to those of the compressed text. In practice, block trees offer comparable query performance to state-of-the-art compressed rank and select indices. However, their construction is significantly slower. Additionally, the fastest construction algorithms require a significant amount of working memory. To address this issue, we propose fast and lightweight parallel algorithms for the efficient construction of block trees. Our algorithm achieves similar speed than the currently fastest construction algorithm on one core and is up to four times faster using 64 cores. It achieves all that while requiring an order of magnitude less memory. As result of independent interest, we present a data parallel algorithm for Karp-Rabin fingerprint computation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL\u3001MLIR\u3001HLS\u6216\u56fe\u5904\u7406\u65e0\u5173\u3002\n\u5757\u6811\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u538b\u7f29\u6587\u672c\u8868\u793a\u7ed3\u6784\uff0c\u7136\u800c\u5176\u6784\u5efa\u901f\u5ea6\u7f13\u6162\u4e14\u5360\u7528\u5927\u91cf\u5185\u5b58\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u4e14\u5360\u7528\u5185\u5b58\u5c0f\u7684\u5e76\u884c\u7b97\u6cd5\u6765\u9ad8\u6548\u6784\u5efa\u5757\u6811\uff0c\u8be5\u7b97\u6cd5\u5728\u5355\u6838\u4e0a\u901f\u5ea6\u53ef\u4e0e\u73b0\u6709\u6700\u5feb\u7b97\u6cd5\u5ab2\u7f8e\uff0c\u4f7f\u7528 64 \u6838\u65f6\u53ef\u63d0\u901f\u56db\u500d\uff0c\u540c\u65f6\u5185\u5b58\u5360\u7528\u51cf\u5c11\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e Karp-Rabin \u6307\u7eb9\u8ba1\u7b97\u7684\u6570\u636e\u5e76\u884c\u7b97\u6cd5\u3002", "motivation": "\u5757\u6811\uff08block tree\uff09\u662f\u4e00\u79cd\u538b\u7f29\u6587\u672c\u8868\u793a\u65b9\u6cd5\uff0c\u5b83\u652f\u6301\u8bbf\u95ee\u3001\u79e9\uff08rank\uff09\u548c\u9009\u62e9\uff08select\uff09\u67e5\u8be2\uff0c\u6240\u9700\u7684\u7a7a\u95f4\u4e0e\u538b\u7f29\u6587\u672c\u7684\u6e10\u8fdb\u7a7a\u95f4\u9700\u6c42\u76f8\u4f3c\uff08$O(z\\log\\frac{n}{z})$ \u8bcd\uff0c\u5176\u4e2d $z$ \u662f Lempel-Ziv \u56e0\u5b50\u6570\uff09\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5757\u6811\u7684\u67e5\u8be2\u6027\u80fd\u4e0e\u6700\u5148\u8fdb\u7684\u538b\u7f29\u79e9\u548c\u9009\u62e9\u7d22\u5f15\u76f8\u5f53\uff0c\u4f46\u5176\u6784\u5efa\u901f\u5ea6\u660e\u663e\u8f83\u6162\uff0c\u5e76\u4e14\u6700\u5feb\u7684\u6784\u5efa\u7b97\u6cd5\u9700\u8981\u5927\u91cf\u7684\u5185\u5b58\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u89e3\u51b3\u5757\u6811\u6784\u5efa\u901f\u5ea6\u6162\u548c\u5bf9\u5de5\u4f5c\u5185\u5b58\u8981\u6c42\u9ad8\u7684\u95ee\u9898\uff0c\u4ee5\u63d0\u9ad8\u5176\u5b9e\u7528\u6027\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u4e14\u5360\u7528\u5185\u5b58\u5c0f\u7684\u5e76\u884c\u7b97\u6cd5\u6765\u9ad8\u6548\u6784\u5efa\u5757\u6811\u3002\u6587\u4e2d\u63d0\u5230\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u5e76\u884c\u7b97\u6cd5\u7528\u4e8e Karp-Rabin \u6307\u7eb9\u8ba1\u7b97\uff0c\u8fd9\u53ef\u80fd\u662f\u52a0\u901f\u5757\u6811\u5e76\u884c\u6784\u5efa\u7684\u4e00\u79cd\u6280\u672f\u3002\u6838\u5fc3\u65b9\u6cd5\u662f\u901a\u8fc7\u5e76\u884c\u5316\u6765\u52a0\u901f\u5757\u6811\u7684\u6784\u5efa\u8fc7\u7a0b\uff0c\u540c\u65f6\u4f18\u5316\u5185\u5b58\u4f7f\u7528\uff0c\u4ece\u800c\u5728\u4fdd\u8bc1\u901f\u5ea6\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u6240\u9700\u7684\u5185\u5b58\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u5e76\u884c\u6784\u5efa\u7b97\u6cd5\u5728\u5355\u6838\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u76ee\u524d\u6700\u5feb\u7684\u6784\u5efa\u7b97\u6cd5\u76f8\u4f3c\u7684\u901f\u5ea6\u3002\u5728\u4f7f\u7528 64 \u6838\u65f6\uff0c\u901f\u5ea6\u6700\u9ad8\u53ef\u8fbe\u5230\u5f53\u524d\u6700\u5feb\u7b97\u6cd5\u7684\u56db\u500d\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u8be5\u7b97\u6cd5\u5728\u5b9e\u73b0\u901f\u5ea6\u63d0\u5347\u7684\u540c\u65f6\uff0c\u6240\u9700\u7684\u5185\u5b58\u6bd4\u73b0\u6709\u7b97\u6cd5\u5c11\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u72ec\u7acb\u7684\u6570\u636e\u5e76\u884c\u7b97\u6cd5\u7528\u4e8e Karp-Rabin \u6307\u7eb9\u8ba1\u7b97\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u5feb\u901f\u4e14\u5360\u7528\u5185\u5b58\u5c0f\u7684\u5e76\u884c\u7b97\u6cd5\u6765\u9ad8\u6548\u6784\u5efa\u5757\u6811\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u5355\u6838\u4e0a\u4e0e\u76ee\u524d\u6700\u5feb\u7684\u6784\u5efa\u7b97\u6cd5\u901f\u5ea6\u76f8\u5f53\uff0c\u800c\u5728\u4f7f\u7528 64 \u6838\u65f6\u901f\u5ea6\u6700\u9ad8\u53ef\u63d0\u5347\u56db\u500d\uff0c\u540c\u65f6\u5185\u5b58\u9700\u6c42\u5927\u5e45\u964d\u4f4e\u3002\u4f5c\u8005\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u5e76\u884c\u7b97\u6cd5\u7528\u4e8e Karp-Rabin \u6307\u7eb9\u8ba1\u7b97\uff0c\u4f5c\u4e3a\u4e00\u9879\u72ec\u7acb\u7684\u6210\u679c\u3002\u672c\u6587\u6210\u529f\u89e3\u51b3\u4e86\u5757\u6811\u6784\u5efa\u901f\u5ea6\u6162\u548c\u5185\u5b58\u5360\u7528\u5927\u7684\u95ee\u9898\uff0c\u6709\u671b\u4fc3\u8fdb\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u63a8\u5e7f\u3002"}}
{"id": "2512.22684", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.22684", "abs": "https://arxiv.org/abs/2512.22684", "authors": ["Jos\u00e9 Luis Romero", "Crist\u00f3bal Isla", "Mat\u00edas Toro", "\u00c9ric Tanter"], "title": "Compiling Gradual Types with Evidence", "comment": "Submitted to TOPLAS", "summary": "Efficiently supporting sound gradual typing in a language with structural types is challenging. To date, the Grift compiler is the only close-to-the-metal implementation of gradual typing in this setting, exploiting coercions for runtime checks, and further extended with monotonic references for efficient access to statically-typed data structures. On the language design and semantics side, the Abstracting Gradual Typing (AGT) methodology has proven fruitful to elucidate existing designs and to innovate by deriving gradualizations of a wide variety of typing disciplines and language features. Grounded in abstract interpretation, the Curry-Howard inspired runtime semantics of AGT is based on the notion of evidence for consistent judgments that evolve during reduction, monitoring the plausibility of well-typedness. While expressive and versatile, it is unclear whether such evidence-based semantics are a viable route to realize an efficient implementation of gradual typing.\n  In this work, we explore this question by designing, implementing, and evaluating an evidence-based compiler, called GrEv. We explain how to bridge the gap between the formal semantics and the GrEv compiler implementation, and identify novel monotonic semantics. We empirically evaluate the performance of GrEv on the Grift benchmark suite. The results show that an evidence-based compiler can be competitive with, and even faster than, a coercion-based compiler, exhibiting more stability across configurations on the static-to-dynamic spectrum. In addition to enriching the space of gradual typing compilers, this work opens a direct door to exploring efficient implementations of the many advanced gradual typing disciplines formally derived with AGT in the literature.", "AI": {"tldr": "\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS\u76f8\u5173\uff1a\u7f16\u8bd1\u5668\u3002\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aGrEv\u7684\u7f16\u8bd1\u5668\uff0c\u5b83\u57fa\u4e8e\u62bd\u8c61\u6e10\u8fdb\u7c7b\u578b\uff08AGT\uff09\u7684\u8bc1\u636e\u8bed\u4e49\u5b9e\u73b0\u4e86\u6e10\u8fdb\u7c7b\u578b\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u79cd\u57fa\u4e8e\u8bc1\u636e\u7684\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u53ef\u4ee5\u4e0e\u73b0\u6709\u7684\u57fa\u4e8e\u5f3a\u5236\u8f6c\u6362\u7684\u5b9e\u73b0\uff08\u5982Grift\uff09\u76f8\u5ab2\u7f8e\u751a\u81f3\u66f4\u5feb\uff0c\u4e14\u5728\u4e0d\u540c\u914d\u7f6e\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u4e3a\u5b9e\u73b0AGT\u5f62\u5f0f\u5316\u63a8\u5bfc\u7684\u590d\u6742\u6e10\u8fdb\u7c7b\u578b\u89c4\u7a0b\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u73b0\u7684\u9014\u5f84\u3002", "motivation": "\u73b0\u6709\u7684\u5728\u5177\u6709\u7ed3\u6784\u5316\u7c7b\u578b\u7684\u8bed\u8a00\u4e2d\u652f\u6301\u53ef\u9760\u6e10\u8fdb\u7c7b\u578b\u7684\u65b9\u6cd5\uff0c\u4e3b\u8981\u4f9d\u8d56\u4e8e\u57fa\u4e8e\u5f3a\u5236\u8f6c\u6362\u7684\u5b9e\u73b0\uff08\u5982Grift\uff09\u3002\u7136\u800c\uff0c\u62bd\u8c61\u6e10\u8fdb\u7c7b\u578b\uff08AGT\uff09\u65b9\u6cd5\u867d\u7136\u5728\u8bed\u4e49\u4e0a\u5177\u6709\u8868\u8fbe\u6027\u548c\u901a\u7528\u6027\uff0c\u5176\u57fa\u4e8e\u8bc1\u636e\u7684\u8fd0\u884c\u65f6\u8bed\u4e49\u662f\u5426\u80fd\u5b9e\u73b0\u9ad8\u6548\u7684\u6e10\u8fdb\u7c7b\u578b\u5b9e\u73b0\u5c1a\u4e0d\u660e\u786e\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u63a2\u7d22\u5e76\u9a8c\u8bc1\u57fa\u4e8e\u8bc1\u636e\u7684\u8bed\u4e49\u662f\u5426\u80fd\u6210\u4e3a\u5b9e\u73b0\u9ad8\u6548\u6e10\u8fdb\u7c7b\u578b\u7f16\u8bd1\u5668\u7684\u53ef\u884c\u9014\u5f84\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u3001\u5b9e\u73b0\u5e76\u8bc4\u4f30\u4e86\u4e00\u4e2a\u540d\u4e3aGrEv\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u6e10\u8fdb\u7c7b\u578b\u7f16\u8bd1\u5668\u3002\u4ed6\u4eec\u89e3\u91ca\u4e86\u5982\u4f55\u5f25\u5408\u5f62\u5f0f\u8bed\u4e49\u4e0e\u7f16\u8bd1\u5668\u5b9e\u73b0\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u5355\u8c03\u8bed\u4e49\u3002\u968f\u540e\uff0c\u4ed6\u4eec\u4f7f\u7528Grift\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u5bf9GrEv\u7684\u6027\u80fd\u8fdb\u884c\u4e86\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u8bc1\u636e\u7684\u7f16\u8bd1\u5668GrEv\u5728\u6027\u80fd\u4e0a\u53ef\u4ee5\u4e0e\u57fa\u4e8e\u5f3a\u5236\u8f6c\u6362\u7684\u7f16\u8bd1\u5668Grift\u76f8\u5ab2\u7f8e\uff0c\u751a\u81f3\u66f4\u5feb\u3002\u6b64\u5916\uff0cGrEv\u5728\u9759\u6001\u5230\u52a8\u6001\u8c31\u7cfb\u7684\u914d\u7f6e\u4e0a\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u7a33\u5b9a\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86GrEv\u7f16\u8bd1\u5668\uff0c\u5b83\u57fa\u4e8e\u8bc1\u636e\u7684\u8bed\u4e49\u5b9e\u73b0\u4e86\u6e10\u8fdb\u7c7b\u578b\uff0c\u5e76\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u53ef\u4ee5\u4e0e\u4f20\u7edf\u7684\u57fa\u4e8e\u5f3a\u5236\u8f6c\u6362\u7684\u7f16\u8bd1\u5668\uff08\u5982Grift\uff09\u76f8\u5ab2\u7f8e\u751a\u81f3\u66f4\u5feb\uff0c\u7279\u522b\u662f\u5728\u9759\u6001\u5230\u52a8\u6001\u8c31\u7cfb\u7684\u914d\u7f6e\u4e0a\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u7a33\u5b9a\u6027\u3002\u8fd9\u9879\u5de5\u4f5c\u4e0d\u4ec5\u4e30\u5bcc\u4e86\u6e10\u8fdb\u7c7b\u578b\u7f16\u8bd1\u5668\u7684\u9886\u57df\uff0c\u4e5f\u4e3a\u63a2\u7d22\u57fa\u4e8eAGT\u5f62\u5f0f\u5316\u63a8\u5bfc\u51fa\u7684\u590d\u6742\u6e10\u8fdb\u7c7b\u578b\u89c4\u7a0b\u7684\u9ad8\u6548\u5b9e\u73b0\u5f00\u8f9f\u4e86\u9053\u8def\u3002"}}
{"id": "2512.22147", "categories": ["cs.DC", "cs.AI", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.22147", "abs": "https://arxiv.org/abs/2512.22147", "authors": ["Ruifan Chu", "Anbang Wang", "Xiuxiu Bai", "Shuai Liu", "Xiaoshe Dong"], "title": "GPU Kernel Optimization Beyond Full Builds: An LLM Framework with Minimal Executable Programs", "comment": null, "summary": "In high-performance computing, hotspot GPU kernels are primary bottlenecks, and expert manual tuning is costly and hard to port. Large language model methods often assume kernels can be compiled and executed cheaply, which fails in large applications where full builds and runs are expensive. We present an end-to-end LLM framework with performance feedback that optimizes kernels without building the full application. From independently extracted hotspot kernels, it automatically completes code into a Minimal Executable Program (MEP), then performs multi-round iterative optimization and evaluation outside the full application. The framework integrates Automatic Error Repair and Performance Pattern Inheritance to fix faults, preserve correctness, reuse effective tiling/memory/synchronization strategies, and reduce search cost. Optimized variants are reintegrated into the original application for validation. We evaluate on NVIDIA GPUs and the Haiguang Deep Computing Unit (DCU) platform (AMD-licensed architecture) using PolyBench, the AMD APP SDK, and hotspot kernels from large-scale supercomputing applications. The method achieves average speedups of 5.05x (PolyBench on NVIDIA), 7.77x (PolyBench on DCU), 1.77x (AMD APP SDK), and 1.25x on three hotspot kernels, surpassing direct LLM optimization. The approach requires no full-source dependencies, offers cross-platform portability, and enables practical, low-cost GPU kernel optimization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e**\u7f16\u8bd1\u5668**\u548c**\u9ad8\u6027\u80fd\u8ba1\u7b97/GPU\u4f18\u5316**(\u5c5e\u4e8e\u5e7f\u4e49\u7684\u7f16\u8bd1\u5668\u4f18\u5316\u6216\u4ee3\u7801\u751f\u6210\u8303\u7574)\u76f8\u5173\u3002\u56e0\u4e3a\u5b83\u4e13\u6ce8\u4e8eGPU\u5185\u6838\u7684\u6027\u80fd\u4f18\u5316\uff0c\u5e76\u4f7f\u7528LLM\u6846\u67b6\u6765\u751f\u6210\u548c\u4f18\u5316\u4ee3\u7801\uff0c\u8fd9\u6d89\u53ca\u4ee3\u7801\u8f6c\u6362\u3001\u6027\u80fd\u8c03\u4f18\u548c\u8de8\u5e73\u53f0\u79fb\u690d\u3002\n\n**TLDR:** \u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aefLLM\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u4e0d\u6784\u5efa\u5b8c\u6574\u5e94\u7528\u7684\u60c5\u51b5\u4e0b\u4f18\u5316GPU\u70ed\u70b9\u5185\u6838\u3002\u5b83\u901a\u8fc7\u5c06\u5185\u6838\u8f6c\u5316\u4e3a\u6700\u5c0f\u53ef\u6267\u884c\u7a0b\u5e8f\uff08MEP\uff09\uff0c\u5e76\u5728\u5e94\u7528\u5916\u90e8\u8fdb\u884c\u591a\u8f6e\u8fed\u4ee3\u4f18\u5316\uff0c\u96c6\u6210\u4e86\u81ea\u52a8\u9519\u8bef\u4fee\u590d\u548c\u6027\u80fd\u6a21\u5f0f\u7ee7\u627f\uff0c\u4ee5\u63d0\u9ad8\u6548\u7387\u5e76\u4fdd\u6301\u6b63\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5728NVIDIA GPU\u548c\u6d77\u5149DCU\u4e0a\u5bf9PolyBench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u5b9e\u73b0\u4e86\u6700\u9ad87.77\u500d\u7684\u52a0\u901f\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u4f4e\u6210\u672c\u7684\u8de8\u5e73\u53f0GPU\u5185\u6838\u4f18\u5316\u65b9\u6848\u3002", "motivation": "\u5728\u9ad8\u6027\u80fd\u8ba1\u7b97\u4e2d\uff0cGPU\u70ed\u70b9\u5185\u6838\u662f\u4e3b\u8981\u7684\u6027\u80fd\u74f6\u9888\u3002\u4f20\u7edf\u7684\u4e13\u5bb6\u624b\u52a8\u8c03\u4f18\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u79fb\u690d\u3002\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5185\u6838\u53ef\u4ee5\u5ec9\u4ef7\u5730\u7f16\u8bd1\u548c\u6267\u884c\uff0c\u4f46\u8fd9\u4e0d\u9002\u7528\u4e8e\u5927\u578b\u5e94\u7528\u7a0b\u5e8f\uff0c\u56e0\u4e3a\u5b8c\u6574\u7684\u6784\u5efa\u548c\u8fd0\u884c\u6210\u672c\u6781\u9ad8\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u3001\u5177\u6709\u6027\u80fd\u53cd\u9988\u7684LLM\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u80fd\u591f\u5728\u4e0d\u6784\u5efa\u5b8c\u6574\u5e94\u7528\u7a0b\u5e8f\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u5185\u6838\uff0c\u4ee5\u5b9e\u73b0\u5b9e\u7528\u3001\u4f4e\u6210\u672c\u7684GPU\u5185\u6838\u4f18\u5316\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7684\u6838\u5fc3\u6b65\u9aa4\u5305\u62ec\uff1a1. **\u70ed\u70b9\u5185\u6838\u63d0\u53d6\u4e0e\u72ec\u7acb\u5316**\uff1a\u4ece\u5927\u578b\u5e94\u7528\u4e2d\u63d0\u53d6\u72ec\u7acb\u7684\u70ed\u70b9GPU\u5185\u6838\u30022. **\u6700\u5c0f\u53ef\u6267\u884c\u7a0b\u5e8f\uff08MEP\uff09\u751f\u6210**\uff1a\u81ea\u52a8\u5c06\u63d0\u53d6\u7684\u5185\u6838\u4ee3\u7801\u8865\u5168\u4e3a\u6700\u5c0f\u53ef\u6267\u884c\u7a0b\u5e8f\uff0c\u4f7f\u5176\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u5b8c\u6574\u5e94\u7528\u7684\u60c5\u51b5\u4e0b\u72ec\u7acb\u7f16\u8bd1\u548c\u8fd0\u884c\u30023. **\u591a\u8f6e\u8fed\u4ee3\u4f18\u5316\u4e0e\u8bc4\u4f30**\uff1a\u5728\u5b8c\u6574\u5e94\u7528\u7a0b\u5e8f\u5916\u90e8\uff0c\u5bf9MEP\u8fdb\u884c\u591a\u8f6e\u8fed\u4ee3\u4f18\u5316\u548c\u6027\u80fd\u8bc4\u4f30\u30024. **\u96c6\u6210\u4f18\u5316\u673a\u5236**\uff1a\u6846\u67b6\u96c6\u6210\u4e86\u201c\u81ea\u52a8\u9519\u8bef\u4fee\u590d\u201d\uff08Automatic Error Repair\uff09\u6765\u5904\u7406\u6545\u969c\uff0c\u4ee5\u53ca\u201c\u6027\u80fd\u6a21\u5f0f\u7ee7\u627f\u201d\uff08Performance Pattern Inheritance\uff09\u6765\u91cd\u7528\u6709\u6548\u7684\u6027\u80fd\u7b56\u7565\uff08\u5982\u5e73\u94fa\u3001\u5185\u5b58\u548c\u540c\u6b65\u7b56\u7565\uff09\uff0c\u4ee5\u4fdd\u6301\u6b63\u786e\u6027\u5e76\u51cf\u5c11\u641c\u7d22\u6210\u672c\u30025. **\u7ed3\u679c\u56de\u96c6\u6210\u4e0e\u9a8c\u8bc1**\uff1a\u5c06\u4f18\u5316\u540e\u7684\u53d8\u4f53\u91cd\u65b0\u96c6\u6210\u56de\u539f\u59cb\u5e94\u7528\u7a0b\u5e8f\u4e2d\u8fdb\u884c\u6700\u7ec8\u9a8c\u8bc1\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u5e73\u53f0\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1a1. **NVIDIA GPU (PolyBench)**\uff1a\u5e73\u5747\u52a0\u901f\u6bd4\u4e3a5.05\u500d\u30022. **\u6d77\u5149DCU (PolyBench)**\uff1a\u5e73\u5747\u52a0\u901f\u6bd4\u4e3a7.77\u500d\u30023. **AMD APP SDK**\uff1a\u52a0\u901f\u6bd4\u4e3a1.77\u500d\u30024. **\u5927\u578b\u8d85\u7b97\u5e94\u7528\u4e2d\u7684\u4e09\u4e2a\u70ed\u70b9\u5185\u6838**\uff1a\u52a0\u901f\u6bd4\u4e3a1.25\u500d\u3002\u8fd9\u4e9b\u7ed3\u679c\u5747\u8d85\u8fc7\u4e86\u76f4\u63a5\u4f7f\u7528LLM\u8fdb\u884c\u4f18\u5316\u7684\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u5b8c\u6574\u6e90\u4ee3\u7801\u4f9d\u8d56\uff0c\u5e76\u5177\u5907\u8de8\u5e73\u53f0\u79fb\u690d\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7aef\u5230\u7aefLLM\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u53ef\u6267\u884c\u7a0b\u5e8f\uff08MEP\uff09\u7684\u6784\u5efa\u548c\u5916\u90e8\u5e94\u7528\u7a0b\u5e8f\u7684\u591a\u8f6e\u8fed\u4ee3\u4f18\u5316\uff0c\u6709\u6548\u5730\u514b\u670d\u4e86\u4f20\u7edfLLM\u4f18\u5316\u65b9\u6cd5\u5728\u5927\u578b\u5e94\u7528\u4e2d\u7f16\u8bd1\u548c\u8fd0\u884c\u6210\u672c\u9ad8\u6602\u7684\u7f3a\u70b9\u3002\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u81ea\u52a8\u9519\u8bef\u4fee\u590d\u548c\u6027\u80fd\u6a21\u5f0f\u7ee7\u627f\uff0c\u63d0\u9ad8\u4e86\u4f18\u5316\u6548\u7387\u3001\u4fdd\u6301\u4e86\u4ee3\u7801\u6b63\u786e\u6027\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u96c6\u548c\u8de8\u5e73\u53f0\uff08NVIDIA GPU\u548c\u6d77\u5149DCU\uff09\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u5bf9\u4e8ePolyBench\u548cAMD APP SDK\uff0c\u5206\u522b\u5b9e\u73b0\u4e865.05\u500d\u52307.77\u500d\u548c1.77\u500d\u7684\u52a0\u901f\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u9ad8\u6027\u80fd\u8ba1\u7b97\u73af\u5883\u4e2d\u5bf9GPU\u5185\u6838\u4f18\u5316\u7684\u5b9e\u7528\u6027\u548c\u4f4e\u6210\u672c\u4f18\u52bf\u3002"}}
{"id": "2512.23468", "categories": ["cs.DS", "cs.CC"], "pdf": "https://arxiv.org/pdf/2512.23468", "abs": "https://arxiv.org/abs/2512.23468", "authors": ["Aryan Agarwala", "Nithin Varma"], "title": "Pseudodeterministic Algorithms for Minimum Cut Problems", "comment": "Accepted to ITCS 2026", "summary": "In this paper, we present efficient pseudodeterministic algorithms for both the global minimum cut and minimum s-t cut problems. The running time of our algorithm for the global minimum cut problem is asymptotically better than the fastest sequential deterministic global minimum cut algorithm (Henzinger, Li, Rao, Wang; SODA 2024).\n  Furthermore, we implement our algorithm in sequential, streaming, PRAM, and cut-query models, where no efficient deterministic global minimum cut algorithms are known.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\u76f8\u5173\u3002\u5b83\u63d0\u51fa\u4e86\u5168\u5c40\u6700\u5c0f\u5272\u548c\u6700\u5c0f $s$-$t$ \u5272\u7684\u9ad8\u6548\u4f2a\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u4f18\u4e8e\u76ee\u524d\u6700\u5feb\u7684\u987a\u5e8f\u786e\u5b9a\u6027\u5168\u5c40\u6700\u5c0f\u5272\u7b97\u6cd5\uff0c\u5e76\u6210\u529f\u5728\u987a\u5e8f\u3001\u6d41\u5f0f\u3001PRAM \u548c\u5272\u67e5\u8be2\u7b49\u591a\u79cd\u8ba1\u7b97\u6a21\u578b\u4e2d\u5b9e\u73b0\u3002", "motivation": "\u5168\u5c40\u6700\u5c0f\u5272\u548c\u6700\u5c0f $s$-$t$ \u5272\u662f\u56fe\u8bba\u4e2d\u7684\u57fa\u672c\u95ee\u9898\u3002\u5c3d\u7ba1\u5df2\u7ecf\u5b58\u5728\u786e\u5b9a\u6027\u7b97\u6cd5\uff0c\u4f46\u4f5c\u8005\u7684\u52a8\u673a\u5728\u4e8e\u8ffd\u6c42\u66f4\u9ad8\u7684\u6548\u7387\uff0c\u5c24\u5176\u662f\u5728\u901f\u5ea6\u4e0a\u8d85\u8d8a\u73b0\u6709\u7684\u6700\u597d\u786e\u5b9a\u6027\u7b97\u6cd5\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u4e5f\u5e0c\u671b\u5728\u7f3a\u4e4f\u9ad8\u6548\u786e\u5b9a\u6027\u5168\u5c40\u6700\u5c0f\u5272\u7b97\u6cd5\u7684\u5404\u79cd\u8ba1\u7b97\u6a21\u578b\uff08\u5982\u6d41\u5f0f\u3001PRAM\u7b49\uff09\u4e2d\u63d0\u4f9b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u7684\u6838\u5fc3\u65b9\u6cd5\u662f\u63d0\u51fa\u4e86\u5168\u5c40\u6700\u5c0f\u5272\u548c\u6700\u5c0f $s$-$t$ \u5272\u7684\u9ad8\u6548\u4f2a\u786e\u5b9a\u6027\u7b97\u6cd5\u3002\u867d\u7136\u6ca1\u6709\u8be6\u7ec6\u63cf\u8ff0\u7b97\u6cd5\u7684\u5177\u4f53\u6b65\u9aa4\uff0c\u4f46\u5f3a\u8c03\u4e86\u5176\u5728\u5404\u79cd\u8ba1\u7b97\u6a21\u578b\uff08\u987a\u5e8f\u3001\u6d41\u5f0f\u3001PRAM\u3001\u5272\u67e5\u8be2\u6a21\u578b\uff09\u4e2d\u7684\u5b9e\u73b0\u548c\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5176\u8fd0\u884c\u65f6\u95f4\u4f18\u4e8e\u73b0\u6709\u7684\u6700\u5feb\u987a\u5e8f\u786e\u5b9a\u6027\u7b97\u6cd5\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u5168\u5c40\u6700\u5c0f\u5272\u4f2a\u786e\u5b9a\u6027\u7b97\u6cd5\u5728\u8fd0\u884c\u65f6\u95f4\u4e0a\u6e10\u8fdb\u5730\u4f18\u4e8e\u76ee\u524d\u6700\u5feb\u7684\u987a\u5e8f\u786e\u5b9a\u6027\u5168\u5c40\u6700\u5c0f\u5272\u7b97\u6cd5\uff08Henzinger, Li, Rao, Wang; SODA 2024\uff09\u3002\u8be5\u7b97\u6cd5\u6210\u529f\u5730\u5728\u987a\u5e8f\u3001\u6d41\u5f0f\u3001PRAM \u548c\u5272\u67e5\u8be2\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5b9e\u73b0\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u4e3a\u5168\u5c40\u6700\u5c0f\u5272\u548c\u6700\u5c0f $s$-$t$ \u5272\u95ee\u9898\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u4f2a\u786e\u5b9a\u6027\u7b97\u6cd5\u3002\u8fd9\u4e9b\u7b97\u6cd5\u5728\u8fd0\u884c\u65f6\u4e0a\u4f18\u4e8e\u76ee\u524d\u6700\u5feb\u7684\u987a\u5e8f\u786e\u5b9a\u6027\u5168\u5c40\u6700\u5c0f\u5272\u7b97\u6cd5\uff0c\u5e76\u4e14\u5728\u987a\u5e8f\u3001\u6d41\u5f0f\u3001PRAM \u548c\u5272\u67e5\u8be2\u6a21\u578b\u7b49\u7f3a\u4e4f\u9ad8\u6548\u786e\u5b9a\u6027\u7b97\u6cd5\u7684\u573a\u666f\u4e0b\u5f97\u5230\u4e86\u6709\u6548\u7684\u5b9e\u73b0\uff0c\u5c55\u793a\u4e86\u4f2a\u786e\u5b9a\u6027\u65b9\u6cd5\u5728\u56fe\u7b97\u6cd5\u9886\u57df\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.22149", "categories": ["cs.DC", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2512.22149", "abs": "https://arxiv.org/abs/2512.22149", "authors": ["Guilin Zhang", "Wulan Guo", "Ziqi Tan"], "title": "Adaptive GPU Resource Allocation for Multi-Agent Collaborative Reasoning in Serverless Environments", "comment": "7 pages, 2 figures", "summary": "Multi-agent systems powered by large language models have emerged as a promising paradigm for solving complex reasoning tasks through collaborative intelligence. However, efficiently deploying these systems on serverless GPU platforms presents significant resource allocation challenges due to heterogeneous agent workloads, varying computational demands, and the need for cost-effective scaling. This paper presents an adaptive GPU resource allocation framework that achieves 85\\% latency reduction compared to round-robin scheduling while maintaining comparable throughput to static allocation, using an $O(N)$ complexity algorithm for real-time adaptation. Our approach dynamically allocates GPU resources based on workload characteristics, agent priorities, and minimum resource requirements, enabling efficient utilization while maintaining quality of service. The framework addresses three key challenges: (1) heterogeneous computational demands across lightweight coordinators and heavyweight specialists, (2) dynamic workload fluctuations requiring millisecond-scale reallocation, and (3) capacity constraints in serverless environments. Through comprehensive simulations modeling realistic multi-agent workflows with four heterogeneous agents, we demonstrate that adaptive allocation outperforms static equal and round-robin strategies across latency, cost, and GPU utilization metrics. The framework provides a practical solution for deploying cost-efficient multi-agent AI systems on serverless GPU infrastructure.", "AI": {"tldr": "This paper is related to **Compiler** (as it addresses resource allocation and deployment for AI systems, which often involves compiler-related optimization in the ML/AI domain, although not explicitly mentioned).\n\n\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u65e0\u670d\u52a1\u5668GPU\u5e73\u53f0\u4e0a\u90e8\u7f72\u65f6\uff0c\u9762\u4e34\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u3001\u52a8\u6001\u8ba1\u7b97\u9700\u6c42\u548c\u6210\u672c\u6548\u76ca\u4f38\u7f29\u5e26\u6765\u7684\u8d44\u6e90\u5206\u914d\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u81ea\u9002\u5e94GPU\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u4e00\u4e2a\u590d\u6742\u5ea6\u4e3aO(N)\u7684\u7b97\u6cd5\uff0c\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u3001\u667a\u80fd\u4f53\u4f18\u5148\u7ea7\u548c\u6700\u5c0f\u9700\u6c42\u52a8\u6001\u5206\u914d\u8d44\u6e90\u3002\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u5faa\u73af\u8c03\u5ea6\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u541e\u5410\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e8685%\u7684\u5ef6\u8fdf\u964d\u4f4e\uff0c\u5e76\u63d0\u9ad8\u4e86GPU\u5229\u7528\u7387\uff0c\u4e3a\u5728\u65e0\u670d\u52a1\u5668\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\u9ad8\u6210\u672c\u6548\u76ca\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u65e0\u670d\u52a1\u5668GPU\u5e73\u53f0\u4e0a\u90e8\u7f72\u65f6\uff0c\u9762\u4e34\u7740\u8d44\u6e90\u5206\u914d\u7684\u5de8\u5927\u6311\u6218\u3002\u4e3b\u8981\u539f\u56e0\u5305\u62ec\uff1a\u667a\u80fd\u4f53\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5f02\u6784\u6027\u3001\u8ba1\u7b97\u9700\u6c42\u7684\u53d8\u5316\u4ee5\u53ca\u5bf9\u6210\u672c\u6548\u76ca\u6269\u5c55\u7684\u8981\u6c42\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u9700\u8981\u89e3\u51b3(1)\u8f7b\u91cf\u7ea7\u534f\u8c03\u5668\u548c\u91cd\u91cf\u7ea7\u4e13\u5bb6\u4e4b\u95f4\u8ba1\u7b97\u9700\u6c42\u7684\u5f02\u6784\u6027\uff0c(2)\u9700\u8981\u6beb\u79d2\u7ea7\u91cd\u5206\u914d\u7684\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\uff0c\u548c(3)\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u7684\u5bb9\u91cf\u7ea6\u675f\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94GPU\u8d44\u6e90\u5206\u914d\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u4e86\u4e00\u4e2a\u590d\u6742\u5ea6\u4e3aO(N)\u7684\u7b97\u6cd5\u8fdb\u884c\u5b9e\u65f6\u8c03\u6574\u3002\u8be5\u65b9\u6cd5\u6839\u636e\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u3001\u667a\u80fd\u4f53\u4f18\u5148\u7ea7\u548c\u6700\u5c0f\u8d44\u6e90\u9700\u6c42\u52a8\u6001\u5206\u914dGPU\u8d44\u6e90\u3002\u5b83\u901a\u8fc7\u5efa\u6a21\u5305\u542b\u8f7b\u91cf\u7ea7\u534f\u8c03\u5668\u548c\u91cd\u91cf\u7ea7\u4e13\u5bb6\u7684\u5f02\u6784\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5e76\u5728\u5bb9\u91cf\u53d7\u9650\u7684\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u8fdb\u884c\u4eff\u771f\uff0c\u6765\u89e3\u51b3\u52a8\u6001\u5de5\u4f5c\u8d1f\u8f7d\u6ce2\u52a8\u548c\u5f02\u6784\u8ba1\u7b97\u9700\u6c42\u5e26\u6765\u7684\u6311\u6218\u3002", "result": "\u4e0e\u5faa\u73af\u8c03\u5ea6\uff08round-robin scheduling\uff09\u76f8\u6bd4\uff0c\u672c\u6587\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u5206\u914d\u7b56\u7565\u5b9e\u73b0\u4e8685%\u7684\u5ef6\u8fdf\u964d\u4f4e\u3002\u540c\u65f6\uff0c\u5b83\u4fdd\u6301\u4e86\u4e0e\u9759\u6001\u5206\u914d\u76f8\u5f53\u7684\u541e\u5410\u91cf\u3002\u8be5\u65b9\u6cd5\u91c7\u7528\u4e86\u590d\u6742\u5ea6\u4e3aO(N)\u7684\u7b97\u6cd5\u8fdb\u884c\u5b9e\u65f6\u9002\u5e94\uff0c\u5e76\u5728\u5ef6\u8fdf\u3001\u6210\u672c\u548cGPU\u5229\u7528\u7387\u65b9\u9762\u4f18\u4e8e\u9759\u6001\u7b49\u5206\u548c\u5faa\u73af\u8c03\u5ea6\u7b56\u7565\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u81ea\u9002\u5e94GPU\u8d44\u6e90\u5206\u914d\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u5728\u65e0\u670d\u52a1\u5668GPU\u5e73\u53f0\u4e0a\u90e8\u7f72LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6240\u9762\u4e34\u7684\u8d44\u6e90\u6311\u6218\u3002\u901a\u8fc7\u52a8\u6001\u5206\u914d\uff0c\u5b83\u5728\u4fdd\u6301\u541e\u5410\u91cf\u548c\u63d0\u9ad8\u8d44\u6e90\u5229\u7528\u7387\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\uff0885%\u7684\u5ef6\u8fdf\u964d\u4f4e\uff09\uff0c\u4ece\u800c\u4e3a\u5728\u65e0\u670d\u52a1\u5668\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\u9ad8\u6210\u672c\u6548\u76ca\u7684\u591a\u667a\u80fd\u4f53AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.23492", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2512.23492", "abs": "https://arxiv.org/abs/2512.23492", "authors": ["Christophe Paul", "Ignaz Rutter"], "title": "Circle graphs can be recognized in linear time", "comment": "To appear in 43rd International Symposium on Theoretical Aspects of Computer Science (STACS 2026)", "summary": "To date, the best circle graph recognition algorithm runs in almost linear time as it relies on a split decomposition algorithm that uses the union-find data-structure. We show that in the case of circle graphs, the PC-tree data-structure allows one to avoid the union-find data-structure to compute the split decomposition in linear time. As a consequence, we obtain the first linear-time recognition algorithm for circle graphs.", "AI": {"tldr": "This paper is related to graph processing. The paper presents the first linear-time recognition algorithm for circle graphs by replacing the union-find data structure with a PC-tree in the split decomposition algorithm, thereby achieving linear-time split decomposition calculation.", "motivation": "\u73b0\u6709\u7684\u6700\u4f73\u5706\u56fe\uff08circle graph\uff09\u8bc6\u522b\u7b97\u6cd5\u8fd0\u884c\u65f6\u95f4\u63a5\u8fd1\u7ebf\u6027\uff0c\u56e0\u4e3a\u5b83\u4f9d\u8d56\u4e8e\u4f7f\u7528union-find\u6570\u636e\u7ed3\u6784\u7684\u5206\u5272\u5206\u89e3\uff08split decomposition\uff09\u7b97\u6cd5\u3002\u4f5c\u8005\u7684\u52a8\u673a\u662f\u5e0c\u671b\u6d88\u9664\u5bf9union-find\u6570\u636e\u7ed3\u6784\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u5c06\u5706\u56fe\u8bc6\u522b\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u6b63\u5f0f\u4f18\u5316\u5230\u4e25\u683c\u7684\u7ebf\u6027\u65f6\u95f4$O(n+m)$\u3002", "method": "\u672c\u6587\u7684\u6838\u5fc3\u65b9\u6cd5\u662f\u4f7f\u7528PC\u6811\uff08Parent-Child tree, \u53ef\u80fd\u662f\u6307Prime-Component tree\u6216\u76f8\u5173\u7684\u5408\u6210\u5206\u89e3\u6811\uff09\u6570\u636e\u7ed3\u6784\u6765\u66ff\u4ee3\u73b0\u6709\u7684\u5706\u56fe\u8bc6\u522b\u7b97\u6cd5\u4e2d\u7684union-find\u6570\u636e\u7ed3\u6784\u8fdb\u884c\u5206\u5272\u5206\u89e3\uff08split decomposition\uff09\u7684\u8ba1\u7b97\u3002\u5177\u4f53\u800c\u8a00\uff0c\u901a\u8fc7\u8fd9\u79cd\u66ff\u4ee3\uff0c\u5b9e\u73b0\u4e86\u7ebf\u6027\u65f6\u95f4$O(n+m)$\u5185\u5b8c\u6210\u5206\u5272\u5206\u89e3\uff0c\u4ece\u800c\u4f7f\u6574\u4e2a\u5706\u56fe\u8bc6\u522b\u7b97\u6cd5\u8fbe\u5230\u7ebf\u6027\u65f6\u95f4\u3002", "result": "\u901a\u8fc7\u7528PC\u6811\u6570\u636e\u7ed3\u6784\u66ff\u6362\u5206\u5272\u5206\u89e3\u7b97\u6cd5\u4e2d\u7684union-find\u6570\u636e\u7ed3\u6784\uff0c\u4f5c\u8005\u6210\u529f\u5730\u5728\u5706\u56fe\u7684\u8bc6\u522b\u4e2d\u5b9e\u73b0\u4e86\u9996\u6b21\u7ebf\u6027\u65f6\u95f4$O(n+m)$\u8bc6\u522b\u7b97\u6cd5\u3002\u8fd9\u8868\u660ePC\u6811\u80fd\u591f\u5728\u7ebf\u6027\u65f6\u95f4\u5185\u5b8c\u6210\u5206\u5272\u5206\u89e3\u7684\u8ba1\u7b97\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u5c06\u5706\u56fe\u8bc6\u522b\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u7ebf\u6027\u65f6\u95f4$O(n+m)$\uff0c\u8fd9\u662f\u901a\u8fc7\u4f7f\u7528PC\u6811\u6570\u636e\u7ed3\u6784\u66ff\u4ee3\u73b0\u6709\u7b97\u6cd5\u4e2d\u4f7f\u7528\u7684union-find\u6570\u636e\u7ed3\u6784\u6765\u5b9e\u73b0\u7684\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u7ebf\u6027\u65f6\u95f4\u5185\u7684\u5206\u5272\u5206\u89e3\u8ba1\u7b97\u3002\u8fd9\u4f7f\u5f97\u5706\u56fe\u8bc6\u522b\u7b97\u6cd5\u9996\u6b21\u8fbe\u5230\u4e86\u7406\u8bba\u4e0a\u7684\u6700\u4f18\u65f6\u95f4\u590d\u6742\u5ea6\u3002"}}
{"id": "2512.23497", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23497", "abs": "https://arxiv.org/abs/2512.23497", "authors": ["Giuseppe De Palma", "Saverio Giallorenzo", "Ivan Lanese", "Gianluigi Zavattaro"], "title": "Adaptable TeaStore: A Choreographic Approach", "comment": "In Proceedings WACA 2025, arXiv:2512.22054", "summary": "The Adaptable TeaStore has recently been proposed as a reference model for adaptable microservice architectures. It includes different configurations, as well as scenarios requiring to transition between them. We describe an implementation of the Adaptable TeaStore based on AIOCJ, a choreographic language that allows one to program multiparty systems that can adapt at runtime to different conditions. Following the choreographic tradition, AIOCJ ensures by-construction correctness of communications (e.g., no deadlocks) before, during, and after adaptation. Adaptation is dynamic, and the adaptation scenarios need to be fully specified only at runtime. Using AIOCJ to model the Adaptable TeaStore, we showcase the strengths of the approach and its current limitations, providing suggestions for future directions for refining the paradigm (and the AIOCJ language, in particular), to better align it with real-world Cloud architectures.", "AI": {"tldr": "\u4e0d\u662f\uff08\u672c\u6587\u4e0d\u76f4\u63a5\u6d89\u53caDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\uff09\u3002\n\u672c\u6587\u5206\u6790\u4e86Adaptable TeaStore\u5fae\u670d\u52a1\u67b6\u6784\u53c2\u8003\u6a21\u578b\uff0c\u5e76\u5c06\u5176\u57fa\u4e8eAIOCJ\uff08\u4e00\u79cd\u7f16\u821e\u8bed\u8a00\uff09\u5b9e\u73b0\u3002AIOCJ\u7684\u7f16\u821e\u7279\u6027\u786e\u4fdd\u4e86\u7cfb\u7edf\u5728\u52a8\u6001\u9002\u5e94\u4e0d\u540c\u8fd0\u884c\u65f6\u914d\u7f6e\uff08\u5305\u62ec\u914d\u7f6e\u8f6c\u6362\uff09\u65f6\u7684\u901a\u4fe1\u6b63\u786e\u6027\uff08\u5982\u65e0\u6b7b\u9501\uff09\u3002\u8be5\u5de5\u4f5c\u8bc4\u4f30\u4e86AIOCJ\u5728\u53ef\u9002\u5e94\u5fae\u670d\u52a1\u4e2d\u7684\u80fd\u529b\u548c\u5f53\u524d\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u7684\u5fae\u670d\u52a1\u67b6\u6784\u901a\u5e38\u9700\u8981\u5177\u5907\u53ef\u9002\u5e94\u6027\uff08Adaptable\uff09\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u540c\u7684\u914d\u7f6e\u548c\u8fd0\u884c\u65f6\u6761\u4ef6\u3002Adaptable TeaStore \u662f\u4e3a\u6b64\u63d0\u51fa\u7684\u4e00\u4e2a\u53c2\u8003\u6a21\u578b\u3002\u4f5c\u8005\u7684\u52a8\u673a\u662f\u5229\u7528\u7f16\u821e\u8bed\u8a00AIOCJ\u7684\u7279\u6027\uff0c\u63d0\u4f9b\u4e00\u4e2a\u5177\u6709\u8fd0\u884c\u65f6\u9002\u5e94\u80fd\u529b\u4e14\u80fd\u4fdd\u8bc1\u901a\u4fe1\u6b63\u786e\u6027\uff08\u5982\u65e0\u6b7b\u9501\uff09\u7684\u5fae\u670d\u52a1\u67b6\u6784\u5b9e\u73b0\uff0c\u5e76\u8bc4\u4f30\u5176\u6709\u6548\u6027\u548c\u5c40\u9650\u6027\u3002", "method": "\u672c\u6587\u5c06\u53ef\u9002\u5e94\u7684TeaStore\u5fae\u670d\u52a1\u53c2\u8003\u6a21\u578b\u5b9e\u73b0\u57fa\u4e8eAIOCJ\uff08\u4e00\u79cd\u7f16\u821e\u8bed\u8a00\uff09\u3002AIOCJ\u5141\u8bb8\u5bf9\u591a\u65b9\u7cfb\u7edf\u8fdb\u884c\u7f16\u7a0b\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u8fd0\u884c\u65f6\u9002\u5e94\u4e0d\u540c\u7684\u6761\u4ef6\u3002\u8be5\u65b9\u6cd5\u9075\u5faa\u7f16\u821e\uff08choreographic\uff09\u4f20\u7edf\uff0c\u901a\u8fc7\u5728\u8bbe\u8ba1\u9636\u6bb5\u5206\u6790\u7cfb\u7edf\u901a\u4fe1\uff0c\u786e\u4fdd\u4e86\u5728\u9002\u5e94\uff08adaptation\uff09\u524d\u3001\u4e2d\u3001\u540e\u901a\u4fe1\u7684\u6b63\u786e\u6027\uff08\u5982\u65e0\u6b7b\u9501\uff09\u3002\u9002\u5e94\u662f\u52a8\u6001\u7684\uff0c\u9002\u5e94\u573a\u666f\u53ea\u9700\u8981\u5728\u8fd0\u884c\u65f6\u5b8c\u5168\u6307\u5b9a\u3002", "result": "\u901a\u8fc7\u4f7f\u7528AIOCJ\u5bf9Adaptable TeaStore\u8fdb\u884c\u5efa\u6a21\u548c\u5b9e\u73b0\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u52bf\uff1a\u5373\u5728\u652f\u6301\u8fd0\u884c\u65f6\u52a8\u6001\u9002\u5e94\u6027\u7684\u540c\u65f6\uff0c\u80fd\u591f\u786e\u4fdd\u901a\u4fe1\u7684\u6b63\u786e\u6027\u3002\u4f46\u540c\u65f6\u4e5f\u66b4\u9732\u4e86\u8be5\u65b9\u6cd5\u7684\u5f53\u524d\u5c40\u9650\u6027\uff0c\u5e76\u6839\u636e\u8fd9\u4e9b\u5c40\u9650\u6027\u63d0\u51fa\u4e86\u672a\u6765\u6539\u8fdb AIOCJ \u7f16\u7a0b\u8303\u5f0f\u548c\u8bed\u8a00\u7684\u5efa\u8bae\uff0c\u4ee5\u4f7f\u5176\u66f4\u597d\u5730\u4e0e\u771f\u5b9e\u4e16\u754c\u7684\u4e91\u67b6\u6784\u4fdd\u6301\u4e00\u81f4\u3002", "conclusion": "\u672c\u6587\u5c06\u53ef\u9002\u5e94\u7684TeaStore\u5fae\u670d\u52a1\u53c2\u8003\u6a21\u578b\u5b9e\u73b0\u57fa\u4e8eAIOCJ\uff08\u4e00\u79cd\u7f16\u821e\u8bed\u8a00\uff09\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7f16\u821e\u4f20\u7edf\uff0c\u786e\u4fdd\u4e86\u5728\u8fd0\u884c\u65f6\u9002\u5e94\u4e0d\u540c\u914d\u7f6e\u7684\u7cfb\u7edf\u7684\u901a\u4fe1\u6b63\u786e\u6027\uff08\u5982\u65e0\u6b7b\u9501\uff09\u3002\u8fd9\u5c55\u793a\u4e86AIOCJ\u5728\u5904\u7406\u590d\u6742\u4e14\u9700\u8981\u8fd0\u884c\u65f6\u9002\u5e94\u7684\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u4e5f\u6307\u51fa\u4e86\u8be5\u65b9\u6cd5\u5728\u66f4\u597d\u5951\u5408\u771f\u5b9e\u4e16\u754c\u4e91\u67b6\u6784\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2512.23552", "categories": ["cs.PL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23552", "abs": "https://arxiv.org/abs/2512.23552", "authors": ["Martin Sulzmann"], "title": "Beyond Per-Thread Lock Sets: Multi-Thread Critical Sections and Dynamic Deadlock Prediction", "comment": null, "summary": "Lock sets are commonly used for dynamic analysis of deadlocks. The standard per-thread lock set construction only considers locks acquired in the same thread, but is unaware of locks acquired in another thread. This leads to false positives and false negatives. The underlying issue is that the commonly used notion of a critical section on which the lock set construction relies ignores events from other threads. We give a trace-based characterization of critical sections that drops this restriction. Critical sections are no longer restricted to a single thread and can cover multiple threads. Such forms of critical sections exist, are natural, and correct the standard formulation.\n  We show how to soundly approximate the trace-based characterization via partial order relations. Thus, we obtain an improved lock set construction that can still be efficiently computed and allows us to remove false positives reported by the DIRK deadlock predictor and remove false negatives by extending the SPDOffline deadlock predictor. We integrate various lock set constructions with increased precision in an extension of SPDOffline. Our extensions remain sound (no false positives) but are more complete (fewer false negatives) w.r.t. SPDOffline. For an extensive standard benchmark suite we can also show that the performance is not affected.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\u90e8\u5206\uff08\u6b7b\u9501\u52a8\u6001\u5206\u6790\u3001\u9501\u96c6\u6784\u9020\uff09\uff0c\u4e0eHLS\u76f8\u5173\u90e8\u5206\uff08\u65e0\uff09\u3002\n\u592a\u957f\u4e0d\u8bfb\uff1a\u73b0\u6709\u6b7b\u9501\u5206\u6790\u5de5\u5177\u7684\u9501\u96c6\u7ed3\u6784\u56e0\u5ffd\u7565\u8de8\u7ebf\u7a0b\u4e8b\u4ef6\u800c\u5bfc\u81f4\u8bef\u62a5\u548c\u6f0f\u62a5\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ddf\u8e2a\u548c\u504f\u5e8f\u5173\u7cfb\u7684\u65b0\u4e34\u754c\u533a\u7279\u5f81\u5316\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u8de8\u7ebf\u7a0b\u7684\u9501\u96c6\u6784\u9020\uff0c\u4ece\u800c\u6539\u8fdb\u4e86\u9501\u96c6\u7cbe\u5ea6\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6d88\u9664DIRK\u7684\u8bef\u62a5\u5e76\u51cf\u5c11SPDOffline\u7684\u6f0f\u62a5\uff0c\u5728\u4e0d\u5f71\u54cd\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u63d0\u9ad8\u4e86\u6b7b\u9501\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6b7b\u9501\u52a8\u6001\u5206\u6790\u5de5\u5177\uff08\u5982\u4f7f\u7528\u9501\u96c6\uff09\u4f9d\u8d56\u4e8e\u6807\u51c6\u7684\u6bcf\u7ebf\u7a0b\u9501\u96c6\u7ed3\u6784\uff0c\u8be5\u7ed3\u6784\u53ea\u8003\u8651\u540c\u4e00\u7ebf\u7a0b\u4e2d\u83b7\u53d6\u7684\u9501\uff0c\u5ffd\u7565\u4e86\u5176\u4ed6\u7ebf\u7a0b\u4e2d\u83b7\u53d6\u7684\u9501\u3002\u8fd9\u79cd\u9650\u5236\u5bfc\u81f4\u4e86\u6b7b\u9501\u9884\u6d4b\u4e2d\u7684\u8bef\u62a5\uff08false positives\uff09\u548c\u6f0f\u62a5\uff08false negatives\uff09\u3002\n\u6839\u672c\u539f\u56e0\u5728\u4e8e\uff0c\u6807\u51c6\u7684\u4e34\u754c\u533a\u6982\u5ff5\u5ffd\u7565\u4e86\u6765\u81ea\u5176\u4ed6\u7ebf\u7a0b\u7684\u4e8b\u4ef6\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u63d0\u51fa\u4e00\u79cd\u66f4\u51c6\u786e\u7684\u3001\u80fd\u591f\u6db5\u76d6\u8de8\u7ebf\u7a0b\u4e8b\u4ef6\u7684\u4e34\u754c\u533a\u7279\u5f81\u5316\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u9501\u96c6\u7ed3\u6784\uff0c\u4ece\u800c\u63d0\u9ad8\u6b7b\u9501\u68c0\u6d4b\u7684\u7cbe\u5ea6\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5bf9\u4e34\u754c\u533a\u8fdb\u884c\u57fa\u4e8e\u8ddf\u8e2a\u7684\u7279\u5f81\u5316\uff0c\u6253\u7834\u4e86\u4f20\u7edf\u9501\u96c6\u7ed3\u6784\u4e2d\u4e34\u754c\u533a\u4ec5\u9650\u4e8e\u5355\u7ebf\u7a0b\u7684\u9650\u5236\u3002\u65b0\u7684\u4e34\u754c\u533a\u53ef\u8de8\u8d8a\u591a\u4e2a\u7ebf\u7a0b\uff0c\u66f4\u52a0\u7b26\u5408\u5b9e\u9645\u60c5\u51b5\u3002\n\u968f\u540e\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u504f\u5e8f\u5173\u7cfb\u6765\u6709\u58f0\u5730\u8fd1\u4f3c\u8fd9\u79cd\u57fa\u4e8e\u8ddf\u8e2a\u7684\u7279\u5f81\u5316\uff0c\u4ece\u800c\u5f97\u5230\u66f4\u7cbe\u786e\u4e14\u4ecd\u80fd\u9ad8\u6548\u8ba1\u7b97\u7684\u6539\u8fdb\u9501\u96c6\u7ed3\u6784\u3002\n\u6700\u540e\uff0c\u4f5c\u8005\u5c06\u8fd9\u4e9b\u6539\u8fdb\u7684\u9501\u96c6\u7ed3\u6784\u96c6\u6210\u5230SPDOffline\u7684\u6269\u5c55\u4e2d\uff0c\u5e76\u8bc1\u660e\u4e86\u5b83\u4eec\u5728\u4fdd\u8bc1\u5065\u5168\u6027\uff08\u65e0\u8bef\u62a5\uff09\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u5b8c\u6574\u6027\uff08\u51cf\u5c11\u6f0f\u62a5\uff09\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u9501\u96c6\u7ed3\u6784\uff1a\n1. **\u51cf\u5c11\u8bef\u62a5\uff08False Positives\uff09\uff1a** \u65b0\u7684\u9501\u96c6\u7ed3\u6784\u80fd\u591f\u6d88\u9664DIRK\u6b7b\u9501\u9884\u6d4b\u5668\u62a5\u544a\u7684\u8bef\u62a5\u3002\n2. **\u51cf\u5c11\u6f0f\u62a5\uff08False Negatives\uff09\u5e76\u63d0\u9ad8\u5b8c\u6574\u6027\uff08Completeness\uff09\uff1a** \u901a\u8fc7\u6269\u5c55SPDOffline\u6b7b\u9501\u9884\u6d4b\u5668\uff0c\u65b0\u7684\u9501\u96c6\u7ed3\u6784\u51cf\u5c11\u4e86\u6f0f\u62a5\uff0c\u4f7f\u5f97\u6b7b\u9501\u9884\u6d4b\u66f4\u52a0\u5b8c\u6574\u3002\n3. **\u4fdd\u6301\u5065\u5168\u6027\uff08Soundness\uff09\uff1a** \u76f8\u5bf9\u4e8eSPDOffline\uff0c\u6269\u5c55\u7684\u5de5\u5177\u4ecd\u4fdd\u6301\u4e86\u5065\u5168\u6027\uff08\u65e0\u8bef\u62a5\uff09\u3002\n4. **\u6027\u80fd\u65e0\u5f71\u54cd\uff1a** \u5728\u5e7f\u6cdb\u7684\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u7684\u6027\u80fd\u6ca1\u6709\u53d7\u5230\u5f71\u54cd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u52a8\u6001\u5206\u6790\u7684\u4e34\u754c\u533a\u7279\u5f81\u5316\u65b9\u6cd5\uff0c\u4ee5\u6539\u8fdb\u6b7b\u9501\u68c0\u6d4b\u4e2d\u7684\u9501\u96c6\u7ed3\u6784\u3002\u901a\u8fc7\u8003\u91cf\u8de8\u7ebf\u7a0b\u4e8b\u4ef6\uff0c\u65b0\u7684\u9501\u96c6\u7ed3\u6784\u80fd\u591f\u51cf\u5c11\u73b0\u6709\u6b7b\u9501\u9884\u6d4b\u5de5\u5177\uff08\u5982DIRK\u548cSPDOffline\uff09\u4e2d\u7684\u8bef\u62a5\u548c\u6f0f\u62a5\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u6b7b\u9501\u9884\u6d4b\u7684\u5b8c\u6574\u6027\uff0c\u5e76\u672a\u5f71\u54cd\u6027\u80fd\u3002"}}
{"id": "2512.22173", "categories": ["cs.DC", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.22173", "abs": "https://arxiv.org/abs/2512.22173", "authors": ["Aliaksandr V. Yakutovich", "Jusong Yu", "Daniel Hollas", "Edan Bainglass", "Corsin Battaglia", "Miki Bonacci", "Lucas Fernandez Vilanova", "Stephan Henne", "Anders Kaestner", "Michel Kenzelmann", "Graham Kimbell", "Jakob Lass", "Fabio Lopes", "Daniel G. Mazzone", "Andres Ortega-Guerrero", "Xing Wang", "Nicola Marzari", "Carlo A. Pignedoli", "Giovanni Pizzi"], "title": "AiiDAlab: on the route to accelerate science", "comment": null, "summary": "With the availability of ever-increasing computational capabilities, robust and automated research workflows are essential to enable and facilitate the execution and orchestration of large numbers of interdependent simulations in supercomputer facilities. However, the execution of these workflows still typically requires technical expertise in setting up calculation inputs, interpreting outputs, and handling the complexity of parallel code execution on remote machines. To address these challenges, the AiiDAlab platform was developed, making complex computational workflows accessible through an intuitive user interface that runs in a web browser. Here, we discuss how AiiDAlab has matured over the past few years, shifting its focus from computational materials science to become a powerful platform that accelerates scientific discovery across multiple disciplines. Thanks to its design, AiiDAlab allows scientists to focus on their research rather than on computational details and challenges, while keeping automatically track of the full simulation provenance via the underlying AiiDA engine and thus ensuring reproducibility. In particular, we discuss its adoption into quantum chemistry, atmospheric modeling, battery research, and even experimental data analysis at large-scale facilities, while also being actively used in educational settings. Driven by user feedback, significant effort has been made to simplify user onboarding, streamline access to computational resources, and provide robust mechanisms to work with large datasets. Furthermore, AiiDAlab is being integrated with electronic laboratory notebooks (ELNs), reinforcing adherence to the FAIR principles and supporting researchers in data-centric scientific disciplines in easily generating reproducible Open Research Data (ORD).", "AI": {"tldr": "\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u65e0\u5173\u3002\n\u6458\u8981\uff1aAiiDAlab\u5e73\u53f0\u5df2\u4ece\u8ba1\u7b97\u6750\u6599\u79d1\u5b66\u5de5\u4f5c\u6d41\u53d1\u5c55\u4e3a\u8de8\u5b66\u79d1\u7684\u79d1\u5b66\u53d1\u73b0\u52a0\u901f\u5668\u3002\u5b83\u901a\u8fc7\u76f4\u89c2\u7684\u7f51\u9875\u754c\u9762\u7b80\u5316\u590d\u6742\u7684\u8ba1\u7b97\u6d41\u7a0b\uff0c\u81ea\u52a8\u8ffd\u8e2a\u5b8c\u6574\u7684\u6a21\u62df\u6eaf\u6e90\uff0c\u786e\u4fdd\u4e86\u53ef\u91cd\u590d\u6027\uff0c\u5e76\u5df2\u88ab\u5e94\u7528\u4e8e\u591a\u4e2a\u9886\u57df\uff0c\u5305\u62ec\u91cf\u5b50\u5316\u5b66\u3001\u5927\u6c14\u5efa\u6a21\u7b49\uff0c\u540c\u65f6\u6b63\u5728\u96c6\u6210\u7535\u5b50\u5b9e\u9a8c\u7b14\u8bb0\u672c\u4ee5\u652f\u6301\u5f00\u653e\u7814\u7a76\u6570\u636e\uff08ORD\uff09\u3002", "motivation": "\u968f\u7740\u8ba1\u7b97\u80fd\u529b\u7684\u4e0d\u65ad\u589e\u5f3a\uff0c\u9700\u8981\u7a33\u5065\u4e14\u81ea\u52a8\u5316\u7684\u7814\u7a76\u5de5\u4f5c\u6d41\u6765\u5728\u8d85\u7ea7\u8ba1\u7b97\u8bbe\u65bd\u4e2d\u5b9e\u73b0\u548c\u534f\u8c03\u5927\u91cf\u76f8\u4e92\u4f9d\u8d56\u7684\u6a21\u62df\u3002\u7136\u800c\uff0c\u6267\u884c\u8fd9\u4e9b\u5de5\u4f5c\u6d41\u901a\u5e38\u9700\u8981\u6280\u672f\u4e13\u957f\u6765\u8bbe\u7f6e\u8ba1\u7b97\u8f93\u5165\u3001\u89e3\u91ca\u8f93\u51fa\u548c\u5904\u7406\u8fdc\u7a0b\u673a\u5668\u4e0a\u5e76\u884c\u4ee3\u7801\u6267\u884c\u7684\u590d\u6742\u6027\u3002AiiDAlab\u5e73\u53f0\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u901a\u8fc7\u76f4\u89c2\u7684\u7f51\u9875\u7528\u6237\u754c\u9762\u4f7f\u590d\u6742\u7684\u8ba1\u7b97\u5de5\u4f5c\u6d41\u53d8\u5f97\u6613\u4e8e\u8bbf\u95ee\uff0c\u4ece\u800c\u8ba9\u79d1\u5b66\u5bb6\u80fd\u591f\u4e13\u6ce8\u4e8e\u7814\u7a76\u800c\u975e\u8ba1\u7b97\u7ec6\u8282\u3002", "method": "\u6587\u7ae0\u63cf\u8ff0\u7684AiiDAlab\u5e73\u53f0\u662f\u5b9e\u73b0\u7a33\u5065\u548c\u81ea\u52a8\u5316\u7684\u7814\u7a76\u5de5\u4f5c\u6d41\u7684\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u76f4\u89c2\u7684\u7f51\u9875\u7528\u6237\u754c\u9762\u63d0\u4f9b\u5bf9\u590d\u6742\u8ba1\u7b97\u5de5\u4f5c\u6d41\u7684\u8bbf\u95ee\u548c\u7f16\u6392\uff0c\u5e76\u5229\u7528\u5e95\u5c42\u7684AiiDA\u5f15\u64ce\u81ea\u52a8\u8ddf\u8e2a\u5b8c\u6574\u7684\u6a21\u62df\u6eaf\u6e90\uff08provenance\uff09\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u91c7\u7528\u4e86\u7b80\u5316\u7528\u6237\u5165\u95e8\u3001\u7cbe\u7b80\u8ba1\u7b97\u8d44\u6e90\u8bbf\u95ee\u3001\u63d0\u4f9b\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u7684\u673a\u5236\uff0c\u5e76\u6b63\u96c6\u6210\u7535\u5b50\u5b9e\u9a8c\u7b14\u8bb0\u672c\uff08ELNs\uff09\u7b49\u65b9\u6cd5\u3002", "result": "AiiDAlab\u5df2\u53d1\u5c55\u6210\u4e3a\u4e00\u4e2a\u5f3a\u5927\u7684\u5e73\u53f0\uff0c\u52a0\u901f\u4e86\u8de8\u591a\u4e2a\u5b66\u79d1\u7684\u79d1\u5b66\u53d1\u73b0\uff0c\u5305\u62ec\u91cf\u5b50\u5316\u5b66\u3001\u5927\u6c14\u5efa\u6a21\u3001\u7535\u6c60\u7814\u7a76\u3001\u5927\u578b\u8bbe\u65bd\u7684\u5b9e\u9a8c\u6570\u636e\u5206\u6790\u4ee5\u53ca\u6559\u80b2\u8bbe\u7f6e\u3002\u5b83\u4f7f\u5f97\u79d1\u5b66\u5bb6\u80fd\u4e13\u6ce8\u4e8e\u7814\u7a76\uff0c\u540c\u65f6\u901a\u8fc7AiiDA\u5f15\u64ce\u81ea\u52a8\u8bb0\u5f55\u5b8c\u6574\u7684\u6a21\u62df\u6eaf\u6e90\uff0c\u786e\u4fdd\u4e86\u7ed3\u679c\u7684\u53ef\u91cd\u590d\u6027\u3002\u540c\u65f6\u7b80\u5316\u4e86\u7528\u6237\u5165\u95e8\u3001\u4f18\u5316\u4e86\u5bf9\u8ba1\u7b97\u8d44\u6e90\u7684\u8bbf\u95ee\uff0c\u5e76\u589e\u5f3a\u4e86\u5904\u7406\u5927\u578b\u6570\u636e\u96c6\u7684\u80fd\u529b\u3002\u6b64\u5916\uff0c\u5b83\u8fd8\u901a\u8fc7\u96c6\u6210\u7535\u5b50\u5b9e\u9a8c\u7b14\u8bb0\u672c\uff08ELNs\uff09\u52a0\u5f3a\u4e86\u5bf9FAIR\u539f\u5219\u7684\u9075\u5faa\uff0c\u652f\u6301\u4e86\u53ef\u91cd\u590d\u7684\u5f00\u653e\u7814\u7a76\u6570\u636e\uff08ORD\uff09\u7684\u751f\u6210\u3002", "conclusion": "AiiDAlab\u5df2\u4ece\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u8ba1\u7b97\u6750\u6599\u79d1\u5b66\u7684\u5e73\u53f0\u6210\u719f\u4e3a\u4e00\u4e2a\u5f3a\u5927\u7684\u8de8\u5b66\u79d1\u79d1\u5b66\u53d1\u73b0\u52a0\u901f\u5668\u3002\u5b83\u7b80\u5316\u4e86\u590d\u6742\u7684\u8ba1\u7b97\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4f7f\u7528\u6237\u80fd\u591f\u4e13\u6ce8\u4e8e\u7814\u7a76\uff0c\u540c\u65f6\u901a\u8fc7AiiDA\u5f15\u64ce\u81ea\u52a8\u8ddf\u8e2a\u6a21\u62df\u6eaf\u6e90\uff0c\u786e\u4fdd\u4e86\u53ef\u91cd\u590d\u6027\uff0c\u5e76\u6b63\u5728\u96c6\u6210\u7535\u5b50\u5b9e\u9a8c\u7b14\u8bb0\u672c\uff08ELNs\uff09\u4ee5\u7b26\u5408FAIR\u539f\u5219\u5e76\u652f\u6301\u751f\u6210\u5f00\u653e\u7814\u7a76\u6570\u636e\uff08ORD\uff09\u3002"}}
{"id": "2512.23657", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.23657", "abs": "https://arxiv.org/abs/2512.23657", "authors": ["Igor S. Sergeev"], "title": "A note on the depth of optimal fanout-bounded prefix circuits", "comment": "5 pages (in English); 5 pages (in Russian)", "summary": "It is shown that the minimal depth of an optimal prefix circuit (i.e., a zero-deficiency circuit) on $N$ inputs with fanout bounded by $k$ is ${\\log_{\u03b1_k} N \\pm O(1)}$, where $\u03b1_k$ is the unique positive root of the polynomial ${2+x+ x^2+\\ldots + x^{k-2}-x^k}$. This bound was previously known in the cases $k=2$ and $k=\\infty$.", "AI": {"tldr": "\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS\u76f8\u5173\u3002\u56e0\u4e3a\u5b83\u8ba8\u8bba\u4e86\u7535\u8def\u6df1\u5ea6\u548c\u6247\u51fa\u9650\u5236\uff0c\u8fd9\u76f4\u63a5\u5173\u7cfb\u5230\u8ba1\u7b97\u673a\u4f53\u7cfb\u7ed3\u6784\u3001\u786c\u4ef6\u8bbe\u8ba1\u548cHLS\uff08\u9ad8\u5c42\u6b21\u7efc\u5408\uff09\u4e2d\u7535\u8def\u4f18\u5316\u548c\u6027\u80fd\u5206\u6790\u3002\n\u592a\u957f\u4e0d\u770b\uff1a\u672c\u6587\u8bc1\u660e\u4e86\u5728\u6247\u51fa\u9650\u5236\u4e3a $k$ \u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u4f18\u524d\u7f00\u7535\u8def\u7684\u6700\u5c0f\u6df1\u5ea6\u662f ${\\log_{\u03b1_k} N \\pm O(1)}$\uff0c\u5176\u4e2d $\u03b1_k$ \u662f\u7531 $k$ \u51b3\u5b9a\u7684\u7279\u5b9a\u65b9\u7a0b\u7684\u6839\uff0c\u4ece\u800c\u63a8\u5e7f\u4e86 $k=2$ \u548c $k=\\infty$ \u65f6\u7684\u5df2\u77e5\u7ed3\u8bba\u3002", "motivation": "\u5bfb\u627e\u6700\u4f18\u524d\u7f00\u7535\u8def\uff08\u96f6\u7f3a\u9677\u7535\u8def\uff09\u5728\u6709\u9650\u6247\u51fa\u9650\u5236\uff08$k$\uff09\u4e0b\u7684\u6700\u5c0f\u6df1\u5ea6\uff0c\u4ee5\u786e\u5b9a\u7535\u8def\u8bbe\u8ba1\u7684\u7406\u8bba\u6027\u80fd\u754c\u9650\uff0c\u5e76\u63a8\u5e7f\u5148\u524d\u4ec5\u5728 $k=2$ \u548c $k=\\infty$ \u60c5\u51b5\u4e0b\u5df2\u77e5\u7684\u7ed3\u8bba\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u5206\u6790\u548c\u63a8\u5bfc\uff0c\u627e\u5230\u5e76\u8bc1\u660e\u4e86\u5728\u6247\u51fa\u53d7\u9650\u4e8e $k$ \u7684\u6761\u4ef6\u4e0b\uff0c\u6700\u4f18\u524d\u7f00\u7535\u8def\uff08\u96f6\u7f3a\u9677\u7535\u8def\uff09\u6700\u5c0f\u6df1\u5ea6\u7684\u7cbe\u786e\u6e10\u8fd1\u754c\u9650\uff0c\u8be5\u754c\u9650\u7531\u6d89\u53ca $k$ \u7684\u7279\u5b9a\u591a\u9879\u5f0f\u7684\u6839\u6765\u8868\u793a\u3002", "result": "\u5728\u6247\u51fa\u53d7\u9650\u4e8e $k$ \u7684 $N$ \u8f93\u5165\u4e0a\uff0c\u6700\u4f18\u524d\u7f00\u7535\u8def\uff08\u96f6\u7f3a\u9677\u7535\u8def\uff09\u7684\u6700\u5c0f\u6df1\u5ea6\u4e3a ${\\log_{\u03b1_k} N \\pm O(1)}$\uff0c\u5176\u4e2d $\u03b1_k$ \u662f\u591a\u9879\u5f0f ${2+x+ x^2+\\ldots + x^{k-2}-x^k}$ \u7684\u552f\u4e00\u6b63\u6839\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u6247\u51fa\u53d7\u9650\u4e8e $k$ \u7684\u60c5\u51b5\u4e0b\uff0c\u6700\u4f18\u524d\u7f00\u7535\u8def\u7684\u6700\u5c0f\u6df1\u5ea6\u4e3a ${\\log_{\u03b1_k} N \\pm O(1)}$\uff0c\u5176\u4e2d $\u03b1_k$ \u662f\u7279\u5b9a\u591a\u9879\u5f0f\u7684\u552f\u4e00\u6b63\u6839\u3002\u8fd9\u4e00\u7ed3\u8bba\u63a8\u5e7f\u4e86\u5148\u524d\u4ec5\u5728 $k=2$ \u548c $k=\\infty$ \u60c5\u51b5\u4e0b\u5df2\u77e5\u7684\u754c\u9650\u3002"}}
{"id": "2512.23665", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.23665", "abs": "https://arxiv.org/abs/2512.23665", "authors": ["Tim Vieira", "Ryan Cotterell", "Jason Eisner"], "title": "Automating the Analysis of Parsing Algorithms (and other Dynamic Programs)", "comment": "2021 manuscript; accepted by TACL but not revised for publication", "summary": "Much algorithmic research in NLP aims to efficiently manipulate rich formal structures. An algorithm designer typically seeks to provide guarantees about their proposed algorithm -- for example, that its running time or space complexity is upper-bounded as a certain function of its input size. They may also wish to determine the necessary properties of the quantities derived by the algorithm to synthesize efficient data structures and verify type errors. In this paper, we develop a system for helping programmers to perform these types of analyses. We apply our system to a number of NLP algorithms and find that it successfully infers types, dead and redundant code, and parametric runtime and space complexity bounds.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\uff0c\u867d\u7136\u6ca1\u6709\u76f4\u63a5\u6d89\u53caDSL\u6216\u56fe\u5904\u7406\u6216MLIR\u6216HLS\uff0c\u4f46\u5176\u5bf9\u7b97\u6cd5\u7684\u6027\u80fd\u5206\u6790\u548c\u4ee3\u7801\u4f18\u5316\uff08\u5982\u6b7b\u4ee3\u7801\u8bc6\u522b\u3001\u590d\u6742\u5ea6\u63a8\u65ad\uff09\u662f\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u6838\u5fc3\u8bfe\u9898\u4e4b\u4e00\u3002/\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u7cfb\u7edf\uff0c\u65e8\u5728\u5e2e\u52a9\u7a0b\u5e8f\u5458\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7b97\u6cd5\u8fdb\u884c\u5206\u6790\uff0c\u5305\u62ec\u63a8\u65ad\u7c7b\u578b\u3001\u8bc6\u522b\u6b7b\u4ee3\u7801\u548c\u5197\u4f59\u4ee3\u7801\uff0c\u4ee5\u53ca\u786e\u5b9a\u53c2\u6570\u5316\u7684\u8fd0\u884c\u65f6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e0a\u754c\uff0c\u5e76\u5728\u5b9e\u9645\u7684NLP\u7b97\u6cd5\u4e2d\u5f97\u5230\u4e86\u6210\u529f\u7684\u5e94\u7528\u3002", "motivation": "NLP\u7b97\u6cd5\u7684\u7814\u7a76\u901a\u5e38\u6d89\u53ca\u5bf9\u590d\u6742\u7684\u6b63\u5f0f\u7ed3\u6784\u8fdb\u884c\u9ad8\u6548\u64cd\u4f5c\uff0c\u7b97\u6cd5\u8bbe\u8ba1\u8005\u9700\u8981\u5bf9\u5176\u63d0\u51fa\u7684\u7b97\u6cd5\uff08\u5982\u8fd0\u884c\u65f6\u95f4\u6216\u7a7a\u95f4\u590d\u6742\u5ea6\uff09\u6216\u884d\u751f\u7684\u6570\u636e\u7ed3\u6784\u8fdb\u884c\u6027\u80fd\u4fdd\u8bc1\u548c\u5c5e\u6027\u786e\u5b9a\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u4e2a\u7cfb\u7edf\u6765\u534f\u52a9\u7a0b\u5e8f\u5458\u8fdb\u884c\u8fd9\u7c7b\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u4e00\u4e2a\u7cfb\u7edf\uff0c\u4e13\u6ce8\u4e8e\u5bf9NLP\u7b97\u6cd5\u8fdb\u884c\u5206\u6790\uff0c\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\u5bf9\u7b97\u6cd5\u8fdb\u884c\u5206\u6790\u4ee5\u63a8\u65ad\u7c7b\u578b\u3001\u8bc6\u522b\u6b7b\u4ee3\u7801\u548c\u5197\u4f59\u4ee3\u7801\uff0c\u4ee5\u53ca\u5f97\u51fa\u53c2\u6570\u5316\u7684\u8fd0\u884c\u65f6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u754c\u9650\u3002", "result": "\u8be5\u7cfb\u7edf\u6210\u529f\u5730\u5e94\u7528\u4e8e\u591a\u4e2aNLP\u7b97\u6cd5\uff0c\u5e76\u6210\u529f\u5730\u63a8\u65ad\u51fa\u7c7b\u578b\u3001\u6b7b\u4ee3\u7801\u3001\u5197\u4f59\u4ee3\u7801\uff0c\u4ee5\u53ca\u53c2\u6570\u5316\u7684\u8fd0\u884c\u65f6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e0a\u754c\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5f00\u53d1\u7684\u4e00\u4e2a\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u65e8\u5728\u5e2e\u52a9\u7a0b\u5e8f\u5458\u5bf9\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u7b97\u6cd5\u8fdb\u884c\u7c7b\u578b\u63a8\u65ad\u3001\u8bc6\u522b\u6b7b\u4ee3\u7801\u548c\u5197\u4f59\u4ee3\u7801\uff0c\u5e76\u63a8\u65ad\u53c2\u6570\u5316\u7684\u8fd0\u884c\u65f6\u548c\u7a7a\u95f4\u590d\u6742\u5ea6\u4e0a\u754c\u3002\u8be5\u7cfb\u7edf\u7684\u6210\u529f\u5e94\u7528\u8868\u660e\u5b83\u53ef\u4ee5\u6709\u6548\u5730\u5e2e\u52a9\u7b97\u6cd5\u8bbe\u8ba1\u8005\u8fdb\u884c\u6027\u80fd\u5206\u6790\u548c\u4ee3\u7801\u4f18\u5316\u3002"}}
{"id": "2512.23687", "categories": ["cs.DS", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.23687", "abs": "https://arxiv.org/abs/2512.23687", "authors": ["Juan Guti\u00e9rrez", "Sagartanu Pal"], "title": "The Minimum Subgraph Complementation Problem", "comment": null, "summary": "Subgraph complementation is an operation that toggles all adjacencies inside a selected vertex set. Given a graph \\(G\\) and a target class \\(\\mathcal{C}\\), the Minimum Subgraph Complementation problem asks for a minimum-size vertex set \\(S\\) such that complementing the subgraph induced by \\(S\\) transforms \\(G\\) into a graph belonging to \\(\\mathcal{C}\\). While the decision version of Subgraph Complementation has been extensively studied and is NP-complete for many graph classes, the algorithmic complexity of its optimization variant has remained largely unexplored.\n  In this paper, we study MSC from an algorithmic perspective. We present polynomial-time algorithms for MSC in several nontrivial settings. Our results include polynomial-time solvability for transforming graphs between bipartite, co-bipartite, and split graphs, as well as for complementing bipartite regular graphs into chordal graphs. We also show that MSC to the class of graphs of fixed degeneracy can be solved in polynomial time when the input graph is a forest. Moreover, we investigate MSC with respect to connectivity and prove that MSC to the class of disconnected graphs and to the class of 2-connected graphs can be solved in polynomial time for arbitrary inputs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\uff08\"Subgraph complementation\" on graphs, \"bipartite\", \"chordal graphs\"\uff09\u76f8\u5173\u3002\n\u6700\u5c0f\u5b50\u56fe\u8865\u5168\uff08MSC\uff09\u95ee\u9898\uff08\u5373\u627e\u5230\u6700\u5c0f\u7684\u9876\u70b9\u96c6$S$\uff0c\u901a\u8fc7\u5bf9$S$\u8bf1\u5bfc\u7684\u5b50\u56fe\u8fdb\u884c\u8865\u5168\u64cd\u4f5c\uff0c\u4f7f\u56fe$G$\u8f6c\u6362\u4e3a\u76ee\u6807\u56fe\u7c7b$\\mathcal{C}$\uff09\u7684\u51b3\u7b56\u7248\u672c\u7814\u7a76\u5e7f\u6cdb\uff0c\u4f46\u4f18\u5316\u53d8\u4f53\u7684\u7b97\u6cd5\u590d\u6742\u6027\u7814\u7a76\u4e0d\u8db3\u3002\u672c\u6587\u4ece\u7b97\u6cd5\u89d2\u5ea6\u7814\u7a76MSC\uff0c\u5e76\u5728\u591a\u79cd\u6311\u6218\u6027\u8bbe\u7f6e\u4e2d\u7ed9\u51fa\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5305\u62ec\u5728\u4e8c\u5206\u56fe\u3001\u4e92\u8865\u4e8c\u5206\u56fe\u548c\u5206\u88c2\u56fe\u4e4b\u95f4\u7684\u8f6c\u6362\u3001\u5c06\u4e8c\u5206\u6b63\u5219\u56fe\u8f6c\u6362\u4e3a\u5f26\u56fe\u3001\u5728\u8f93\u5165\u4e3a\u68ee\u6797\u65f6\u8f6c\u6362\u4e3a\u56fa\u5b9a\u9000\u5316\u5ea6\u56fe\u3001\u4ee5\u53ca\u8f6c\u6362\u4e3a\u4e0d\u8fde\u901a\u56fe\u548c2-\u8fde\u901a\u56fe\uff0c\u4ece\u800c\u663e\u8457\u63a8\u8fdb\u4e86MSC\u4f18\u5316\u95ee\u9898\u7684\u53ef\u89e3\u6027\u7814\u7a76\u3002", "motivation": "\u6700\u5c0f\u5b50\u56fe\u8865\u5168\uff08MSC\uff09\u95ee\u9898\u7684\u51b3\u7b56\u7248\u672c\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u4f18\u5316\u53d8\u4f53\u7684\u7b97\u6cd5\u590d\u6742\u6027\u5374\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u63a2\u7d22\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u4ece\u7b97\u6cd5\u89d2\u5ea6\u7814\u7a76MSC\u95ee\u9898\uff0c\u5e76\u4e3a\u5982\u4f55\u5728\u5404\u79cd\u7279\u5b9a\u56fe\u7c7b\u522b\u548c\u6027\u8d28\u4e4b\u95f4\u8fdb\u884c\u6700\u5c0f\u6210\u672c\u7684\u56fe\u8f6c\u6362\uff0c\u63d0\u4f9b\u9ad8\u6548\u7684\uff08\u591a\u9879\u5f0f\u65f6\u95f4\uff09\u7b97\u6cd5\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8bbe\u8ba1\u548c\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u6765\u89e3\u51b3\u6700\u5c0f\u5b50\u56fe\u8865\u5168\uff08MSC\uff09\u95ee\u9898\u5728\u591a\u79cd\u975e\u5e73\u51e1\u8bbe\u7f6e\u4e2d\u7684\u4f18\u5316\u53d8\u4f53\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\u5bf9\u5404\u7c7b\u76ee\u6807\u56fe\u6027\u8d28\uff08\u53cc\u5411\u56fe\u3001\u5206\u88c2\u56fe\u3001\u5f26\u56fe\u3001\u56fa\u5b9a\u9000\u5316\u5ea6\u3001\u8fde\u901a\u6027\uff09\u7684MSC\u95ee\u9898\u8fdb\u884c\u4e86\u6df1\u5165\u7684\u7b97\u6cd5\u590d\u6742\u5ea6\u5206\u6790\u548c\u6c42\u89e3\u3002", "result": "\u672c\u6587\u5728\u591a\u79cd\u975e\u5e73\u51e1\u8bbe\u7f6e\u4e0b\u4e3a\u6700\u5c0f\u5b50\u56fe\u8865\u5168\uff08MSC\uff09\u95ee\u9898\u63d0\u4f9b\u4e86\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002\u5177\u4f53\u7ed3\u679c\u5305\u62ec\uff1a1. \u8bc1\u660e\u4e86\u5728\u4e8c\u5206\u56fe\u3001\u4e92\u8865\u4e8c\u5206\u56fe\u548c\u5206\u88c2\u56fe\u4e4b\u95f4\u8fdb\u884c\u8f6c\u6362\u7684MSC\u95ee\u9898\u53ef\u4ee5\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u30022. \u8bc1\u660e\u4e86\u5c06\u4e8c\u5206\u6b63\u5219\u56fe\u8865\u5168\u4e3a\u5f26\u56fe\u7684MSC\u95ee\u9898\u4e5f\u662f\u591a\u9879\u5f0f\u65f6\u95f4\u53ef\u89e3\u30023. \u8bc1\u660e\u4e86\u5f53\u8f93\u5165\u56fe\u662f\u68ee\u6797\u65f6\uff0cMSC\u5230\u56fa\u5b9a\u9000\u5316\u5ea6\u56fe\u7c7b\u7684\u95ee\u9898\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u30024. \u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u610f\u8f93\u5165\u56fe\uff0cMSC\u5230\u4e0d\u8fde\u901a\u56fe\u7c7b\u548cMSC\u52302-\u8fde\u901a\u56fe\u7c7b\u7684\u95ee\u9898\u90fd\u53ef\u4ee5\u591a\u9879\u5f0f\u65f6\u95f4\u6c42\u89e3\u3002", "conclusion": "\u672c\u6587\u4fa7\u91cd\u4e8eMSC\u95ee\u9898\uff08\u6700\u5c0f\u5b50\u56fe\u8865\u5168\uff09\u7684\u7b97\u6cd5\u89d2\u5ea6\u7814\u7a76\uff0c\u901a\u8fc7\u63d0\u51fa\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u4e3a\u5728\u7279\u5b9a\u56fe\u7c7b\u4e4b\u95f4\u8f6c\u6362\u4ee5\u53ca\u6ee1\u8db3\u7279\u5b9a\u56fe\u6027\u8d28\uff08\u5982\u8fde\u901a\u6027\uff09\u7684MSC\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u586b\u8865\u4e86\u8be5\u9886\u57df\u4f18\u5316\u53d8\u4f53\u7b97\u6cd5\u7814\u7a76\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.22195", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22195", "abs": "https://arxiv.org/abs/2512.22195", "authors": ["Kun-Woo Shin", "Jay H. Park", "Moonwook Oh", "Yohan Jo", "Jaeyoung Do", "Sang-Won Lee"], "title": "MatKV: Trading Compute for Flash Storage in LLM Inference", "comment": "Accepted for publication in ICDE 2026", "summary": "We observe two major trends in LLM-based generative AI: (1) inference is becoming the dominant factor in terms of cost and power consumption, surpassing training, and (2) retrieval augmented generation (RAG) is becoming prevalent. When processing long inputs in RAG, the prefill phase of computing the key-value vectors of input text is energy-intensive and time-consuming even with high-end GPUs. Thus, it is crucial to make the prefill phase in RAG inference efficient. To address this issue, we propose MatKV, a scheme that precomputes the key-value vectors (KVs) of RAG objects (e.g., documents), materializes them in inexpensive but fast and power-efficient flash storage, and reuses them at inference time instead of recomputing the KVs using costly and power-inefficient GPU. Experimental results using Hugging Face's Transformers library across state-of-the-art GPUs and flash memory SSDs confirm that, compared to full KV computation on GPUs, MatKV reduces both inference time and power consumption by half for RAG workloads, without severely impacting accuracy in the question-answering task. Furthermore, we demonstrate that MatKV enables additional optimizations in two ways. First, a GPU can decode text while simultaneously loading the materialized KVs for the next instance, reducing load latency. Second, since decoding speed is less sensitive to GPU performance than KV computation, low-end GPUs can be leveraged for decoding without significantly compromising speed once the materialized KVs are loaded into GPU memory. These findings underscore MatKV's potential to make large-scale generative AI applications more cost-effective, power-efficient, and accessible across a wider range of tasks and hardware environments.", "AI": {"tldr": "\u662f\uff0c\u8be5\u8bba\u6587\u4e0e**\u7f16\u8bd1\u5668**\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u5173\u6ce8\u4e8e\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\u548c\u786c\u4ef6\u5229\u7528\uff0c\u7279\u522b\u662fKV\u8ba1\u7b97\u7684\u4f18\u5316\u662fLLM\u63a8\u7406\u6027\u80fd\u4f18\u5316\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u3002\u8bba\u6587\u4e2d\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5373\u9884\u8ba1\u7b97\u3001\u7269\u5316\u548c\u590d\u7528KVs\uff0c\u662f\u4e00\u79cd\u9488\u5bf9\u7279\u5b9a\u8ba1\u7b97\u6a21\u5f0f\u7684\u7cfb\u7edf\u7ea7\u4f18\u5316\uff0c\u8fd9\u4e0e\u7f16\u8bd1\u5668\u548c\u7cfb\u7edf\u4f18\u5316\u7684\u76ee\u6807\u4e00\u81f4\u3002TLDR: \u968f\u7740LLM\u751f\u6210\u5f0fAI\u4e2d\u63a8\u7406\u6210\u672c\u548cRAG\u7684\u666e\u53ca\uff0c\u8f93\u5165\u6587\u672cKV\u5411\u91cf\u8ba1\u7b97\uff08\u9884\u586b\u5145\u9636\u6bb5\uff09\u53d8\u5f97\u8017\u65f6\u4e14\u8017\u80fd\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0cMatKV\u65b9\u6848\u63d0\u51fa\u9884\u5148\u8ba1\u7b97RAG\u5bf9\u8c61\u7684KV\u5411\u91cf\u5e76\u5c06\u5176\u7269\u5316\u5230\u95ea\u5b58\uff08SSD\uff09\u4e2d\uff0c\u63a8\u7406\u65f6\u590d\u7528\u800c\u975e\u91cd\u65b0\u8ba1\u7b97\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cMatKV\u5c06RAG\u5de5\u4f5c\u8d1f\u8f7d\u7684\u63a8\u7406\u65f6\u95f4\u548c\u529f\u8017\u51cf\u5c11\u4e86\u4e00\u534a\uff0c\u4e14\u4e0d\u4e25\u91cd\u5f71\u54cd\u51c6\u786e\u6027\u3002MatKV\u8fd8\u5b9e\u73b0\u4e86\u6d41\u6c34\u7ebf\u52a0\u8f7d\u4f18\u5316\u548c\u4f4e\u7aefGPU\u89e3\u7801\u4f18\u5316\uff0c\u4f7f\u5927\u89c4\u6a21\u751f\u6210\u5f0fAI\u66f4\u5177\u6210\u672c\u6548\u76ca\u548c\u80fd\u6548\u3002", "motivation": "\u968f\u7740LLM\u751f\u6210\u5f0fAI\u7684\u53d1\u5c55\uff0c\u51fa\u73b0\u4e86\u4e24\u4e2a\u4e3b\u8981\u8d8b\u52bf\uff1a1\uff09\u63a8\u7406\u7684\u6210\u672c\u548c\u529f\u8017\u6b63\u5728\u6210\u4e3a\u4e3b\u5bfc\u56e0\u7d20\uff1b2\uff09\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u53d8\u5f97\u666e\u53ca\u3002\u5728RAG\u4e2d\u5904\u7406\u957f\u8f93\u5165\u65f6\uff0c\u8ba1\u7b97\u8f93\u5165\u6587\u672c\u7684\u952e\u503c\u5411\u91cf\uff08KVs\uff09\u7684\u9884\u586b\u5145\u9636\u6bb5\u5373\u4f7f\u5728\u9ad8\u7aefGPU\u4e0a\u4e5f\u662f\u80fd\u8017\u9ad8\u4e14\u8017\u65f6\u7684\uff0c\u56e0\u6b64\uff0c\u63d0\u9ad8RAG\u63a8\u7406\u4e2d\u9884\u586b\u5145\u9636\u6bb5\u7684\u6548\u7387\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86MatKV\u65b9\u6848\uff0c\u5176\u6838\u5fc3\u601d\u60f3\u662f\u9884\u5148\u8ba1\u7b97RAG\u5bf9\u8c61\uff08\u5982\u6587\u6863\uff09\u7684\u952e\u503c\u5411\u91cf\uff08KVs\uff09\uff0c\u5c06\u5b83\u4eec\u7269\u5316\uff08materialize\uff09\u5230\u5ec9\u4ef7\u3001\u5feb\u901f\u4e14\u8282\u80fd\u7684\u95ea\u5b58\u5b58\u50a8\u4e2d\uff0c\u5e76\u5728\u63a8\u7406\u65f6\u590d\u7528\u8fd9\u4e9bKVs\uff0c\u800c\u4e0d\u662f\u5728\u6602\u8d35\u4e14\u9ad8\u529f\u8017\u7684GPU\u4e0a\u91cd\u65b0\u8ba1\u7b97\u3002\u6b64\u5916\uff0cMatKV\u8fd8\u901a\u8fc7\u5141\u8bb8GPU\u5728\u89e3\u7801\u6587\u672c\u7684\u540c\u65f6\u52a0\u8f7d\u4e0b\u4e00\u4e2a\u5b9e\u4f8b\u7684\u7269\u5316KVs\uff0c\u4ee5\u53ca\u5229\u7528\u4f4e\u7aefGPU\u8fdb\u884c\u89e3\u7801\u7b49\u65b9\u5f0f\uff0c\u5b9e\u73b0\u4e86\u989d\u5916\u7684\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u5728GPU\u4e0a\u8fdb\u884c\u5b8c\u6574\u7684KV\u8ba1\u7b97\u76f8\u6bd4\uff0c\u5bf9\u4e8eRAG\u5de5\u4f5c\u8d1f\u8f7d\uff0cMatKV\u5c06\u63a8\u7406\u65f6\u95f4\u548c\u529f\u8017\u90fd\u51cf\u5c11\u4e86\u4e00\u534a\uff0c\u5e76\u4e14\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u6ca1\u6709\u4e25\u91cd\u5f71\u54cd\u51c6\u786e\u6027\u3002\u6b64\u5916\uff0cMatKV\u4f7f\u989d\u5916\u7684\u4f18\u5316\u6210\u4e3a\u53ef\u80fd\uff1a1\uff09GPU\u53ef\u4ee5\u5728\u89e3\u7801\u6587\u672c\u7684\u540c\u65f6\u52a0\u8f7d\u4e0b\u4e00\u4e2a\u5b9e\u4f8b\u7684\u7269\u5316KVs\uff0c\u51cf\u5c11\u52a0\u8f7d\u5ef6\u8fdf\uff1b2\uff09\u7531\u4e8e\u89e3\u7801\u901f\u5ea6\u5bf9GPU\u6027\u80fd\u7684\u654f\u611f\u6027\u4f4e\u4e8eKV\u8ba1\u7b97\uff0c\u56e0\u6b64\u5728\u52a0\u8f7d\u7269\u5316KVs\u5230GPU\u5185\u5b58\u540e\uff0c\u53ef\u4ee5\u5229\u7528\u4f4e\u7aefGPU\u8fdb\u884c\u89e3\u7801\u800c\u4e0d\u4f1a\u663e\u8457\u964d\u4f4e\u901f\u5ea6\u3002", "conclusion": "MatKV\u901a\u8fc7\u5c06\u9884\u8ba1\u7b97\u7684KV\u5411\u91cf\u7269\u5316\u5230\u95ea\u5b58\u5b58\u50a8\u4e2d\u5e76\u5728\u63a8\u7406\u65f6\u590d\u7528\uff0c\u53ef\u4ee5\u663e\u8457\u964d\u4f4eRAG\u5de5\u4f5c\u8d1f\u8f7d\u7684\u63a8\u7406\u65f6\u95f4\u548c\u529f\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u95ee\u7b54\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002\u5b83\u8fd8\u80fd\u5b9e\u73b0\u989d\u5916\u7684\u4f18\u5316\uff0c\u4f8b\u5982\u540c\u65f6\u8fdb\u884c\u6587\u672c\u89e3\u7801\u548cKV\u52a0\u8f7d\uff0c\u4ee5\u53ca\u5229\u7528\u4f4e\u7aefGPU\u8fdb\u884c\u89e3\u7801\u3002\u8fd9\u4e9b\u4f18\u52bf\u4f7fMatKV\u6210\u4e3a\u964d\u4f4e\u5927\u89c4\u6a21\u751f\u6210\u5f0fAI\u5e94\u7528\u6210\u672c\u548c\u80fd\u8017\uff0c\u5e76\u6269\u5927\u5176\u9002\u7528\u6027\u7684\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.22215", "categories": ["cs.DC", "cs.MS", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.22215", "abs": "https://arxiv.org/abs/2512.22215", "authors": ["Simone Bn\u00e0", "Giuseppe Giaquinto", "Ettore Fadiga", "Tommaso Zanelli", "Francesco Bottau"], "title": "SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM", "comment": "43 pages", "summary": "High Performance Computing (HPC) on hybrid clusters represents a significant opportunity for Computational Fluid Dynamics (CFD), especially when modern accelerators are utilized effectively. However, despite the widespread adoption of GPUs, programmability remains a challenge, particularly in open-source contexts. In this paper, we present SPUMA, a full GPU porting of OPENFOAM targeting NVIDIA and AMD GPUs. The implementation strategy is based on a portable programming model and the adoption of a memory pool manager that leverages the unified memory feature of modern GPUs. This approach is discussed alongside several numerical tests conducted on two pre-exascale clusters in Europe, LUMI and Leonardo, which host AMD MI250X and NVIDIA A100 GPUs, respectively. In the performance analysis section, we present results related to memory usage profiling and kernel wall-time, the impact of the memory pool, and energy consumption obtained by simulating the well-known DrivAer industrial test case. GPU utilization strongly affects strong scalability results, reaching 65% efficiency on both LUMI and Leonardo when approaching a load of 8 million cells per GPU. Weak scalability results, obtained on 20 GPUs with the OpenFOAM native multigrid solver, range from 75% on Leonardo to 85% on LUMI. Notably, efficiency is no lower than 90% when switching to the NVIDIA AmgX linear algebra solver. Our tests also reveal that one A100 GPU on Leonardo is equivalent 200-300 Intel Sapphire Rapids cores, provided the GPUs are sufficiently oversubscribed (more than 10 million of cells per GPU). Finally, energy consumption is reduced by up to 82% compared to analogous simulations executed on CPUs.", "AI": {"tldr": "This paper is related to ***Compiler*** (by discussing the impact of programming model and optimizations for parallel computing), ***Graph Processing*** (CFD simulations often involve mesh/graph-based computations), and ***HLS*** (High-Level Synthesis, although not directly mentioned, the focus on programmability and performance on heterogeneous hardware aligns with HLS goals). The paper is related to ***Compiler*** and ***Graph Processing***.\n\nSPUMA \u662f\u4e00\u4e2a\u5b8c\u6574\u7684 OpenFOAM GPU \u79fb\u690d\u65b9\u6848\uff0c\u5b83\u5229\u7528\u53ef\u79fb\u690d\u7f16\u7a0b\u6a21\u578b\u548c\u7edf\u4e00\u5185\u5b58\u7ba1\u7406\uff0c\u9996\u6b21\u5168\u9762\u652f\u6301 NVIDIA A100 \u548c AMD MI250X \u4e24\u79cd\u4e3b\u8981\u7684\u9884\u767e\u4ebf\u4ebf\u6b21\u7ea7 GPU\u3002\u5728 DrivAer \u5de5\u4e1a\u6848\u4f8b\u4e2d\uff0cSPUMA \u5c55\u73b0\u4e86\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\uff08\u5f3a\u53ef\u6269\u5c55\u6027\u8fbe 65%\uff0c\u5f31\u53ef\u6269\u5c55\u6027\u9ad8\u8fbe 85%\uff09\uff0c\u5e76\u5728\u4f7f\u7528\u9ad8\u6027\u80fd\u6c42\u89e3\u5668\u65f6\u6548\u7387\u53ef\u8fbe 90% \u4ee5\u4e0a\u3002\u6b64\u5916\uff0c\u4e00\u4e2a A100 GPU \u7684\u6027\u80fd\u76f8\u5f53\u4e8e 200-300 \u4e2a Intel Sapphire Rapids \u6838\u5fc3\uff0c\u5e76\u4e14\u80fd\u8017\u964d\u4f4e\u4e86\u9ad8\u8fbe 82%\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6848\u5728\u52a0\u901f\u8ba1\u7b97\u6d41\u4f53\u529b\u5b66\u548c\u63d0\u9ad8\u80fd\u6548\u65b9\u9762\u7684\u5de8\u5927\u6f5c\u529b\u3002", "motivation": "\u5c3d\u7ba1 GPU \u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\uff0c\u7279\u522b\u662f\u5728\u8ba1\u7b97\u6d41\u4f53\u529b\u5b66\uff08CFD\uff09\u9886\u57df\uff0c\u4f46***\u53ef\u7f16\u7a0b\u6027\u4ecd\u662f\u4e00\u4e2a\u6311\u6218***\uff0c\u7279\u522b\u662f\u5728***\u5f00\u6e90***\u73af\u5883\u4e2d\uff0c\u5982 OpenFOAM\u3002\u672c\u6587\u7684\u52a8\u673a\u662f***\u63d0\u4f9b\u4e00\u4e2a\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u7684\u5b8c\u6574 GPU \u79fb\u690d\u89e3\u51b3\u65b9\u6848\uff08SPUMA\uff09***\uff0c\u4ee5\u6709\u6548\u5730\u5229\u7528\u73b0\u4ee3\u52a0\u901f\u5668\u5728\u6df7\u5408\u96c6\u7fa4\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd CFD \u8ba1\u7b97\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86 SPUMA\uff0c\u8fd9\u662f\u5c06\u5f00\u6e90 CFD \u8f6f\u4ef6 OpenFOAM \u5b8c\u5168\u79fb\u690d\u5230 GPU \u7684\u65b9\u6cd5\u3002\u8be5\u5b9e\u73b0\u57fa\u4e8e\u4e00\u79cd***\u53ef\u79fb\u690d\u7f16\u7a0b\u6a21\u578b***\uff0c\u5e76\u91c7\u7528\u4e86\u5229\u7528\u73b0\u4ee3 GPU ***\u7edf\u4e00\u5185\u5b58***\u7279\u6027\u7684***\u5185\u5b58\u6c60\u7ba1\u7406\u5668***\u3002\u4e3a\u4e86\u9a8c\u8bc1\u6027\u80fd\uff0c\u4f5c\u8005\u5728\u6b27\u6d32\u7684\u4e24\u4e2a\u9884\u767e\u4ebf\u4ebf\u6b21\u7ea7\u96c6\u7fa4 LUMI\uff08AMD MI250X\uff09\u548c Leonardo\uff08NVIDIA A100\uff09\u4e0a\u8fdb\u884c\u4e86\u6570\u503c\u6d4b\u8bd5\uff0c\u7279\u522b\u5173\u6ce8\u4e86\u5185\u5b58\u4f7f\u7528\u3001\u5185\u6838\u8fd0\u884c\u65f6\u95f4\u3001\u5185\u5b58\u6c60\u7684\u5f71\u54cd\u4ee5\u53ca\u80fd\u8017\u3002\u6d4b\u8bd5\u6848\u4f8b\u662f\u8457\u540d\u7684 DrivAer \u5de5\u4e1a\u6d4b\u8bd5\u6848\u4f8b\u3002", "result": "1. **\u5f3a\u53ef\u6269\u5c55\u6027\uff1a** \u5728\u63a5\u8fd1\u6bcf\u4e2a GPU 800 \u4e07\u4e2a\u5355\u5143\u7684\u8d1f\u8f7d\u65f6\uff0c\u5728 LUMI \u548c Leonardo \u4e0a\u5747\u8fbe\u5230\u4e86 65% \u7684\u6548\u7387\u3002\n2. **\u5f31\u53ef\u6269\u5c55\u6027\uff1a** \u5728 20 \u4e2a GPU \u4e0a\u4f7f\u7528 OpenFOAM \u539f\u751f\u591a\u91cd\u7f51\u683c\u6c42\u89e3\u5668\u65f6\uff0c\u6548\u7387\u8303\u56f4\u4ece Leonardo \u4e0a\u7684 75% \u5230 LUMI \u4e0a\u7684 85%\u3002\n3. **\u6c42\u89e3\u5668\u5f71\u54cd\uff1a** \u5207\u6362\u5230 NVIDIA AmgX \u7ebf\u6027\u4ee3\u6570\u6c42\u89e3\u5668\u65f6\uff0c\u6548\u7387\u4e0d\u4f4e\u4e8e 90%\u3002\n4. **\u6027\u80fd\u5bf9\u6bd4\uff1a** \u5728\u8db3\u591f\u5927\u7684\u8d1f\u8f7d\uff08\u6bcf\u4e2a GPU \u8d85\u8fc7 1000 \u4e07\u4e2a\u5355\u5143\uff09\u4e0b\uff0cLeonardo \u4e0a\u7684\u4e00\u4e2a A100 GPU \u76f8\u5f53\u4e8e 200-300 \u4e2a Intel Sapphire Rapids \u6838\u5fc3\u3002\n5. **\u80fd\u8017\uff1a** \u4e0e\u5728 CPU \u4e0a\u6267\u884c\u7684\u7c7b\u4f3c\u6a21\u62df\u76f8\u6bd4\uff0c\u80fd\u8017\u964d\u4f4e\u4e86\u9ad8\u8fbe 82%\u3002\n6. **\u5173\u952e\u56e0\u7d20\uff1a** GPU \u5229\u7528\u7387\u5f3a\u70c8\u5f71\u54cd\u5f3a\u53ef\u6269\u5c55\u6027\u7ed3\u679c\u3002", "conclusion": "SPUMA \u6210\u529f\u5730\u5c06 OpenFOAM \u5b8c\u6574\u79fb\u690d\u5230\u4e86 NVIDIA \u548c AMD GPU \u4e0a\uff0c\u5e76\u5728 LUMI \u548c Leonardo \u4e24\u4e2a\u9884\u767e\u4ebf\u4ebf\u6b21\u7ea7\u96c6\u7fa4\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u6d4b\u8bd5\u3002\u7ed3\u679c\u8868\u660e\uff0cSPUMA \u5728\u5f3a\u53ef\u6269\u5c55\u6027\u548c\u5f31\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff08\u5206\u522b\u8fbe\u5230 65% \u548c 75%-85% \u7684\u6548\u7387\uff09\uff0c\u7279\u522b\u662f\u5728\u4f7f\u7528\u9ad8\u6027\u80fd\u7ebf\u6027\u4ee3\u6570\u6c42\u89e3\u5668\u5982 NVIDIA AmgX \u65f6\uff0c\u6548\u7387\u53ef\u8fbe 90% \u4ee5\u4e0a\u3002\u6b64\u5916\uff0c\u4e0e CPU \u76f8\u6bd4\uff0c\u57fa\u4e8e GPU \u7684 SPUMA \u5c06\u80fd\u8017\u964d\u4f4e\u4e86\u9ad8\u8fbe 82%\u3002\u8fd9\u8bc1\u660e\u4e86\u5728\u6df7\u5408\u96c6\u7fa4\u4e0a\u4f7f\u7528\u53ef\u79fb\u690d\u7f16\u7a0b\u6a21\u578b\u548c\u7edf\u4e00\u5185\u5b58\u7ba1\u7406\u52a0\u901f CFD \u5de5\u4f5c\u8d1f\u8f7d\u7684\u53ef\u884c\u6027\u548c\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.22231", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22231", "abs": "https://arxiv.org/abs/2512.22231", "authors": ["Nachiappan Chockalingam", "Akshay Deshpande", "Lokesh Butra", "Ram Sekhar Bodala", "Nitin Saksena", "Adithya Parthasarathy", "Balakrishna Pothineni", "Akash Kumar Agarwal"], "title": "Scalable Cloud-Native Architectures for Intelligent PMU Data Processing", "comment": null, "summary": "Phasor Measurement Units (PMUs) generate high-frequency, time-synchronized data essential for real-time power grid monitoring, yet the growing scale of PMU deployments creates significant challenges in latency, scalability, and reliability. Conventional centralized processing architectures are increasingly unable to handle the volume and velocity of PMU data, particularly in modern grids with dynamic operating conditions. This paper presents a scalable cloud-native architecture for intelligent PMU data processing that integrates artificial intelligence with edge and cloud computing. The proposed framework employs distributed stream processing, containerized microservices, and elastic resource orchestration to enable low-latency ingestion, real-time anomaly detection, and advanced analytics. Machine learning models for time-series analysis are incorporated to enhance grid observability and predictive capabilities. Analytical models are developed to evaluate system latency, throughput, and reliability, showing that the architecture can achieve sub-second response times while scaling to large PMU deployments. Security and privacy mechanisms are embedded to support deployment in critical infrastructure environments. The proposed approach provides a robust and flexible foundation for next-generation smart grid analytics.", "AI": {"tldr": "This content has not passed the compliance test and has been hidden.", "motivation": "\u968f\u7740\u76f8\u91cf\u6d4b\u91cf\u5355\u5143\uff08PMU\uff09\u90e8\u7f72\u89c4\u6a21\u7684\u4e0d\u65ad\u6269\u5927\uff0cPMU \u6570\u636e\u7684\u9ad8\u9891\u3001\u65f6\u95f4\u540c\u6b65\u7279\u6027\u7ed9\u5b9e\u65f6\u7535\u7f51\u76d1\u63a7\u5e26\u6765\u4e86\u5ef6\u8fdf\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u4e25\u5cfb\u6311\u6218\u3002\u4f20\u7edf\u7684\u96c6\u4e2d\u5f0f\u5904\u7406\u67b6\u6784\u8d8a\u6765\u8d8a\u96be\u4ee5\u5e94\u5bf9 PMU \u6570\u636e\u7684\u4f53\u91cf\u548c\u901f\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u8fd0\u884c\u6761\u4ef6\u52a8\u6001\u53d8\u5316\u7684\u73b0\u4ee3\u7535\u7f51\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u4f4e\u5ef6\u8fdf\u4e14\u53ef\u9760\u7684\u65b0\u578b\u67b6\u6784\u6765\u5904\u7406\u548c\u5206\u6790\u5927\u89c4\u6a21 PMU \u6570\u636e\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u4e91\u539f\u751f\u67b6\u6784\uff0c\u7528\u4e8e\u667a\u80fd PMU \u6570\u636e\u5904\u7406\u3002\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u3001\u8fb9\u7f18\u8ba1\u7b97\u548c\u4e91\u8ba1\u7b97\uff0c\u91c7\u7528\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u3001\u5bb9\u5668\u5316\u5fae\u670d\u52a1\u548c\u5f39\u6027\u8d44\u6e90\u7f16\u6392\u3002\u5176\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u6570\u636e\u6444\u53d6\u3001\u5b9e\u65f6\u5f02\u5e38\u68c0\u6d4b\u548c\u9ad8\u7ea7\u5206\u6790\uff1b\u96c6\u6210\u7528\u4e8e\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u4ee5\u589e\u5f3a\u7535\u7f51\u53ef\u89c2\u6d4b\u6027\u548c\u9884\u6d4b\u80fd\u529b\uff1b\u5f00\u53d1\u5206\u6790\u6a21\u578b\u6765\u8bc4\u4f30\u7cfb\u7edf\u7684\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u53ef\u9760\u6027\uff1b\u4ee5\u53ca\u5d4c\u5165\u5b89\u5168\u548c\u9690\u79c1\u673a\u5236\u3002", "result": "\u901a\u8fc7\u63d0\u51fa\u7684\u67b6\u6784\u548c\u5206\u6790\u6a21\u578b\u8bc4\u4f30\uff0c\u8bc1\u660e\u8be5\u67b6\u6784\u80fd\u591f\u5b9e\u73b0\u4e9a\u79d2\u7ea7\u7684\u54cd\u5e94\u65f6\u95f4\uff0c\u540c\u65f6\u53ef\u4ee5\u6269\u5c55\u5230\u5927\u89c4\u6a21\u7684 PMU \u90e8\u7f72\u3002\u8fd9\u8868\u660e\u8be5\u67b6\u6784\u6210\u529f\u5730\u89e3\u51b3\u4e86\u73b0\u6709\u7cfb\u7edf\u5728\u5904\u7406\u5927\u91cf PMU \u6570\u636e\u65f6\u9762\u4e34\u7684\u5ef6\u8fdf\u3001\u541e\u5410\u91cf\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u7535\u7f51\u7684\u53ef\u89c2\u6d4b\u6027\u548c\u9884\u6d4b\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8be5\u7cfb\u7edf\u8fd8\u5d4c\u5165\u4e86\u7528\u4e8e\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u73af\u5883\u7684\u5b89\u5168\u548c\u9690\u79c1\u673a\u5236\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u4e91\u539f\u751f PMU \u6570\u636e\u5904\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u6574\u5408 AI\u3001\u8fb9\u7f18\u548c\u4e91\u8ba1\u7b97\uff0c\u4ee5\u53ca\u91c7\u7528\u5206\u5e03\u5f0f\u6d41\u5904\u7406\u3001\u5bb9\u5668\u5316\u5fae\u670d\u52a1\u548c\u5f39\u6027\u8d44\u6e90\u7f16\u6392\u7b49\u6280\u672f\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u96c6\u4e2d\u5f0f\u67b6\u6784\u5728\u5904\u7406\u5927\u89c4\u6a21 PMU \u6570\u636e\u65f6\u9762\u4e34\u7684\u5ef6\u8fdf\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u6311\u6218\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u667a\u80fd\u7535\u7f51\u63d0\u4f9b\u4e86\u9ad8\u6027\u80fd\u3001\u5b89\u5168\u4e14\u7075\u6d3b\u7684\u5206\u6790\u57fa\u7840\u3002"}}
{"id": "2512.22402", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22402", "abs": "https://arxiv.org/abs/2512.22402", "authors": ["Bhanu Prakash Vangala", "Tanu Malik"], "title": "Efficient Multi-Model Orchestration for Self-Hosted Large Language Models", "comment": null, "summary": "Self-hosting large language models (LLMs) is increasingly appealing for organizations seeking privacy, cost control, and customization. Yet deploying and maintaining in-house models poses challenges in GPU utilization, workload routing, and reliability. We introduce Pick and Spin, a practical framework that makes self-hosted LLM orchestration scalable and economical. Built on Kubernetes, it integrates a unified Helm-based deployment system, adaptive scale-to-zero automation, and a hybrid routing module that balances cost, latency, and accuracy using both keyword heuristics and a lightweight DistilBERT classifier. We evaluate four models, Llama-3 (90B), Gemma-3 (27B), Qwen-3 (235B), and DeepSeek-R1 (685B) across eight public benchmark datasets, with five inference strategies, and two routing variants encompassing 31,019 prompts and 163,720 inference runs. Pick and Spin achieves up to 21.6% higher success rates, 30% lower latency, and 33% lower GPU cost per query compared with static deployments of the same models.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001HLS\u3001MLIR\u3001\u56fe\u5904\u7406\u548cDSL\u7b49\u6280\u672f\u4e0d\u76f4\u63a5\u76f8\u5173\u3002\n\n**\u592a\u957f\u4e0d\u770b (TLDR):** Pick and Spin\u662f\u4e00\u4e2a\u57fa\u4e8eKubernetes\u7684\u5b9e\u7528\u6846\u67b6\uff0c\u7528\u4e8e\u6269\u5c55\u548c\u4f18\u5316\u81ea\u6258\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u90e8\u7f72\u548c\u7f16\u6392\u3002\u5b83\u901a\u8fc7\u7edf\u4e00\u7684Helm\u90e8\u7f72\u3001\u81ea\u9002\u5e94\u7684\u89c4\u6a21\u5f52\u96f6\uff08Scale-to-Zero\uff09\u548c\u6df7\u5408\u8def\u7531\uff08\u7ed3\u5408\u5173\u952e\u8bcd\u548cDistilBERT\u5206\u7c7b\u5668\uff09\u6765\u63d0\u9ad8GPU\u5229\u7528\u7387\u548c\u53ef\u9760\u6027\u3002\u4e0e\u9759\u6001\u90e8\u7f72\u76f8\u6bd4\uff0c\u8be5\u6846\u67b6\u5728\u56db\u79cd\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u4e0a\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6210\u529f\u7387\uff08+21.6%\uff09\u3001\u66f4\u4f4e\u7684\u5ef6\u8fdf\uff08-30%\uff09\u548c\u66f4\u4f4e\u7684GPU\u6210\u672c\uff08-33%\uff09\u3002", "motivation": "\u7ec4\u7ec7\u51fa\u4e8e\u5bf9\u9690\u79c1\u3001\u6210\u672c\u63a7\u5236\u548c\u5b9a\u5236\u5316\u7684\u9700\u6c42\uff0c\u8d8a\u6765\u8d8a\u503e\u5411\u4e8e\u81ea\u6258\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3002\u7136\u800c\uff0c\u5728\u5185\u90e8\u7f72\u548c\u7ef4\u62a4\u8fd9\u4e9b\u6a21\u578b\u9762\u4e34\u7740GPU\u5229\u7528\u7387\u3001\u5de5\u4f5c\u8d1f\u8f7d\u8def\u7531\u548c\u53ef\u9760\u6027\u65b9\u9762\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e86\u57fa\u4e8eKubernetes\u7684\u6846\u67b6\uff0c\u5305\u542b\u7edf\u4e00\u7684Helm\u90e8\u7f72\u7cfb\u7edf\u3001\u81ea\u9002\u5e94\u7684Scale-to-Zero\u81ea\u52a8\u5316\uff0c\u4ee5\u53ca\u4e00\u4e2a\u6df7\u5408\u8def\u7531\u6a21\u5757\u3002\u8be5\u8def\u7531\u6a21\u5757\u7ed3\u5408\u4e86\u5173\u952e\u8bcd\u542f\u53d1\u5f0f\u548c\u8f7b\u91cf\u7ea7\u7684DistilBERT\u5206\u7c7b\u5668\uff0c\u7528\u4e8e\u5e73\u8861\u6210\u672c\u3001\u5ef6\u8fdf\u548c\u51c6\u786e\u6027\u3002\u901a\u8fc7\u8bc4\u4f30\u56db\u79cd\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\uff08Llama-3 (90B), Gemma-3 (27B), Qwen-3 (235B), DeepSeek-R1 (685B)\uff09\uff0c\u4e94\u79cd\u63a8\u7406\u7b56\u7565\uff0c\u4ee5\u53ca\u4e24\u79cd\u8def\u7531\u53d8\u4f53\uff0c\u5728\u516b\u4e2a\u516c\u5171\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e8631,019\u4e2a\u63d0\u793a\u548c163,720\u6b21\u63a8\u7406\u8fd0\u884c\u7684\u5168\u9762\u6d4b\u8bd5\u3002", "result": "\u4e0e\u76f8\u540c\u6a21\u578b\u7684\u9759\u6001\u90e8\u7f72\u76f8\u6bd4\uff0cPick and Spin\u6846\u67b6\u5c06\u6210\u529f\u7387\u63d0\u9ad8\u4e8621.6%\uff0c\u5ef6\u8fdf\u964d\u4f4e\u4e8630%\uff0c\u6bcf\u67e5\u8be2\u7684GPU\u6210\u672c\u964d\u4f4e\u4e8633%\u3002", "conclusion": "Pick and Spin\u6846\u67b6\u901a\u8fc7\u7edf\u4e00\u7684\u90e8\u7f72\u3001\u81ea\u9002\u5e94\u7684\u4f38\u7f29\u548c\u6df7\u5408\u8def\u7531\uff0c\u5b9e\u73b0\u4e86\u81ea\u6258\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u3001\u7ecf\u6d4e\u548c\u53ef\u9760\u8fd0\u884c\uff0c\u663e\u8457\u4f18\u4e8e\u9759\u6001\u90e8\u7f72\u3002"}}
{"id": "2512.22420", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.22420", "abs": "https://arxiv.org/abs/2512.22420", "authors": ["Rui Li", "Zhaoning Zhang", "Libo Zhang", "Huaimin Wang", "Xiang Fu", "Zhiquan Lai"], "title": "Nightjar: Dynamic Adaptive Speculative Decoding for Large Language Models Serving", "comment": "6 pages, 11 figures", "summary": "Speculative decoding (SD) accelerates LLM inference by verifying draft tokens in parallel. However, this method presents a critical trade-off: it improves throughput in low-load, memory-bound systems but degrades performance in high-load, compute-bound environments due to verification overhead. Current SD implementations use a fixed speculative length, failing to adapt to dynamic request rates and creating a significant performance bottleneck in real-world serving scenarios. To overcome this, we propose Nightjar, a novel learning-based algorithm for adaptive speculative inference that adjusts to request load by dynamically selecting the optimal speculative length for different batch sizes and even disabling speculative decoding when it provides no benefit. Experiments show that Nightjar achieves up to 14.8% higher throughput and 20.2% lower latency compared to standard speculative decoding, demonstrating robust efficiency for real-time serving.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL\u3001\u56fe\u5904\u7406\u3001MLIR \u6216 HLS \u65e0\u5173\u3002\n\n\u592a\u957f\u4e0d\u770b\uff1a\u6295\u673a\u89e3\u7801\uff08SD\uff09\u52a0\u901f LLM \u63a8\u7406\uff0c\u4f46\u56fa\u5b9a\u957f\u5ea6\u5728\u4e0d\u540c\u8d1f\u8f7d\u4e0b\u6027\u80fd\u4e0d\u4f73\u3002\u672c\u6587\u63d0\u51fa\u4e86 Nightjar\uff0c\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u81ea\u9002\u5e94 SD \u7b97\u6cd5\uff0c\u5b83\u80fd\u6839\u636e\u8bf7\u6c42\u8d1f\u8f7d\u52a8\u6001\u8c03\u6574\u6295\u673a\u957f\u5ea6\u6216\u7981\u7528 SD\uff0c\u4ece\u800c\u5728\u5b9e\u65f6\u670d\u52a1\u573a\u666f\u4e2d\u5b9e\u73b0\u9ad8\u8fbe 14.8% \u7684\u541e\u5410\u91cf\u63d0\u5347\u548c 20.2% \u7684\u5ef6\u8fdf\u964d\u4f4e\u3002", "motivation": "\u73b0\u6709\u7684 LLM \u63a8\u7406\u52a0\u901f\u65b9\u6cd5\u2014\u2014\u6295\u673a\u89e3\u7801\uff08Speculative Decoding\uff0cSD\uff09\u2014\u2014\u5728\u4f4e\u8d1f\u8f7d\u3001\u5185\u5b58\u53d7\u9650\u7684\u7cfb\u7edf\u4e2d\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\uff0c\u4f46\u5728\u9ad8\u8d1f\u8f7d\u3001\u8ba1\u7b97\u53d7\u9650\u7684\u73af\u5883\u4e2d\u7531\u4e8e\u9a8c\u8bc1\u5f00\u9500\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u5f53\u524d SD \u5b9e\u73b0\u4e2d\u7684\u56fa\u5b9a\u63a8\u6d4b\u957f\u5ea6\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u8bf7\u6c42\u901f\u7387\uff0c\u5728\u5b9e\u9645\u670d\u52a1\u573a\u666f\u4e2d\u9020\u6210\u4e86\u663e\u8457\u7684\u6027\u80fd\u74f6\u9888\u3002\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u63d0\u51fa Nightjar \u89e3\u51b3\u8fd9\u4e00\u5173\u952e\u7684\u6743\u8861\u95ee\u9898\u5e76\u4f18\u5316\u6027\u80fd\u3002", "method": "Nightjar \u662f\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u63a8\u6d4b\u63a8\u65ad\u7b97\u6cd5\u3002\u5b83\u4e0d\u662f\u4f7f\u7528\u56fa\u5b9a\u7684\u63a8\u6d4b\u957f\u5ea6\uff0c\u800c\u662f\u52a8\u6001\u5730\u9009\u62e9\u4e0d\u540c\u6279\u6b21\u5927\u5c0f\u7684\u6700\u4f73\u63a8\u6d4b\u957f\u5ea6\uff0c\u751a\u81f3\u5728\u6295\u673a\u89e3\u7801\u6ca1\u6709\u4f18\u52bf\u65f6\u5c06\u5176\u7981\u7528\uff0c\u4ee5\u9002\u5e94\u52a8\u6001\u7684\u8bf7\u6c42\u901f\u7387\u548c\u4e0d\u540c\u7684\u7cfb\u7edf\u8d1f\u8f7d\u3002", "result": "\u4e0e\u6807\u51c6\u7684\u6295\u673a\u89e3\u7801\u76f8\u6bd4\uff0cNightjar \u5b9e\u73b0\u4e86\u9ad8\u8fbe 14.8% \u7684\u541e\u5410\u91cf\u63d0\u5347\u548c 20.2% \u7684\u5ef6\u8fdf\u964d\u4f4e\u3002\u8fd9\u8868\u660e Nightjar \u5728\u5b9e\u65f6\u670d\u52a1\u4e2d\u5177\u6709\u5f3a\u5927\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Nightjar \u7684\u65b0\u9896\u7684\u57fa\u4e8e\u5b66\u4e60\u7684\u81ea\u9002\u5e94\u63a8\u65ad\u7b97\u6cd5\uff0c\u5b83\u80fd\u591f\u6839\u636e\u8bf7\u6c42\u8d1f\u8f7d\u52a8\u6001\u8c03\u6574\u63a8\u6d4b\u957f\u5ea6\uff0c\u5e76\u5728\u6ca1\u6709\u76ca\u5904\u65f6\u7981\u7528\u63a8\u6d4b\u89e3\u7801\u3002\u5b9e\u9a8c\u548c\u5206\u6790\u8868\u660e\uff0cNightjar \u5728\u541e\u5410\u91cf\u548c\u5ef6\u8fdf\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u7684\u6295\u673a\u89e3\u7801\uff0c\u5c55\u73b0\u51fa\u5728\u5b9e\u65f6\u670d\u52a1\u573a\u666f\u4e2d\u7684\u5f3a\u5927\u6548\u7387\uff0c\u6700\u9ad8\u53ef\u5b9e\u73b0 14.8% \u7684\u541e\u5410\u91cf\u63d0\u5347\u548c 20.2% \u7684\u5ef6\u8fdf\u964d\u4f4e\u3002"}}
{"id": "2512.22492", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22492", "abs": "https://arxiv.org/abs/2512.22492", "authors": ["Zhenqian Chen", "Baoquan Zhong", "Xiang Li", "Qing Dai", "Xinkui Zhao", "Miao Ye", "Ren Cheng", "Lufei Zhang", "Jianwei Yin"], "title": "Role-Based Fault Tolerance System for LLM RL Post-Training", "comment": "16 pages, 19 figures", "summary": "RL post-training for LLMs has been widely scaled to enhance reasoning and tool-using capabilities. However, RL post-training interleaves training and inference workloads, exposing the system to faults from both sides. Existing fault tolerance frameworks for LLMs target either training or inference, leaving the optimization potential in the asynchronous execution unexplored for RL. Our key insight is role-based fault isolation so the failure in one machine does not affect the others. We treat trainer, rollout, and other management roles in RL training as distinct distributed sub-tasks. Instead of restarting the entire RL task in ByteRobust, we recover only the failed role and reconnect it to living ones, thereby eliminating the full-restart overhead including rollout replay and initialization delay.\n  We present RobustRL, the first comprehensive robust system to handle GPU machine errors for RL post-training Effective Training Time Ratio improvement. (1) \\textit{Detect}. We implement role-aware monitoring to distinguish actual failures from role-specific behaviors to avoid the false positive and delayed detection. (2) \\textit{Restart}. For trainers, we implement a non-disruptive recovery where rollouts persist state and continue trajectory generation, while the trainer is rapidly restored via rollout warm standbys. For rollout, we perform isolated machine replacement without interrupting the RL task. (3) \\textit{Reconnect}. We replace static collective communication with dynamic, UCX-based (Unified Communication X) point-to-point communication, enabling immediate weight synchronization between recovered roles. In an RL training task on a 256-GPU cluster with Qwen3-8B-Math workload under 10\\% failure injection frequency, RobustRL can achieve an ETTR of over 80\\% compared with the 60\\% in ByteRobust and achieves 8.4\\%-17.4\\% faster in end-to-end training time.", "AI": {"tldr": "\u76f8\u5173\u6027\uff1a\u8be5\u8bba\u6587\u4e0e**\u7f16\u8bd1\u5668**\uff08\u7cfb\u7edf\u4f18\u5316\uff09\u3001**\u56fe\u5904\u7406**\uff08\u5206\u5e03\u5f0f\u7cfb\u7edf\u548c\u901a\u4fe1\u673a\u5236\uff09\u548c**MLIR**\uff08\u7cfb\u7edf\u5e95\u5c42\u4f18\u5316\uff0c\u867d\u7136\u672a\u76f4\u63a5\u63d0\u53ca\u4f46\u76f8\u5173\u6027\u8f83\u5f31\uff09\u548c**HLS**\uff08\u786c\u4ef6\u7cfb\u7edf\u8bbe\u8ba1\uff0c\u867d\u7136\u672a\u76f4\u63a5\u63d0\u53ca\u4f46\u76f8\u5173\u6027\u8f83\u5f31\uff09\u548c**DSL**\uff08\u9886\u57df\u7279\u5b9a\u8bed\u8a00\uff0c\u672a\u76f4\u63a5\u63d0\u53ca\uff09\u548c**\u7f16\u8bd1\u5668**\uff08\u867d\u7136\u672a\u76f4\u63a5\u63d0\u53ca\u4f46\u7cfb\u7edf\u7ea7\u4f18\u5316\u76f8\u5173\uff09\u4e0d\u76f4\u63a5\u76f8\u5173\u3002\u6700\u76f8\u5173\u7684\u9886\u57df\u662f**\u5206\u5e03\u5f0f\u7cfb\u7edf/\u9ad8\u6027\u80fd\u8ba1\u7b97**\u548c**\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8bad\u7ec3/RL\u540e\u8bad\u7ec3**\u3002TLDR: \u73b0\u6709LLM RL\u540e\u8bad\u7ec3\u7684\u6545\u969c\u5bb9\u5fcd\u7cfb\u7edf\u5728\u5904\u7406\u8bad\u7ec3\u548c\u63a8\u7406\u4ea4\u9519\u7684\u5de5\u4f5c\u8d1f\u8f7d\u65f6\u6548\u7387\u4f4e\u4e0b\uff0c\u7ecf\u5e38\u9700\u8981\u91cd\u542f\u6574\u4e2a\u4efb\u52a1\uff0c\u9020\u6210\u5de8\u5927\u5f00\u9500\u3002RobustRL\u662f\u9996\u4e2a\u9488\u5bf9RL\u540e\u8bad\u7ec3\u4e2dGPU\u673a\u5668\u9519\u8bef\u7684\u5168\u9762\u9c81\u68d2\u7cfb\u7edf\uff0c\u901a\u8fc7\u57fa\u4e8e**\u89d2\u8272\u7684\u6545\u969c\u9694\u79bb**\uff0c\u5c06Trainer\u3001Rollout\u7b49\u89c6\u4e3a\u72ec\u7acb\u5b50\u4efb\u52a1\u3002\u5f53\u6545\u969c\u53d1\u751f\u65f6\uff0cRobustRL\u4ec5\u6062\u590d\u5931\u8d25\u7684\u89d2\u8272\u5e76\u91cd\u65b0\u8fde\u63a5\u5230\u5b58\u6d3b\u7684\u89d2\u8272\uff0c\u907f\u514d\u4e86\u5168\u4efb\u52a1\u91cd\u542f\u7684\u5f00\u9500\uff08\u5982Rollout\u91cd\u653e\uff09\u3002\u5b83\u901a\u8fc7\u89d2\u8272\u611f\u77e5\u68c0\u6d4b\u3001\u975e\u7834\u574f\u6027\u6062\u590d\u548c\u52a8\u6001UCX\u70b9\u5bf9\u70b9\u901a\u4fe1\u540c\u6b65\u6743\u91cd\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6709\u6548\u8bad\u7ec3\u65f6\u95f4\u6bd4\uff08ETTR\uff09\u3002\u5b9e\u9a8c\u663e\u793a\uff0c\u572810%\u6545\u969c\u6ce8\u5165\u4e0b\uff0cRobustRL\u7684ETTR\u8d85\u8fc780%\uff08\u76f8\u6bd4\u4e8eByteRobust\u768460%\uff09\uff0c\u5e76\u4f7f\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u52a0\u5feb8.4%\u81f317.4%\u3002", "motivation": "\u73b0\u6709\u7684LLM\u6545\u969c\u5bb9\u5fcd\u6846\u67b6\u5927\u591a\u53ea\u9488\u5bf9\u8bad\u7ec3\u6216\u63a8\u7406\uff0c\u6ca1\u6709\u5145\u5206\u63a2\u7d22RL\u540e\u8bad\u7ec3\u4e2d\u8bad\u7ec3\u548c\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u4ea4\u9519\u6267\u884c\u6240\u5e26\u6765\u7684\u5f02\u6b65\u4f18\u5316\u6f5c\u529b\u3002RL\u540e\u8bad\u7ec3\u4e2d\u7684\u6545\u969c\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u9762\u4e34\u6765\u81ea\u8bad\u7ec3\u548c\u63a8\u7406\u4e24\u65b9\u9762\u7684\u98ce\u9669\u3002\u73b0\u6709\u7684\u6545\u969c\u6062\u590d\u7b56\u7565\uff08\u5982ByteRobust\uff09\u901a\u5e38\u9700\u8981\u91cd\u542f\u6574\u4e2aRL\u4efb\u52a1\uff0c\u8fd9\u4f1a\u5bfc\u81f4\u5de8\u5927\u7684\u5f00\u9500\uff0c\u5305\u62ecRollout\u91cd\u653e\u548c\u521d\u59cb\u5316\u5ef6\u8fdf\uff0c\u4ece\u800c\u964d\u4f4e\u8bad\u7ec3\u6548\u7387\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u65b0\u7684\u9c81\u68d2\u7cfb\u7edf\u6765\u63d0\u9ad8RL\u540e\u8bad\u7ec3\u5728\u9762\u4e34GPU\u673a\u5668\u6545\u969c\u65f6\u7684\u6709\u6548\u8bad\u7ec3\u65f6\u95f4\u6bd4\uff08ETTR\uff09\u3002", "method": "RobustRL\u901a\u8fc7\u4e09\u6b65\u6cd5\u5b9e\u73b0\u5176\u9c81\u68d2\u6027\uff1a1. **\u68c0\u6d4b\uff08Detect\uff09**\uff1a\u5b9e\u73b0\u89d2\u8272\u611f\u77e5\u76d1\u63a7\uff0c\u533a\u5206\u771f\u5b9e\u6545\u969c\u4e0e\u89d2\u8272\u7279\u5b9a\u884c\u4e3a\uff0c\u907f\u514d\u8bef\u62a5\u548c\u5ef6\u8fdf\u68c0\u6d4b\u30022. **\u91cd\u542f\uff08Restart\uff09**\uff1a\u5bf9\u8bad\u7ec3\u5668\uff08Trainer\uff09\u91c7\u7528\u975e\u7834\u574f\u6027\u6062\u590d\uff0c\u8ba9Rollout\u89d2\u8272\u6301\u4e45\u5316\u72b6\u6001\u5e76\u7ee7\u7eed\u8f68\u8ff9\u751f\u6210\uff0c\u5e76\u901a\u8fc7Rollout\u70ed\u5907\uff08warm standbys\uff09\u5feb\u901f\u6062\u590d\u8bad\u7ec3\u5668\u3002\u5bf9Rollout\u89d2\u8272\u5219\u6267\u884c\u9694\u79bb\u7684\u673a\u5668\u66ff\u6362\u30023. **\u91cd\u65b0\u8fde\u63a5\uff08Reconnect\uff09**\uff1a\u7528\u52a8\u6001\u3001\u57fa\u4e8eUCX\u7684\u70b9\u5bf9\u70b9\u901a\u4fe1\u66ff\u4ee3\u9759\u6001\u96c6\u4f53\u901a\u4fe1\uff0c\u5b9e\u73b0\u6545\u969c\u6062\u590d\u540e\u89d2\u8272\u95f4\u6743\u91cd\u7684\u5373\u65f6\u540c\u6b65\u3002\u6838\u5fc3\u6d1e\u5bdf\u662f\u57fa\u4e8e\u89d2\u8272\u7684\u6545\u969c\u9694\u79bb\u3002", "result": "\u5728256\u4e2aGPU\u96c6\u7fa4\u4e0a\uff0c\u4f7f\u7528Qwen3-8B-Math\u5de5\u4f5c\u8d1f\u8f7d\u548c10%\u7684\u6545\u969c\u6ce8\u5165\u9891\u7387\u8fdb\u884cRL\u8bad\u7ec3\u4efb\u52a1\u6d4b\u8bd5\u65f6\uff1aRobustRL\u7684\u6709\u6548\u8bad\u7ec3\u65f6\u95f4\u6bd4\uff08ETTR\uff09\u53ef\u4ee5\u8fbe\u523080%\u4ee5\u4e0a\uff0c\u663e\u8457\u9ad8\u4e8eByteRobust\u768460%\u3002RobustRL\u5728\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u4e0a\u5feb\u4e868.4%\u81f317.4%\u3002", "conclusion": "RobustRL\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u89d2\u8272\u7684\u6545\u969c\u9694\u79bb\u673a\u5236\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM RL\u540e\u8bad\u7ec3\u7684\u9c81\u68d2\u6027\u548c\u8bad\u7ec3\u6548\u7387\u3002\u5b83\u5728\u68c0\u6d4b\u3001\u91cd\u542f\u548c\u91cd\u65b0\u8fde\u63a5\u4e09\u4e2a\u5173\u952e\u65b9\u9762\u8fdb\u884c\u4e86\u521b\u65b0\uff0c\u4f7f\u5f97\u7cfb\u7edf\u5728\u9762\u5bf9GPU\u673a\u5668\u6545\u969c\u65f6\uff0c\u80fd\u591f\u975e\u7834\u574f\u6027\u5730\u6062\u590d\u5931\u8d25\u7684\u89d2\u8272\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u91cd\u542f\u6574\u4e2a\u4efb\u52a1\u7684\u5de8\u5927\u5f00\u9500\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cRobustRL\u5728\u6545\u969c\u6ce8\u5165\u573a\u666f\u4e0b\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6709\u6548\u8bad\u7ec3\u65f6\u95f4\u6bd4\u548c\u66f4\u5feb\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u3002"}}
{"id": "2512.22560", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.22560", "abs": "https://arxiv.org/abs/2512.22560", "authors": ["Wei Gao", "Yuheng Zhao", "Tianyuan Wu", "Shaopan Xiong", "Weixun Wang", "Dakai An", "Lunxi Cao", "Dilxat Muhtar", "Zichen Liu", "Haizhou Zhao", "Ju Huang", "Siran Yang", "Yongbin Li", "Wenbo Su", "Jiamang Wang", "Lin Qu", "Bo Zheng", "Wei Wang"], "title": "RollArt: Scaling Agentic RL Training via Disaggregated Infrastructure", "comment": "17 pages, 17 figures", "summary": "Agentic Reinforcement Learning (RL) enables Large Language Models (LLMs) to perform autonomous decision-making and long-term planning. Unlike standard LLM post-training, agentic RL workloads are highly heterogeneous, combining compute-intensive prefill phases, bandwidth-bound decoding, and stateful, CPU-heavy environment simulations. We argue that efficient agentic RL training requires disaggregated infrastructure to leverage specialized, best-fit hardware. However, naive disaggregation introduces substantial synchronization overhead and resource underutilization due to the complex dependencies between stages.\n  We present RollArc, a distributed system designed to maximize throughput for multi-task agentic RL on disaggregated infrastructure. RollArc is built on three core principles: (1) hardware-affinity workload mapping, which routes compute-bound and bandwidth-bound tasks to bestfit GPU devices, (2) fine-grained asynchrony, which manages execution at the trajectory level to mitigate resource bubbles, and (3) statefulness-aware computation, which offloads stateless components (e.g., reward models) to serverless infrastructure for elastic scaling. Our results demonstrate that RollArc effectively improves training throughput and achieves 1.35-2.05\\(\\times\\) end-to-end training time reduction compared to monolithic and synchronous baselines. We also evaluate RollArc by training a hundreds-of-billions-parameter MoE model for Qoder product on an Alibaba cluster with more than 3,000 GPUs, further demonstrating RollArc scalability and robustness. The code is available at https://github.com/alibaba/ROLL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS\u5747\u4e0d\u76f4\u63a5\u76f8\u5173\uff0c\u5b83\u4e13\u6ce8\u4e8e**\u5206\u5e03\u5f0f\u7cfb\u7edf**\u548c**\u5f3a\u5316\u5b66\u4e60**\uff08Agentic RL\uff09\u5de5\u4f5c\u8d1f\u8f7d\u7684\u4f18\u5316\u3002\nTLDR: \u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08Agentic RL\uff09\u8bad\u7ec3\u5177\u6709\u9ad8\u5ea6\u5f02\u6784\u6027\uff0c\u5728\u5206\u6563\u5f0f\u57fa\u7840\u8bbe\u65bd\u4e0a\u4f1a\u9020\u6210\u540c\u6b65\u5f00\u9500\u548c\u8d44\u6e90\u6d6a\u8d39\u3002RollArc\u662f\u4e00\u4e2a\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u901a\u8fc7\u786c\u4ef6\u4eb2\u548c\u6027\u6620\u5c04\u3001\u7ec6\u7c92\u5ea6\u5f02\u6b65\u548c\u6709\u72b6\u6001\u611f\u77e5\u8ba1\u7b97\uff0c\u5c06\u5f02\u6784\u4efb\u52a1\u5206\u53d1\u5230\u6700\u5408\u9002\u7684\u786c\u4ef6\u5e76\u5b9e\u73b0\u5f39\u6027\u6269\u5c55\u3002\u5b83\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\uff0c\u5c06\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e861.35-2.05\u500d\uff0c\u5e76\u5728\u4e00\u4e2a\u8d85\u8fc73,000\u4e2aGPU\u7684\u5927\u89c4\u6a21MoE\u6a21\u578b\u8bad\u7ec3\u4e2d\u5c55\u793a\u4e86\u5176\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08Agentic RL\uff09\u8bad\u7ec3\u5de5\u4f5c\u8d1f\u8f7d\u9ad8\u5ea6\u5f02\u6784\uff0c\u7ed3\u5408\u4e86\u8ba1\u7b97\u5bc6\u96c6\u7684\u9884\u586b\u5145\u9636\u6bb5\u3001\u5e26\u5bbd\u9650\u5236\u7684\u89e3\u7801\u4ee5\u53ca\u6709\u72b6\u6001\u3001CPU\u5bc6\u96c6\u578b\u7684\u73af\u5883\u6a21\u62df\u3002\u8fd9\u79cd\u5f02\u6784\u6027\u4f7f\u5f97\u73b0\u6709\u7684\u57fa\u7840\u8bbe\u65bd\u96be\u4ee5\u6709\u6548\u5904\u7406\uff0c\u7279\u522b\u662f\u5728\u5206\u6563\u5f0f\u57fa\u7840\u8bbe\u65bd\u4e0a\uff0c\u6734\u7d20\u7684\u89e3\u8026\u4f1a\u5f15\u5165\u5927\u91cf\u7684\u540c\u6b65\u5f00\u9500\u548c\u8d44\u6e90\u5229\u7528\u7387\u4e0d\u8db3\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u5229\u7528\u4e13\u4e1a\u5316\u786c\u4ef6\u5e76\u6700\u5927\u5316\u541e\u5410\u91cf\u7684\u7cfb\u7edf\u6765\u9ad8\u6548\u5730\u8fdb\u884cAgentic RL\u8bad\u7ec3\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86RollArc\uff0c\u4e00\u4e2a\u5206\u5e03\u5f0f\u7cfb\u7edf\uff0c\u65e8\u5728\u6700\u5927\u5316\u5206\u6563\u5f0f\u57fa\u7840\u8bbe\u65bd\u4e0a\u591a\u4efb\u52a1\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u541e\u5410\u91cf\u3002RollArc\u5efa\u7acb\u5728\u4e09\u4e2a\u6838\u5fc3\u539f\u5219\u4e0a\uff1a1. \u786c\u4ef6\u4eb2\u548c\u6027\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\uff0c\u5c06\u8ba1\u7b97\u5bc6\u96c6\u578b\u548c\u5e26\u5bbd\u5bc6\u96c6\u578b\u4efb\u52a1\u5206\u914d\u7ed9\u6700\u5408\u9002\u7684GPU\u8bbe\u5907\uff1b2. \u7ec6\u7c92\u5ea6\u5f02\u6b65\uff0c\u5728\u8f68\u8ff9\u7ea7\u522b\u7ba1\u7406\u6267\u884c\u4ee5\u7f13\u89e3\u8d44\u6e90\u6c14\u6ce1\uff1b3. \u6709\u72b6\u6001\u611f\u77e5\u7684\u8ba1\u7b97\uff0c\u5c06\u65e0\u72b6\u6001\u7ec4\u4ef6\uff08\u5982\u5956\u52b1\u6a21\u578b\uff09\u5378\u8f7d\u5230\u65e0\u670d\u52a1\u5668\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u5f39\u6027\u6269\u5c55\u3002", "result": "RollArc\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u541e\u5410\u91cf\uff0c\u76f8\u6bd4\u5355\u4f53\u548c\u540c\u6b65\u57fa\u7ebf\uff0c\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e861.35-2.05\u500d\u3002\u6b64\u5916\uff0cRollArc\u5728\u963f\u91cc\u5df4\u5df4\u96c6\u7fa4\u4e0a\u4f7f\u7528\u8d85\u8fc73,000\u4e2aGPU\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5177\u6709\u6570\u5343\u4ebf\u53c2\u6570\u7684MoE\u6a21\u578b\u7528\u4e8eQoder\u4ea7\u54c1\uff0c\u8fdb\u4e00\u6b65\u8bc1\u660e\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "RollArc\u901a\u8fc7\u5728\u5206\u6563\u5f0f\u57fa\u7840\u8bbe\u65bd\u4e0a\u5e94\u7528\u786c\u4ef6\u4eb2\u548c\u6027\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u3001\u7ec6\u7c92\u5ea6\u5f02\u6b65\u4ee5\u53ca\u6709\u72b6\u6001\u611f\u77e5\u7684\u8ba1\u7b97\u5378\u8f7d\uff0c\u89e3\u51b3\u4e86\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08Agentic RL\uff09\u8bad\u7ec3\u4e2d\u56fa\u6709\u7684\u5f02\u6784\u6027\u548c\u540c\u6b65\u5f00\u9500\u95ee\u9898\u3002RollArc\u5728\u8bad\u7ec3\u541e\u5410\u91cf\u548c\u7aef\u5230\u7aef\u8bad\u7ec3\u65f6\u95f4\u4e0a\u4f18\u4e8e\u5355\u4f53\u548c\u540c\u6b65\u57fa\u7ebf\uff081.35-2.05\u500d\u7684\u964d\u4f4e\uff09\uff0c\u5e76\u5728\u5927\u89c4\u6a21MoE\u6a21\u578b\u8bad\u7ec3\u4e2d\u5c55\u793a\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u9ad8\u6548Agentic RL\u8bad\u7ec3\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.22695", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.22695", "abs": "https://arxiv.org/abs/2512.22695", "authors": ["Mona Moghadampanah", "Adib Rezaei Shahmirzadi", "Farhana Amin", "Dimitrios S. Nikolopoulos"], "title": "Modality Inflation: Energy Characterization and Optimization Opportunities for MLLM Inference", "comment": null, "summary": "Multimodal large language models (MLLMs) are built on text-only LLMs by incorporating additional modalities, enabling multimodal understanding and a broader range of applications. However, these additions introduce a previously unexplored energy trade-off across modalities that remains poorly understood, as most prior work focuses on text-only models. In this paper, we examine modality inflation, a key source of inefficiency in which multimodal inputs increase inference workloads through extra encoding stages and expanded token sequences. We provide the first detailed, stage-level analysis of energy consumption in MLLM inference by breaking the pipeline into vision encoding, prefill, and decoding stages. Using four representative MLLMs evaluated on NVIDIA A100 GPU, we quantify the additional energy required for multimodal inference compared to text-only baselines, observing overheads ranging from 17% to 94% across models for identical inputs. Our results show that energy bottlenecks differ widely across model architectures, stemming either from compute-heavy vision encoders or from the downstream impact of large visual token sequences during prefill. By examining GPU power traces, we further uncover substantial GPU underutilization during multimodal execution and show that input complexity leads to markedly different energy scaling behaviors across models. Finally, we demonstrate that stage-wise dynamic voltage and frequency scaling (DVFS) is an effective optimization, allowing energy savings with only modest performance impact. Together, these findings offer practical insights and concrete guidance for designing more energy-efficient multimodal LLM serving systems.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u548c\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09\u76f8\u5173\u3002\u5b83\u5206\u6790\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u80fd\u8017\u548c\u6548\u7387\u95ee\u9898\uff0c\u7279\u522b\u5173\u6ce8\u201c\u6a21\u6001\u81a8\u80c0\u201d\u5e26\u6765\u7684\u989d\u5916\u5f00\u9500\u3002\u7814\u7a76\u901a\u8fc7\u9636\u6bb5\u6027\u5206\u6790\u91cf\u5316\u4e86\u80fd\u8017\u5f00\u9500\uff0817% \u81f3 94%\uff09\uff0c\u786e\u5b9a\u4e86\u80fd\u8017\u74f6\u9888\uff0c\u63ed\u793a\u4e86 GPU \u5229\u7528\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u9636\u6bb5\u6027\u52a8\u6001\u7535\u538b\u548c\u9891\u7387\u7f29\u653e\uff08DVFS\uff09\u4f5c\u4e3a\u6709\u6548\u7684\u8282\u80fd\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7684 MLLM \u901a\u8fc7\u6574\u5408\u989d\u5916\u7684\u6a21\u6001\uff08\u5982\u89c6\u89c9\uff09\u589e\u5f3a\u4e86\u529f\u80fd\uff0c\u4f46\u8fd9\u79cd\u65b0\u589e\u5e26\u6765\u4e86\u5148\u524d\u672a\u88ab\u63a2\u7d22\u7684\u8de8\u6a21\u6001\u80fd\u6e90\u6743\u8861\u95ee\u9898\uff0c\u5e76\u4e14\u7531\u4e8e\u5927\u591a\u6570\u5148\u524d\u7684\u5de5\u4f5c\u53ea\u5173\u6ce8\u7eaf\u6587\u672c\u6a21\u578b\uff0c\u56e0\u6b64\u5bf9\u8fd9\u4e2a\u6743\u8861\u7684\u7406\u89e3\u5f88\u6709\u9650\u3002\u8bba\u6587\u7684\u52a8\u673a\u662f\u63a2\u8ba8\u201c\u6a21\u6001\u81a8\u80c0\u201d\u2014\u2014\u8fd9\u662f\u4e00\u4e2a\u5173\u952e\u7684\u6548\u7387\u4f4e\u4e0b\u6765\u6e90\uff0c\u5373\u591a\u6a21\u6001\u8f93\u5165\u901a\u8fc7\u989d\u5916\u7684\u7f16\u7801\u9636\u6bb5\u548c\u6269\u5c55\u7684 token \u5e8f\u5217\u589e\u52a0\u4e86\u63a8\u7406\u5de5\u4f5c\u8d1f\u8f7d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u5bf9 MLLM \u63a8\u7406\u7684\u80fd\u8017\u8fdb\u884c\u6df1\u5165\u7684\u3001\u9636\u6bb5\u6027\u7684\u5206\u6790\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5c06 MLLM \u63a8\u7406\u7ba1\u7ebf\u5206\u89e3\u4e3a\u89c6\u89c9\u7f16\u7801\u3001\u9884\u586b\u5145\u548c\u89e3\u7801\u4e09\u4e2a\u9636\u6bb5\uff0c\u9996\u6b21\u8fdb\u884c\u4e86\u8be6\u7ec6\u7684\u3001\u9636\u6bb5\u7ea7\u522b\u7684\u80fd\u8017\u5206\u6790\u3002\u4ed6\u4eec\u4f7f\u7528\u56db\u79cd\u5177\u6709\u4ee3\u8868\u6027\u7684 MLLM \u6a21\u578b\uff0c\u5728 NVIDIA A100 GPU \u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u91cf\u5316\u4e86\u76f8\u5bf9\u4e8e\u7eaf\u6587\u672c\u57fa\u7ebf\u7684\u591a\u6a21\u6001\u63a8\u7406\u6240\u9700\u7684\u989d\u5916\u80fd\u8017\u3002\u901a\u8fc7\u68c0\u67e5 GPU \u529f\u7387\u8f68\u8ff9\uff0c\u4f5c\u8005\u63ed\u793a\u4e86\u591a\u6a21\u6001\u6267\u884c\u671f\u95f4 GPU \u7684\u5229\u7528\u4e0d\u8db3\uff0c\u5e76\u5c55\u793a\u4e86\u8f93\u5165\u590d\u6742\u6027\u5982\u4f55\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u80fd\u8017\u6269\u5c55\u884c\u4e3a\u7684\u663e\u8457\u5dee\u5f02\u3002\u6700\u540e\uff0c\u4ed6\u4eec\u5c55\u793a\u4e86\u9636\u6bb5\u6027\u52a8\u6001\u7535\u538b\u548c\u9891\u7387\u7f29\u653e\uff08DVFS\uff09\u662f\u4e00\u79cd\u6709\u6548\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u7814\u7a76\u91cf\u5316\u4e86\u591a\u6a21\u6001\u63a8\u7406\u4e0e\u7eaf\u6587\u672c\u57fa\u7ebf\u76f8\u6bd4\u6240\u9700\u7684\u989d\u5916\u80fd\u8017\uff0c\u89c2\u5bdf\u5230\u6a21\u578b\u95f4\u7684\u5f00\u9500\u8303\u56f4\u5728 17% \u5230 94% \u4e4b\u95f4\uff08\u5bf9\u4e8e\u76f8\u540c\u8f93\u5165\uff09\u3002\u7ed3\u679c\u8868\u660e\uff0c\u80fd\u8017\u74f6\u9888\u56e0\u6a21\u578b\u67b6\u6784\u800c\u5f02\uff0c\u53ef\u80fd\u6e90\u4e8e\u8ba1\u7b97\u5bc6\u96c6\u7684\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u6216\u6e90\u4e8e\u9884\u586b\u5145\u9636\u6bb5\u4e2d\u5927\u89c4\u6a21\u89c6\u89c9 token \u5e8f\u5217\u7684\u4e0b\u6e38\u5f71\u54cd\u3002\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u5728\u591a\u6a21\u6001\u6267\u884c\u8fc7\u7a0b\u4e2d\u5b58\u5728\u663e\u8457\u7684 GPU \u5229\u7528\u4e0d\u8db3\u3002\u8f93\u5165\u590d\u6742\u6027\u5bfc\u81f4\u4e0d\u540c\u6a21\u578b\u4e4b\u95f4\u7684\u80fd\u8017\u6269\u5c55\u884c\u4e3a\u660e\u663e\u4e0d\u540c\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u9636\u6bb5\u6027 DVFS \u662f\u4e00\u79cd\u6709\u6548\u7684\u4f18\u5316\u624b\u6bb5\uff0c\u53ef\u4ee5\u5728\u9002\u5ea6\u7684\u6027\u80fd\u5f71\u54cd\u4e0b\u5b9e\u73b0\u80fd\u6e90\u8282\u7ea6\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u5957\u65b0\u7684\u89c1\u89e3\u548c\u5b9e\u9645\u6307\u5bfc\uff0c\u65e8\u5728\u8bbe\u8ba1\u66f4\u8282\u80fd\u7684\u591a\u6a21\u6001 LLM \u670d\u52a1\u7cfb\u7edf\u3002\u7814\u7a76\u8868\u660e\uff0c\u9636\u6bb5\u6027 DVFS \u662f\u4e00\u79cd\u6709\u6548\u7684\u4f18\u5316\u624b\u6bb5\uff0c\u53ef\u4ee5\u5728\u9002\u5ea6\u7684\u6027\u80fd\u5f71\u54cd\u4e0b\u5b9e\u73b0\u80fd\u6e90\u8282\u7ea6\u3002"}}
{"id": "2512.22925", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.22925", "abs": "https://arxiv.org/abs/2512.22925", "authors": ["Panlong Wu", "Yifei Zhong", "Danyang Chen", "Ting Wang", "Fangxin Wang"], "title": "Argus: Token Aware Distributed LLM Inference Optimization", "comment": null, "summary": "Large Language Models (LLMs) are rapidly being integrated into real-world applications, yet their autoregressive architectures introduce significant inference time variability, especially when deployed across heterogeneous edge-cloud systems. Existing solutions largely neglect the dynamic, stochastic, and heterogeneous nature of such environments, often ignoring the impact of variable output token lengths and device diversity. In this work, we present Argus, the first token-aware distributed edge-cloud LLM inference framework that conducts efficient task offloading. Argus features a Length-Aware Semantics (LAS) module, which predicts output token lengths for incoming prompts using a fine-tuned language model with token-length-sensitive feature modulation, enabling precise estimation. Building on this, our Lyapunov-guided Offloading Optimization (LOO) module formulates long-term Quality-of-Experience optimization that explicitly considers both LLM prefilling and decoding costs. We introduce a novel Iterative Offloading Algorithm with Damping and Congestion Control (IODCC) to effectively solve the resulting integer nonlinear programming problem under time-varying constraints. Extensive theoretical and empirical evaluations demonstrate that Argus achieves robust performance and superior efficiency in highly dynamic, heterogeneous settings.", "AI": {"tldr": "\u76f8\u5173\uff1a\u8be5\u8bba\u6587\u4e0e**LLM**\u3001**\u7f16\u8bd1\u5668**\uff08\u6d89\u53ca\u63a8\u7406\u4f18\u5316\u548c\u90e8\u7f72\uff09\u3001**\u56fe\u5904\u7406**\uff08\u5982\u679c\u6a21\u578b\u5185\u90e8\u4f7f\u7528\u4e86\u56fe\u7ed3\u6784\u4f18\u5316\uff0c\u4f46\u6458\u8981\u672a\u660e\u786e\u8bf4\u660e\uff09\u76f8\u5173\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u662f\u4e00\u4e2a\u5173\u4e8eLLM\u63a8\u7406\u4f18\u5316\u548c\u90e8\u7f72\u7684\u7cfb\u7edf\u5de5\u4f5c\u3002\n\u603b\u7ed3\uff1aArgus\u662f\u9996\u4e2a\u4ee4\u724c\u611f\u77e5\u7684\u5206\u5e03\u5f0f\u8fb9\u7f18-\u4e91LLM\u63a8\u7406\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u5f02\u6784\u8fb9\u7f18-\u4e91\u73af\u5883\u4e2dLLM\u63a8\u7406\u65f6\u95f4\u7684\u9ad8\u5ea6\u53d8\u52a8\u6027\u95ee\u9898\u3002\u5b83\u901a\u8fc7Length-Aware Semantics (LAS)\u6a21\u5757\u9884\u6d4b\u7cbe\u786e\u7684\u8f93\u51fa\u4ee4\u724c\u957f\u5ea6\uff0c\u7136\u540e\u5229\u7528Lyapunov-guided Offloading Optimization (LOO)\u6a21\u5757\uff0c\u8003\u8651\u9884\u586b\u5145\u548c\u89e3\u7801\u6210\u672c\uff0c\u5c06\u957f\u671f\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\uff08QoE\uff09\u4f18\u5316\u516c\u5f0f\u5316\u3002\u6700\u540e\uff0c\u91c7\u7528\u5e26\u6709\u963b\u5c3c\u548c\u62e5\u585e\u63a7\u5236\u7684\u8fed\u4ee3\u5378\u8f7d\u7b97\u6cd5\uff08IODCC\uff09\u6765\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660eArgus\u5728\u52a8\u6001\u548c\u5f02\u6784\u8bbe\u7f6e\u4e2d\u5177\u6709\u4f18\u8d8a\u7684\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u90e8\u7f72\u65b9\u6848\u672a\u80fd\u5145\u5206\u89e3\u51b3\u5728\u5f02\u6784\u8fb9\u7f18-\u4e91\u7cfb\u7edf\u4e2d\u56fa\u6709\u7684\u52a8\u6001\u3001\u968f\u673a\u548c\u5f02\u6784\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u5ffd\u7565\u4e86\u53ef\u53d8\u7684\u8f93\u51fa\u4ee4\u724c\u957f\u5ea6\u548c\u8bbe\u5907\u591a\u6837\u6027\u5bf9\u63a8\u7406\u65f6\u95f4\u53d8\u52a8\u6027\u7684\u5f71\u54cd\uff0c\u8fd9\u9650\u5236\u4e86LLMs\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "method": "Argus\u6846\u67b6\u5305\u62ec\uff1a1. **\u957f\u5ea6\u611f\u77e5\u8bed\u4e49\uff08Length-Aware Semantics, LAS\uff09\u6a21\u5757**\uff1a\u4f7f\u7528\u7ecf\u8fc7\u5fae\u8c03\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u654f\u611f\u4e8e\u4ee4\u724c\u957f\u5ea6\u7684\u7279\u5f81\u8c03\u5236\u6765\u9884\u6d4b\u8f93\u5165\u63d0\u793a\u7684\u8f93\u51fa\u4ee4\u724c\u957f\u5ea6\uff0c\u5b9e\u73b0\u7cbe\u786e\u4f30\u8ba1\u30022. **Lyapunov\u6307\u5bfc\u7684\u5378\u8f7d\u4f18\u5316\uff08Lyapunov-guided Offloading Optimization, LOO\uff09\u6a21\u5757**\uff1a\u5c06\u957f\u671f\u7528\u6237\u4f53\u9a8c\u8d28\u91cf\uff08QoE\uff09\u4f18\u5316\u516c\u5f0f\u5316\uff0c\u660e\u786e\u8003\u8651\u4e86LLM\u7684\u9884\u586b\u5145\u548c\u89e3\u7801\u6210\u672c\u30023. **\u5e26\u6709\u963b\u5c3c\u548c\u62e5\u585e\u63a7\u5236\u7684\u8fed\u4ee3\u5378\u8f7d\u7b97\u6cd5\uff08Iterative Offloading Algorithm with Damping and Congestion Control, IODCC\uff09**\uff1a\u7528\u4e8e\u5728\u65f6\u53d8\u7ea6\u675f\u4e0b\u6709\u6548\u89e3\u51b3\u7531\u6b64\u4ea7\u751f\u7684\u6574\u6570\u975e\u7ebf\u6027\u89c4\u5212\u95ee\u9898\u3002", "result": "\u5e7f\u6cdb\u7684\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc4\u4f30\u8bc1\u660e\uff0cArgus\u5728\u9ad8\u5ea6\u52a8\u6001\u548c\u5f02\u6784\u7684\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u6027\u80fd\u548c\u5353\u8d8a\u7684\u6548\u7387\u3002\u5b83\u6210\u4e3a\u9996\u4e2a\u4ee4\u724c\u611f\u77e5\u7684\u5206\u5e03\u5f0f\u8fb9\u7f18-\u4e91LLM\u63a8\u7406\u6846\u67b6\uff0c\u80fd\u591f\u8fdb\u884c\u9ad8\u6548\u7684\u4efb\u52a1\u5378\u8f7d\u3002", "conclusion": "Argus\u662f\u9996\u4e2a\u4ee4\u724c\u611f\u77e5\u7684\u5206\u5e03\u5f0f\u8fb9\u7f18-\u4e91LLM\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7LAS\u5b9e\u73b0\u7cbe\u786e\u7684\u8f93\u51fa\u957f\u5ea6\u9884\u6d4b\uff0c\u5e76\u901a\u8fc7LOO\u548cIODCC\u5b9e\u73b0\u9ad8\u6548\u548c\u9c81\u68d2\u7684\u4efb\u52a1\u5378\u8f7d\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u5728\u52a8\u6001\u548c\u5f02\u6784\u73af\u5883\u4e2d\u7684\u63a8\u7406\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2512.23434", "categories": ["cs.DC", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.23434", "abs": "https://arxiv.org/abs/2512.23434", "authors": ["Yongjie Guan"], "title": "Local Rendezvous Hashing: Bounded Loads and Minimal Churn via Cache-Local Candidates", "comment": "14 pages, 10 figures. Includes appendices", "summary": "Consistent hashing is fundamental to distributed systems, but ring-based schemes can exhibit high peak-to-average load ratios unless they use many virtual nodes, while multi-probe methods improve balance at the cost of scattered memory accesses. This paper introduces Local Rendezvous Hashing (LRH), which preserves a token ring but restricts Highest Random Weight (HRW) selection to a cache-local window of C distinct neighboring physical nodes. LRH locates a key by one binary search, enumerates exactly C distinct candidates using precomputed next-distinct offsets, and chooses the HRW winner (optionally weighted). Lookup cost is O(log|R| + C). Under fixed-topology liveness changes, fixed-candidate filtering remaps only keys whose original winner is down, yielding zero excess churn. In a benchmark with N=5000, V=256 (|R|=1.28M), K=50M and C=8, LRH reduces Max/Avg load from 1.2785 to 1.0947 and achieves 60.05 Mkeys/s, about 6.8x faster than multi-probe consistent hashing with 8 probes (8.80 Mkeys/s) while approaching its balance (Max/Avg 1.0697). A microbenchmark indicates multi-probe assignment is dominated by repeated ring searches and memory traffic rather than probe-generation arithmetic.", "AI": {"tldr": "This paper is related to graph processing and compiler, especially the hash table structure and search. The paper introduces Local Rendezvous Hashing (LRH), a new consistent hashing scheme that combines a token ring with restricted Highest Random Weight (HRW) selection within a cache-local window of C neighboring physical nodes. LRH achieves a Max/Avg load ratio of 1.0947 and a throughput of 60.05 Mkeys/s (6.8x faster than multi-probe consistent hashing) in a benchmark, with a lookup cost of $O(\\log|R| + C)$ and zero excess churn under liveness changes.", "motivation": "\u73b0\u6709\u7684\u4e09\u79cd\u4e3b\u8981\u4e00\u81f4\u6027\u54c8\u5e0c\u65b9\u6848\u5b58\u5728\u5c40\u9650\u6027\uff1a\u73af\u5f62\u65b9\u6848\u9700\u8981\u5927\u91cf\u865a\u62df\u8282\u70b9\u624d\u80fd\u5b9e\u73b0\u826f\u597d\u7684\u8d1f\u8f7d\u5747\u8861\uff0c\u5bfc\u81f4\u9ad8\u6602\u7684\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\uff1b\u591a\u63a2\u5934\u65b9\u6848\u867d\u7136\u6539\u5584\u4e86\u8d1f\u8f7d\u5747\u8861\uff0c\u4f46\u7531\u4e8e\u5206\u6563\u7684\u5185\u5b58\u8bbf\u95ee\u800c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff1b\u4f20\u7edf\u7684 Rendezvous Hashing \u867d\u7136\u5728\u8d1f\u8f7d\u5747\u8861\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u901a\u5e38\u9700\u8981\u5bf9\u6240\u6709\u8282\u70b9\u8fdb\u884c\u8ba1\u7b97\uff0c\u6548\u7387\u4e0d\u9ad8\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u5b9e\u73b0\u826f\u597d\u8d1f\u8f7d\u5747\u8861\uff0c\u53c8\u80fd\u4fdd\u6301\u9ad8\u67e5\u627e\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86 Local Rendezvous Hashing (LRH)\uff0c\u5b83\u4fdd\u7559\u4e86\u4ee4\u724c\u73af\u7ed3\u6784\uff0c\u4f46\u5c06\u6700\u9ad8\u968f\u673a\u6743\u91cd (HRW) \u7684\u9009\u62e9\u9650\u5236\u5728 C \u4e2a\u4e0d\u540c\u7684\u76f8\u90bb\u7269\u7406\u8282\u70b9\u7684\u7f13\u5b58\u5c40\u90e8\u7a97\u53e3\u5185\u3002LRH \u901a\u8fc7\u4e00\u6b21\u4e8c\u5206\u67e5\u627e\u5b9a\u4f4d\u952e\uff0c\u4f7f\u7528\u9884\u5148\u8ba1\u7b97\u7684\u4e0b\u4e00\u4e2a\u4e0d\u540c\u504f\u79fb\u91cf\u7cbe\u786e\u679a\u4e3e C \u4e2a\u5019\u9009\u8282\u70b9\uff0c\u5e76\u4ece\u4e2d\u9009\u62e9 HRW \u8d62\u5bb6\uff08\u53ef\u9009\u52a0\u6743\uff09\u3002\u67e5\u627e\u6210\u672c\u4e3a $O(\\log|R| + C)$\u3002\u5728\u56fa\u5b9a\u62d3\u6251\u4e0b\uff0cLRH \u5728\u8282\u70b9\u5931\u6548\u65f6\u5b9e\u73b0\u96f6\u989d\u5916\u6d41\u5931\u3002\u901a\u8fc7\u9650\u5236\u9009\u62e9\u8303\u56f4\u548c\u4f7f\u7528\u9884\u8ba1\u7b97\u7684\u504f\u79fb\u91cf\uff0cLRH \u663e\u8457\u63d0\u9ad8\u4e86\u67e5\u627e\u901f\u5ea6\u3002", "result": "\u5728 $N=5000$ \u4e2a\u7269\u7406\u8282\u70b9\u3001$V=256$ \u4e2a\u865a\u62df\u8282\u70b9\uff08$|R|=1.28M$ \u4e2a\u73af\u8282\u70b9\uff09\u3001$K=50M$ \u4e2a\u952e\u548c\u7a97\u53e3\u5927\u5c0f $C=8$ \u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLRH \u5c06\u5cf0\u503c/\u5e73\u5747\u8d1f\u8f7d\u6bd4\u4ece\u4f20\u7edf\u73af\u5f62\u54c8\u5e0c\u7684 $1.2785$ \u964d\u4f4e\u5230 $1.0947$\u3002LRH \u5b9e\u73b0\u4e86 $60.05$ Mkeys/s \u7684\u541e\u5410\u91cf\uff0c\u6bd4\u91c7\u7528 $8$ \u4e2a\u63a2\u5934\u7684\u591a\u63a2\u5934\u4e00\u81f4\u6027\u54c8\u5e0c\u5feb\u7ea6 $6.8$ \u500d\uff08\u540e\u8005\u4e3a $8.80$ Mkeys/s\uff09\uff0c\u540c\u65f6\u5176\u8d1f\u8f7d\u5747\u8861\u6027\u80fd\u63a5\u8fd1\u540e\u8005\uff08\u5cf0\u503c/\u5e73\u5747 $1.0697$\uff09\u3002LRH \u7684\u67e5\u627e\u6210\u672c\u662f $O(\\log|R| + C)$\u3002\u5728\u8282\u70b9\u5931\u6548\u65f6\uff0cLRH \u5b9e\u73b0\u96f6\u989d\u5916\u6d41\u5931\u3002\u5fae\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0c\u591a\u63a2\u5934\u5206\u914d\u7684\u6027\u80fd\u74f6\u9888\u5728\u4e8e\u91cd\u590d\u7684\u73af\u5f62\u641c\u7d22\u548c\u5185\u5b58\u6d41\u91cf\uff0c\u800c\u4e0d\u662f\u63a2\u5934\u751f\u6210\u7b97\u672f\u3002", "conclusion": "Local Rendezvous Hashing (LRH) \u662f\u4e00\u79cd\u65b0\u7684\u9009\u62e9\u4e00\u81f4\u6027\u54c8\u5e0c\u76ee\u6807\u8282\u70b9\u7684\u7b97\u6cd5\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u73af\u5f62\u7ed3\u6784\u548c\u9650\u5236\u6700\u9ad8\u968f\u673a\u6743\u91cd (HRW) \u9009\u62e9\u8303\u56f4\u6765\u63d0\u9ad8\u6027\u80fd\u548c\u8d1f\u8f7d\u5747\u8861\u3002LRH \u5728\u4fdd\u6301\u4f4e\u67e5\u627e\u6210\u672c\u548c\u907f\u514d\u5185\u5b58\u8bbf\u95ee\u5206\u6563\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u5e76\u63d0\u4f9b\u4e86\u53ef\u63a5\u53d7\u7684\u8d1f\u8f7d\u5747\u8861\uff0c\u7279\u522b\u5728\u5927\u89c4\u6a21\u548c\u9ad8\u5e76\u53d1\u573a\u666f\u4e2d\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2512.23494", "categories": ["cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.23494", "abs": "https://arxiv.org/abs/2512.23494", "authors": ["Eddy Truyen", "Wouter Joosen"], "title": "Optimal Configuration of API Resources in Cloud Native Computing", "comment": "In Proceedings WACA 2025, arXiv:2512.22054", "summary": "This paper presents how an existing framework for offline performance optimization can be applied to microservice applications during the Release phase of the DevOps life cycle. Optimization of resource allocation configuration parameters for CPU and memory during the Release phase remains a largely unexplored problem as most research has focused on intelligent scheduling and autoscaling of microservices during the Ops stage of the DevOps cycle. Yet horizontal auto-scaling of containers, based on CPU usage for instance, may still leave these containers with an inappropriately allocated amount of memory, if no upfront fine-tuning of both resources is applied before the Deployment phase. We evaluate the performance optimization framework using the TeaStore microservice application and statistically compare different optimization algorithms, supporting informed decisions about their trade-offs between sampling cost and distance to the optimal resource configuration. This shows that upfront factor screening, for reducing the search space, is helpful when the goal is to find the optimal resource configuration with an affordable sampling budget. When the goal is to statistically compare different algorithms, screening must also be applied to make data collection of all data points in the search space feasible.  If the goal is to find a near-optimal configuration, however, it is better to run bayesian optimization without screening.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u548c DSL \u6216\u56fe\u5904\u7406\u6216 MLIR \u6216 HLS \u65e0\u5173\u3002\n\n\u8fd9\u7bc7\u8bba\u6587\u4ecb\u7ecd\u4e86\u5982\u4f55\u5c06\u4e00\u4e2a\u79bb\u7ebf\u6027\u80fd\u4f18\u5316\u6846\u67b6\u5e94\u7528\u4e8e\u5fae\u670d\u52a1\u5e94\u7528\u7684 DevOps \u53d1\u5e03\u9636\u6bb5\uff0c\u4ee5\u4f18\u5316 CPU \u548c\u5185\u5b58\u7684\u8d44\u6e90\u5206\u914d\u914d\u7f6e\u3002\u7814\u7a76\u8bc4\u4f30\u4e86\u4e0d\u540c\u7684\u4f18\u5316\u7b97\u6cd5\uff08\u5305\u62ec\u524d\u671f\u56e0\u7d20\u7b5b\u9009\u548c\u8d1d\u53f6\u65af\u4f18\u5316\uff09\u4f7f\u7528 TeaStore \u5fae\u670d\u52a1\u5e94\u7528\uff0c\u53d1\u73b0\u524d\u671f\u56e0\u7d20\u7b5b\u9009\u6709\u52a9\u4e8e\u5728\u91c7\u6837\u9884\u7b97\u6709\u9650\u65f6\u627e\u5230\u6700\u4f18\u914d\u7f6e\uff0c\u4f46\u5bf9\u4e8e\u5bfb\u627e\u8fd1\u6700\u4f18\u914d\u7f6e\uff0c\u4e0d\u8fdb\u884c\u7b5b\u9009\u7684\u8d1d\u53f6\u65af\u4f18\u5316\u53ef\u80fd\u66f4\u4f18\u3002\u8fd9\u4e00\u5de5\u4f5c\u65e8\u5728\u89e3\u51b3\u9884\u90e8\u7f72\u9636\u6bb5\u8d44\u6e90\u7cbe\u7ec6\u8c03\u6574\u7814\u7a76\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u5fae\u670d\u52a1\u6027\u80fd\u4f18\u5316\u7814\u7a76\u5927\u591a\u96c6\u4e2d\u5728 DevOps \u751f\u547d\u5468\u671f\u201c\u8fd0\u8425\u201d\uff08Ops\uff09\u9636\u6bb5\u7684\u667a\u80fd\u8c03\u5ea6\u548c\u81ea\u52a8\u4f38\u7f29\uff0c\u800c\u5bf9\u4e8e\u201c\u53d1\u5e03\u201d\uff08Release\uff09\u9636\u6bb5\uff0c\u7279\u522b\u662f\u5728\u90e8\u7f72\u524d\u9884\u5148\u7cbe\u7ec6\u8c03\u6574 CPU \u548c\u5185\u5b58\u7b49\u8d44\u6e90\u5206\u914d\u914d\u7f6e\u53c2\u6570\u7684\u95ee\u9898\uff0c\u7814\u7a76\u8f83\u5c11\u3002\u7136\u800c\uff0c\u5982\u679c\u4e0d\u9884\u5148\u6b63\u786e\u914d\u7f6e\u8d44\u6e90\uff0c\u5373\u4f7f\u8fdb\u884c\u81ea\u52a8\u4f38\u7f29\uff08\u5982\u57fa\u4e8e CPU \u4f7f\u7528\u7387\u7684\u6c34\u5e73\u6269\u5c55\uff09\uff0c\u5bb9\u5668\u7684\u5185\u5b58\u5206\u914d\u4ecd\u53ef\u80fd\u4e0d\u5f53\u3002\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u89e3\u51b3\u8fd9\u4e00\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u8bc4\u4f30\u4e00\u4e2a\u79bb\u7ebf\u6027\u80fd\u4f18\u5316\u6846\u67b6\u6765\u4f18\u5316\u5fae\u670d\u52a1\u5e94\u7528\u7684\u9884\u90e8\u7f72\u8d44\u6e90\u914d\u7f6e\u3002", "method": "\u672c\u6587\u7684\u65b9\u6cd5\u662f\u91c7\u7528\u4e00\u4e2a\u73b0\u6709\u7684\u79bb\u7ebf\u6027\u80fd\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u5fae\u670d\u52a1\u5e94\u7528\u7684\u53d1\u5e03\u9636\u6bb5\uff0c\u4e13\u6ce8\u4e8e\u4f18\u5316 CPU \u548c\u5185\u5b58\u7684\u8d44\u6e90\u914d\u7f6e\u53c2\u6570\u3002\u7814\u7a76\u4f7f\u7528\u4e86 TeaStore \u5fae\u670d\u52a1\u5e94\u7528\u4f5c\u4e3a\u8bc4\u4f30\u5bf9\u8c61\uff0c\u5e76\u7edf\u8ba1\u6027\u5730\u6bd4\u8f83\u4e86\u5305\u62ec\u524d\u671f\u56e0\u7d20\u7b5b\u9009\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u5185\u7684\u4e0d\u540c\u4f18\u5316\u7b97\u6cd5\uff0c\u4ee5\u8bc4\u4f30\u5b83\u4eec\u5728\u91c7\u6837\u6210\u672c\u548c\u63a5\u8fd1\u6700\u4f18\u914d\u7f6e\u7684\u8ddd\u79bb\u4e4b\u95f4\u7684\u6027\u80fd\u6743\u8861\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u524d\u671f\u56e0\u7d20\u7b5b\u9009\uff08Factor Screening\uff09\u5bf9\u4e8e\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u5728\u91c7\u6837\u9884\u7b97\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5bfb\u627e\u201c\u6700\u4f18\u201d\u8d44\u6e90\u914d\u7f6e\u662f\u6709\u5e2e\u52a9\u7684\u3002\u5f53\u76ee\u6807\u662f\u201c\u7edf\u8ba1\u6bd4\u8f83\u201d\u4e0d\u540c\u7684\u4f18\u5316\u7b97\u6cd5\u65f6\uff0c\u4e5f\u9700\u8981\u8fdb\u884c\u7b5b\u9009\u4ee5\u4f7f\u6570\u636e\u6536\u96c6\u53ef\u884c\u3002\u7136\u800c\uff0c\u5982\u679c\u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u201c\u8fd1\u6700\u4f18\u201d\u914d\u7f6e\uff0c\u4e0d\u8fdb\u884c\u7b5b\u9009\u800c\u76f4\u63a5\u8fd0\u884c\u8d1d\u53f6\u65af\u4f18\u5316\uff08Bayesian Optimization\uff09\u53ef\u80fd\u662f\u4e00\u4e2a\u66f4\u597d\u7684\u9009\u62e9\u3002\u8fd9\u610f\u5473\u7740\u4f18\u5316\u7b56\u7565\u5e94\u6839\u636e\u5177\u4f53\u7684\u4f18\u5316\u76ee\u6807\uff08\u6700\u4f18\u6027\u3001\u53ef\u6bd4\u8f83\u6027\u6216\u8fd1\u6700\u4f18\u6027\uff09\u8fdb\u884c\u8c03\u6574\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u4e00\u4e2a\u5df2\u6709\u7684\u79bb\u7ebf\u6027\u80fd\u4f18\u5316\u6846\u67b6\uff0c\u7528\u4e8e\u5728 DevOps \u751f\u547d\u5468\u671f\u4e2d\u7684\u53d1\u5e03\uff08Release\uff09\u9636\u6bb5\u5bf9\u5fae\u670d\u52a1\u5e94\u7528\u7684 CPU \u548c\u5185\u5b58\u8d44\u6e90\u914d\u7f6e\u8fdb\u884c\u4f18\u5316\u3002\u7814\u7a76\u7ed3\u679c\u901a\u8fc7 TeaStore \u5fae\u670d\u52a1\u5e94\u7528\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u7edf\u8ba1\u6bd4\u8f83\u4e86\u4e0d\u540c\u7684\u4f18\u5316\u7b97\u6cd5\uff0c\u5c55\u793a\u4e86\u5728\u4e0d\u540c\u4f18\u5316\u76ee\u6807\u4e0b\uff0c\u662f\u5426\u8fdb\u884c\u524d\u671f\u56e0\u7d20\u7b5b\u9009\u548c\u91c7\u7528\u54ea\u79cd\u4f18\u5316\u7b97\u6cd5\uff08\u5982\u8d1d\u53f6\u65af\u4f18\u5316\uff09\u7684\u6743\u8861\u3002\u4e3b\u8981\u7684\u7ed3\u8bba\u662f\uff0c\u9488\u5bf9\u4e0d\u540c\u76ee\u6807\uff08\u5bfb\u627e\u6700\u4f18\u914d\u7f6e\u3001\u6bd4\u8f83\u7b97\u6cd5\u6216\u5bfb\u627e\u8fd1\u6700\u4f18\u914d\u7f6e\uff09\uff0c\u524d\u671f\u56e0\u7d20\u7b5b\u9009\u548c\u4f18\u5316\u7b97\u6cd5\u7684\u9009\u62e9\u7b56\u7565\u5e94\u6709\u6240\u4e0d\u540c\uff0c\u4ee5\u5e73\u8861\u91c7\u6837\u6210\u672c\u548c\u4f18\u5316\u6548\u679c\u3002"}}
{"id": "2512.23495", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.23495", "abs": "https://arxiv.org/abs/2512.23495", "authors": ["Eddy Truyen"], "title": "Decoupling Adaptive Control in TeaStore", "comment": "In Proceedings WACA 2025, arXiv:2512.22054", "summary": "The Adaptable TeaStore specification provides a microservice-based case study for implementing self-adaptation through a control loop.  We argue that implementations of this specification should be informed by key properties of self-adaptation: system-wide consistency (coordinated adaptations across replicas), planning (executing an adaptation until appropriate conditions are met),  and modularity (clean integration of adaptation logic).  In this implementation discussion paper, we examine how software architectural methods, the cloud-native Operator pattern, and legacy programming language techniques can decouple self-adaptive control logic from the TeaStore application. We analyze the trade-offs that these different approaches make between fine-grained expressive adaptation and system-wide control, and highlight when reuse of adaptation strategies is most effective. Our analysis suggests that these approaches are not mutually exclusive but can be combined into a multi-tiered architecture for self-adaptive microservices.", "AI": {"tldr": "\u8fd9\u4e0d\u662f\u4e00\u4e2a\u4e0e DSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216 HLS \u76f4\u63a5\u76f8\u5173\u7684\u8bba\u6587\u3002\u5176\u4e3b\u8981\u7814\u7a76\u9886\u57df\u662f\u5fae\u670d\u52a1\u3001\u81ea\u9002\u5e94\u7cfb\u7edf\u548c\u8f6f\u4ef6\u67b6\u6784\u3002/\u592a\u957f\u4e0d\u770b\uff1a\u672c\u6587\u8ba8\u8bba\u4e86\u5982\u4f55\u5c06\u81ea\u9002\u5e94\u63a7\u5236\u903b\u8f91\u4ece\u5fae\u670d\u52a1\u5e94\u7528\uff08TeaStore\uff09\u4e2d\u89e3\u8026\u51fa\u6765\u3002\u6587\u7ae0\u5206\u6790\u4e86\u8f6f\u4ef6\u67b6\u6784\u65b9\u6cd5\u3001\u4e91\u539f\u751f Operator \u6a21\u5f0f\u548c\u4f20\u7edf\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\uff0c\u5728\u5b9e\u73b0\u7cfb\u7edf\u8303\u56f4\u4e00\u81f4\u6027\u3001\u89c4\u5212\u6027\u548c\u6a21\u5757\u5316\u7b49\u81ea\u9002\u5e94\u5173\u952e\u7279\u6027\u65f6\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u51fa\u53ef\u4ee5\u7ed3\u5408\u8fd9\u4e9b\u65b9\u6cd5\u6784\u5efa\u591a\u5c42\u7ea7\u7684\u81ea\u9002\u5e94\u5fae\u670d\u52a1\u67b6\u6784\u3002", "motivation": "TeaStore \u89c4\u8303\u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5fae\u670d\u52a1\u7684\u6848\u4f8b\u7814\u7a76\uff0c\u7528\u4e8e\u901a\u8fc7\u63a7\u5236\u5faa\u73af\u5b9e\u73b0\u81ea\u9002\u5e94\u3002\u7136\u800c\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u65f6\uff0c\u9700\u8981\u8003\u8651\u81ea\u9002\u5e94\u7684\u5173\u952e\u7279\u6027\uff1a\u7cfb\u7edf\u8303\u56f4\u7684\u4e00\u81f4\u6027\uff08\u8de8\u526f\u672c\u7684\u534f\u8c03\u9002\u5e94\uff09\u3001\u89c4\u5212\uff08\u6267\u884c\u9002\u5e94\u76f4\u5230\u6ee1\u8db3\u9002\u5f53\u6761\u4ef6\uff09\u548c\u6a21\u5757\u5316\uff08\u9002\u5e94\u903b\u8f91\u7684\u6e05\u6670\u96c6\u6210\uff09\u3002\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u8ba8\u5982\u4f55\u5b9e\u73b0\u8fd9\u4e9b\u5173\u952e\u7279\u6027\uff0c\u7279\u522b\u662f\u5982\u4f55\u5c06\u81ea\u9002\u5e94\u63a7\u5236\u903b\u8f91\u4ece TeaStore \u5e94\u7528\u4e2d\u89e3\u8026\u51fa\u6765\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6df1\u5165\u63a2\u8ba8\u548c\u5206\u6790\uff0c\u7814\u7a76\u4e86\u4e09\u79cd\u4e0d\u540c\u7684\u6280\u672f\u65b9\u6cd5\uff1a\u8f6f\u4ef6\u67b6\u6784\u65b9\u6cd5\u3001\u4e91\u539f\u751f Operator \u6a21\u5f0f\u4ee5\u53ca\u4f20\u7edf\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\uff0c\u5982\u4f55\u7528\u4e8e\u5b9e\u73b0\u5c06\u81ea\u9002\u5e94\u63a7\u5236\u903b\u8f91\u4e0e\u5fae\u670d\u52a1\u5e94\u7528\uff08TeaStore\uff09\u89e3\u8026\u7684\u76ee\u6807\u3002\u540c\u65f6\uff0c\u672c\u6587\u5bf9\u8fd9\u4e9b\u65b9\u6cd5\u5728\u7ec6\u7c92\u5ea6\u8868\u8fbe\u6027\u9002\u5e94\u4e0e\u7cfb\u7edf\u7ea7\u63a7\u5236\u4e4b\u95f4\u7684\u6743\u8861\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u7814\u7a76\u4e86\u8f6f\u4ef6\u67b6\u6784\u65b9\u6cd5\u3001\u4e91\u539f\u751f Operator \u6a21\u5f0f\u548c\u4f20\u7edf\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\u5728\u5b9e\u73b0\u81ea\u9002\u5e94\u63a7\u5236\u903b\u8f91\u4e0e TeaStore \u5e94\u7528\u89e3\u8026\u65f6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5b83\u4eec\u5728\u201c\u7ec6\u7c92\u5ea6\u8868\u8fbe\u6027\u9002\u5e94\u201d\u4e0e\u201c\u7cfb\u7edf\u8303\u56f4\u63a7\u5236\u201d\u4e4b\u95f4\u7684\u6743\u8861\u3002\u5206\u6790\u8868\u660e\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\uff0c\u81ea\u9002\u5e94\u7b56\u7565\u7684\u91cd\u7528\u975e\u5e38\u6709\u6548\u3002\u6700\u7ec8\u7684\u5206\u6790\u7ed3\u8bba\u662f\u8fd9\u4e9b\u65b9\u6cd5\u5e76\u975e\u4e92\u65a5\uff0c\u53ef\u4ee5\u7ed3\u5408\u6210\u4e00\u4e2a\u591a\u5c42\u7ea7\u7684\u81ea\u9002\u5e94\u5fae\u670d\u52a1\u67b6\u6784\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u5c06\u8f6f\u4ef6\u67b6\u6784\u65b9\u6cd5\u3001\u4e91\u539f\u751f Operator \u6a21\u5f0f\u4ee5\u53ca\u4f20\u7edf\u7f16\u7a0b\u8bed\u8a00\u6280\u672f\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u5b9e\u73b0\u81ea\u9002\u5e94\u63a7\u5236\u903b\u8f91\u4e0e TeaStore \u5e94\u7528\u89e3\u8026\u7684\u53ef\u80fd\u6027\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5e76\u975e\u4e92\u65a5\uff0c\u800c\u662f\u53ef\u4ee5\u7ed3\u5408\u6210\u4e00\u4e2a\u591a\u5c42\u7ea7\u67b6\u6784\uff0c\u4ece\u800c\u4e3a\u81ea\u9002\u5e94\u5fae\u670d\u52a1\u63d0\u4f9b\u4e00\u4e2a\u7075\u6d3b\u4e14\u5206\u5c42\u7684\u9002\u5e94\u80fd\u529b\u3002"}}
