<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 10]
- [cs.AR](#cs.AR) [Total: 2]
- [cs.PL](#cs.PL) [Total: 2]
- [cs.DS](#cs.DS) [Total: 3]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Toward Sustainability-Aware LLM Inference on Edge Clusters](https://arxiv.org/abs/2512.04088)
*Kolichala Rajashekar,Nafiseh Sharghivand,Radu Prodan,Reza Farahani*

Main category: cs.DC

TL;DR: 该论文与以下领域相关：图处理（graph processing，**没有**明确涉及，但 LLM 的内部结构有时可以被视为图）、编译器（compiler，**没有**明确涉及）、HLS（**没有**明确涉及）、DSL（**没有**明确涉及）、LLM 推理（inference，**明确相关**）、边缘计算（edge computing，**明确相关**）、可持续性/能耗（sustainability/energy consumption，**明确相关**）。

**太长不看 (TL;DR) 摘要:** 大语言模型（LLMs）的推理带来巨大的能耗和成本，尤其是在云端面临延迟和带宽限制。为了实现可持续性，本文提出了一种针对包含 NVIDIA Jetson Orin NX 和 Ada 2000 设备的边缘集群的 LLM 推理方法。通过对不同 prompt 和批处理配置下的能耗和延迟进行基准测试，设计了碳感知和延迟感知路由策略，将推理任务分配给特定的硬件，以平衡性能与碳足迹。实验结果显示，四条 prompt 的批处理大小在吞吐量和能效之间取得了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 大语言模型 (LLMs) 的推理需要大量计算资源，导致高昂的碳排放和运营成本。尽管云端推理具有可扩展性，但受限于集中处理和连续数据传输带来的延迟和带宽问题。边缘集群可以缓解这些限制，但面临性能、能效和设备约束之间的权衡。因此，需要一种可持续性感知的 LLM 推理方法，以平衡推理延迟和碳足迹。

Method: 提出了一种针对边缘集群的、可持续性感知的 LLM 推理方法，旨在平衡推理延迟和碳足迹。具体方法是使用基于经验基准测试的碳感知和延迟感知路由策略，将 prompt 路由到特定的硬件（NVIDIA Jetson Orin NX (8GB) 和 Nvidia Ada 2000 (16GB)）上。基准测试涵盖了不同 prompt 和批处理配置下的能耗和执行时间。并将这些策略与基线贪婪策略进行了比较。

Result: 在 NVIDIA Jetson Orin NX 和 Nvidia Ada 2000 组成的边缘集群上进行了实验评估。结果表明，四条 prompt 的批处理大小在吞吐量和能效之间达到了一个良好的平衡点，而更大的批处理大小可能会导致 GPU 内存饱和。碳感知和延迟感知策略在 prompt 路由中与基线贪婪策略进行了比较，证明了其有效性。

Conclusion: 本文通过实验验证，四条 prompt 的批处理大小在吞吐量和能效之间取得了良好的平衡，更大的批处理大小则可能导致 GPU 内存饱和。所提出的碳感知和延迟感知路由策略为边缘集群的 LLM 推理提供了在性能和可持续性之间进行权衡的有效方法。

Abstract: Large language models (LLMs) require substantial computational resources, leading to significant carbon emissions and operational costs. Although training is energy-intensive, the long-term environmental burden arises from inference, amplified by the massive global query volume. Cloud-based inference offers scalability but suffers from latency and bandwidth constraints due to centralized processing and continuous data transfer. Edge clusters instead can mitigate these limitations by enabling localized execution, yet they face trade-offs between performance, energy efficiency, and device constraints. This short paper presents a sustainability-aware LLM inference for edge clusters comprising NVIDIA Jetson Orin NX (8GB) and Nvidia Ada 2000 (16GB) devices. It aims to balance inference latency and carbon footprint through carbon- and latency-aware routing strategies, guided by empirical benchmarking of energy consumption and execution time across diverse prompts and batch (i.e., group of prompts) configurations. We compared baseline greedy strategies to carbon-aware and latency-aware strategies in prompt routing to specific hardware based on benchmarking information. Experimental evaluation shows that a batch size of four prompts achieves a trade-off between throughput, energy efficiency, while larger batches risk GPU memory saturation.

</details>


### [2] [Serverless Everywhere: A Comparative Analysis of WebAssembly Workflows Across Browser, Edge, and Cloud](https://arxiv.org/abs/2512.04089)
*Mario Colosi,Reza Farahani,Lauri Loven,Radu Prodan,Massimo Villari*

Main category: cs.DC

TL;DR: 关联：本文与 DSL、图处理、MLIR、编译器、HLS 没有直接关联。它专注于 WebAssembly (Wasm) 的性能评估，Wasm 本身与编译器技术相关，但本文的研究点在于其 **无服务器工作流** 场景下的性能分析。
太长不读：本文评估了基于 Wasm 的无服务器工作流在浏览器、边缘和云环境中的性能。结果显示，AOT 编译和实例预热能大幅减少启动延迟。对于小负载，浏览器表现良好；但随着负载增大，边缘和云节点的 AOT 执行性能明显优于浏览器。


<details>
  <summary>Details</summary>
Motivation: WebAssembly (Wasm) 作为一种便携、沙盒化、接近原生执行的二进制指令格式，非常适合在浏览器、边缘节点和云服务器等异构平台上执行无服务器工作流。然而，其性能和稳定性受到启动开销、运行时执行模型（如 AOT/JIT）和部署环境资源可变性等因素的严重影响。因此，有必要对 Wasm-based 无服务器工作流在不同环境中的实际性能进行评估。

Method: 本文通过在浏览器、边缘节点和云服务器上一致地执行基于 Wasm 的无服务器工作流（使用 wasm32-wasi 模块），并对冷启动/热启动延迟、每一步骤延迟、工作流完成时间、吞吐量以及 CPU/内存利用率等指标进行测量和评估，以捕获跨环境的端到端行为。具体设置包括：浏览器中在 web worker 内执行，边缘和云端使用 HTTP shim 将帧流式传输到 Wasm 运行时。

Result: 评估结果显示：1. AOT 编译和实例预热能显著减少启动延迟。2. 对于小负载工作流，浏览器由于完全在内存中进行数据交换，实现了具有竞争力的性能。3. 随着负载增大，工作流转变为计算密集型和内存密集型，此时边缘和云节点上的 AOT 执行性能明显优于浏览器。

Conclusion: 本文评估的 Wasm-based 无服务器工作流在不同环境（浏览器、边缘节点和云服务器）下的执行性能和资源消耗。结论表明，使用 AOT 编译和实例预热可以显著减少启动延迟，提高性能。对于小负载工作流，由于全内存数据交换，浏览器具有竞争力；而随着负载增大，工作流转变为计算和内存密集型，边缘和云节点上的 AOT 执行性能明显优于浏览器。

Abstract: WebAssembly (Wasm) is a binary instruction format that enables portable, sandboxed, and near-native execution across heterogeneous platforms, making it well-suited for serverless workflow execution on browsers, edge nodes, and cloud servers. However, its performance and stability depend heavily on factors such as startup overhead, runtime execution model (e.g., Ahead-of-Time (AOT) and Just-in-Time (JIT) compilation), and resource variability across deployment contexts. This paper evaluates a Wasm-based serverless workflow executed consistently from the browser to edge and cloud instances. The setup uses wasm32-wasi modules: in the browser, execution occurs within a web worker, while on Edge and Cloud, an HTTP shim streams frames to the Wasm runtime. We measure cold- and warm-start latency, per-step delays, workflow makespan, throughput, and CPU/memory utilization to capture the end-to-end behavior across environments. Results show that AOT compilation and instance warming substantially reduce startup latency. For workflows with small payloads, the browser achieves competitive performance owing to fully in-memory data exchanges. In contrast, as payloads grow, the workflow transitions into a compute- and memory-intensive phase where AOT execution on edge and cloud nodes distinctly surpasses browser performance.

</details>


### [3] [Energy-Efficient Resource Management in Microservices-based Fog and Edge Computing: State-of-the-Art and Future Directions](https://arxiv.org/abs/2512.04093)
*Ali Akbar Vali,Sadoon Azizi,Mohammad Shojafar,Rajkumar Buyya*

Main category: cs.DC

TL;DR: This paper is related to Compiler/HLS since it involves resource management and optimization in a distributed computing environment, which relates to efficient resource allocation akin to compiler/HLS's goal of optimization for hardware. This paper is not directly related to DSL, Graph Processing or MLIR.
这是一篇关于微服务下雾和边缘计算资源管理的综合综述。由于物联网设备激增对高效服务的需求，雾和边缘计算的资源管理面临挑战。该综述系统回顾了2020-2024年间超过136项研究，将其分为服务放置、资源调配、任务调度和卸载、资源分配以及实例选择五个子领域，并特别关注节能解决方案。作者指出了现有研究中资源管理各组件间缺乏协同作用的问题，并提出了利用AI驱动优化、量子计算和Serverless计算等未来研究方向，旨在为该领域研究人员和实践者提供一个统一且注重能效的视角。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）设备的指数级增长，对高效和响应式服务的需求愈发紧迫。雾和边缘计算虽然通过将计算资源靠近终端用户来减少延迟、带宽限制和能耗，但在资源受限、计算异构性、动态工作负载和多样化的QoS要求下，其资源管理面临挑战。因此，需要一个关于最先进资源管理策略的全面综述，尤其关注微服务下的节能解决方案。

Method: 本文对2020年至2024年的超过136项研究进行了系统回顾和分类，将其划分为五个关键子领域：服务放置、资源调配、任务调度和卸载、资源分配以及实例选择。分类基于优化技术、目标和每种方法的优缺点。同时，它还审查了现有综述，并指出了尚未解决的挑战和文献中的空白。

Result: 本文系统地回顾和分类了超过136项研究（2020-2024），将其归类为五个子领域：服务放置、资源调配、任务调度和卸载、资源分配、实例选择。通过识别现有工作中的不足，特别是缺乏各个资源管理组件间的协同作用，本文提出了未来有希望的研究方向，如AI驱动的优化、量子计算和Serverless计算。

Conclusion: 这篇综述总结了微服务下雾和边缘计算资源管理的最新进展，特别是关注节能解决方案。它强调了现有研究中缺乏协同作用，并指出了未来有前景的研究方向，包括利用AI驱动的优化、量子计算和Serverless计算，旨在为研究人员和实践者提供一个统一且注重能效的资源管理视角，为更集成、高效和可持续的未来解决方案奠定基础。

Abstract: The exponential growth of Internet of Things (IoT) devices has intensified the demand for efficient and responsive services. To address this demand, fog and edge computing have emerged as distributed paradigms that bring computational resources closer to end users, reducing latency, bandwidth limitations, and energy consumption. However, these paradigms present challenges in resource management due to resource constraints, computational heterogeneity, dynamic workloads, and diverse Quality of Service (QoS) requirements. This paper presents a comprehensive survey of state-of-the-art resource management strategies in microservices-based fog and edge computing, focusing on energy-efficient solutions. We systematically review and classify more than 136 studies (2020-2024) into five key subdomains: service placement, resource provisioning, task scheduling and offloading, resource allocation, and instance selection. Our categorization is based on optimization techniques, targeted objectives, and the strengths and limitations of each approach. In addition, we examine existing surveys and identify unresolved challenges and gaps in the literature. By highlighting the lack of synergy among fundamental resource management components, we outline promising research directions leveraging AI-driven optimization, quantum computing, and serverless computing. This survey serves as a comprehensive reference for researchers and practitioners by providing a unified and energy-aware perspective on resource management in microservices-based fog and edge computing, paving the way for more integrated, efficient, and sustainable future solutions.

</details>


### [4] [Formal Specification for Fast ACS: Low-Latency File-Based Ordered Message Delivery at Scale](https://arxiv.org/abs/2512.04096)
*Sushant Kumar Gupta,Anil Raghunath Iyer,Chang Yu,Neel Bagora,Olivier Pomerleau,Vivek Kumar,Prunthaban Kanthakumar*

Main category: cs.DC

TL;DR: 这个论文与DSL或图处理或MLIR或编译器或HLS无关。

Too Long; Didn't Read (TLDR): Fast ACS 是一种文件化的有序消息传递系统，它结合了RPC（双边）和RMA（单边）机制，实现了跨集群的低延迟消息交付。该系统已成功部署到生产环境，能够扩展至数千个消费者，峰值流量达Tbps，并在全球范围内以亚秒级（p99）的低延迟交付消息，同时保持低资源成本。


<details>
  <summary>Details</summary>
Motivation: 实时系统对低延迟消息交付有极高的要求，而现有系统需要一个健壮的消息传递系统来处理日益增长的计算规模和跨越大范围集群的消息传输。特别是在有数千个数据消费者的情况下，系统需要确保消息的有序性和至少一次交付，同时避免消费者过载，并允许他们以自己的速度消费消息。

Method: Fast ACS 的设计结合了双边（RPC，用于集群间通信）和单边（RMA，用于集群内通信）通信原语来实现消息交付。它是一种基于文件的有序消息传递系统，旨在提供低延迟、有序和至少一次交付的消息服务，同时允许消费者按自己的节奏消费消息。

Result: Fast ACS 已成功部署到数十个生产集群，并且在每个集群内可扩展到容纳数千个消费者，峰值时集群内消费者流量达到 Tbps 级别。显著地，Fast ACS 能够在低资源成本下，根据消息量和消费者规模，在全球范围内以几秒甚至亚秒级（p99）的延迟向消费者交付消息。

Conclusion: Fast ACS 是一个文件化的有序消息传递系统，它结合了双边（RPC）和单边（RMA）通信原语，实现了跨集群的低延迟消息交付，并在保证有序性和至少一次交付的同时，避免消费者过载。该系统已成功部署到生产集群，在低资源成本下，能够扩展到数千个消费者，并在全球范围内以秒级甚至亚秒级（p99）的延迟交付消息。

Abstract: Low-latency message delivery is crucial for real-time systems. Data originating from a producer must be delivered to consumers, potentially distributed in clusters across metropolitan and continental boundaries. With the growing scale of computing, there can be several thousand consumers of the data. Such systems require a robust messaging system capable of transmitting messages containing data across clusters and efficiently delivering them to consumers. The system must offer guarantees like ordering and at-least-once delivery while avoiding overload on consumers, allowing them to consume messages at their own pace.
  This paper presents the design of Fast ACS (an abbreviation for Ads Copy Service), a file-based ordered message delivery system that leverages a combination of two-sided (inter-cluster) and one-sided (intra-cluster) communication primitives - namely, Remote Procedure Call and Remote Memory Access, respectively - to deliver messages. The system has been successfully deployed to dozens of production clusters and scales to accommodate several thousand consumers within each cluster, which amounts to Tbps-scale intra-cluster consumer traffic at peak. Notably, Fast ACS delivers messages to consumers across the globe within a few seconds or even sub-seconds (p99) based on the message volume and consumer scale, at a low resource cost.

</details>


### [5] [tritonBLAS: Triton-based Analytical Approach for GEMM Kernel Parameter Selection](https://arxiv.org/abs/2512.04226)
*Ryan Swann,Muhammad Osama,Xiaohu Guo,Bryant Nelson,Lixun Zhang,Alex Brown,Yen Ong,Ali Yazdani,Sean Siddens,Ganesh Dasika,Alex Underwood*

Main category: cs.DC

TL;DR: 该论文与编译器、DSL（Triton）和图处理相关，因为它研究了用于高性能计算的通用矩阵乘法（GEMM）内核的生成和优化。特别是，它利用像Triton这样的特定领域语言（DSL）开发了一个分析模型（tritonBLAS）来生成高性能的GPU内核，而无需传统的自动调优。

tritonBLAS是一个用于GPU GEMM的快速、确定性分析模型和框架。它通过显式建模缓存层次结构、数据布局、矩阵形状和算法分块等架构和算法参数，来预测并生成近乎最优的GEMM配置，从而消除了耗时的运行时自动调优需求。在多种现代GPU上的评估显示，tritonBLAS的性能超过自动调优解决方案的95%，同时将调优时间降至零，使其成为HPC和ML生产环境中经验性调优的实用替代方案。


<details>
  <summary>Details</summary>
Motivation: 现有的高性能GEMM内核通常依赖于耗时的运行时自动调优（Autotuning）来寻找最优配置。本文的动机是开发一个快速、确定性的分析模型——tritonBLAS，该模型无需运行时调优，即可根据架构参数和代码数据布局，预测并生成性能接近经验性调优解决方案的GEMM内核，从而解决自动调优耗时的问题。

Method: tritonBLAS通过建立快速且确定性的分析模型来生成高性能的GPU GEMM内核。该模型明确地将架构拓扑（如缓存层次结构）、代码和数据相对位置、矩阵形状以及算法分块行为之间的关系进行建模，以预测近乎最优的配置。基于此模型，开发实现了一个完全在Triton内部的轻量级GEMM框架。

Result: tritonBLAS在各种GEMM问题规模上进行了评估，并在现代GPU上展示出优异的性能。其性能达到了自动调优解决方案的95%以上，同时将调优时间减少到零。这证明tritonBLAS是生产HPC和ML工作负载中经验性调优（empirical tuning）的实用替代品。

Conclusion: tritonBLAS是一个针对GPU GEMM的高效且确定性的分析模型和框架。它通过建模架构参数和算法行为，实现了接近运行时自动调优（Autotuning）的性能（超过95%），而将调优时间降低为零。这使其成为生产级HPC和ML工作负载中经验性调优的实用替代品。

Abstract: We present tritonBLAS, a fast and deterministic analytical model that uses architectural parameters like the cache hierarchy, and relative code and data placement to generate performant GPU GEMM kernels. tritonBLAS explicitly models the relationship between architectural topology, matrix shapes, and algorithmic blocking behavior to predict near-optimal configurations without runtime autotuning. Based on this model, we developed and implemented a lightweight GEMM framework entirely within Triton. We evaluate the performance of tritonBLAS across a diverse set of GEMM problem sizes on modern GPUs. tritonBLAS achieves over 95% of the performance of autotuning solutions, while reducing autotuning time to zero. This makes tritonBLAS a practical drop-in replacement for empirical tuning in production HPC and ML workloads.

</details>


### [6] [VLCs: Managing Parallelism with Virtualized Libraries](https://arxiv.org/abs/2512.04320)
*Yineng Yan,William Ruys,Hochan Lee,Ian Henriksen,Arthur Peters,Sean Stephens,Bozhi You,Henrique Fingler,Martin Burtscher,Milos Gligoric,Keshav Pingali,Mattan Erez,George Biros,Christopher J. Rossbach*

Main category: cs.DC

TL;DR: 该论文与编译器和高性能计算相关。这篇文章提出了虚拟库上下文（VLCs）作为一种无需修改库代码的解决方案，用于管理现代并行系统中使用并发库时的资源分配和解决线程不安全问题。VLCs是进程的子单元，可以隔离库及其资源，从而有效防止资源争用，并允许在同一进程内并行执行原本线程不安全的库代码。实验结果显示，VLCs在涉及OpenMP、OpenBLAS和LibTorch的应用中实现了高达2.85倍的加速比。


<details>
  <summary>Details</summary>
Motivation: 随着现代并行机器的复杂性和规模持续增长，程序员越来越依赖软件库组合来封装和利用并行性。然而，许多库并非以组合性为设计初衷，并假设它们可以独占所有资源。并发使用此类库可能导致资源争用和性能下降。现有的解决方案通常涉及修改库或操作系统，但在许多情况下并不可行。因此，需要一种无需修改库代码即可解决资源争用和线程不安全问题的机制。

Method: 文章提出了一种名为虚拟库上下文（VLCs）的机制。VLCs是进程的子单元，用于封装一组库及其相关的资源分配。VLCs在不修改库代码的情况下控制这些库的资源利用。这允许用户在库之间划分资源以防止争用，或者加载同一库的多个副本以允许在同一进程中并行执行原本线程不安全的代码。作者使用C++和Python原型对VLCs进行了描述和评估。

Result: 作者在C++和Python中实现了VLCs的原型，并在包含使用OpenMP、OpenBLAS和LibTorch的应用程序的基准测试中进行了评估。实验结果表明，VLCs可以实现高达2.85倍的加速比。

Conclusion: 虚拟库上下文（VLCs）是一种有效的、无需修改库代码的解决方案，可以解决现代并行系统中并发使用库时资源争用和线程不安全代码的问题。我们的实验证明了VLCs在提高性能方面的潜力，特别是在涉及OpenMP、OpenBLAS和LibTorch等主流并行库的应用中。

Abstract: As the complexity and scale of modern parallel machines continue to grow, programmers increasingly rely on composition of software libraries to encapsulate and exploit parallelism. However, many libraries are not designed with composition in mind and assume they have exclusive access to all resources. Using such libraries concurrently can result in contention and degraded performance. Prior solutions involve modifying the libraries or the OS, which is often infeasible.
  We propose Virtual Library Contexts (VLCs), which are process subunits that encapsulate sets of libraries and associated resource allocations. VLCs control the resource utilization of these libraries without modifying library code. This enables the user to partition resources between libraries to prevent contention, or load multiple copies of the same library to allow parallel execution of otherwise thread-unsafe code within the same process.
  In this paper, we describe and evaluate C++ and Python prototypes of VLCs. Experiments show VLCs enable a speedup up to 2.85x on benchmarks including applications using OpenMP, OpenBLAS, and LibTorch.

</details>


### [7] [Counting Without Running: Evaluating LLMs' Reasoning About Code Complexity](https://arxiv.org/abs/2512.04355)
*Gregory Bolet,Giorgis Georgakoudis,Konstantinos Parasyris,Harshitha Menon,Niranjan Hasabnis,Kirk W. Cameron,Gal Oren*

Main category: cs.DC

TL;DR: 相关领域：编译器、图处理、LLM。
太长不读：现代GPU软件栈需要预先预测FLOPs，但LLMs在这方面表现不佳。本文提出了gpuFLOPBench基准测试，包含577个来自HeCBench的CUDA内核，要求LLMs预测单精度和双精度的FLOPs，旨在测试LLMs进行前瞻性性能推理的能力。评估结果显示，最新的LLMs在直接内核上表现良好，但在存在隐式FLOPs时仍有数量级的误差，这暴露了现有代码助手无法内化硬件特定微码效应的核心限制。gpuFLOPBench可作为开发更严谨性能推理LLM工具的测试平台。


<details>
  <summary>Details</summary>
Motivation: 现代GPU软件栈要求开发人员在启动内核之前预测性能瓶颈，错误地判断浮点工作负载会影响调优、调度甚至硬件采购。尽管代码生成方面取得了快速进展，但当前的大型语言模型（LLMs）很少接受这种前瞻性推理的测试。作者旨在通过提出gpuFLOPBench来弥补这一差距。

Method: 提出了gpuFLOPBench基准测试，要求模型通过预测来自HeCBench的577个CUDA内核的单精度和双精度FLOP计数来“不运行而计数”。基准测试注释了真实情况的配置文件和八个执行属性，这些属性区分了易于分析的代码和FLOPs依赖于隐藏的编译器或运行时行为的内核。评估了当前的闭源推理模型。

Result: 最新的LLMs在直接的内核上实现了完美的分类，但当隐式FLOPs（例如来自除法、内在数学函数或常见子表达式）出现时，仍然会产生多个数量级的错误。这表明，现有代码助手的主要限制在于无法内化硬件特定的微码效应。

Conclusion: gpuFLOPBench为LLM研究提供了一个集中的测试平台，旨在开发能够像经验丰富的GPU开发人员一样严格地推理性能的工具。结果揭示了现有代码助手的一个核心限制：无法内化硬件特定的微码效应。

Abstract: Modern GPU software stacks demand developers who can anticipate performance bottlenecks before ever launching a kernel; misjudging floating-point workloads upstream can derail tuning, scheduling, and even hardware procurement. Yet despite rapid progress in code generation, today's Large Language Models (LLMs) are rarely tested on this kind of forward-looking reasoning. We close that gap with gpuFLOPBench, a benchmark that asks models to "count without running" by predicting single and double-precision FLOP counts for 577 CUDA kernels drawn from HeCBench, annotated with ground-truth profiles and eight execution attributes that distinguish trivially analyzable code from kernels whose FLOPs depend on hidden compiler or runtime behavior. Evaluating current closed-source reasoning models shows clear but uneven progress: the newest LLMs achieve perfect classification on straightforward kernels but still incur multiple order-of-magnitude errors whenever implicit FLOPs arise from division, intrinsic math functions, or common subexpressions. These results surface a core limitation of existing code assistants -- the inability to internalize hardware-specific microcode effects -- and position gpuFLOPBench as a focused testbed for developing LLM tooling that can reason about performance with the same rigor as experienced GPU developers. Sources are available at our repository: https://github.com/Scientific-Computing-Lab/gpuFLOPBench

</details>


### [8] [A Structure-Aware Irregular Blocking Method for Sparse LU Factorization](https://arxiv.org/abs/2512.04389)
*Zhen Hu,Dongliang Xiong,Kai Huang,Changjun Wu,Xiaowen Jiang*

Main category: cs.DC

TL;DR: 该论文与图处理（稀疏矩阵可以视为图的邻接矩阵，且LU分解是图算法相关）相关。

这篇论文提出了一种结构感知的非规则分块方法，用于优化稀疏LU分解中的数值分解。针对稀疏矩阵中非零元素的非均匀分布导致的负载不平衡问题，作者引入了一种新的基于对角块的特征量化局部非零分布。基于此特征，该方法在密集区域采用细粒度块，在稀疏区域采用粗粒度块，从而在依赖树的同一级和跨级上平衡非零元素。实验结果显示，在单张和四张 NVIDIA A100 GPU上，该方法相对于PanguLU和SuperLU_DIST均取得了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 稀疏LU分解后，非零元素在稀疏矩阵中呈非均匀分布（通常集中在对角线和右下角区域）。现有的规则二维分块（regular 2D blocking）在处理这种非均匀分布结构时会导致负载不平衡。此外，现有的矩阵特征无法有效地指导分块策略。因此，需要一种能够根据非零元素的局部分布进行调整的非规则分块方法来提高数值分解的效率和负载均衡。

Method: 本文提出了一种结构感知的非规则分块方法（structure-aware irregular blocking），具体步骤包括：1. 引入了一种新颖的基于对角块的特征（diagonal block-based feature）来有效地刻画稀疏矩阵的局部非零分布。2. 基于该特征，提出了一种非规则分块方法，根据非零元素的局部分布调整块大小。3. 策略上，在密集区域使用细粒度块，在稀疏区域使用粗粒度块，以充分平衡依赖树中同一级别和跨级别块的非零元素。

Result: 在单张NVIDIA A100 GPU上，所提出的非规则分块方法相对于PanguLU和最新的SuperLU_DIST分别实现了平均1.50倍和3.32倍的加速。在4张NVIDIA A100 GPU上，相对于PanguLU和SuperLU_DIST分别实现了1.40倍和3.84倍的加速。

Conclusion: 本文提出了一种结构感知的非规则分块方法，通过引入新的对角块基特征来表征稀疏矩阵的局部非零分布。实验结果表明，该非规则分块方法在单张和多张NVIDIA A100 GPU上，相对于现有的PanguLU和SuperLU_DIST等方法，取得了显著的性能提升。

Abstract: In sparse LU factorization, nonzero elements after symbolic factorization tend to distribute in diagonal and right-bottom region of sparse matrices. However, regular 2D blocking on this non-uniform distribution structure may lead to workload imbalance across blocks. Besides, existing matrix features fail to guide us effectively in blocking. In this paper, we propose a structure-aware irregular blocking method for numerical factorization. A novel diagonal block-based feature is introduced to effectively characterize the local nonzero distribution of sparse matrices. Based on this, we further propose an irregular blocking method that adjusts block sizes according to the local distribution of nonzeros. The strategy utilizes fine-grained blocks in dense regions and coarse-grained blocks in sparse regions, adequately balancing the nonzeros of blocks both within the same level and across levels in the dependency tree. Experiments demonstrate that, on a single NVIDIA A100 GPU, our proposed irregular blocking method achieves average speedups of 1.50x and 3.32x over PanguLU and the latest SuperLU_DIST, respectively. In addition, it achieves speedups of 1.40x and 3.84x over PanguLU and SuperLU_DIST on 4 NVIDIA A100 GPUs.

</details>


### [9] [Offloading to CXL-based Computational Memory](https://arxiv.org/abs/2512.04449)
*Suyeon Lee,Kangkyu Park,Kwangsik Shin,Ada Gavrilovska*

Main category: cs.DC

TL;DR: 该论文与 DSL、图处理、MLIR、编译器或 HLS 不直接相关。

太长不看（TLDR）摘要：这篇论文提出了一种名为 KAI 的新型系统，用于优化基于 CXL（Compute Express Link）的计算内存（CCM）的性能。通过分析不同 CXL 协议下操作卸载的权衡，作者设计并实现了“异步回流（Asynchronous Back-Streaming）”协议，以支持主机和 CCM 之间的异步数据移动和轻量级流水线。实验结果显示，KAI 将端到端运行时间最多减少 50.4%，并显著降低了 CCM 和主机的空闲时间，从而有效解决了内存解耦系统中数据移动和系统效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的内存解耦系统（disaggregated memory systems）中的数据移动开销限制了系统的整体性能。基于 CXL 的计算内存（CCM）提供了在扩展的远程内存中进行近内存处理的能力，但现有的操作卸载机制无法有效利用基于不同 CXL 协议的模型之间的权衡。因此，需要一种能够充分利用 CXL 协议优势并减少数据移动和处理器空闲时间的新机制来加速性能。

Method: 本文首先分析了基于不同CXL协议的操作卸载机制的权衡及其对端到端性能和系统效率的影响。在此基础上，提出了一种新颖的“异步回流（Asynchronous Back-Streaming）”协议，该协议通过精心设计数据和控制传输操作在底层CXL协议上进行分层。然后，他们设计了一个名为 KAI 的系统来实现这种异步回流模型，该系统支持主机-CCM交互中的异步数据移动和轻量级流水线。

Result: KAI 系统将端到端运行时间最多减少了 50.4%，并将 CCM 和主机的空闲时间分别平均减少了 22.11 倍和 3.85 倍。

Conclusion: KAI通过引入异步回流协议，有效整合了数据和控制传输操作，实现了主机和CCM之间的高效异步数据移动和轻量级流水线，从而显著降低了CCM系统的端到端执行时间，并减少了CCM和主机的空闲时间。这表明基于CCM的近内存计算可以通过精心设计的协议优化，极大地提升性能和系统效率。

Abstract: CXL-based Computational Memory (CCM) enables near-memory processing within expanded remote memory, presenting opportunities to address data movement costs associated with disaggregated memory systems and to accelerate overall performance. However, existing operation offloading mechanisms are not capable of leveraging the trade-offs of different models based on different CXL protocols. This work first examines these tradeoffs and demonstrates their impact on end-to-end performance and system efficiency for workloads with diverse data and processing requirements. We propose a novel 'Asynchronous Back-Streaming' protocol by carefully layering data and control transfer operations on top of the underlying CXL protocols. We design KAI, a system that realizes the asynchronous back-streaming model that supports asynchronous data movement and lightweight pipelining in host-CCM interactions. Overall, KAI reduces end-to-end runtime by up to 50.4%, and CCM and host idle times by average 22.11x and 3.85x, respectively.

</details>


### [10] [Federated Learning for Terahertz Wireless Communication](https://arxiv.org/abs/2512.04984)
*O. Tansel Baydas,Ozgur B. Akan*

Main category: cs.DC

TL;DR: This paper is related to Wireless Communications (THz), Distributed Learning (Federated Learning), and Optimization Dynamics. The paper develops a multi-carrier stochastic framework to analyze the impact of realistic wideband THz impairments (beam squint, molecular absorption, jitter) on Federated Learning convergence. It discovers a critical "diversity trap" where the convergence error floor is limited by the harmonic mean of subcarrier SNRs, meaning a single spectral hole can be debilitating. It also identifies a bandwidth limit and proposes an SNR-weighted aggregation strategy to recover convergence by mitigating variance singularity at spectral holes, a necessity when standard averaging fails in high-squint regimes.


<details>
  <summary>Details</summary>
Motivation: 尽管太赫兹通信和联邦学习（FL）的结合有望实现超快分布式学习，但现实宽带损伤对优化动态的影响尚未得到理论上的刻画，本文旨在弥合这一差距。

Method: 本文通过开发一个多载波随机框架来分析问题，该框架将局部梯度更新与频率选择性太赫兹效应（包括波束斜视、分子吸收和抖动）明确地耦合起来。进而通过理论分析和数值结果验证了所发现的效应和提出的解决方案。

Result: 发现了“多样性陷阱”现象：标准无偏聚合下的收敛误差下限由子载波信噪比的调和平均值决定，单一的频谱漏洞会导致带宽失效。提出了一个基本的带宽限制，超越临界点会导致收敛恶化。提出并证明了信噪比加权的聚合策略是必要的，以在高斜视情况下恢复收敛。数值结果验证了物理层参数对太赫兹-FL系统性能预期的影响。

Conclusion: 本文分析了太赫兹通信和联邦学习结合的场景下，现实宽带损伤对优化动态的影响。研究发现，在标准无偏聚合下，收敛误差下限由子载波信噪比的调和平均值驱动，单一的频谱漏洞（由波束斜视造成）可能导致整个带宽无法进行可靠的模型更新，形成“多样性陷阱”。同时，本文提出了一个基本的带宽限制，超过临界点的带宽扩展会因集成热噪声和增益崩溃而恶化收敛。为了解决这些问题，提出了一种信噪比加权的聚合策略，以抑制频谱漏洞处的方差奇异性，在标准平均失败的高斜视区域恢复收敛。

Abstract: The convergence of Terahertz (THz) communications and Federated Learning (FL) promises ultra-fast distributed learning, yet the impact of realistic wideband impairments on optimization dynamics remains theoretically uncharacterized. This paper bridges this gap by developing a multicarrier stochastic framework that explicitly couples local gradient updates with frequency-selective THz effects, including beam squint, molecular absorption, and jitter. Our analysis uncovers a critical diversity trap: under standard unbiased aggregation, the convergence error floor is driven by the harmonic mean of subcarrier SNRs. Consequently, a single spectral hole caused by severe beam squint can render the entire bandwidth useless for reliable model updates. We further identify a fundamental bandwidth limit, revealing that expanding the spectrum beyond a critical point degrades convergence due to the integration of thermal noise and gain collapse at band edges. Finally, we demonstrate that an SNR-weighted aggregation strategy is necessary to suppress the variance singularity at these spectral holes, effectively recovering convergence in high-squint regimes where standard averaging fails. Numerical results validate the expected impact of the discussed physical layer parameters' on performance of THz-FL systems.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [11] [FLEX: Leveraging FPGA-CPU Synergy for Mixed-Cell-Height Legalization Acceleration](https://arxiv.org/abs/2512.04527)
*Xingyu Liu,Jiawei Liang,Linfeng Du,Yipu Zhang,Chaofang Ma,Hanwei Fan,Jiang Xu,Wei Zhang*

Main category: cs.AR

TL;DR: 该论文与编译器和HLS无关，但是与FPGA相关，可以视为广义上的硬件加速或EDA工具设计。
FLEX是一种新型的FPGA-CPU混合单元高度合法化加速器。通过优化任务分配、FPGA/CPU协同、多粒度流水线技术，以及针对耗时计算（FOP中的单元移位）的专门优化，FLEX在速度上比现有的CPU-GPU和多线程CPU合法化工具分别提高了18.3倍和5.4倍，并提高了合法化质量。


<details>
  <summary>Details</summary>
Motivation: 电子设计自动化（EDA）中的合法化（legalization）任务，特别是针对混合单元高度的合法化，是一个计算密集型的过程。研究的动机在于克服现有解决方案（如CPU-GPU和多线程CPU）的速度限制和可扩展性挑战，通过设计一个高性能的FPGA-CPU异构加速器来显著提升合法化任务的处理速度和效率。

Method: 该论文提出了FLEX加速器，其核心方法包括：1. 优化任务分配策略，在FPGA和CPU之间进行高效的任务划分，以利用它们各自的优势。2. 采用多粒度流水线技术，加速合法化中最耗时的步骤，即寻找最佳放置位置（FOP）。3. 优化FOP中计算密集型的单元移位过程，使其与多粒度流水线框架无缝集成以进一步加速。

Result: 实验结果表明，与现有最先进的CPU-GPU和多线程CPU合法化工具相比，FLEX分别实现了高达18.3倍和5.4倍的加速，并展现出更好的可扩展性。同时，FLEX在合法化质量方面也分别提高了4%和1%。

Conclusion: FLEX是一种新颖的FPGA-CPU混合单元高度合法化（mixed-cell-height legalization）加速器。通过优化任务分配、FPGA与CPU的有效协同、多粒度流水线技术，以及针对耗时部分的优化设计，FLEX实现了显著的加速和可扩展性提升，同时也保持或提高了合法化质量。这项工作为电子设计自动化（EDA）中的布局布线问题提供了一个高性能的硬件加速解决方案。

Abstract: In this work, we present FLEX, an FPGA-CPU accelerator for mixed-cell-height legalization tasks. We address challenges from the following perspectives. First, we optimize the task assignment strategy and perform an efficient task partition between FPGA and CPU to exploit their complementary strengths. Second, a multi-granularity pipelining technique is employed to accelerate the most time-consuming step, finding optimal placement position (FOP), in legalization. At last, we particularly target the computationally intensive cell shifting process in FOP, optimizing the design to align it seamlessly with the multi-granularity pipelining framework for further speedup. Experimental results show that FLEX achieves up to 18.3x and 5.4x speedups compared to state-of-the-art CPU-GPU and multi-threaded CPU legalizers with better scalability, while improving legalization quality by 4% and 1%.

</details>


### [12] [Declarative Synthesis and Multi-Objective Optimization of Stripboard Circuit Layouts Using Answer Set Programming](https://arxiv.org/abs/2512.04910)
*Fang Li*

Main category: cs.AR

TL;DR: 关联：无。
太长不看：本文提出了一个基于 Answer Set Programming (ASP) 的自动化条形板电路布局设计方法。该方法将布局问题建模为综合和多目标优化任务，目标是最小化板面积和元件条带交叉，并使用 ASP 的声明性特点自然地表达复杂的几何和电气约束。通过两阶段求解，该方法能生成紧凑、可制造的布局，为电子原型设计和教育提供实用工具，并展示了声明式编程在复杂设计自动化中的潜力。


<details>
  <summary>Details</summary>
Motivation: 条形板电路布局设计是一个复杂的几何和电气约束问题，需要自动化的解决方案来提高电子原型设计和教育中的效率和布局质量。传统的自动化布局方法可能难以有效地处理这些复杂的约束和多目标优化。因此，需要开发一种新颖的方法来自动生成紧凑、可制造的条形板布局。

Method: 本文提出了一种使用 Answer Set Programming (ASP) 自动化条形板电路布局设计的新方法。该方法将布局问题表述为综合任务和多目标优化任务，目标是同时生成可行的布局，并最小化电路板面积和元件条带交叉。求解过程采用两阶段方法：第一阶段确保布局的可行性，第二阶段优化布局质量。核心是利用 ASP 的声明性特点来自然简洁地表达复杂的几何和电气约束。

Result: 实验结果表明，该方法能够针对一系列电路复杂程度，生成紧凑且可制造的布局。这证明了其在自动化条形板布局方面的显著进步，为电子原型设计和教育提供了一个实用的工具，并展示了声奥式编程在解决复杂设计自动化问题中的能力。

Conclusion: 本文提出的基于 Answer Set Programming (ASP) 的方法，通过将条形板电路布局问题建模为综合和多目标优化任务，能够自动生成紧凑、可制造的布局。该方法利用 ASP 的声明性特性，自然简洁地表达了复杂的几何和电气约束，并通过两阶段求解方法（先确保可行性，再优化质量）有效地解决了问题。这一进展为电子原型设计和教育提供了一个实用的工具，并展示了声明式编程在解决复杂设计自动化问题中的潜力。

Abstract: This paper presents a novel approach to automated stripboard circuit layout design using Answer Set Programming (ASP). The work formulates the layout problem as both a synthesis and multi-objective optimization task that simultaneously generates viable layouts while minimizing board area and component strip crossing. By leveraging ASP's declarative nature, this work expresses complex geometric and electrical constraints in a natural and concise manner. The two-phase solving methodology first ensures feasibility before optimizing layout quality. Experimental results demonstrate that this approach generates compact, manufacturable layouts for a range of circuit complexities. This work represents a significant advancement in automated stripboard layout, offering a practical tool for electronics prototyping and education while showcasing the power of declarative programming for solving complex design automation problems.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [13] [Optimizations and extensions for fair join pattern matching](https://arxiv.org/abs/2512.04876)
*Ioannis Karras*

Main category: cs.PL

TL;DR: 该论文与 DSL（Join Patterns 可被视为一种并发编程的 DSL）、图处理（Join Patterns 匹配类似于图匹配问题，但这里主要是一个基于树的算法优化）、编译器（没有直接提到编译器，但优化算法可能与编译器优化有关，不过抽象中未明确说明）、HLS（不相关）有关。

本文旨在提升并发和分布式系统编程中的 Join Patterns 匹配算法的性能。Join Patterns 允许 Actor 模型匹配邮箱中的消息组合。Haller 等人提出的基于树的、有状态的公平匹配算法虽然在处理带重型条件守卫的模式时表现良好，但在常规基准测试中不如 Rete 算法的实现。本文通过对 Haller 算法的增强和优化，使其在某些基准测试上实现了高达十倍的性能提升，在常规基准测试上接近 Rete 算法的性能，同时保持了处理重型守卫的优势。同时，本文还改进了基准测试套件，扩展了 Join Patterns 的实现，支持新的语法和动态模式切换，并展示了其在微服务 Web 架构中的应用。


<details>
  <summary>Details</summary>
Motivation: Join Patterns 是并发和分布式系统中一种未被充分探索的编程方法，它为 Actor 模型提供了匹配 Actor 邮箱中消息组合的新颖能力。Haller 等人的工作探索了带条件守卫的 Join Patterns，并规范了公平且确定的匹配语义，但其时间效率未被充分探索。虽然 Haller 等人的有状态、基于树的匹配算法在重型条件守卫的变体上表现良好，但在常规的 Join Pattern 匹配基准测试上表现不如改编自 Rete 算法的实现，且将 Rete 算法应用于 Join Pattern 匹配需要大量的手动改编。因此，本文旨在增强和优化 Haller 等人的匹配算法，以提高其性能，尤其是在常规基准测试上的表现，同时保持其处理条件守卫的优势。

Method: 本文增强并优化了 Haller 等人提出的有状态的、基于树的匹配算法，以提高性能。同时，改进了基准测试套件，扩展了 Join Pattern 的实现使其支持动态模式切换和改进的语法，并提出了一个微服务 Web 架构的用例。

Result: 本文将 Haller 等人的有状态、基于树的匹配算法的性能提升了高达十倍，使其在常规基准测试上接近了 Rete 算法的性能，同时保持了在重型条件守卫上的多功能性和性能优势。本文还增强了基准测试套件，增加了新功能和更好的可扩展性/用户友好性，并扩展了 Join Pattern 的实现，使其具有更少歧义的语法和动态模式切换。最后，本文展示了一个 Join Pattern 在微服务 Web 架构中的复杂模型用例。

Conclusion: 本文增强并优化了 Haller 等人的有状态的、基于树的匹配算法，使其性能在某些基准测试上提高了十倍，在常规基准测试上接近 Rete 算法的性能，同时保持了重型条件守卫下的多功能性和性能优势。同时，本文还改进了基准测试套件，添加了新的功能，增强了可扩展性和用户友好性，并扩展了 Join Pattern 的实现，使其具有更少歧义的语法以及动态模式切换功能。最后，本文展示了一个 Join Pattern 的复杂模型用例，证明了其在微服务 Web 架构中的适用性。

Abstract: Join patterns are an underexplored approach for the programming of concurrent and distributed systems. When applied to the actor model, join patterns offer the novel capability of matching combinations of messages in the mailbox of an actor. Previous work by Philipp Haller et al. in the paper "Fair Join Pattern Matching for Actors" (ECOOP 2024) explored join patterns with conditional guards in an actor-based setting with a specification of fair and deterministic matching semantics. Nevertheless, the question of time efficiency in fair join pattern matching has remained underexplored. The stateful tree-based matching algorithm of Haller et al. performs worse than an implementation that adapts the Rete algorithm to the regular version of a join pattern matching benchmark, while outperforming on a variant with heavy conditional guards, which take longer to evaluate. Nevertheless, conforming Rete to the problem of join pattern matching requires heavy manual adaptation.
  In this thesis, we enhance and optimize the stateful tree-based matching algorithm of Haller et al. to achieve up to tenfold performance improvements on certain benchmarks, approaching the performance of Rete on regular benchmarks while maintaining the advantages of versatility and performance with heavy guards. We also enhance the benchmark suite, adding new features and enhancing its extensibility and user-friendliness. We extend the join pattern implementation with a less ambiguous syntax as well as dynamic pattern switching. Finally, we present a new complex model use case for join patterns, showing their applicability in a microservice web architecture.

</details>


### [14] [Typing Fallback Functions: A Semantic Approach to Type Safe Smart Contracts](https://arxiv.org/abs/2512.04755)
*Stian Lybech,Daniele Gorla,Luca Aceto*

Main category: cs.PL

TL;DR: 该论文与DSL、图处理、MLIR、编译器或HLS都有关，因为它研究了一种被称为TINYSOL的精简版Solidity语言（可以看作是特定领域语言 **DSL** 的一种形式）的类型安全，并涉及 **编译器** 理论中的类型化操作语义以及安全证明的表达和检查机制。

该论文提出了一种在智能合约环境中实现**语义类型化**的方法，以确保使用静态不可类型化构造（如回退函数）的代码的**类型安全**。其核心思想是采用**携带证明代码 (Proof-Carrying Code, PCC)** 的模式：合约创建者为代码附上基于类型语义的类型安全形式化证明证书，用户只需检查证书的有效性。具体针对**TINYSOL**语言，该方法通过安全类型实现了**信息流控制和非干扰性**，并通过**类型化操作语义和余归纳定义的类型化解释**来表达和紧凑表示安全证明。该工作的主要贡献在于为在**区块链/智能合约**设置中实现这种高级安全保证提供了必要的**理论发展**。


<details>
  <summary>Details</summary>
Motivation: 智能合约语言（如Solidity）中的某些特殊语言构造（如回退函数，fallback function）是静态不可类型化的，这使得使用这些构造的代码难以进行类型安全检查。在区块链环境的不可变性和公开性背景下，类型不安全可能导致严重的安全漏洞。因此，确保智能合约代码的类型安全至关重要，尤其是在涉及到信息流控制等安全属性时。本文旨在开发一种机制，即使对于静态不可类型化的构造，也能在智能合约设置中保证代码的类型安全。

Method: 1. **语义类型化和证明携带代码（PCC）的概念引入：** 为了确保使用静态不可类型化结构（如回退函数）的智能合约代码的类型安全，作者提出了在智能合约设置中进行语义类型化。合约创建者为包含此类构造的代码附上类型安全的形式化证明（基于类型的语义），用户只需检查提供的“证明证书”的有效性。这本质上是一种在区块链环境中实现的携带证明代码（PCC）形式。
2. **具体应用：** 以Solidity的精简版语言TINYSOL为例，通过安全类型来确保信息流控制和非干扰性（non-interference）。
3. **技术实现：** 提供了TINYSOL的类型化操作语义以定义类型的语义。
4. **证明表达和紧凑表示：** 将安全证明表达为余归纳定义的类型化解释（coinductively-defined typing interpretations），并借鉴双相似性（bisimilarity）中使用的 up-to 技术对其进行紧凑表示。
5. **案例展示：** 展示了该机制如何用于对基于回退函数的典型“指向实现”模式（pointer-to-implementation pattern）进行类型化。

Result: 1. 成功建立了一个理论框架，用于在智能合约（特别是针对TINYSOL）环境中实现语义类型化和证明携带代码（PCC）。
2. 该框架能够通过安全类型确保信息流控制和非干扰性。
3. 提供了将安全证明表示为紧凑的余归纳定义的类型化解释的方法。
4. 证明表明，该机制可用于对基于回退函数的“指向实现”模式进行类型化。
5. 作者强调，主要贡献在于使得这种方法在区块链/智能合约设置中可行的理论发展，而非特定安全定理的证明本身。

Conclusion: 本文的关键贡献在于提供了一套理论框架，将携带证明代码（Proof-Carrying Code, PCC）与智能合约环境相结合，确保了使用静态不可类型化结构（如回退函数）的智能合约代码的类型安全。这种安全保证是通过附带的类型安全形式化证明证书并在区块链上进行有效性检查来实现的。这种方法有助于解决智能合约中如信息流控制和非干扰性等安全问题，并提供了一种在区块链不可变环境中实现高级类型安全检查的可行途径。

Abstract: This paper develops semantic typing in a smart-contract setting to ensure type safety of code that uses statically untypable language constructs, such as the fallback function. The idea is that the creator of a contract on the blockchain equips code containing such constructs with a formal proof of its type safety, given in terms of the semantics of types. Then, a user of the contract only needs to check the validity of the provided `proof certificate' of type safety. This is a form of proof-carrying code, which naturally fits with the immutable nature of the blockchain environment.
  As a concrete application of our approach, we focus on ensuring information flow control and non-interference for the language TINYSOL, a distilled version of the Solidity language, through security types. We provide the semantics of types in terms of a typed operational semantics of TINYSOL, and a way for expressing the proofs of safety as coinductively-defined typing interpretations and for representing them compactly via up-to techniques, similar to those used for bisimilarity. We also show how our machinery can be used to type the typical pointer-to-implementation pattern based on the fallback function. However, our main contribution is not the safety theorem per se (and so security properties different from non-interference can be considered as well), but rather the presentation of the theoretical developments necessary to make this approach work in a blockchain/smart-contract setting.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [15] [Improved Time-Space Tradeoffs for 3SUM-Indexing](https://arxiv.org/abs/2512.04258)
*Itai Dinur,Alexander Golovnev*

Main category: cs.DS

TL;DR: 该论文与 DSL、图处理、MLIR、编译器或 HLS 无关。

太长不看版：3SUM-Indexing 是一种预处理变体的 3SUM 问题，其时空权衡 $T S^3 = n^6$ 是由通用的 Fiat-Naor 算法达到的。本文利用 3SUM-Indexing 的结构，提出了一种将反演函数分解为“子函数”的新方法来应用改进的 Fiat-Naor 算法，从而在特定参数范围 $n^{3/2} \ll S \ll n^{7/4}$ 内将时空权衡改进到 $T S = n^{2.5}$，优于现有最佳结果。该改进还扩展到了 $k$SUM-Indexing、$k$XOR-Indexing、Gapped String Indexing 和 Jumbled Indexing 等相关问题。


<details>
  <summary>Details</summary>
Motivation: 3SUM-Indexing 是 3SUM 问题的一个预处理变体，其最佳时空权衡是 $T S^3 = n^6$（忽略对数因子），这是通过使用 Fiat-Naor 函数反演通用算法实现的。先前的工作 [GGHPV20] 提出是否可以通过利用 3SUM-Indexing 的结构来改进这种通用算法。本文的动机正是要回答这一问题，通过结构性利用来改进 3SUM-Indexing、kSUM-Indexing、kXOR-Indexing 以及相关问题的时空权衡。

Method: 本文通过利用 3SUM-Indexing 问题的结构性，提出了一种应用 Fiat-Naor 算法的替代方法。具体来说，新方法是将待反演的函数分解为具有特定性质的“子函数”，从而能够将 [GGPS23] 中对 Fiat-Naor 算法的改进应用于 3SUM-Indexing，并大幅扩展了适用参数的范围。

Result: 1. 对于 3SUM-Indexing，在 $n^{3/2} \ll S \ll n^{7/4}$ 的范围内，将最佳已知时空权衡从 $T S^3 = n^6$ 改进到 $T S = n^{2.5}$。
2. 将这种改进扩展到 $k$SUM-Indexing（3SUM-Indexing 的推广）和 $k$XOR-Indexing（将加法替换为 XOR 的问题）。
3. 改进了 Gapped String Indexing 和 Jumbled Indexing 问题的现有最佳时空权衡。

Conclusion: 本文通过利用 3SUM-Indexing 问题的结构，提出了一种分解函数为具有特定性质的“子函数”的新方法来应用 Fiat-Naor 算法。这使得之前针对 Fiat-Naor 算法的改进（GGPS23）能在更广的参数范围内适用于 3SUM-Indexing，从而在 $n^{3/2} \ll S \ll n^{7/4}$ 的范围内，将 3SUM-Indexing 的时空权衡从 $T S^3 = n^6$ 改进到 $T S = n^{2.5}$。这种技术也被扩展到 $k$SUM-Indexing、$k$XOR-Indexing、Gapped String Indexing 和 Jumbled Indexing 问题，并提供了新的、更好的时空权衡。作者相信这种技术可用于 Fiat-Naor 算法更多依赖于应用的优化中。

Abstract: 3SUM-Indexing is a preprocessing variant of the 3SUM problem that has recently received a lot of attention. The best known time-space tradeoff for the problem is $T S^3 = n^{6}$ (up to logarithmic factors), where $n$ is the number of input integers, $S$ is the length of the preprocessed data structure, and $T$ is the running time of the query algorithm. This tradeoff was achieved in [KP19, GGHPV20] using the Fiat-Naor generic algorithm for Function Inversion. Consequently, [GGHPV20] asked whether this algorithm can be improved by leveraging the structure of 3SUM-Indexing.
  In this paper, we exploit the structure of 3SUM-Indexing to give a time-space tradeoff of $T S = n^{2.5}$, which is better than the best known one in the range $n^{3/2} \ll S \ll n^{7/4}$. We further extend this improvement to the $k$SUM-Indexing problem-a generalization of 3SUM-Indexing-and to the related $k$XOR-Indexing problem, where addition is replaced with XOR. Additionally, we improve the best known time-space tradeoffs for the Gapped String Indexing and Jumbled Indexing problems, which are well-known data structure problems related to 3SUM-Indexing.
  Our improvement comes from an alternative way to apply the Fiat-Naor algorithm to 3SUM-Indexing. Specifically, we exploit the structure of the function to be inverted by decomposing it into "sub-functions" with certain properties. This allows us to apply an improvement to the Fiat-Naor algorithm (which is not directly applicable to 3SUM-Indexing), obtained in [GGPS23] in a much larger range of parameters. We believe that our techniques may be useful in additional application-dependent optimizations of the Fiat-Naor algorithm.

</details>


### [16] [A customizable inexact subgraph matching algorithm for attributed graphs](https://arxiv.org/abs/2512.04280)
*Tatyana Benko,Rebecca Jones,Lucas Tate*

Main category: cs.DS

TL;DR: 相关：图处理（子图匹配）。总结：该论文提出了一种新的可定制的非精确子图匹配算法。该算法利用节点和边属性来缩小搜索空间，并通过使用可修改的图编辑距离成本函数来配对节点，使其具有灵活性，能够处理包含噪声和错误数据的现实世界数据集。实验证明了它在家族树图和控制流图上的有效性。


<details>
  <summary>Details</summary>
Motivation: 在许多现实世界的应用（如生物信息学、二进制分析、模式识别和计算机视觉）中，需要在大图中识别较小的查询图的实例，即子图匹配。由于数据集通常包含噪声和错误，精确子图匹配算法不再适用，因此需要一种非精确子图匹配算法。

Method: 本文提出了一种新的可定制的非精确子图匹配算法。该算法利用节点和边属性来缩小搜索空间。它通过使用可修改的图编辑距离成本函数来配对节点，从而具有灵活性，能够处理各种类型的子图匹配和数据集。

Result: 本文提出的可定制的非精确子图匹配算法有效地用于家族树图和控制流图。

Conclusion: 本文提出了一种新的可定制的非精确子图匹配算法。该算法通过使用可修改的图编辑距离成本函数来配对节点，从而具有灵活性，可适用于不同类型的子图匹配和数据集。实验证明了该算法在家族树图和控制流图上的有效性。

Abstract: Graphs provide a natural way to represent data by encoding information about objects and the relationships between them. With the ever-increasing amount of data collected and generated, locating specific patterns of relationships between objects in a graph is often required. Given a larger graph and a smaller graph, one may wish to identify instances of the smaller query graph in the larger target graph. This task is called subgraph identification or matching. Subgraph matching is helpful in areas such as bioinformatics, binary analysis, pattern recognition, and computer vision. In these applications, datasets frequently contain noise and errors, thus exact subgraph matching algorithms do not apply. In this paper we introduce a new customizable algorithm for inexact subgraph matching. Our algorithm utilizes node and edge attributes which are often present in real-world datasets to narrow down the search space. The algorithm is flexible in the type of subgraph matching it can perform and the types of datasets it can process by its use of a modifiable graph edit distance cost function for pairing nodes. We show its effectiveness on family trees graphs and control-flow graphs.

</details>


### [17] [On Tight FPT Time Approximation Algorithms for k-Clustering Problems](https://arxiv.org/abs/2512.04614)
*Han Dai,Shi Li,Sijin Peng*

Main category: cs.DS

TL;DR: 与 DSL 或图处理或 MLIR 或编译器或 HLS 不相关。
本文在结合近似算法和固定参数可解性（FPT）的背景下，研究了最小范数 $k$-聚类问题（以 $k$ 为参数）的 FPT 时间近似算法。对于有容量设置，提出了 $\left(3+\varepsilon\right)$-近似算法，改进了有容量 $k$-中心问题的近似比。对于无容量 $top$-$cn$ 范数 $k$-聚类问题，提出了 $\big(1 + \frac 2{ec} + \varepsilon\big)$-近似算法。所有结果都基于一个统一的框架：结合 LP 舍入、客户端代表采样和枢轴猜测。


<details>
  <summary>Details</summary>
Motivation: 追随近期将近似算法与固定参数可解性（FPT）结合的进展，研究最小范数 $k$-聚类问题的 FPT 时间近似算法，尤其关注按开放设施数量 $k$ 参数化的情形。旨在为有容量和无容量设置下的不同 $k$-聚类变体提供更高效（FPT 时间）和更优的近似比。

Method: 核心方法是一个统一的框架：首先通过 LP 舍入计算一个使用 $O\left(\frac{k\log n}ε\right)$ 个设施 $S$ 的 $(1+\varepsilon)$-近似解；然后基于 $S$ 抽取少量客户端代表 $R$；接着从 $S \cup R$ 中猜测少量枢轴和它们的半径信息；最后利用猜测的信息求解问题。

Result: 1. **有容量设置**：对一般范数有容量 $k$-聚类问题，给出了一个（在 $k$ 和 $\varepsilon$ 参数化下）紧致的 $\left(3+\varepsilon\right)$-近似 FPT 算法。这推广了先前仅对有容量 $k$-中位数问题的已知结果。特例是，为有容量 $k$-中心问题提供了 FPT 时间 $3$-近似，优于此前最佳的多项式时间 $9$-近似。
2. **无容量设置**：对 $top$-$cn$ 范数 $k$-聚类问题，当 $c \in \big(\frac1e, 1\big]$ 时，给出了紧致的 $\big(1 + \frac 2{ec} + \varepsilon\big)$-近似算法（$c \leq \frac1e$ 时为紧致的 $3+\varepsilon$ 近似）。
3. **双目标近似**：框架可扩展到对 ($k$-中心, $k$-中位数) 问题在 FPT 时间内给出紧致的 $\left(3, 1+\frac2e + \varepsilon\right)$-双目标近似，优于先前最佳的多项式时间 $(4, 8)$ 保证。

Conclusion: 本文基于统一框架，为最小范数 $k$-聚类问题（按开放设施数量 $k$ 参数化）提供了 FPT 时间近似算法。对于有容量设置，得到了$\left(3+\varepsilon\right)$-近似；对于无容量设置，得到了$\big(1 + \frac 2{ec} + \varepsilon\big)$-近似。这些结果改进了或首次研究了相关问题的近似比，并提供了一个可推广到未来工作的通用框架。

Abstract: Following recent advances in combining approximation algorithms with fixed-parameter tractability (FPT), we study FPT-time approximation algorithms for minimum-norm $k$-clustering problems, parameterized by the number $k$ of open facilities.
  For the capacitated setting, we give a tight $(3+ε)$-approximation for the general-norm capacitated $k$-clustering problem in FPT-time parameterized by $k$ and $ε$. Prior to our work, such a result was only known for the capacitated $k$-median problem [CL, ICALP, 2019]. As a special case, our result yields an FPT-time $3$-approximation for capacitated $k$-center. The problem has not been studied in the FPT-time setting, with the previous best known polynomial-time approximation ratio being 9 [ABCG, MP, 2015].
  In the uncapacitated setting, we consider the $top$-$cn$ norm $k$-clustering problem, where the goal of the problem is to minimize the $top$-$cn$ norm of the connection distance vector. Our main result is a tight $\big(1 + \frac 2{ec} + ε\big)$-approximation algorithm for the problem with $c \in \big(\frac1e, 1\big]$. (For the case $c \leq \frac1e$, there is a simple tight $(3+ε)$-approximation.) Our framework can be easily extended to give a tight $\left(3, 1+\frac2e + ε\right)$-bicriteria approximation for the ($k$-center, $k$-median) problem in FPT time, improving the previous best polynomial-time $(4, 8)$ guarantee [AB, WAOA, 2017].
  All results are based on a unified framework: computing a $(1+ε)$-approximate solution using $O\left(\frac{k\log n}ε\right)$ facilities $S$ via LP rounding, sampling a few client representatives $R$ based on the solution $S$, guessing a few pivots from $S \cup R$ and some radius information on the pivots, and solving the problem using the guesses. We believe this framework can lead to further results on $k$-clustering problems.

</details>
