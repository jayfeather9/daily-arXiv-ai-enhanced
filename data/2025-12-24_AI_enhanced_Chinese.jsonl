{"id": "2512.20180", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.20180", "abs": "https://arxiv.org/abs/2512.20180", "authors": ["Zeev Nutov", "Anael Vaknin"], "title": "Approximation and parameterized algorithms for covering disjointness-compliable set families", "comment": null, "summary": "A set-family ${\\cal F}$ is disjointness-compliable if $A' \\subseteq A \\in {\\cal F}$ implies $A' \\in {\\cal F}$ or $A \\setminus A' \\in {\\cal F}$; if ${\\cal F}$ is also symmetric then ${\\cal F}$ is proper. A classic result of Goemans and Williamson [SODA 92:307-316] states that the problem of covering a proper set-family by a min-cost edge set admits approximation ratio $2$, by a classic primal-dual algorithm. However, there are several famous algorithmic problems whose set-family ${\\cal F}$ is disjointness-compliable but not symmetric -- among them $k$-Minimum Spanning Tree ($k$-MST), Generalized Point-to-Point Connection (G-P2P), Group Steiner, Covering Steiner, multiroot versions of these problems, and others. We will show that any such problem admits approximation ratio $O(\u03b1\\log \u03c4)$, where $\u03c4$ is the number of inclusion-minimal sets in the family ${\\cal F}$ that models the problem and $\u03b1$ is the best known approximation ratio for the case when $\u03c4=1$. This immediately implies several results, among them the following two. (i) The first deterministic polynomial time $O(\\log n)$-approximation algorithm for the G-P2P problem. Here the $\u03c4=1$ case is the $k$-MST problem. (ii) Approximation ratio $O(\\log^4 n)$ for the multiroot version of the Covering Steiner problem, where each root has its own set of groups. Here the $\u03c4=1$ case is the Covering Steiner problem.\n  We also discuss the parameterized complexity of covering a disjointness-compliable family ${\\cal F}$, when parametrized by $\u03c4$. We will show that if ${\\cal F}$ is proper then the problem is fixed parameter tractable and can be solved in time $O^*(3^\u03c4)$. For the non-symmetric case we will show that the problem admits approximation ratio between $\u03b1$ and $\u03b1+1$ in time $O^*(3^\u03c4)$, which is essentially the best possible.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\uff08Graph Processing\uff0c\u56e0\u4e3a\u6d89\u53ca $k$-MST\u3001$G$-P2P\u3001Steiner \u7b49\u56fe\u4e0a\u7684\u8986\u76d6\u95ee\u9898\u548c\u6700\u5c0f\u6210\u672c\u8fb9\u96c6\u95ee\u9898\uff09\u548c\u7f16\u8bd1\u5668\uff08Compiler\uff0c\u6d89\u53ca\u7ec4\u5408\u4f18\u5316\uff09\u76f8\u5173\u3002TLDR: \u672c\u6587\u7814\u7a76\u4e86\u8986\u76d6\u4e00\u7c7b\u65b0\u6027\u8d28\u7684\u96c6\u5408\u65cf\uff08\u4e0d\u4ea4\u6027\u517c\u5bb9\u4f46\u975e\u5bf9\u79f0\uff09\u7684\u6700\u5c0f\u6210\u672c\u8fb9\u96c6\u95ee\u9898\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u8fd1\u4f3c\u6bd4\u4e3a $O(\\alpha \\log \\tau)$\uff0c\u5176\u4e2d $\\tau$ \u662f\u5305\u542b\u6781\u5c0f\u96c6\u5408\u7684\u6570\u91cf\uff0c$\\alpha$ \u662f $\\tau=1$ \u65f6\u7684\u6700\u4f73\u8fd1\u4f3c\u6bd4\u3002\u8fd9\u4e00\u63a8\u5e7f\u7ed3\u679c\u9996\u6b21\u4e3a\u5e7f\u4e49\u70b9\u5bf9\u70b9\u8fde\u63a5\uff08G-P2P\uff09\u95ee\u9898\u63d0\u4f9b\u4e86 $O(\\log n)$ \u7684\u786e\u5b9a\u6027\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86\u591a\u6839\u8986\u76d6 Steiner \u95ee\u9898\u7684\u8fd1\u4f3c\u6bd4\u3002\u540c\u65f6\uff0c\u672c\u6587\u8fd8\u5206\u6790\u4e86\u8fd9\u4e9b\u95ee\u9898\u7684\u53c2\u6570\u5316\u590d\u6742\u6027\uff0c\u8bc1\u660e\u4e86\u5728\u5bf9\u79f0\u60c5\u51b5\u4e0b\u662f\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\u7684\u3002", "motivation": "Goemans \u548c Williamson \u7684\u7ecf\u5178\u7ed3\u679c\u8868\u660e\uff0c\u8986\u76d6\u4e00\u4e2a\u201cProper\u201d\uff08\u5373\u201c\u4e0d\u4ea4\u6027\u517c\u5bb9\u201d\u4e14\u201c\u5bf9\u79f0\u201d\uff09\u96c6\u5408\u65cf\u7684\u6700\u5c0f\u6210\u672c\u8fb9\u96c6\u95ee\u9898\uff0c\u53ef\u4ee5\u901a\u8fc7\u7ecf\u5178\u7684\u539f\u59cb-\u5bf9\u5076\u7b97\u6cd5\u5f97\u5230 $2$ \u7684\u8fd1\u4f3c\u6bd4\u3002\u7136\u800c\uff0c\u8bb8\u591a\u8457\u540d\u7684\u7b97\u6cd5\u95ee\u9898\uff08\u5982 $k$-MST\u3001$G$-P2P\u3001Group Steiner\u3001\u8986\u76d6 Steiner \u53ca\u5176\u591a\u6839\u7248\u672c\uff09\u6240\u5bf9\u5e94\u7684\u96c6\u5408\u65cf\u662f\u201c\u4e0d\u4ea4\u6027\u517c\u5bb9\u201d\u7684\uff0c\u4f46\u4e0d\u662f\u201c\u5bf9\u79f0\u201d\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u7814\u7a76\u9488\u5bf9\u8fd9\u7c7b\u201c\u4e0d\u4ea4\u6027\u517c\u5bb9\u4f46\u975e\u5bf9\u79f0\u201d\u96c6\u5408\u65cf\u7684\u8986\u76d6\u95ee\u9898\uff0c\u4ee5\u63a8\u5e7f Goemans \u548c Williamson \u7684\u7ecf\u5178\u7ed3\u679c\uff0c\u5e76\u4e3a\u8fd9\u4e9b\u8457\u540d\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "method": "\u672c\u6587\u7684\u4e3b\u8981\u65b9\u6cd5\u662f\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u7684\u96c6\u5408\u65cf\u6027\u8d28\u2014\u2014\u201c\u4e0d\u4ea4\u6027\u517c\u5bb9\u201d\uff08disjointness-compliable\uff09\u4f46\u201c\u975e\u5bf9\u79f0\u201d\u7684\u96c6\u5408\u65cf\uff0c\u5e76\u8bc1\u660e\u4e86\u8986\u76d6\u8fd9\u7c7b\u96c6\u5408\u65cf\u7684\u6700\u5c0f\u6210\u672c\u8fb9\u96c6\u95ee\u9898\u7684\u8fd1\u4f3c\u6bd4\u4e3a $O(\\alpha \\log \\tau)$\u3002\u5176\u4e2d\uff0c$\\tau$ \u662f\u96c6\u5408\u65cf\u4e2d\u5305\u542b\u6781\u5c0f\u96c6\u5408\u7684\u6570\u91cf\uff0c$\\alpha$ \u662f $\\tau=1$ \u65f6\u7684\u6700\u4f73\u8fd1\u4f3c\u6bd4\u3002\u63a5\u7740\uff0c\u4f5c\u8005\u5c06\u8fd9\u4e00\u7406\u8bba\u7ed3\u679c\u5e94\u7528\u4e8e\u4e00\u7cfb\u5217\u8457\u540d\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff08\u5982 G-P2P\u3001\u591a\u6839\u8986\u76d6 Steiner \u95ee\u9898\uff09\u4ee5\u5f97\u5230\u5177\u4f53\u7684\u8fd1\u4f3c\u7b97\u6cd5\u548c\u8fd1\u4f3c\u6bd4\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u4ece\u53c2\u6570\u5316\u590d\u6742\u6027\uff08parameterized complexity\uff09\u7684\u89d2\u5ea6\uff0c\u5206\u6790\u4e86\u4ee5 $\\tau$ \u4e3a\u53c2\u6570\u65f6\u7684\u8986\u76d6\u95ee\u9898\u7684\u53ef\u89e3\u6027\u3002", "result": "1. **\u4e00\u822c\u6027\u8fd1\u4f3c\u6bd4\u7ed3\u679c\uff1a** \u8bc1\u660e\u4e86\u5bf9\u4e8e\u4efb\u4f55\u201c\u4e0d\u4ea4\u6027\u517c\u5bb9\u201d\u4f46\u201c\u975e\u5bf9\u79f0\u201d\u7684\u96c6\u5408\u65cf ${\\cal F}$\uff0c\u8986\u76d6\u5b83\u7684\u6700\u5c0f\u6210\u672c\u8fb9\u96c6\u95ee\u9898\u5177\u6709 $O(\\alpha \\log \\tau)$ \u7684\u8fd1\u4f3c\u6bd4\uff0c\u5176\u4e2d $\\tau$ \u662f ${\\cal F}$ \u4e2d\u5305\u542b\u6781\u5c0f\u96c6\u5408\u7684\u6570\u91cf\uff0c$\u03b1$ \u662f $\\tau=1$ \u65f6\u7684\u6700\u4f73\u8fd1\u4f3c\u6bd4\u3002\n2. **\u5177\u4f53\u5e94\u7528\uff1a**\n    * \u4e3a G-P2P \u95ee\u9898\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u786e\u5b9a\u6027\u591a\u9879\u5f0f\u65f6\u95f4 $O(\\log n)$-\u8fd1\u4f3c\u7b97\u6cd5\uff08\u5176\u4e2d $\\tau=1$ \u7684\u60c5\u51b5\u662f $k$-MST \u95ee\u9898\uff09\u3002\n    * \u4e3a\u591a\u6839\u7248\u672c\u7684\u8986\u76d6 Steiner \u95ee\u9898\uff08\u6bcf\u4e2a\u6839\u6709\u81ea\u5df1\u7684\u7ec4\u96c6\u5408\uff09\u63d0\u4f9b\u4e86 $O(\\log^4 n)$ \u7684\u8fd1\u4f3c\u6bd4\uff08\u5176\u4e2d $\\tau=1$ \u7684\u60c5\u51b5\u662f\u8986\u76d6 Steiner \u95ee\u9898\uff09\u3002\n3. **\u53c2\u6570\u5316\u590d\u6742\u6027\u7ed3\u679c\uff1a**\n    * \u5f53\u4ee5 $\\tau$ \u4e3a\u53c2\u6570\u65f6\uff0c\u5982\u679c\u96c6\u5408\u65cf ${\\cal F}$ \u662f Proper \u7684\uff0c\u5219\u8986\u76d6\u95ee\u9898\u662f Fixed Parameter Tractable (FPT)\uff0c\u53ef\u5728 $O^*(3^\\tau)$ \u65f6\u95f4\u5185\u89e3\u51b3\u3002\n    * \u5bf9\u4e8e\u975e\u5bf9\u79f0\u7684\u60c5\u51b5\uff0c\u5728 $O^*(3^\\tau)$ \u65f6\u95f4\u5185\u53ef\u4ee5\u5b9e\u73b0 $\\alpha$ \u548c $\\alpha+1$ \u4e4b\u95f4\u7684\u8fd1\u4f3c\u6bd4\uff0c\u8fd9\u5728\u672c\u8d28\u4e0a\u662f\u6700\u4f73\u7684\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u4e00\u7c7b\u65b0\u7684\u96c6\u5408\u65cf\u8986\u76d6\u95ee\u9898\uff0c\u5373\u9488\u5bf9\u201c\u4e0d\u4ea4\u6027\u517c\u5bb9\u4f46\u975e\u5bf9\u79f0\u201d\u7684\u96c6\u5408\u65cf\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u8fd1\u4f3c\u6bd4\u4e3a $O(\\alpha \\log \\tau)$\uff0c\u5176\u4e2d $\\tau$ \u662f\u5305\u542b\u6781\u5c0f\u96c6\u5408\u7684\u6570\u91cf\uff0c$\\alpha$ \u662f $\\tau=1$ \u65f6\u7684\u6700\u4f73\u8fd1\u4f3c\u6bd4\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u5206\u6790\u4e86\u8fd9\u7c7b\u95ee\u9898\u5728\u53c2\u6570\u5316\u590d\u6742\u6027\u65b9\u9762\u7684\u8868\u73b0\uff0c\u5e76\u5728\u5bf9\u79f0\u548c\u975e\u5bf9\u79f0\u60c5\u51b5\u4e0b\u5206\u522b\u5f97\u5230\u4e86\u56fa\u5b9a\u7684\u53c2\u6570\u53ef\u89e3\u6027\u548c\u8fd1\u4f3c\u6bd4\u7ed3\u679c\u3002\u8fd9\u9879\u5de5\u4f5c\u63a8\u5e7f\u4e86 Goemans \u548c Williamson \u7684\u7ecf\u5178\u7ed3\u679c\uff0c\u4e3a\u4e00\u7cfb\u5217\u8457\u540d\u7684\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff08\u5982 G-P2P\u3001\u591a\u6839\u8986\u76d6 Steiner \u95ee\u9898\uff09\u63d0\u4f9b\u4e86\u65b0\u7684\u8fd1\u4f3c\u7b97\u6cd5\u6216\u6539\u8fdb\u4e86\u73b0\u6709\u7b97\u6cd5\u7684\u8fd1\u4f3c\u6bd4\u3002"}}
{"id": "2512.20598", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.20598", "abs": "https://arxiv.org/abs/2512.20598", "authors": ["Vinicius T. V. Date", "Leandro M. Zatesko"], "title": "On the near-tightness of $\u03c7\\leq 2r$: a general $\u03c3$-ary construction and a binary case via LFSRs", "comment": "Accepted to LATIN 2026. 16 pages, 0 figures", "summary": "In the field of compressed string indexes, recent work has introduced suffixient sets and their corresponding repetitiveness measure $\u03c7$. In particular, researchers have explored its relationship to other repetitiveness measures, notably $r$, the number of runs in the Burrows--Wheeler Transform (BWT) of a string. Navarro et al. (2025) proved that $\u03c7\\leq 2r$, although empirical results by Cenzato et al. (2024) suggest that this bound is loose, with real data bounding $\u03c7$ by around $1.13r$ to $1.33r$ when the size of the alphabet is $\u03c3= 4$. To better understand this gap, we present two cases for the asymptotic tightness of the $\u03c7\\leq 2r$ bound: a general construction for arbitrary $\u03c3$ values, and a binary alphabet case, consisting of de Bruijn sequences constructed by linear-feedback shift registers (LFSRs) from primitive polynomials over $\\mathbb{F}_2$. The second is a novel characterization of which de Bruijn sequences achieve the literature run-minimal pattern for the cyclic BWT. Moreover, we show that de Bruijn sequences fail to close the gap for $\u03c3\\geq 3$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\u548c\u7f16\u8bd1\u5668\u6216 HLS \u4e0d\u76f8\u5173\uff0c\u4f46\u4e0e DSL \u76f8\u5173\uff08\u538b\u7f29\u5b57\u7b26\u4e32\u7d22\u5f15\u4e2d\u7684\u91cd\u590d\u6027\u5ea6\u91cf\uff09\u548c MLIR \u76f8\u5173\uff08\u8be5\u672f\u8bed\u4e0d\u9002\u7528\uff09\u3002\u6587\u7ae0\u56f4\u7ed5\u538b\u7f29\u5b57\u7b26\u4e32\u7d22\u5f15\u4e2d\u7684 $ \\chi $ \u548c $ r $ \u4e24\u4e2a\u91cd\u590d\u6027\u5ea6\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u5c55\u5f00, \u7406\u8bba\u8bc1\u660e $ \\chi \\leq 2r $\uff0c\u4f46\u7ecf\u9a8c\u4e0a\u8be5\u754c\u9650\u8f83\u677e\u3002\u672c\u6587\u7684\u76ee\u7684\u662f\u901a\u8fc7\u6784\u9020\u7279\u6b8a\u6848\u4f8b\u6765\u8bc1\u660e $ \\chi \\leq 2r $ \u6e10\u8fdb\u7d27\u5bc6\u6027\uff0c\u6700\u7ec8\u63d0\u4f9b\u4e86\u4e24\u4e2a\u8bc1\u660e\u8be5\u4e0a\u754c\u6e10\u8fdb\u7d27\u5bc6\u6027\u7684\u6848\u4f8b\uff1a\u4e00\u4e2a\u9488\u5bf9\u4efb\u610f\u5b57\u6bcd\u8868 $ \\sigma $ \u7684\u901a\u7528\u6784\u9020\uff0c\u4ee5\u53ca\u4e00\u4e2a\u9488\u5bf9\u4e8c\u5143\u5b57\u6bcd\u8868\u7684\u57fa\u4e8e LFSR \u7684 de Bruijn \u5e8f\u5217\u6784\u9020\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u8868\u660e\u5bf9\u4e8e $ \\sigma \\geq 3 $ de Bruijn \u5e8f\u5217\u4e0d\u80fd\u7f29\u5c0f $ \\chi $ \u548c $ r $ \u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7684\u7814\u7a76\u8868\u660e\uff0c\u5728\u538b\u7f29\u5b57\u7b26\u4e32\u7d22\u5f15\u9886\u57df\uff0c\u91cd\u590d\u6027\u5ea6\u91cf $ \\chi $\uff08\u57fa\u4e8e\u540e\u7f00\u96c6\u5408\uff09\u548c $ r $\uff08Burrows--Wheeler \u53d8\u6362 BWT \u4e2d\u7684 runs \u6570\u91cf\uff09\u4e4b\u95f4\u5b58\u5728\u7406\u8bba\u754c $ \\chi \\leq 2r $\uff0c\u4f46\u7ecf\u9a8c\u7ed3\u679c\uff08\u7279\u522b\u662f $ \\sigma=4 $ \u65f6 $ \\chi $ \u7ea6\u4e3a $ 1.13r $ \u5230 $ 1.33r $\uff09\u663e\u793a\u8fd9\u4e2a\u754c\u9650\u662f\u677e\u6563\u7684\u3002\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u586b\u8865\u7406\u8bba\u4e0e\u7ecf\u9a8c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u8bc6\u522b\u6e10\u8fdb\u7d27\u5bc6\u7684\u6848\u4f8b\u6765\u66f4\u597d\u5730\u7406\u89e3 $ \\chi \\leq 2r $ \u8fd9\u4e00\u4e0a\u754c\u3002", "method": "\u901a\u8fc7\u6784\u9020\u7279\u6b8a\u5b57\u7b26\u4e32\u6848\u4f8b\u6765\u5206\u6790\u548c\u8bc1\u660e $ \\chi \\leq 2r $ \u4e0a\u754c\u7684\u6e10\u8fdb\u7d27\u5bc6\u6027\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. \u9488\u5bf9\u4efb\u610f\u5b57\u6bcd\u8868\u5927\u5c0f $ \\sigma $ \u7684\u4e00\u822c\u6027\u6784\u9020\uff1b2. \u9488\u5bf9\u4e8c\u5143\u5b57\u6bcd\u8868\uff08$ \\sigma=2 $\uff09\u7684\u57fa\u4e8e\u7ebf\u6027\u53cd\u9988\u79fb\u4f4d\u5bc4\u5b58\u5668\uff08LFSR\uff09\u7684 de Bruijn \u5e8f\u5217\u6784\u9020\u3002\u6b64\u5916\uff0c\u8fd8\u5bf9 de Bruijn \u5e8f\u5217\u5728\u5faa\u73af BWT \u4e2d\u7684\u8fd0\u884c\u6700\u5c0f\u6a21\u5f0f\u8fdb\u884c\u4e86\u65b0\u7684\u8868\u5f81\uff0c\u5e76\u5206\u6790\u4e86 $ \\sigma \\geq 3 $ \u65f6 de Bruijn \u5e8f\u5217\u7684\u8868\u73b0\u3002", "result": "\u672c\u6587\u6210\u529f\u5730\u63d0\u4f9b\u4e86\u4e24\u4e2a\u8bc1\u660e $ \\chi \\leq 2r $ \u4e0a\u754c\u5177\u6709\u6e10\u8fdb\u7d27\u5bc6\u6027\u7684\u6848\u4f8b\uff1a1. \u9488\u5bf9\u4efb\u610f $ \\sigma $ \u503c\u7684\u901a\u7528\u6784\u9020\uff1b2. \u9488\u5bf9\u4e8c\u5143\u5b57\u6bcd\u8868\u7684 de Bruijn \u5e8f\u5217\u6784\u9020\uff0c\u8be5\u5e8f\u5217\u662f\u901a\u8fc7 $ \\mathbb{F}_2 $ \u4e0a\u7684\u672c\u539f\u591a\u9879\u5f0f\u7684\u7ebf\u6027\u53cd\u9988\u79fb\u4f4d\u5bc4\u5b58\u5668\uff08LFSR\uff09\u751f\u6210\u7684\u3002\u7b2c\u4e8c\u4e2a\u6848\u4f8b\u8fd8\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u8868\u5f81\uff0c\u8bf4\u660e\u4e86\u54ea\u4e9b de Bruijn \u5e8f\u5217\u5728\u5faa\u73af BWT \u4e2d\u5b9e\u73b0\u4e86\u6587\u732e\u4e2d\u7684\u8fd0\u884c\u6700\u5c0f\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5bf9\u4e8e $ \\sigma \\geq 3 $\uff0cde Bruijn \u5e8f\u5217\u4e0d\u80fd\u7f29\u5c0f $ \\chi $ \u548c $ r $ \u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u538b\u7f29\u5b57\u7b26\u4e32\u7d22\u5f15\u4e2d\uff0c$ \\chi $ \u548c $ r $ \u4e24\u4e2a\u91cd\u590d\u6027\u5ea6\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5c3d\u7ba1\u5df2\u6709\u7406\u8bba\u8bc1\u660e $ \\chi \\leq 2r $\uff0c\u4f46\u7ecf\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u4e0a\u754c\u8f83\u677e\u3002\u672c\u6587\u901a\u8fc7\u6784\u9020\u5177\u6709\u6e10\u8fdb\u7d27\u5bc6\u6027\u7684\u4e24\u4e2a\u6848\u4f8b\uff1a\u4e00\u4e2a\u9488\u5bf9\u4efb\u610f\u5b57\u6bcd\u8868\u5927\u5c0f $ \\sigma $ \u7684\u4e00\u822c\u6027\u6784\u9020\uff0c\u4ee5\u53ca\u4e00\u4e2a\u9488\u5bf9\u4e8c\u5143\u5b57\u6bcd\u8868\u7684\u57fa\u4e8e\u7ebf\u6027\u53cd\u9988\u79fb\u4f4d\u5bc4\u5b58\u5668\uff08LFSR\uff09\u7684 de Bruijn \u5e8f\u5217\u6784\u9020\uff0c\u6765\u8bc1\u660e $ \\chi \\leq 2r $ \u7684\u6e10\u8fdb\u7d27\u5bc6\u6027\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u53d1\u73b0 de Bruijn \u5e8f\u5217\u5728 $ \\sigma \\geq 3 $ \u65f6\u4e0d\u80fd\u7f29\u5c0f $ \\chi $ \u548c $ r $ \u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u8fd9\u4e9b\u7ed3\u679c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u548c\u8bc4\u4f30\u57fa\u4e8e $ \\chi $ \u5ea6\u91cf\u7684\u538b\u7f29\u5b57\u7b26\u4e32\u7d22\u5f15\u7684\u6027\u80fd\u3002"}}
{"id": "2512.20073", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20073", "abs": "https://arxiv.org/abs/2512.20073", "authors": ["Hongyang Shang", "Shuai Dong", "Ye Ke", "Arindam Basu"], "title": "3D Stack In-Sensor-Computing (3DS-ISC): Accelerating Time-Surface Construction for Neuromorphic Event Cameras", "comment": null, "summary": "This work proposes a 3D Stack In-Sensor-Computing (3DS-ISC) architecture for efficient event-based vision processing. A real-time normalization method using an exponential decay function is introduced to construct the time-surface, reducing hardware usage while preserving temporal information. The circuit design utilizes the leakage characterization of Dynamic Random Access Memory(DRAM) for timestamp normalization. Custom interdigitated metal-oxide-metal capacitor (MOMCAP) is used to store the charge and low leakage switch (LL switch) is used to extend the effective charge storage time. The 3DS-ISC architecture integrates sensing, memory, and computation to overcome the memory wall problem, reducing power, latency, and reducing area by 69x, 2.2x and 1.9x, respectively, compared with its 2D counterpart. Moreover, compared to works using a 16-bit SRAM to store timestamps, the ISC analog array can reduce power consumption by three orders of magnitude. In real computer vision (CV) tasks, we applied the spatial-temporal correlation filter (STCF) for denoise, and 3D-ISC achieved almost equivalent accuracy compared to the digital implementation using high precision timestamps. As for the image classification, time-surface constructed by 3D-ISC is used as the input of GoogleNet, achieving 99% on N-MNIST, 85% on N-Caltech101, 78% on CIFAR10-DVS, and 97% on DVS128 Gesture, comparable with state-of-the-art results on each dataset. Additionally, the 3D-ISC method is also applied to image reconstruction using the DAVIS240C dataset, achieving the highest average SSIM (0.62) among three methods. This work establishes a foundation for real-time, resource-efficient event-based processing and points to future integration of advanced computational circuits for broader applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e**\u7f16\u8bd1\u5668\uff08Compiler\uff09**\u90e8\u5206\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u6d89\u53ca\u5230\u5b9a\u5236\u7684\u786c\u4ef6\u52a0\u901f\u67b6\u6784\u548c\u4f4e\u529f\u8017\u7535\u8def\u8bbe\u8ba1\uff0c\u8fd9\u901a\u5e38\u662f\u9ad8\u7ea7\u7efc\u5408\uff08HLS\uff09\u548c\u7279\u5b9a\u9886\u57df\u67b6\u6784\u7f16\u8bd1\u5668\u4f18\u5316\u7684\u76ee\u6807\u3002\n\n\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u79cd 3D Stack In-Sensor-Computing\uff083DS-ISC\uff09\u7684\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u6307\u6570\u8870\u51cf\u7684\u5b9e\u65f6\u5f52\u4e00\u5316\u65b9\u6cd5\u548c\u5229\u7528 DRAM \u6cc4\u6f0f\u7279\u6027\u7684\u5b9a\u5236\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\uff0c\u6210\u529f\u5730\u5c06\u4f20\u611f\u3001\u5b58\u50a8\u548c\u8ba1\u7b97\u96c6\u6210\u8d77\u6765\u30023DS-ISC \u5927\u5e45\u51cf\u5c11\u4e86\u529f\u8017\uff08\u6700\u9ad8 69 \u500d\uff09\u548c\u9762\u79ef\uff081.9 \u500d\uff09\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7684\u5b58\u50a8\u5899\u95ee\u9898\u3002\u5728\u53bb\u566a\u3001\u56fe\u50cf\u5206\u7c7b\u548c\u56fe\u50cf\u91cd\u5efa\u7b49\u591a\u4e2a CV \u4efb\u52a1\u4e2d\uff0c\u8be5\u67b6\u6784\u5747\u53d6\u5f97\u4e86\u4e0e\u9ad8\u7cbe\u5ea6\u6570\u5b57\u5b9e\u73b0\u76f8\u5f53\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u65f6\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u4e8b\u4ef6\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u7840\u3002", "motivation": "\u73b0\u6709\u7684\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\u7cfb\u7edf\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u4e25\u91cd\u7684**\u5b58\u50a8\u5899\u95ee\u9898**\uff08memory wall problem\uff09\uff0c\u8fd9\u5bfc\u81f4\u4e86\u9ad8\u529f\u8017\u3001\u9ad8\u5ef6\u8fdf\u548c\u8f83\u5927\u7684\u82af\u7247\u9762\u79ef\u3002\u4f20\u7edf\u7684\u6570\u5b57\u5b9e\u73b0\u65b9\u6848\uff0c\u7279\u522b\u662f\u4f7f\u7528 16-bit SRAM \u5b58\u50a8\u65f6\u95f4\u6233\u7684\u65b9\u6cd5\uff0c\u9700\u8981\u5927\u91cf\u7684\u80fd\u91cf\u548c\u8d44\u6e90\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u96c6\u6210\u7684\u3001\u9ad8\u6548\u7684\u67b6\u6784\uff0c\u80fd\u591f\u5c06\u4f20\u611f\u3001\u5b58\u50a8\u548c\u8ba1\u7b97\u7ed3\u5408\u8d77\u6765\uff0c\u4ee5\u5b9e\u65f6\u3001\u4f4e\u529f\u8017\u3001\u5c0f\u9762\u79ef\u5730\u5904\u7406\u4e8b\u4ef6\u6570\u636e\u3002\u8fd9\u9879\u5de5\u4f5c\u7684\u52a8\u673a\u6b63\u662f\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9650\u5236\uff0c\u63d0\u51fa\u4e00\u79cd\u9ad8\u5ea6\u96c6\u6210\u7684\u611f\u7b97\u4e00\u4f53\u5316\uff08In-Sensor-Computing\uff09\u67b6\u6784\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a 3D Stack In-Sensor-Computing\uff083DS-ISC\uff09\u7684\u67b6\u6784\uff0c\u7528\u4e8e\u9ad8\u6548\u7684\u4e8b\u4ef6\u89c6\u89c9\u5904\u7406\u3002\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a1. **\u5b9e\u65f6\u5f52\u4e00\u5316\uff08Real-time Normalization\uff09**\uff1a\u5f15\u5165\u57fa\u4e8e\u6307\u6570\u8870\u51cf\u51fd\u6570\u7684\u5b9e\u65f6\u5f52\u4e00\u5316\u65b9\u6cd5\u6765\u6784\u5efa\u65f6\u95f4\u8868\u9762\uff08time-surface\uff09\uff0c\u4f7f\u7528\u6cc4\u6f0f\u7279\u6027\u8fdb\u884c\u65f6\u95f4\u6233\u5f52\u4e00\u5316\uff0c\u4ee5\u51cf\u5c11\u786c\u4ef6\u5f00\u9500\u5e76\u4fdd\u7559\u65f6\u95f4\u4fe1\u606f\u30022. **\u5b9a\u5236\u7535\u8def\u8bbe\u8ba1**\uff1a\u5229\u7528 DRAM\uff08\u52a8\u6001\u968f\u673a\u5b58\u53d6\u5b58\u50a8\u5668\uff09\u7684\u6cc4\u6f0f\u7279\u6027\u8fdb\u884c\u65f6\u95f4\u6233\u5f52\u4e00\u5316\u3002\u4f7f\u7528\u5b9a\u5236\u7684\u4ea4\u9519\u91d1\u5c5e-\u6c27\u5316\u7269-\u91d1\u5c5e\u7535\u5bb9\u5668\uff08MOMCAP\uff09\u6765\u5b58\u50a8\u7535\u8377\uff0c\u5e76\u4f7f\u7528\u4f4e\u6cc4\u6f0f\u5f00\u5173\uff08LL switch\uff09\u5ef6\u957f\u6709\u6548\u7535\u8377\u5b58\u50a8\u65f6\u95f4\u30023. **\u96c6\u6210\u4e0e\u8ba1\u7b97**\uff1a\u5c06\u4f20\u611f\u3001\u5b58\u50a8\u548c\u8ba1\u7b97\u529f\u80fd\u96c6\u6210\uff0c\u4ee5\u89e3\u51b3\u5b58\u50a8\u5899\u95ee\u9898\u30024. **\u5e94\u7528\u4e0e\u6027\u80fd\u8bc4\u4f30**\uff1a\u4f7f\u7528\u7a7a\u95f4-\u65f6\u95f4\u76f8\u5173\u6ee4\u6ce2\u5668\uff08STCF\uff09\u8fdb\u884c\u53bb\u566a\uff0c\u5e76\u5c06\u5176\u65f6\u95f4\u8868\u9762\u5e94\u7528\u4e8e GoogleNet \u8fdb\u884c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\uff08N-MNIST, N-Caltech101, CIFAR10-DVS, DVS128 Gesture\uff09\uff0c\u4ee5\u53ca\u5e94\u7528\u4e8e\u56fe\u50cf\u91cd\u5efa\uff08DAVIS240C \u6570\u636e\u96c6\uff09\u6765\u9a8c\u8bc1\u5176\u5728\u771f\u5b9e\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002", "result": "3D Stack In-Sensor-Computing\uff083DS-ISC\uff09\u67b6\u6784\u4e0e 2D \u5bf9\u5e94\u7269\u76f8\u6bd4\uff0c\u5c06\u529f\u8017\u3001\u5ef6\u8fdf\u548c\u9762\u79ef\u5206\u522b\u51cf\u5c11\u4e86 **69 \u500d\u30012.2 \u500d\u548c 1.9 \u500d**\u3002\u4e0e\u4f7f\u7528 16-bit SRAM \u5b58\u50a8\u65f6\u95f4\u6233\u7684\u5de5\u4f5c\u76f8\u6bd4\uff0cISC \u6a21\u62df\u9635\u5217\u53ef\u4ee5\u5c06\u529f\u8017\u964d\u4f4e **\u4e09\u4e2a\u6570\u91cf\u7ea7**\u3002\u5728\u5b9e\u9645\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\uff1a1. **\u53bb\u566a**\uff1a\u4f7f\u7528\u7a7a\u95f4-\u65f6\u95f4\u76f8\u5173\u6ee4\u6ce2\u5668\uff08STCF\uff09\u8fdb\u884c\u53bb\u566a\u65f6\uff0c3D-ISC \u8fbe\u5230\u4e86\u4e0e\u9ad8\u7cbe\u5ea6\u65f6\u95f4\u6233\u6570\u5b57\u5b9e\u73b0**\u51e0\u4e4e\u76f8\u5f53\u7684\u7cbe\u5ea6**\u30022. **\u56fe\u50cf\u5206\u7c7b**\uff1a\u65f6\u95f4\u8868\u9762\u4f5c\u4e3a GoogleNet \u7684\u8f93\u5165\uff0c\u5728 N-MNIST \u4e0a\u8fbe\u5230\u4e86 99%\uff0cN-Caltech101 \u4e0a\u8fbe\u5230 85%\uff0cCIFAR10-DVS \u4e0a\u8fbe\u5230 78%\uff0cDVS128 Gesture \u4e0a\u8fbe\u5230 97%\uff0c**\u4e0e\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u76f8\u5f53**\u30023. **\u56fe\u50cf\u91cd\u5efa**\uff1a\u5728 DAVIS240C \u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5e73\u5747 SSIM\uff080.62\uff09\uff0c**\u4f18\u4e8e\u4e09\u79cd\u6bd4\u8f83\u65b9\u6cd5**\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u63d0\u51fa\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u8d44\u6e90\u53d7\u9650\u7684\u4e8b\u4ef6\u5904\u7406\u65b0\u6846\u67b6\u30023DS-ISC \u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u65b0\u9896\u7684\u5b9e\u65f6\u65f6\u95f4\u8868\u9762\u5f52\u4e00\u5316\u548c\u6a21\u62df\u7535\u8def\u8bbe\u8ba1\uff0c\u6210\u529f\u514b\u670d\u4e86\u4f20\u7edf\u6570\u5b57\u5b9e\u73b0\u4e2d\u7684\u5b58\u50a8\u5899\u95ee\u9898\u548c\u9ad8\u529f\u8017\uff0c\u540c\u65f6\u5728\u591a\u4e2a\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u4fdd\u6301\u4e86\u4e0e\u9ad8\u7cbe\u5ea6\u6570\u5b57\u5b9e\u73b0\u76f8\u5f53\u751a\u81f3\u8d85\u8d8a\u7684\u6027\u80fd\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5b9e\u65f6\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u4e8b\u4ef6\u5904\u7406\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u5e76\u9884\u793a\u7740\u672a\u6765\u8ba1\u7b97\u7535\u8def\u7684\u96c6\u6210\u5c06\u5e26\u6765\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u3002"}}
{"id": "2512.20198", "categories": ["cs.AR", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.20198", "abs": "https://arxiv.org/abs/2512.20198", "authors": ["Huizheng Wang", "Taiquan Wei", "Hongbin Wang", "Zichuan Wang", "Xinru Tang", "Zhiheng Yue", "Shaojun Wei", "Yang Hu", "Shouyi Yin"], "title": "Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling", "comment": "Accepted for publication in IEEE Transactions on Computers", "summary": "Large language models (LLMs) rely on self-attention for contextual understanding, demanding high-throughput inference and large-scale token parallelism (LTPP). Existing dynamic sparsity accelerators falter under LTPP scenarios due to stage-isolated optimizations. Revisiting the end-to-end sparsity acceleration flow, we identify an overlooked opportunity: cross-stage coordination can substantially reduce redundant computation and memory access. We propose STAR, a cross-stage compute- and memory-efficient algorithm-hardware co-design tailored for Transformer inference under LTPP. STAR introduces a leading-zero-based sparsity prediction using log-domain add-only operations to minimize prediction overhead. It further employs distributed sorting and a sorted updating FlashAttention mechanism, guided by a coordinated tiling strategy that enables fine-grained stage interaction for improved memory efficiency and latency. These optimizations are supported by a dedicated STAR accelerator architecture, achieving up to 9.2$\\times$ speedup and 71.2$\\times$ energy efficiency over A100, and surpassing SOTA accelerators by up to 16.1$\\times$ energy and 27.1$\\times$ area efficiency gains. Further, we deploy STAR onto a multi-core spatial architecture, optimizing dataflow and execution orchestration for ultra-long sequence processing. Architectural evaluation shows that, compared to the baseline design, Spatial-STAR achieves a 20.1$\\times$ throughput improvement.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u548cHLS\u76f8\u5173\uff08\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u52a0\u901f\u5668\u67b6\u6784\uff0c\u6570\u636e\u6d41\u4f18\u5316\uff09\u3002\u8fd9\u662f\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63a8\u7406\u6548\u7387\u548c\u541e\u5410\u91cf\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u52a0\u901f\u5668\u7814\u7a76\u3002STAR\u901a\u8fc7\u5f15\u5165\u8de8\u9636\u6bb5\u534f\u540c\u3001\u57fa\u4e8e\u524d\u5bfc\u96f6\u7684\u7a00\u758f\u6027\u9884\u6d4b\u4ee5\u53ca\u4f18\u5316\u7684FlashAttention\u673a\u5236\uff0c\u4e13\u95e8\u9488\u5bf9\u5927\u89c4\u6a21\u4ee4\u724c\u5e76\u884c\uff08LTPP\uff09\u573a\u666f\u8fdb\u884c\u4e86\u4f18\u5316\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSTAR\u5728\u901f\u5ea6\u3001\u80fd\u6548\u548c\u9762\u79ef\u6548\u7387\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709GPU\u548cSOTA\u52a0\u901f\u5668\uff0c\u5e76\u5728\u8d85\u957f\u5e8f\u5217\u5904\u7406\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4f9d\u8d56\u4e8e\u9ad8\u541e\u5410\u91cf\u63a8\u7406\u548c\u5927\u89c4\u6a21\u4ee4\u724c\u5e76\u884c\uff08LTPP\uff09\u3002\u73b0\u6709\u7684\u52a8\u6001\u7a00\u758f\u6027\u52a0\u901f\u5668\u5728LTPP\u573a\u666f\u4e0b\u6548\u7387\u4f4e\u4e0b\uff0c\u539f\u56e0\u662f\u5b83\u4eec\u91c7\u7528\u4e86\u5b64\u7acb\u7684\u9636\u6bb5\u4f18\u5316\uff08stage-isolated optimizations\uff09\u3002\u4f5c\u8005\u8ba4\u4e3a\uff0c\u901a\u8fc7\u5bf9\u7aef\u5230\u7aef\u7a00\u758f\u6027\u52a0\u901f\u6d41\u7a0b\u7684\u91cd\u65b0\u5ba1\u89c6\uff0c\u53d1\u73b0\u4e86\u4e00\u4e2a\u88ab\u5ffd\u89c6\u7684\u673a\u4f1a\uff1a\u8de8\u9636\u6bb5\u7684\u534f\u540c\uff08cross-stage coordination\uff09\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u548c\u5185\u5b58\u8bbf\u95ee\uff0c\u4ece\u800c\u63d0\u9ad8\u6548\u7387\u3002", "method": "STAR\u7684\u6838\u5fc3\u65b9\u6cd5\u662f\u8de8\u9636\u6bb5\u534f\u540c\uff08cross-stage coordination\uff09\uff0c\u65e8\u5728\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u548c\u5185\u5b58\u8bbf\u95ee\u3002\u5177\u4f53\u5b9e\u65bd\u5305\u62ec\uff1a1. \u63d0\u51fa\u4e86\u4e00\u7a2e\u57fa\u4e8e\u524d\u5bfc\u96f6\uff08leading-zero-based\uff09\u7684\u7a00\u758f\u6027\u9884\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u5bf9\u6570\u57df\u52a0\u6cd5\u64cd\u4f5c\u6765\u6700\u5c0f\u5316\u9884\u6d4b\u5f00\u9500\u30022. \u91c7\u7528\u4e86\u5206\u5e03\u5f0f\u6392\u5e8f\u548c\u4e00\u79cd\u6392\u5e8f\u66f4\u65b0\u7684FlashAttention\u673a\u5236\u30023. \u5f15\u5165\u4e86\u534f\u8c03\u5206\u5757\u7b56\u7565\uff08coordinated tiling strategy\uff09\uff0c\u4ee5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u9636\u6bb5\u4ea4\u4e92\uff0c\u63d0\u9ad8\u5185\u5b58\u6548\u7387\u548c\u5ef6\u8fdf\u30024. \u8bbe\u8ba1\u4e86\u4e13\u95e8\u7684STAR\u52a0\u901f\u5668\u67b6\u6784\uff08dedicated STAR accelerator architecture\uff09\u6765\u652f\u6301\u8fd9\u4e9b\u4f18\u5316\u30025. \u5c06STAR\u90e8\u7f72\u5230\u591a\u6838\u7a7a\u95f4\u67b6\u6784\uff08multi-core spatial architecture\uff09\u4e0a\uff0c\u4f18\u5316\u6570\u636e\u6d41\u548c\u6267\u884c\u7f16\u6392\uff0c\u4ee5\u8fdb\u884c\u8d85\u957f\u5e8f\u5217\u5904\u7406\u3002", "result": "STAR\u76f8\u8f83\u4e8eA100 GPU\u5b9e\u73b0\u4e86\u9ad8\u8fbe9.2\u500d\u7684\u901f\u5ea6\u63d0\u5347\u548c71.2\u500d\u7684\u80fd\u6548\u63d0\u5347\u3002\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\uff08SOTA\uff09\u7684\u52a0\u901f\u5668\uff0cSTAR\u5728\u80fd\u6548\u4e0a\u63d0\u9ad8\u4e8616.1\u500d\uff0c\u5728\u9762\u79ef\u6548\u7387\u4e0a\u63d0\u9ad8\u4e8627.1\u500d\u3002Spatial-STAR\uff08\u90e8\u7f72\u5728\u591a\u6838\u7a7a\u95f4\u67b6\u6784\u4e0a\u7684STAR\uff09\u76f8\u8f83\u4e8e\u57fa\u7ebf\u8bbe\u8ba1\uff0c\u5728\u5904\u7406\u8d85\u957f\u5e8f\u5217\u65f6\u5b9e\u73b0\u4e8620.1\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "STAR\u662f\u4e00\u79cd\u7528\u4e8eTransformer\u63a8\u7406\u7684\u8de8\u9636\u6bb5\u8ba1\u7b97\u548c\u5185\u5b58\u9ad8\u6548\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u7279\u522b\u9488\u5bf9 LTPP\u3002\u5b83\u901a\u8fc7\u8de8\u9636\u6bb5\u534f\u540c\u3001\u57fa\u4e8e\u524d\u5bfc\u96f6\u7684\u7a00\u758f\u6027\u9884\u6d4b\u3001\u5206\u5e03\u5f0f\u6392\u5e8f\u548c\u4f18\u5316\u7684FlashAttention\u673a\u5236\uff0c\u8f85\u4ee5\u4e13\u95e8\u7684\u52a0\u901f\u5668\u67b6\u6784\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u63a8\u7406\u7684\u541e\u5410\u91cf\u548c\u80fd\u6548\uff0c\u5e76\u5728\u8d85\u957f\u5e8f\u5217\u5904\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2512.20495", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20495", "abs": "https://arxiv.org/abs/2512.20495", "authors": ["He Zhu", "Zheng Liu", "Xingyang Li", "Anbang Wu", "Jieru Zhao", "Fangxin Liu", "Yiming Gan", "Jingwen Leng", "Yu Feng"], "title": "Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization", "comment": null, "summary": "3D Gaussian splatting (3DGS) has drawn significant attention in the architectural community recently. However, current architectural designs often overlook the 3DGS scalability, making them fragile for extremely large-scale 3DGS. Meanwhile, the VR bandwidth requirement makes it impossible to deliver high-fidelity and smooth VR content from the cloud.\n  We present Nebula, a coherent acceleration framework for large-scale 3DGS collaborative rendering. Instead of streaming videos, Nebula streams intermediate results after the LoD search, reducing 1925% data communication between the cloud and the client. To further enhance the motion-to-photon experience, we introduce a temporal-aware LoD search in the cloud that tames the irregular memory access and reduces redundant data access by exploiting temporal coherence across frames. On the client side, we propose a novel stereo rasterization that enables two eyes to share most computations during the stereo rendering with bit-accurate quality. With minimal hardware augmentations, Nebula achieves 2.7$\\times$ motion-to-photon speedup and reduces 1925% bandwidth over lossy video streaming.", "AI": {"tldr": "\u90e8\u5206\u6d89\u53caMLIR\u6216HLS\u6216\u7f16\u8bd1\u5668\u6216DSL\u6216\u56fe\u5904\u7406\u6216\u7f16\u8bd1\u5668\u7684\u90e8\u5206\uff1a\u65e0\u3002\n\u592a\u957f\u4e0d\u770b\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aNebula\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a213DGS\u7684\u534f\u540c\u6e32\u67d3\u52a0\u901f\uff0c\u901a\u8fc7\u6d41\u5f0f\u4f20\u8f93LoD\u641c\u7d22\u540e\u7684\u4e2d\u95f4\u7ed3\u679c\u3001\u5f15\u5165\u65f6\u95f4\u611f\u77e5LoD\u641c\u7d22\u53ca\u65b0\u9896\u7684\u7acb\u4f53\u5149\u6805\u5316\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u901a\u4fe1\u5e26\u5bbd\uff0c\u63d0\u5347\u4e86\u8fd0\u52a8\u5230\u5149\u5b50\u7684\u901f\u5ea6\u3002", "motivation": "\u5f53\u524d\u5efa\u7b51\u9886\u57df\u76843D\u9ad8\u65af\u6e85\u5c04\uff083DGS\uff09\u8bbe\u8ba1\u5ffd\u7565\u4e86\u5176\u53ef\u6269\u5c55\u6027\uff0c\u5bf9\u4e8e\u8d85\u5927\u89c4\u6a213DGS\u800c\u8a00\u975e\u5e38\u8106\u5f31\u3002\u6b64\u5916\uff0cVR\u5e26\u5bbd\u8981\u6c42\u4f7f\u5f97\u65e0\u6cd5\u4ece\u4e91\u7aef\u63d0\u4f9b\u9ad8\u4fdd\u771f\u548c\u5e73\u6ed1\u7684VR\u5185\u5bb9\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5927\u89c4\u6a213DGS\u534f\u540c\u6e32\u67d3\u4e2d\u7684\u53ef\u4f38\u7f29\u6027\u3001\u5e26\u5bbd\u548c\u8fd0\u52a8\u5230\u5149\u5b50\u5ef6\u8fdf\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aNebula\u7684\u534f\u540c\u52a0\u901f\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a213DGS\u534f\u540c\u6e32\u67d3\u3002\u8be5\u65b9\u6cd5\u4e0d\u6d41\u5f0f\u4f20\u8f93\u89c6\u9891\uff0c\u800c\u662f\u5728\u7ecf\u8fc7LoD\u641c\u7d22\u540e\u6d41\u5f0f\u4f20\u8f93\u4e2d\u95f4\u7ed3\u679c\uff0c\u4ece\u800c\u5c06\u4e91\u7aef\u548c\u5ba2\u6237\u7aef\u4e4b\u95f4\u7684\u6570\u636e\u901a\u4fe1\u91cf\u51cf\u5c11\u4e861925%\u3002\u4e3a\u4e86\u589e\u5f3a\u8fd0\u52a8\u5230\u5149\u5b50\u7684\u4f53\u9a8c\uff0c\u4f5c\u8005\u5728\u4e91\u7aef\u5f15\u5165\u4e86\u4e00\u4e2a\u65f6\u95f4\u611f\u77e5LoD\u641c\u7d22\uff0c\u901a\u8fc7\u5229\u7528\u5e27\u95f4\u7684\u65f6\u95f4\u76f8\u5e72\u6027\u6765\u89e3\u51b3\u4e0d\u89c4\u5219\u5185\u5b58\u8bbf\u95ee\u548c\u51cf\u5c11\u5197\u4f59\u6570\u636e\u8bbf\u95ee\u3002\u5728\u5ba2\u6237\u7aef\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u7acb\u4f53\u5149\u6805\u5316\uff0c\u4f7f\u5f97\u5728\u7acb\u4f53\u6e32\u67d3\u8fc7\u7a0b\u4e2d\u4e24\u773c\u53ef\u4ee5\u5171\u4eab\u5927\u90e8\u5206\u8ba1\u7b97\uff0c\u5e76\u5b9e\u73b0\u4f4d\u7cbe\u786e\u7684\u8d28\u91cf\u3002", "result": "Nebula\uff08\u5177\u6709\u6700\u5c0f\u7684\u786c\u4ef6\u589e\u5f3a\uff09\u5b9e\u73b0\u4e862.7\u500d\u7684\u8fd0\u52a8\u5230\u5149\u5b50\u901f\u5ea6\u63d0\u5347\uff0c\u5e76\u5728\u6709\u635f\u89c6\u9891\u6d41\u4e0a\u5c06\u5e26\u5bbd\u5f00\u9500\u51cf\u5c11\u4e861925%\u3002", "conclusion": "Nebula\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u611f\u77e5LoD\u641c\u7d22\u548c\u65b0\u9896\u7684\u7acb\u4f53\u5149\u6805\u5316\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u89c4\u6a213DGS\u534f\u540c\u6e32\u67d3\u7684\u8fd0\u52a8\u5230\u5149\u5b50\u901f\u5ea6\u548c\u5e26\u5bbd\u6548\u7387\u3002\u4f5c\u8005\u8ba4\u4e3a\u901a\u8fc7\u6700\u5c0f\u7684\u786c\u4ef6\u8865\u5145\uff0c\u53ef\u4ee5\u5c06\u8fd0\u52a8\u5230\u5149\u5b50\u901f\u5ea6\u63d0\u9ad82.7\u500d\uff0c\u5e76\u5c06\u5e26\u5bbd\u5f00\u9500\u51cf\u5c111925%\u3002"}}
{"id": "2512.19851", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.19851", "abs": "https://arxiv.org/abs/2512.19851", "authors": ["Aditya Bhosale", "Laxmikant Kale"], "title": "An Adaptive Distributed Stencil Abstraction for GPUs", "comment": null, "summary": "The scientific computing ecosystem in Python is largely confined to single-node parallelism, creating a gap between high-level prototyping in NumPy and high-performance execution on modern supercomputers. The increasing prevalence of hardware accelerators and the need for energy efficiency have made resource adaptivity a critical requirement, yet traditional HPC abstractions remain rigid. To address these challenges, we present an adaptive, distributed abstraction for stencil computations on multi-node GPUs. This abstraction is built using CharmTyles, a framework based on the adaptive Charm++ runtime, and features a familiar NumPy-like syntax to minimize the porting effort from prototype to production code. We showcase the resource elasticity of our abstraction by dynamically rescaling a running application across a different number of nodes and present a performance analysis of the associated overheads. Furthermore, we demonstrate that our abstraction achieves significant performance improvements over both a specialized, high-performance stencil DSL and a generalized NumPy replacement.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL \u548c\u56fe\u5904\u7406\u76f8\u5173\u3002\u56e0\u4e3a\u5b83\u63d0\u5230\u4e86\u4e00\u4e2a\u9ad8\u6027\u80fd stencil DSL\uff08\u7279\u5b9a\u9886\u57df\u8bed\u8a00\uff09\u4ee5\u53ca\u5982\u4f55\u6784\u5efa\u4e00\u4e2a\u9ad8\u6027\u80fd\u8ba1\u7b97\u7684\u62bd\u8c61\u6765\u66ff\u4ee3\u5b83\uff0c\u8fd9\u6d89\u53ca\u5230\u8f6f\u4ef6\u62bd\u8c61\u548c\u6027\u80fd\u4f18\u5316\u65b9\u9762\uff0c\u53ef\u80fd\u4e0e\u7f16\u8bd1\u548c\u8fd0\u884c\u65f6\u7cfb\u7edf\u6709\u5173\u3002\u6458\u8981\uff1a\u76ee\u524d\u7684 Python \u79d1\u5b66\u8ba1\u7b97\u5de5\u5177\u94fe\uff08\u5982 NumPy\uff09\u96be\u4ee5\u5145\u5206\u5229\u7528\u591a\u8282\u70b9\u8d85\u7ea7\u8ba1\u7b97\u673a\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u786c\u4ef6\u52a0\u901f\u5668\u548c\u8d44\u6e90\u9002\u5e94\u6027\u7684\u9700\u6c42\u5f97\u4e0d\u5230\u6ee1\u8db3\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u4f7f\u7528 CharmTyles \u548c\u81ea\u9002\u5e94 Charm++ \u8fd0\u884c\u65f6\u6784\u5efa\u7684\u3001\u9488\u5bf9\u591a\u8282\u70b9 GPU \u4e0a stencil \u8ba1\u7b97\u7684\u81ea\u9002\u5e94\u3001\u5206\u5e03\u5f0f\u62bd\u8c61\uff0c\u8be5\u62bd\u8c61\u5177\u6709 NumPy \u98ce\u683c\u7684\u8bed\u6cd5\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u62bd\u8c61\u5177\u6709\u52a8\u6001\u8d44\u6e90\u5f39\u6027\uff0c\u5e76\u4e14\u6027\u80fd\u4f18\u4e8e\u4e13\u95e8\u7684 DSL \u548c\u901a\u7528\u7684 NumPy \u66ff\u4ee3\u54c1\u3002", "motivation": "\u5f53\u524d\u7684 Python \u79d1\u5b66\u8ba1\u7b97\u751f\u6001\u7cfb\u7edf\u5927\u591a\u5c40\u9650\u4e8e\u5355\u8282\u70b9\u5e76\u884c\u6027\uff0c\u5bfc\u81f4 NumPy \u7b49\u9ad8\u7ea7\u539f\u578b\u8bbe\u8ba1\u4e0e\u73b0\u4ee3\u8d85\u7ea7\u8ba1\u7b97\u673a\u4e0a\u7684\u9ad8\u6027\u80fd\u6267\u884c\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\u3002\u540c\u65f6\uff0c\u786c\u4ef6\u52a0\u901f\u5668\u7684\u666e\u53ca\u548c\u5bf9\u80fd\u6548\u7684\u9700\u6c42\u4f7f\u5f97\u8d44\u6e90\u9002\u5e94\u6027\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u8981\u6c42\uff0c\u800c\u4f20\u7edf\u7684 HPC \u62bd\u8c61\u5374\u8fc7\u4e8e\u50f5\u5316\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u81ea\u9002\u5e94\u7684\u3001\u5206\u5e03\u5f0f\u7684\u62bd\u8c61\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5229\u7528\u57fa\u4e8e\u81ea\u9002\u5e94 Charm++ \u8fd0\u884c\u65f6\u7684 CharmTyles \u6846\u67b6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7528\u4e8e\u591a\u8282\u70b9 GPU \u4e0a stencil \u8ba1\u7b97\u7684\u81ea\u9002\u5e94\u3001\u5206\u5e03\u5f0f\u62bd\u8c61\u3002\u8be5\u62bd\u8c61\u91c7\u7528\u4e86 NumPy \u98ce\u683c\u7684\u8bed\u6cd5\u4ee5\u7b80\u5316\u4ece\u539f\u578b\u5230\u751f\u4ea7\u4ee3\u7801\u7684\u8fc1\u79fb\u3002\u901a\u8fc7\u52a8\u6001\u91cd\u65b0\u8c03\u6574\u6b63\u5728\u8fd0\u884c\u7684\u5e94\u7528\u7a0b\u5e8f\u7684\u8282\u70b9\u6570\u91cf\uff0c\u5c55\u793a\u4e86\u5176\u8d44\u6e90\u5f39\u6027\uff0c\u5e76\u5bf9\u76f8\u5173\u5f00\u9500\u8fdb\u884c\u4e86\u6027\u80fd\u5206\u6790\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u62bd\u8c61\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\uff0c\u4f18\u4e8e\u4e00\u4e2a\u4e13\u95e8\u7684\u9ad8\u6027\u80fd stencil DSL \u548c\u4e00\u4e2a\u901a\u7528\u7684 NumPy \u66ff\u4ee3\u65b9\u6848\u3002\u6b64\u5916\uff0c\u8be5\u62bd\u8c61\u8fd8\u5c55\u793a\u4e86\u826f\u597d\u7684\u8d44\u6e90\u5f39\u6027\uff0c\u80fd\u591f\u52a8\u6001\u5730\u91cd\u65b0\u8c03\u6574\u8fd0\u884c\u4e2d\u7684\u5e94\u7528\u6240\u4f7f\u7528\u7684\u8282\u70b9\u6570\u91cf\u3002\u6027\u80fd\u5206\u6790\u90e8\u5206\u91cf\u5316\u4e86\u76f8\u5173\u7684\u5f00\u9500\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u3001\u5206\u5e03\u5f0f\u62bd\u8c61\u4e3a\u591a\u8282\u70b9 GPU \u4e0a\u7684 stencil \u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6027\u80fd\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002\u901a\u8fc7\u5229\u7528 CharmTyles \u548c Charm++ \u8fd0\u884c\u65f6\uff0c\u7ed3\u5408 NumPy \u98ce\u683c\u7684\u8bed\u6cd5\uff0c\u8be5\u62bd\u8c61\u6210\u529f\u5730\u5f25\u5408\u4e86 Python \u79d1\u5b66\u8ba1\u7b97\u4e2d\u7684\u539f\u578b\u8bbe\u8ba1\u4e0e\u8d85\u7ea7\u8ba1\u7b97\u673a\u9ad8\u6027\u80fd\u6267\u884c\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u5c55\u793a\u4e86\u5728\u8d44\u6e90\u5f39\u6027\u548c\u6027\u80fd\u4e0a\u7684\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.20571", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.20571", "abs": "https://arxiv.org/abs/2512.20571", "authors": ["Brennan Romero", "D. G. Perera"], "title": "Composing Mini Oscilloscope on Embedded Systems", "comment": "22 pages, 11 figures", "summary": "In this paper, our goal is to reproduce the basic functionalities of a regular oscilloscope, using the Nuvoton NUC-140 embedded systems development platform as the front-end and display method. A custom-built daughter board connects the NUC-140 to a variety of peripherals, including two BNC scope-probe connections, an external nine-button keypad, and a calibration signal. The LCD of the NUC-140 development board serves as the waveform display. From the experimental results, it is demonstrated that our proposed system became a very competent debugging tool. It implements 90% of the features we typically use on original oscilloscopes, including: automatic, edge-triggered, and single modes; waveform visualization using vertical and horizontal scaling; probe calibration.", "AI": {"tldr": "\u4e0d\u76f8\u5173\u3002\n\u672c\u6587\u65e8\u5728\u5229\u7528 Nuvoton NUC-140 \u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u5e73\u53f0\u91cd\u73b0\u5e38\u89c4\u793a\u6ce2\u5668\u7684\u57fa\u672c\u529f\u80fd\uff0c\u901a\u8fc7\u5b9a\u5236\u5b50\u677f\u8fde\u63a5\u5916\u8bbe\uff08\u5982 BNC \u63a2\u5934\u3001\u952e\u76d8\u3001\u6821\u51c6\u4fe1\u53f7\uff09\uff0c\u5e76\u7528\u5f00\u53d1\u677f\u7684 LCD \u663e\u793a\u6ce2\u5f62\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u7cfb\u7edf\u662f\u4e00\u4e2a\u5408\u683c\u7684\u8c03\u8bd5\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u5e38\u89c4\u793a\u6ce2\u5668 90% \u7684\u5e38\u7528\u529f\u80fd\uff0c\u4f8b\u5982\u5404\u79cd\u89e6\u53d1\u6a21\u5f0f\u3001\u6ce2\u5f62\u7f29\u653e\u548c\u63a2\u5934\u6821\u51c6\u3002", "motivation": "\u4f7f\u7528 Nuvoton NUC-140 \u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u5e73\u53f0\u6a21\u4eff\u5e38\u89c4\u793a\u6ce2\u5668\u7684\u57fa\u672c\u529f\u80fd\uff0c\u4ee5\u521b\u5efa\u4e00\u4e2a\u6709\u80fd\u529b\u7684\u8c03\u8bd5\u5de5\u5177\u3002", "method": "\u4f7f\u7528 Nuvoton NUC-140 \u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u5e73\u53f0\u4f5c\u4e3a\u793a\u6ce2\u5668\u7684\u524d\u7aef\u548c\u663e\u793a\u65b9\u6cd5\u3002\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5b9a\u5236\u7684\u5b50\u677f\uff0c\u5c06 NUC-140 \u8fde\u63a5\u5230\u5404\u79cd\u5916\u56f4\u8bbe\u5907\uff0c\u5305\u62ec\u4e24\u4e2a BNC \u793a\u6ce2\u5668\u63a2\u5934\u8fde\u63a5\u3001\u4e00\u4e2a\u5916\u90e8\u4e5d\u952e\u952e\u76d8\u548c\u4e00\u4e2a\u6821\u51c6\u4fe1\u53f7\u3002\u5229\u7528 NUC-140 \u5f00\u53d1\u677f\u4e0a\u7684 LCD \u4f5c\u4e3a\u6ce2\u5f62\u663e\u793a\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u5177\u6709\u5f88\u5f3a\u7684\u8c03\u8bd5\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u5e38\u89c4\u793a\u6ce2\u5668\u4e2d 90% \u7684\u5e38\u7528\u529f\u80fd\uff0c\u5305\u62ec\uff1a\u81ea\u52a8\u3001\u8fb9\u6cbf\u89e6\u53d1\u548c\u5355\u6b21\u6a21\u5f0f\uff1b\u4f7f\u7528\u5782\u76f4\u548c\u6c34\u5e73\u7f29\u653e\u8fdb\u884c\u6ce2\u5f62\u53ef\u89c6\u5316\uff1b\u63a2\u5934\u6821\u51c6\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5730\u4f7f\u7528 Nuvoton NUC-140 \u5d4c\u5165\u5f0f\u7cfb\u7edf\u5f00\u53d1\u5e73\u53f0\u4f5c\u4e3a\u524d\u7aef\u548c\u663e\u793a\u65b9\u6cd5\uff0c\u91cd\u73b0\u4e86\u5e38\u89c4\u793a\u6ce2\u5668\u7684\u57fa\u672c\u529f\u80fd\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7cfb\u7edf\u662f\u4e00\u4e2a\u975e\u5e38\u6709\u80fd\u529b\u7684\u8c03\u8bd5\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u5e38\u89c4\u793a\u6ce2\u5668\u4e2d\u901a\u5e38\u4f7f\u7528\u7684 90% \u7684\u529f\u80fd\u3002"}}
{"id": "2512.19972", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.19972", "abs": "https://arxiv.org/abs/2512.19972", "authors": ["Pengchao Han", "Xi Huang", "Yi Fang", "Guojun Han"], "title": "Rethinking Knowledge Distillation in Collaborative Machine Learning: Memory, Knowledge, and Their Interactions", "comment": "Published in IEEE TNSE", "summary": "Collaborative learning has emerged as a key paradigm in large-scale intelligent systems, enabling distributed agents to cooperatively train their models while addressing their privacy concerns. Central to this paradigm is knowledge distillation (KD), a technique that facilitates efficient knowledge transfer among agents. However, the underlying mechanisms by which KD leverages memory and knowledge across agents remain underexplored. This paper aims to bridge this gap by offering a comprehensive review of KD in collaborative learning, with a focus on the roles of memory and knowledge. We define and categorize memory and knowledge within the KD process and explore their interrelationships, providing a clear understanding of how knowledge is extracted, stored, and shared in collaborative settings. We examine various collaborative learning patterns, including distributed, hierarchical, and decentralized structures, and provide insights into how memory and knowledge dynamics shape the effectiveness of KD in collaborative learning. Particularly, we emphasize task heterogeneity in distributed learning pattern covering federated learning (FL), multi-agent domain adaptation (MADA), federated multi-modal learning (FML), federated continual learning (FCL), federated multi-task learning (FMTL), and federated graph knowledge embedding (FKGE). Additionally, we highlight model heterogeneity, data heterogeneity, resource heterogeneity, and privacy concerns of these tasks. Our analysis categorizes existing work based on how they handle memory and knowledge. Finally, we discuss existing challenges and propose future directions for advancing KD techniques in the context of collaborative learning.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0eMLIR\u3001DSL\u3001\u56fe\u5904\u7406\u3001\u7f16\u8bd1\u3001HLS\u4e0d\u76f4\u63a5\u76f8\u5173\uff0c\u5b83\u5c5e\u4e8e\u673a\u5668\u5b66\u4e60/\u4eba\u5de5\u667a\u80fd\uff08AI\uff09\u9886\u57df\u7684\u7814\u7a76\uff0c\u7279\u522b\u662f\u5173\u4e8e**\u534f\u4f5c\u5b66\u4e60\uff08Collaborative Learning\uff09**\u548c**\u77e5\u8bc6\u84b8\u998f\uff08Knowledge Distillation, KD\uff09**\u3002\n\n\u603b\u7ed3\uff1a\u8fd9\u7bc7\u7efc\u8ff0\u6587\u7ae0\u5168\u9762\u56de\u987e\u4e86\u534f\u4f5c\u5b66\u4e60\u4e2d\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u7684\u5e94\u7528\uff0c\u5e76\u805a\u7126\u4e8e\u8bb0\u5fc6\u548c\u77e5\u8bc6\u5728\u5176\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002\u6587\u7ae0\u9996\u5148\u5b9a\u4e49\u4e86KD\u4e2d\u7684\u8bb0\u5fc6\u548c\u77e5\u8bc6\uff0c\u5e76\u89e3\u91ca\u4e86\u5b83\u4eec\u5982\u4f55\u5f71\u54cd\u77e5\u8bc6\u5728\u5206\u5e03\u5f0f\u3001\u5c42\u7ea7\u5f0f\u548c\u53bb\u4e2d\u5fc3\u5316\u534f\u4f5c\u6a21\u5f0f\u4e2d\u7684\u63d0\u53d6\u3001\u5b58\u50a8\u548c\u5171\u4eab\u3002\u5b83\u7279\u522b\u5f3a\u8c03\u4e86\u8054\u90a6\u5b66\u4e60\uff08FL\uff09\u7b49\u5206\u5e03\u5f0f\u5b66\u4e60\u6a21\u5f0f\u4e2d\u7684\u4efb\u52a1\u5f02\u6784\u6027\uff0c\u4ee5\u53ca\u6a21\u578b\u3001\u6570\u636e\u3001\u8d44\u6e90\u548c\u9690\u79c1\u95ee\u9898\u3002\u6700\u7ec8\uff0c\u6587\u7ae0\u5bf9\u73b0\u6709\u5de5\u4f5c\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5e76\u8ba8\u8bba\u4e86\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7684\u534f\u4f5c\u5b66\u4e60\u8303\u5f0f\uff0c\u7279\u522b\u662f\u5176\u4e2d\u7684\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u6280\u672f\uff0c\u867d\u7136\u6709\u6548\uff0c\u4f46\u5bf9\u4e8e\u201cKD\u5982\u4f55\u5229\u7528\u8de8\u4e3b\u4f53\uff08agents\uff09\u95f4\u7684\u8bb0\u5fc6\u548c\u77e5\u8bc6\u201d\u8fd9\u4e00\u5e95\u5c42\u673a\u5236\u7f3a\u4e4f\u6df1\u5165\u7684\u63a2\u7d22\u548c\u7406\u89e3\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u5ba1\u89c6\u8bb0\u5fc6\u548c\u77e5\u8bc6\u5728\u534f\u4f5c\u5b66\u4e60\u4e2dKD\u8fc7\u7a0b\u4e2d\u7684\u6838\u5fc3\u4f5c\u7528\uff0c\u4ece\u800c\u4e3a\u63a8\u8fdb\u8be5\u9886\u57df\u7684\u53d1\u5c55\u63d0\u4f9b\u6e05\u6670\u7684\u6846\u67b6\u548c\u6d1e\u5bdf\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u8ff0\u548c\u5206\u7c7b\u5206\u6790\u7684\u65b9\u6cd5\uff0c\u5168\u9762\u56de\u987e\u4e86\u534f\u4f5c\u5b66\u4e60\u4e2d\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u7684\u5e94\u7528\uff0c\u5e76\u7740\u91cd\u5206\u6790\u4e86\u8bb0\u5fc6\uff08Memory\uff09\u548c\u77e5\u8bc6\uff08Knowledge\uff09\u5728\u5176\u4e2d\u7684\u4f5c\u7528\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. **\u5b9a\u4e49\u548c\u5206\u7c7b**\uff1a\u660e\u786e\u5b9a\u4e49KD\u8fc7\u7a0b\u4e2d\u7684\u8bb0\u5fc6\u548c\u77e5\u8bc6\uff0c\u5e76\u8fdb\u884c\u5206\u7c7b\uff1b2. **\u63a2\u8ba8\u76f8\u4e92\u5173\u7cfb**\uff1a\u5206\u6790\u77e5\u8bc6\u662f\u5982\u4f55\u5728\u534f\u4f5c\u73af\u5883\u4e2d\u88ab\u63d0\u53d6\u3001\u5b58\u50a8\u548c\u5171\u4eab\u7684\uff1b3. **\u6a21\u5f0f\u5206\u6790**\uff1a\u8003\u5bdf\u5206\u5e03\u5f0f\u3001\u5c42\u7ea7\u5f0f\u548c\u53bb\u4e2d\u5fc3\u5316\u7b49\u534f\u4f5c\u5b66\u4e60\u6a21\u5f0f\uff0c\u7279\u522b\u5173\u6ce8\u5206\u5e03\u5f0f\u5b66\u4e60\u6a21\u5f0f\u4e0b\u7684\u4efb\u52a1\u5f02\u6784\u6027\uff08\u5982FL\u3001MADA\u3001FML\u3001FCL\u3001FMTL\u3001FKGE\uff09\uff1b4. **\u5f02\u6784\u6027\u5206\u6790**\uff1a\u5f3a\u8c03\u6a21\u578b\u3001\u6570\u636e\u3001\u8d44\u6e90\u5f02\u6784\u6027\u53ca\u5176\u9690\u79c1\u95ee\u9898\uff1b5. **\u5206\u7c7b\u73b0\u6709\u5de5\u4f5c**\uff1a\u6839\u636e\u73b0\u6709\u5de5\u4f5c\u5904\u7406\u8bb0\u5fc6\u548c\u77e5\u8bc6\u7684\u65b9\u5f0f\u5bf9\u5176\u8fdb\u884c\u5206\u7c7b\uff1b6. **\u6311\u6218\u4e0e\u5c55\u671b**\uff1a\u8ba8\u8bba\u73b0\u6709\u6311\u6218\u5e76\u63d0\u51fa\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "result": "\u672c\u6587\u63d0\u4f9b\u4e86\u534f\u4f5c\u5b66\u4e60\u4e2d\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u7684\u5168\u9762\u7efc\u8ff0\uff0c\u91cd\u70b9\u9610\u660e\u4e86\u8bb0\u5fc6\u548c\u77e5\u8bc6\u7684\u4f5c\u7528\u3002\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1a\u5bf9KD\u8fc7\u7a0b\u4e2d\u8bb0\u5fc6\u548c\u77e5\u8bc6\u7684\u6e05\u6670\u5b9a\u4e49\u548c\u5206\u7c7b\uff1b\u63ed\u793a\u4e86\u77e5\u8bc6\u5728\u5206\u5e03\u5f0f\u3001\u5c42\u7ea7\u5f0f\u548c\u53bb\u4e2d\u5fc3\u5316\u7b49\u534f\u4f5c\u5b66\u4e60\u6a21\u5f0f\u4e2d\u662f\u5982\u4f55\u88ab\u63d0\u53d6\u3001\u5b58\u50a8\u548c\u5171\u4eab\u7684\uff1b\u7279\u522b\u5f3a\u8c03\u4e86\u5206\u5e03\u5f0f\u5b66\u4e60\u6a21\u5f0f\u4e0b\u7684\u4efb\u52a1\u5f02\u6784\u6027\uff08\u5982FL\u3001FML\u7b49\uff09\uff1b\u5206\u6790\u548c\u5f3a\u8c03\u4e86\u6a21\u578b\u3001\u6570\u636e\u3001\u8d44\u6e90\u5f02\u6784\u6027\u4ee5\u53ca\u9690\u79c1\u95ee\u9898\uff1b\u6700\u540e\uff0c\u6839\u636e\u73b0\u6709\u5de5\u4f5c\u5904\u7406\u8bb0\u5fc6\u548c\u77e5\u8bc6\u7684\u65b9\u5f0f\u8fdb\u884c\u4e86\u5206\u7c7b\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u901a\u8fc7\u5bf9\u534f\u4f5c\u5b66\u4e60\u4e2d\u77e5\u8bc6\u84b8\u998f\uff08KD\uff09\u7684\u8bb0\u5fc6\u548c\u77e5\u8bc6\u4f5c\u7528\u7684\u6df1\u5165\u7814\u7a76\uff0c\u4e3a\u8be5\u9886\u57df\u672a\u6765\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u5b83\u4e0d\u4ec5\u6e05\u6670\u5730\u5b9a\u4e49\u548c\u5206\u7c7b\u4e86\u5173\u952e\u6982\u5ff5\uff0c\u63ed\u793a\u4e86\u77e5\u8bc6\u5728\u534f\u4f5c\u73af\u5883\u4e2d\u7684\u63d0\u53d6\u3001\u5b58\u50a8\u548c\u5171\u4eab\u673a\u5236\uff0c\u8fd8\u63d0\u51fa\u4e86\u5bf9\u73b0\u6709\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u6df1\u523b\u89c1\u89e3\u3002\u8fd9\u5bf9\u4e8e\u63a8\u8fdb\u5927\u89c4\u6a21\u667a\u80fd\u7cfb\u7edf\u4e2d\u9ad8\u6548\u3001\u9690\u79c1\u4fdd\u62a4\u7684\u77e5\u8bc6\u5171\u4eab\u65b9\u6cd5\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.20017", "categories": ["cs.DC", "cs.GR"], "pdf": "https://arxiv.org/pdf/2512.20017", "abs": "https://arxiv.org/abs/2512.20017", "authors": ["Hexu Zhao", "Xiaoteng Liu", "Xiwen Min", "Jianhao Huang", "Youming Deng", "Yanfei Li", "Ang Li", "Jinyang Li", "Aurojit Panda"], "title": "Scaling Point-based Differentiable Rendering for Large-scale Reconstruction", "comment": "13 pages main text, plus appendix", "summary": "Point-based Differentiable Rendering (PBDR) enables high-fidelity 3D scene reconstruction, but scaling PBDR to high-resolution and large scenes requires efficient distributed training systems. Existing systems are tightly coupled to a specific PBDR method. And they suffer from severe communication overhead due to poor data locality. In this paper, we present Gaian, a general distributed training system for PBDR. Gaian provides a unified API expressive enough to support existing PBDR methods, while exposing rich data-access information, which Gaian leverages to optimize locality and reduce communication. We evaluated Gaian by implementing 4 PBDR algorithms. Our implementations achieve high performance and resource efficiency: across six datasets and up to 128 GPUs, it reduces communication by up to 91% and improves training throughput by 1.50x-3.71x.", "AI": {"tldr": "\u90e8\u5206\u4e0e\u56fe\u5904\u7406\uff08\"Point-based\"\u6697\u793a\u4e86\u70b9\u4e91\u6216\u70b9\u96c6\uff0c\u53ef\u4ee5\u62bd\u8c61\u4e3a\u56fe\u7ed3\u6784\uff09\u548c\u7f16\u8bd1\u5668\uff08\u7cfb\u7edf\u8bbe\u8ba1\u548c\u4f18\u5316\u4e0e\u7f16\u8bd1\u5668\u539f\u7406\u76f8\u5173\uff09\uff0c\u4ee5\u53ca\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u5206\u5e03\u5f0f\u7cfb\u7edf\u76f8\u5173\u3002Gaian\u662f\u4e00\u4e2a\u901a\u7528\u7684\u5206\u5e03\u5f0f\u70b9\u4e91\u5fae\u5206\u6e32\u67d3\uff08PBDR\uff09\u8bad\u7ec3\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u7edf\u4e00API\u548c\u4f18\u5316\u6570\u636e\u5c40\u90e8\u6027\u6765\u5927\u5e45\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\uff08\u9ad8\u8fbe91%\uff09\uff0c\u4ece\u800c\u5728\u591aGPU\u548c\u5927\u89c4\u6a21\u573a\u666f\u4e0b\uff0c\u5c06\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u9ad81.50\u500d\u52303.71\u500d\u3002", "motivation": "\u73b0\u6709\u7684\u70b9\u4e91\u5fae\u5206\u6e32\u67d3\uff08PBDR\uff09\u7cfb\u7edf\u901a\u5e38\u4e0e\u7279\u5b9a\u7684PBDR\u65b9\u6cd5\u7d27\u5bc6\u8026\u5408\uff0c\u5e76\u4e14\u7531\u4e8e\u6570\u636e\u5c40\u90e8\u6027\u5dee\uff0c\u5b58\u5728\u4e25\u91cd\u7684\u901a\u4fe1\u5f00\u9500\uff0c\u8fd9\u963b\u788d\u4e86PBDR\u6269\u5c55\u5230\u9ad8\u5206\u8fa8\u7387\u548c\u5927\u578b\u573a\u666f\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u901a\u7528\u7684\u3001\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u8bad\u7ec3\u7cfb\u7edf\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "Gaian\u901a\u8fc7\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684API\u6765\u652f\u6301\u73b0\u6709\u7684PBDR\u65b9\u6cd5\uff0c\u540c\u65f6\u516c\u5f00\u4e30\u5bcc\u7684\u6570\u636e\u8bbf\u95ee\u4fe1\u606f\u3002Gaian\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u6765\u4f18\u5316\u6570\u636e\u5c40\u90e8\u6027\u5e76\u5927\u5e45\u51cf\u5c11\u901a\u4fe1\u91cf\u3002", "result": "\u901a\u8fc7\u5b9e\u73b0\u548c\u8bc4\u4f304\u79cdPBDR\u7b97\u6cd5\uff0cGaian\u57286\u4e2a\u6570\u636e\u96c6\u548c\u591a\u8fbe128\u4e2aGPU\u4e0a\u5c55\u73b0\u51fa\u9ad8\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\u3002\u5b83\u6210\u529f\u5730\u5c06\u901a\u4fe1\u91cf\u51cf\u5c11\u4e86\u81f3\u591a91%\uff0c\u5e76\u5c06\u8bad\u7ec3\u541e\u5410\u91cf\u63d0\u9ad8\u4e861.50\u500d\u81f33.71\u500d\u3002", "conclusion": "Gaian\u662f\u4e00\u4e2a\u901a\u7528\u7684\u5206\u5e03\u5f0fPBDR\u8bad\u7ec3\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u7edf\u4e00API\u652f\u6301\u591a\u79cd\u73b0\u6709PBDR\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5229\u7528\u4e30\u5bcc\u7684\u6570\u636e\u8bbf\u95ee\u4fe1\u606f\u6765\u4f18\u5316\u6570\u636e\u5c40\u90e8\u6027\u548c\u51cf\u5c11\u901a\u4fe1\u5f00\u9500\u3002\u8fd9\u4f7f\u5f97\u5728\u6269\u5c55\u5230\u9ad8\u5206\u8fa8\u7387\u548c\u5927\u578b\u573a\u666f\u65f6\uff0cPBDR\u8bad\u7ec3\u7684\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\u5f97\u4ee5\u663e\u8457\u63d0\u9ad8\u3002"}}
{"id": "2512.20163", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20163", "abs": "https://arxiv.org/abs/2512.20163", "authors": ["Leszek G\u0105sieniec", "Tytus Grodzicki", "Tomasz Jurdzi\u0144ski", "Jakub Kowalski", "Grzegorz Stachowiak"], "title": "Population Protocols Revisited: Parity and Beyond", "comment": null, "summary": "For nearly two decades, population protocols have been extensively studied, yielding efficient solutions for central problems in distributed computing, including leader election, and majority computation, a predicate type in Presburger Arithmetic closely tied to population protocols. Surprisingly, no protocols have achieved both time- and space-efficiency for congruency predicates, such as parity computation, which are complementary in this arithmetic framework. This gap highlights a significant challenge in the field. To address this gap, we explore the parity problem, where agents are tasked with computing the parity of the given sub-population size. Then we extend the solution for parity to compute congruences modulo an arbitrary $m$.\n  Previous research on efficient population protocols has focused on protocols that minimise both stabilisation time and state utilisation for specific problems. In contrast, this work slightly relaxes this expectation, permitting protocols to place less emphasis on full optimisation and more on universality, robustness, and probabilistic guarantees. This allows us to propose a novel computing paradigm that integrates population weights (or simply weights), a robust clocking mechanism, and efficient anomaly detection coupled with a switching mechanism (which ensures slow but always correct solutions). This paradigm facilitates universal design of efficient multistage stable population protocols. Specifically, the first efficient parity and congruence protocols introduced here use both $O(\\log^3 n)$ states and achieve silent stabilisation in $O(\\log^3 n)$ time. We conclude by discussing the impact of implicit conversion between unary and binary representations enabled by the weight system, with applications to other problems, including the computation and representation of (sub-)population sizes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u5747\u65e0\u76f4\u63a5\u5173\u8054\uff0c\u5b83\u5c5e\u4e8e\u5206\u5e03\u5f0f\u8ba1\u7b97\u548c\u7406\u8bba\u8ba1\u7b97\u673a\u79d1\u5b66\u9886\u57df\uff0c\u7814\u7a76\u7684\u662f\u7fa4\u4f53\u534f\u8bae\uff08Population Protocols\uff09\u3002\n**\u592a\u957f\u4e0d\u770b\u7248\uff08TLDR\uff09\uff1a** \u9488\u5bf9\u7fa4\u4f53\u534f\u8bae\u4e2d\u5947\u5076\u6821\u9a8c\u548c\u540c\u4f59\u8ba1\u7b97\uff08\u6a21\u8fd0\u7b97\uff09\u7f3a\u4e4f\u540c\u65f6\u5177\u5907\u65f6\u95f4\u6548\u7387\u548c\u7a7a\u95f4\u6548\u7387\u7684\u534f\u8bae\u7684\u7a7a\u767d\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6574\u5408\u7fa4\u4f53\u6743\u91cd\u3001\u9c81\u68d2\u65f6\u949f\u548c\u5f02\u5e38\u68c0\u6d4b\u7684\u65b0\u8ba1\u7b97\u8303\u5f0f\u3002\u57fa\u4e8e\u6b64\u8303\u5f0f\uff0c\u672c\u6587\u9996\u6b21\u8bbe\u8ba1\u51fa\u4e86\u9ad8\u6548\u7684\u5947\u5076\u6821\u9a8c\u548c\u540c\u4f59\u534f\u8bae\uff0c\u5b83\u4eec\u7684\u72b6\u6001\u6570\u548c\u9759\u9ed8\u7a33\u5b9a\u65f6\u95f4\u5747\u4e3a $O(\\log^3 n)$\uff0c\u6210\u529f\u5730\u5f25\u8865\u4e86\u8fd9\u4e00\u7406\u8bba\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u7684\u7fa4\u4f53\u534f\u8bae\uff08Population Protocols\uff09\u5728\u8bf8\u5982\u9886\u5bfc\u8005\u9009\u4e3e\u548c\u591a\u6570\u6d3e\u8ba1\u7b97\u7b49\u5206\u5e03\u5f0f\u8ba1\u7b97\u4e2d\u5fc3\u7684\u6807\u51c6\u95ee\u9898\u4e0a\u5df2\u53d6\u5f97\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u4e2d\u591a\u6570\u6d3e\u8ba1\u7b97\u4e0e\u666e\u96f7\u65af\u5821\u7b97\u672f\u4e2d\u7684\u8c13\u8bcd\u7c7b\u578b\u7d27\u5bc6\u76f8\u5173\u3002\u7136\u800c\uff0c\u5bf9\u4e8e\u5728\u8be5\u7b97\u672f\u6846\u67b6\u4e2d\u5177\u6709\u4e92\u8865\u6027\u7684\u540c\u4f59\u8c13\u8bcd\uff08\u5982\u5947\u5076\u6821\u9a8c\uff09\uff0c\u73b0\u6709\u534f\u8bae\u5728\u5b9e\u73b0\u65f6\u95f4\u6548\u7387\u548c\u7a7a\u95f4\u6548\u7387\u517c\u5177\u65b9\u9762\u5b58\u5728\u663e\u8457\u7a7a\u767d\u3002\u672c\u6587\u7684\u52a8\u673a\u6b63\u662f\u4e3a\u4e86\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u901a\u8fc7\u63a2\u7d22\u5947\u5076\u6821\u9a8c\u95ee\u9898\u5e76\u5c06\u5176\u63a8\u5e7f\u5230\u6a21\u4efb\u610f $m$ \u7684\u540c\u4f59\u8ba1\u7b97\uff0c\u4ee5\u671f\u4e3a\u8fd9\u7c7b\u4e92\u8865\u95ee\u9898\u63d0\u4f9b\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7fa4\u4f53\u8ba1\u7b97\u8303\u5f0f\uff0c\u65e8\u5728\u8bbe\u8ba1\u9ad8\u6548\u3001\u901a\u7528\u4e14\u9c81\u68d2\u7684\u591a\u9636\u6bb5\u7a33\u5b9a\u7fa4\u4f53\u534f\u8bae\u3002\u8be5\u8303\u5f0f\u4e3b\u8981\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u673a\u5236\uff1a1. **\u7fa4\u4f53\u6743\u91cd\uff08Population Weights\uff09**\uff1a\u4e00\u79cd\u9c81\u68d2\u7684\u5ea6\u91cf\u673a\u5236\uff1b2. **\u9c81\u68d2\u7684\u65f6\u949f\u673a\u5236\uff08Robust Clocking Mechanism\uff09**\uff1b3. **\u9ad8\u6548\u7684\u5f02\u5e38\u68c0\u6d4b\u4e0e\u5207\u6362\u673a\u5236\uff08Efficient Anomaly Detection Coupled with a Switching Mechanism\uff09**\uff1a\u8be5\u673a\u5236\u786e\u4fdd\u5728\u51fa\u73b0\u5f02\u5e38\u65f6\uff08\u901a\u8fc7\u5207\u6362\u5230\u4e00\u79cd\u201c\u6162\u4f46\u59cb\u7ec8\u6b63\u786e\u201d\u7684\u89e3\u51b3\u65b9\u6848\uff09\uff0c\u534f\u8bae\u4ecd\u7136\u53ef\u4ee5\u6b63\u786e\u8fd0\u884c\u3002\u57fa\u4e8e\u6b64\u8303\u5f0f\uff0c\u4f5c\u8005\u6210\u529f\u8bbe\u8ba1\u4e86\u7b2c\u4e00\u4e2a\u540c\u65f6\u5177\u6709\u65f6\u95f4\u6548\u7387\u548c\u7a7a\u95f4\u6548\u7387\u7684\u5947\u5076\u6821\u9a8c\u548c\u6a21 $m$ \u540c\u4f59\u534f\u8bae\u3002", "result": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u5947\u5076\u6821\u9a8c\uff08Parity\uff09\u548c\u540c\u4f59\uff08Congruence\uff09\u7fa4\u4f53\u534f\u8bae\u3002\u8fd9\u4e9b\u534f\u8bae\u5728\u4e24\u4e2a\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u5747\u5b9e\u73b0\u4e86\u9ad8\u6548\u6027\uff1a\u534f\u8bae\u7684**\u72b6\u6001\u6570**\u4e3a $O(\\log^3 n)$\uff0c\u5e76\u4e14\u5728**\u9759\u9ed8\u7a33\u5b9a\u65f6\u95f4**\u4e0a\u8fbe\u5230\u4e86 $O(\\log^3 n)$\u3002\u8fd9\u4e00\u6210\u5c31\u5c55\u793a\u4e86\u6240\u63d0\u51fa\u7684\u8ba1\u7b97\u8303\u5f0f\uff08\u96c6\u6210\u7fa4\u4f53\u6743\u91cd\u3001\u9c81\u68d2\u65f6\u949f\u548c\u5f02\u5e38\u68c0\u6d4b\uff09\u5728\u901a\u7528\u9ad8\u6548\u7fa4\u4f53\u534f\u8bae\u8bbe\u8ba1\u4e0a\u7684\u6709\u6548\u6027\u3002\u6b64\u5916\uff0c\u5de5\u4f5c\u8fd8\u8ba8\u8bba\u4e86\u6743\u91cd\u7cfb\u7edf\u5728\u4e0d\u540c\u6570\u636e\u8868\u793a\uff08\u4e00\u5143\u548c\u4e8c\u5143\uff09\u4e4b\u95f4\u9690\u5f0f\u8f6c\u6362\u7684\u80fd\u529b\u53ca\u5176\u5bf9\u7fa4\u4f53\u89c4\u6a21\u8ba1\u7b97\u548c\u8868\u793a\u7b49\u5176\u4ed6\u95ee\u9898\u7684\u6f5c\u5728\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u65b0\u7684\u8ba1\u7b97\u8303\u5f0f\uff0c\u5373\u7ed3\u5408\u4e86\u7fa4\u4f53\u6743\u91cd\u3001\u65f6\u949f\u673a\u5236\u548c\u5f02\u5e38\u68c0\u6d4b\uff0c\u6210\u529f\u5730\u5f25\u8865\u4e86\u73b0\u6709\u7fa4\u4f53\u534f\u8bae\u5728\u5904\u7406\u6a21\u8fd0\u7b97\uff08\u5982\u5947\u5076\u6821\u9a8c\uff09\u95ee\u9898\u4e0a\u7684\u4e0d\u8db3\u3002\u8be5\u8303\u5f0f\u9996\u6b21\u5b9e\u73b0\u4e86\u65f6\u95f4\u6548\u7387\u548c\u7a7a\u95f4\u6548\u7387\u517c\u5177\u7684\u5947\u5076\u6821\u9a8c\u548c\u540c\u4f59\u534f\u8bae\uff0c\u5177\u4f53\u4e3a $O(\\log^3 n)$ \u7684\u72b6\u6001\u6570\u548c $O(\\log^3 n)$ \u7684\u9759\u9ed8\u7a33\u5b9a\u65f6\u95f4\u3002\u8fd9\u8868\u660e\u8be5\u65b9\u6cd5\u662f\u8bbe\u8ba1\u9ad8\u6548\u3001\u901a\u7528\u3001\u9c81\u68d2\u7684\u591a\u9636\u6bb5\u7a33\u5b9a\u7fa4\u4f53\u534f\u8bae\u7684\u6709\u6548\u9014\u5f84\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u6743\u91cd\u7cfb\u7edf\u5728\u4e0d\u540c\u6570\u636e\u8868\u793a\uff08\u5982\u4e00\u5143\u548c\u4e8c\u5143\uff09\u4e4b\u95f4\u8f6c\u6362\u7684\u6f5c\u529b\uff0c\u5bf9\u7fa4\u4f53\u8ba1\u7b97\u4e2d\u7684\u5176\u4ed6\u95ee\u9898\uff08\u5982\u7fa4\u4f53\u89c4\u6a21\u7684\u8ba1\u7b97\u548c\u8868\u793a\uff09\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2512.20184", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20184", "abs": "https://arxiv.org/abs/2512.20184", "authors": ["Chaoyi Ruan", "Yiliang Wang", "Ziji Shi", "Jialin Li"], "title": "Reaching Agreement Among Reasoning LLM Agents", "comment": null, "summary": "Multi-agent systems have extended the capability of agentic AI. Instead of single inference passes, multiple agents perform collective reasoning to derive high quality answers. However, existing multi-agent orchestration relies on static heuristic workflows such as fixed loop limits and barrier synchronization. These ad-hoc approaches waste computational resources, incur high latency due to stragglers, and risk finalizing transient agreements. We argue that reliable multi-agent reasoning requires a formal foundation analogous to classical distributed consensus problem.\n  To that end, we propose a formal model of the multi-agent refinement problem. The model includes definitions of the correctness guarantees and formal semantics of agent reasoning. We then introduce Aegean, a consensus protocol designed for stochastic reasoning agents that solves multi-agent refinement. We implement the protocol in Aegean-Serve, a consensus-aware serving engine that performs incremental quorum detection across concurrent agent executions, enabling early termination when sufficient agents converge. Evaluation using four mathematical reasoning benchmarks shows that Aegean provides provable safety and liveness guarantees while reducing latency by 1.2--20$\\times$ compared to state-of-the-art baselines, maintaining answer quality within 2.5%. Consistent gains across both local GPU deployments and commercial API providers validate that consensus-based orchestration eliminates straggler delays without sacrificing correctness.", "AI": {"tldr": "\u5426\uff0c\u672c\u8bba\u6587\u5185\u5bb9\u4e0e DSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216 HLS \u65e0\u5173\u3002\u5b83\u4e3b\u8981\u6d89\u53ca\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u548c\u5171\u8bc6\u534f\u8bae\u3002\n\u603b\u7ed3\uff1a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u76ee\u524d\u7684\u7f16\u6392\u65b9\u6cd5\u5b58\u5728\u6548\u7387\u548c\u53ef\u9760\u6027\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u7cbe\u5316\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e86 Aegean \u8fd9\u4e00\u57fa\u4e8e\u5171\u8bc6\u7684\u534f\u8bae\u548c\u5b9e\u73b0\u5f15\u64ce Aegean-Serve\uff0c\u4ee5\u4fdd\u8bc1\u591a\u667a\u80fd\u4f53\u63a8\u7406\u7684\u53ef\u9760\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cAegean \u5728\u4fdd\u6301\u7b54\u6848\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u63a8\u7406\u5ef6\u8fdf\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u6027\u4e0e\u6d3b\u6027\u4fdd\u969c\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u7f16\u6392\u4f9d\u8d56\u4e8e\u9759\u6001\u542f\u53d1\u5f0f\u5de5\u4f5c\u6d41\uff08\u5982\u56fa\u5b9a\u7684\u5faa\u73af\u9650\u5236\u548c\u5c4f\u969c\u540c\u6b65\uff09\uff0c\u8fd9\u4e9b\u4e34\u65f6\u65b9\u6cd5\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\uff0c\u7531\u4e8e\u201c\u62d6\u6cb9\u74f6\u201d\uff08stragglers\uff09\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\uff0c\u5e76\u6709\u56fa\u5316\u6682\u65f6\u6027\u534f\u8bae\u7684\u98ce\u9669\u3002\u4f5c\u8005\u8ba4\u4e3a\u53ef\u9760\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u9700\u8981\u4e00\u4e2a\u7c7b\u4f3c\u4e8e\u7ecf\u5178\u5206\u5e03\u5f0f\u5171\u8bc6\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u57fa\u7840\u3002", "method": "\u672c\u6587\u9996\u5148\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u7cbe\u5316\u95ee\u9898\u7684\u5f62\u5f0f\u5316\u6a21\u578b\uff0c\u5305\u62ec\u6b63\u786e\u6027\u4fdd\u8bc1\u548c\u667a\u80fd\u4f53\u63a8\u7406\u7684\u5f62\u5f0f\u5316\u8bed\u4e49\u3002\u7136\u540e\uff0c\u4ecb\u7ecd\u4e86 Aegean \u8fd9\u4e00\u4e13\u4e3a\u968f\u673a\u63a8\u7406\u667a\u80fd\u4f53\u8bbe\u8ba1\u7684\u5171\u8bc6\u534f\u8bae\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cbe\u5316\u95ee\u9898\u3002\u6700\u540e\uff0c\u5728 Aegean-Serve \u4e2d\u5b9e\u73b0\u4e86\u8be5\u534f\u8bae\uff0c\u8be5\u670d\u52a1\u5f15\u64ce\u5177\u6709\u5171\u8bc6\u611f\u77e5\u80fd\u529b\uff0c\u5141\u8bb8\u5728\u5e76\u53d1\u667a\u80fd\u4f53\u6267\u884c\u4e2d\u8fdb\u884c\u589e\u91cf\u6cd5\u5b9a\u4eba\u6570\u68c0\u6d4b\uff0c\u4ece\u800c\u5b9e\u73b0\u65e9\u671f\u7ec8\u6b62\u3002", "result": "Aegean \u534f\u8bae\u5728\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u5b89\u5168\u6027\u548c\u6d3b\u6027\u4fdd\u8bc1\u7684\u540c\u65f6\uff0c\u5c06\u5ef6\u8fdf\u964d\u4f4e\u4e86 1.2 \u81f3 20 \u500d\uff0c\u800c\u7b54\u6848\u8d28\u91cf\u4ec5\u7ef4\u6301\u5728 2.5% \u7684\u635f\u5931\u8303\u56f4\u5185\u3002\u5728\u672c\u5730 GPU \u90e8\u7f72\u548c\u5546\u4e1a API \u63d0\u4f9b\u5546\u4e0a\u7684\u6301\u7eed\u6536\u76ca\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u5171\u8bc6\u7684\u7f16\u6392\u5728\u4e0d\u727a\u7272\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\u6d88\u9664\u4e86\u201c\u62d6\u6cb9\u74f6\u201d\u5ef6\u8fdf\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9700\u8981\u4e00\u4e2a\u6b63\u5f0f\u7684\u57fa\u7840\u6765\u4fdd\u8bc1\u53ef\u9760\u6027\uff0c\u800c Aegean \u6b63\u662f\u4e00\u4e2a\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cbe\u5316\u95ee\u9898\u7684\u5171\u8bc6\u534f\u8bae\u3002\u5b83\u901a\u8fc7\u589e\u91cf\u6cd5\u5b9a\u4eba\u6570\u68c0\u6d4b\u5b9e\u73b0\u4e86\u65e9\u671f\u7ec8\u6b62\uff0c\u5e76\u5728\u4fdd\u8bc1\u6b63\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u53ef\u9760\u7684\u591a\u667a\u80fd\u4f53\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u8303\u5f0f\u3002"}}
{"id": "2512.20210", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.20210", "abs": "https://arxiv.org/abs/2512.20210", "authors": ["Yinan Ni", "Xiao Yang", "Yuqi Tang", "Zhimin Qiu", "Chen Wang", "Tingzhou Yuan"], "title": "Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs", "comment": null, "summary": "The serverless computing paradigm offers compelling advantages for deploying Large Language Model (LLM) inference services, including elastic scaling and pay-per-use billing. However, serving multiple fine-tuned LLMs via Low-Rank Adaptation (LoRA) in serverless environments faces critical challenges: reactive adapter loading causes significant cold start latency, and frequent adapter swapping leads to severe GPU memory fragmentation. In this paper, we present Predictive-LoRA (P-LoRA), a proactive and fragmentation-aware serverless inference system for LoRA-based LLMs. P-LoRA introduces two key innovations: (1) a lightweight LSTM-based traffic predictor that forecasts adapter demand and proactively prefetches hot adapters from host memory to GPU, reducing cold start latency by up to 68%; and (2) a page-based adapter memory management mechanism inspired by operating system virtual memory, which keeps GPU memory utilization above 87% even under heterogeneous adapter ranks. We evaluate P-LoRA using production-like workloads derived from the Azure Functions trace. Experimental results demonstrate that P-LoRA achieves 1.52x higher throughput than S-LoRA while reducing the average Time-To-First-Token (TTFT) by 35% under high concurrency scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS\u3001DSL \u548c\u56fe\u5904\u7406\u4e2d\u7684 **\u65e0** \u76f4\u63a5\u5173\u8054\u3002\u5b83\u53ef\u80fd\u4e0e **\u7f16\u8bd1\u5668** \u9886\u57df\u7684\u4f18\u5316\u6280\u672f\u6709\u95f4\u63a5\u5173\u8054\uff0c\u56e0\u4e3a\u5b83\u6d89\u53ca\u7cfb\u7edf\u7ea7\u7684\u6027\u80fd\u4f18\u5316\u548c\u8d44\u6e90\u7ba1\u7406\u3002\u4e3b\u8981\u6d89\u53ca **LLM \u63a8\u7406\u670d\u52a1** \u7684\u6027\u80fd\u4f18\u5316\u548c **\u5185\u5b58\u7ba1\u7406** \u65b9\u9762\u7684\u5de5\u4f5c\u3002\n\n\u8be5\u8bba\u6587\u63d0\u51fa\u4e86 P-LoRA\uff0c\u4e00\u4e2a\u4e3b\u52a8\u4e14\u5bf9\u788e\u7247\u5316\u654f\u611f\u7684\u65e0\u670d\u52a1\u5668 LLM \u63a8\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u670d\u52a1\u57fa\u4e8e LoRA \u7684 LLM\u3002\u4e3a\u4e86\u89e3\u51b3\u51b7\u542f\u52a8\u5ef6\u8fdf\u548c GPU \u5185\u5b58\u788e\u7247\u5316\u95ee\u9898\uff0cP-LoRA \u5f15\u5165\u4e86\u57fa\u4e8e LSTM \u7684\u6d41\u91cf\u9884\u6d4b\u5668\u6765\u4e3b\u52a8\u9884\u53d6\u9002\u914d\u5668\uff08\u5c06\u51b7\u542f\u52a8\u5ef6\u8fdf\u964d\u4f4e 68%\uff09\uff0c\u4ee5\u53ca\u53d7\u64cd\u4f5c\u7cfb\u7edf\u865a\u62df\u5185\u5b58\u542f\u53d1\u7684\u5206\u9875\u5f0f\u9002\u914d\u5668\u5185\u5b58\u7ba1\u7406\u673a\u5236\uff08\u4fdd\u6301 GPU \u5185\u5b58\u5229\u7528\u7387\u5728 87% \u4ee5\u4e0a\uff09\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cP-LoRA \u5728\u9ad8\u5e76\u53d1\u4e0b\u6bd4 S-LoRA \u541e\u5410\u91cf\u63d0\u9ad8\u4e86 1.52 \u500d\uff0c\u5e73\u5747\u9996\u4e2a Token \u751f\u6210\u65f6\u95f4 (TTFT) \u964d\u4f4e\u4e86 35%\u3002", "motivation": "\u5728\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u90e8\u7f72\u57fa\u4e8e LoRA \u7684 LLM \u63a8\u7406\u670d\u52a1\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\n1. **\u51b7\u542f\u52a8\u5ef6\u8fdf\uff1a** \u54cd\u5e94\u5f0f\u5730\u52a0\u8f7d\u9002\u914d\u5668\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u51b7\u542f\u52a8\u5ef6\u8fdf\u3002\n2. **GPU \u5185\u5b58\u788e\u7247\u5316\uff1a** \u9891\u7e41\u7684\u9002\u914d\u5668\u4ea4\u6362\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684 GPU \u5185\u5b58\u788e\u7247\u5316\u3002", "method": "P-LoRA \u91c7\u7528\u4e86\u4e24\u9879\u5173\u952e\u521b\u65b0\u6280\u672f\uff1a\n1. **\u57fa\u4e8e LSTM \u7684\u8f7b\u91cf\u7ea7\u6d41\u91cf\u9884\u6d4b\u5668\uff1a** \u7528\u4e8e\u9884\u6d4b\u9002\u914d\u5668\u9700\u6c42\uff0c\u5e76\u4e3b\u52a8\u5730\u5c06\u70ed\u95e8\u9002\u914d\u5668\u4ece\u4e3b\u673a\u5185\u5b58\u9884\u53d6\u5230 GPU\uff0c\u4ee5\u51cf\u5c11\u51b7\u542f\u52a8\u5ef6\u8fdf\u3002\n2. **\u53d7\u64cd\u4f5c\u7cfb\u7edf\u865a\u62df\u5185\u5b58\u542f\u53d1\u7684\u5206\u9875\u5f0f\u9002\u914d\u5668\u5185\u5b58\u7ba1\u7406\u673a\u5236\uff1a** \u7528\u4e8e\u7ba1\u7406\u9002\u914d\u5668\u5185\u5b58\uff0c\u89e3\u51b3 GPU \u5185\u5b58\u788e\u7247\u5316\u95ee\u9898\uff0c\u5e76\u5728\u5f02\u6784\u9002\u914d\u5668\u79e9\u4e0b\u4fdd\u6301\u8f83\u9ad8\u7684 GPU \u5185\u5b58\u5229\u7528\u7387\u3002", "result": "P-LoRA \u53d6\u5f97\u4e86\u4ee5\u4e0b\u5b9e\u9a8c\u7ed3\u679c\uff1a\n1. \u51b7\u542f\u52a8\u5ef6\u8fdf\u6700\u591a\u964d\u4f4e\u4e86 **68%**\u3002\n2. \u5373\u4f7f\u5728\u5f02\u6784\u9002\u914d\u5668\u79e9\u4e0b\uff0cGPU \u5185\u5b58\u5229\u7528\u7387\u4fdd\u6301\u5728 **87%** \u4ee5\u4e0a\u3002\n3. \u541e\u5410\u91cf\u6bd4 S-LoRA \u9ad8 **1.52 \u500d**\u3002\n4. \u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\uff0c\u5e73\u5747\u9996\u4e2a Token \u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u964d\u4f4e\u4e86 **35%**\u3002", "conclusion": "P-LoRA \u901a\u8fc7\u5f15\u5165\u57fa\u4e8e LSTM \u7684\u6d41\u91cf\u9884\u6d4b\u5668\u548c\u53d7\u64cd\u4f5c\u7cfb\u7edf\u865a\u62df\u5185\u5b58\u542f\u53d1\u7684\u5206\u9875\u5f0f\u9002\u914d\u5668\u5185\u5b58\u7ba1\u7406\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5728\u65e0\u670d\u52a1\u5668\u73af\u5883\u4e2d\u90e8\u7f72 LoRA LLM \u63a8\u7406\u670d\u52a1\u65f6\u9762\u4e34\u7684\u51b7\u542f\u52a8\u5ef6\u8fdf\u548c GPU \u5185\u5b58\u788e\u7247\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cP-LoRA \u5728\u9ad8\u5e76\u53d1\u573a\u666f\u4e0b\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u5e76\u964d\u4f4e\u4e86\u5e73\u5747\u9996\u4e2a Token \u751f\u6210\u65f6\u95f4 (TTFT)\u3002"}}
