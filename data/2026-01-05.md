<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 3]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Efficient Algorithms for Adversarially Robust Approximate Nearest Neighbor Search](https://arxiv.org/abs/2601.00272)
*Alexandr Andoni,Themistoklis Haris,Esty Kelman,Krzysztof Onak*

Main category: cs.DS

TL;DR: This paper is related to graph processing (Locality-Sensitive Hashing is a common technique used to find approximate nearest neighbors, which can be viewed as processing a proximity graph of the data points, and the proposed algorithms operate on data structures to enhance search efficiency and robustness). The paper studies the Approximate Nearest Neighbor (ANN) problem under a strong adaptive adversary, proposing a sequence of increasingly strong algorithms for the high-dimensional regime ($d = \omega(\sqrt{Q})$) that leverage a novel connection between adaptive security and "fairness," and utilize a differentially private mechanism on a Locality-Sensitive Hashing (LSH) structure, leading to a new concentric-annuli LSH construction to break the inherent $\sqrt{n}$ query time barrier. For the low-dimensional regime ($d = O(\sqrt{Q})$), specialized algorithms achieving a strong "for-all" guarantee are proposed using novel metric covering constructions.


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于研究在强大的自适应性对手控制数据集和 $Q$ 个查询序列的场景下的近似最近邻 (ANN) 问题。目标是设计在自适应性攻击下仍能提供强有力保证的 ANN 算法，尤其是在高维和低维的不同情况下。具体来说，在高维情况下，如何通过新的方法（如公平性、差分隐私和新的 LSH 构造）来提高安全性、数据独立性能并克服查询时间障碍 ($\sqrt{n}$) 是一个重要驱动力。在低维情况下，目标是提供对每个可能的查询都正确的“for-all”保证，并简化现有的方法。

Method: 本文提出了在高维和低维设置下解决自适应性 ANN 问题的不同方法。在高维设置 ($d = \omega(\sqrt{Q})$) 下，方法包括：1. 建立自适应安全性与“公平性”之间的联系，利用公平 ANN 搜索以信息论保证隐藏内部随机性。2. 将搜索问题简化为鲁棒决策原语，并使用基于 Locality-Sensitive Hashing (LSH) 数据结构的差分隐私机制来求解，但面临 $\sqrt{n}$ 查询时间障碍。3. 提出一种新的同心圆环带状 LSH 构造，结合了公平性和差分隐私技术，以突破查询时间障碍。在低维设置 ($d = O(\sqrt{Q})$) 下，方法是提出专门的算法，通过引入新颖的度量覆盖构造来达到“for-all”保证，简化并改进了汉明和 $\ell_p$ 空间中现有的 ANN 方法。

Result: 本文的结果是针对高维和低维自适应性 ANN 问题提出了一系列算法：在高维设置中，提出了基于公平性、差分隐私机制和新型同心圆环带状 LSH 构造的算法，这些算法具有渐进式更强的安全保证，并且新方法突破了固有的 $\sqrt{n}$ 查询时间障碍。这一分析还引入了一种稳健地释放底层算法实例计时信息的新方法，并改进了现有公平 ANN 的结果。在低维设置中，提出了具有“for-all”保证的专门算法，通过新颖的度量覆盖构造，简化并改进了汉明和 $\ell_p$ 空间中 ANN 的现有方法。

Conclusion: 本文研究了在高维和低维情况下解决自适应性攻击下的近似最近邻 (ANN) 问题的算法。对于高维情况，作者提出了一系列具有渐进式更强保证的算法，利用公平性、差分隐私和同心圆环带状 LSH 构造来实现抗自适应性攻击和突破固有的查询时间障碍。在低维情况下，作者提出了具有“for-all”保证的专门算法，通过新颖的度量覆盖构造来改进现有的 ANN 方法。核心贡献在于将公平性与自适应安全性联系起来，并在 LSH 结构上应用差分隐私机制，以及提出新的同心圆环带状 LSH 构造。

Abstract: We study the Approximate Nearest Neighbor (ANN) problem under a powerful adaptive adversary that controls both the dataset and a sequence of $Q$ queries.
  Primarily, for the high-dimensional regime of $d = ω(\sqrt{Q})$, we introduce a sequence of algorithms with progressively stronger guarantees. We first establish a novel connection between adaptive security and \textit{fairness}, leveraging fair ANN search to hide internal randomness from the adversary with information-theoretic guarantees. To achieve data-independent performance, we then reduce the search problem to a robust decision primitive, solved using a differentially private mechanism on a Locality-Sensitive Hashing (LSH) data structure. This approach, however, faces an inherent $\sqrt{n}$ query time barrier. To break the barrier, we propose a novel concentric-annuli LSH construction that synthesizes these fairness and differential privacy techniques. The analysis introduces a new method for robustly releasing timing information from the underlying algorithm instances and, as a corollary, also improves existing results for fair ANN.
  In addition, for the low-dimensional regime $d = O(\sqrt{Q})$, we propose specialized algorithms that provide a strong ``for-all'' guarantee: correctness on \textit{every} possible query with high probability. We introduce novel metric covering constructions that simplify and improve prior approaches for ANN in Hamming and $\ell_p$ spaces.

</details>


### [2] [Deterministic Coreset for Lp Subspace](https://arxiv.org/abs/2601.00361)
*Rachit Chhaya,Anirban Dasgupta,Dan Feldman,Supratim Shit*

Main category: cs.DS

TL;DR: This paper is not directly related to DSL, graph processing, MLIR, compiler, or HLS (it is mainly focused on randomized algorithms, data compression/sketching, and $\ell_p$ optimization).
本文提出了首个用于构建确定性 $\ell_p$ 子空间嵌入 $\varepsilon$-coreset 的迭代算法。该算法保证了误差的确定性上下界，并成功将 coreset 的大小优化至 $O\left(\frac{d^{\max\{1,p/2\}}}{\varepsilon^{2}}\right)$，去除了长期存在的对数因子，达到了渐近最优的界限。该 coreset 可用于确定性地近似求解 $\ell_p$ 回归问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 coreset 通常提供概率性保证，但在某些应用中需要确定性保证。特别地，在 $\ell_p$ 子空间嵌入问题中，构建一个具有确定性保证且大小渐近最优的 $\varepsilon$-coreset 并去除 coreset 大小中的对数因子是一个长期存在的开放问题。

Method: 本文提出了一种迭代算法来构建 $\varepsilon$-coreset。该算法在每次迭代中都确保保留的集合上的损失函数与原始数据集上的损失函数在适当的缩放后有上下界，从而保证了 $\ell_p$ 子空间嵌入的确定性。所得到的 coreset 是原始矩阵 $\mathbf{X}$ 行的一个加权子集。

Result: 该算法在 $O(\mathrm{poly}(n,d,\varepsilon^{-1}))$ 时间内，返回了一个确定性的 $\varepsilon$-coreset，用于 $\ell_p$ 子空间嵌入。该 coreset 的大小为 $O\left(\frac{d^{\max\{1,p/2\}}}{\varepsilon^{2}}\right)$，成功去除了 coreset 大小中的对数因子。这个大小与下界紧密匹配，因此所得到的 coreset 是渐近最优的。此外，该 coreset 还可以应用于确定性地近似求解 $\ell_p$ 回归问题。

Conclusion: 本文首次提出了一种用于构建保证确定性 $\ell_p$ 子空间嵌入的 $\varepsilon$-coreset 的迭代算法。该算法通过控制每一步的误差，实现了去除对数因子的 coreset 大小，达到了渐近最优的界限。这不仅解决了 $\ell_p$ 子空间嵌入 coreset 大小的一个长期存在的问题，还为 $\ell_p$ 回归问题提供了一个确定性近似求解的应用。

Abstract: We introduce the first iterative algorithm for constructing a $\varepsilon$-coreset that guarantees deterministic $\ell_p$ subspace embedding for any $p \in [1,\infty)$ and any $\varepsilon > 0$. For a given full rank matrix $\mathbf{X} \in \mathbb{R}^{n \times d}$ where $n \gg d$, $\mathbf{X}' \in \mathbb{R}^{m \times d}$ is an $(\varepsilon,\ell_p)$-subspace embedding of $\mathbf{X}$, if for every $\mathbf{q} \in \mathbb{R}^d$, $(1-\varepsilon)\|\mathbf{Xq}\|_{p}^{p} \leq \|\mathbf{X'q}\|_{p}^{p} \leq (1+\varepsilon)\|\mathbf{Xq}\|_{p}^{p}$. Specifically, in this paper, $\mathbf{X}'$ is a weighted subset of rows of $\mathbf{X}$ which is commonly known in the literature as a coreset. In every iteration, the algorithm ensures that the loss on the maintained set is upper and lower bounded by the loss on the original dataset with appropriate scalings. So, unlike typical coreset guarantees, due to bounded loss, our coreset gives a deterministic guarantee for the $\ell_p$ subspace embedding. For an error parameter $\varepsilon$, our algorithm takes $O(\mathrm{poly}(n,d,\varepsilon^{-1}))$ time and returns a deterministic $\varepsilon$-coreset, for $\ell_p$ subspace embedding whose size is $O\left(\frac{d^{\max\{1,p/2\}}}{\varepsilon^{2}}\right)$. Here, we remove the $\log$ factors in the coreset size, which had been a long-standing open problem. Our coresets are optimal as they are tight with the lower bound. As an application, our coreset can also be used for approximately solving the $\ell_p$ regression problem in a deterministic manner.

</details>


### [3] [Mind the Gap. Doubling Constant Parametrization of Weighted Problems: TSP, Max-Cut, and More](https://arxiv.org/abs/2601.00768)
*Mihail Stoian*

Main category: cs.DS

TL;DR: 该论文与图处理（Graph Processing）（因为它涉及 TSP 和 Weighted Max-Cut 等图论问题）相关。

**太长不看版（TLDR）：**在硬带权问题上，现有方法复用无权算法会导致运行时间上的伪多项式因子。本文提出了一种新的元算法，通过利用构造性 Freiman 定理将具有“小加倍集”的权重实例转换成多项式有界的整数，从而使得多个（min, +）和（max, +）半环上的 NP-难问题（如 TSP, Weighted Max-Cut）的运行时间复杂度能与其无权版本成比例，避免了伪多项式运行时间的限制。


<details>
  <summary>Details</summary>
Motivation: 尽管在无权版本的困难问题上取得了显著的加速成果，但硬带权问题（hard weighted problems）在解决速度上仍然难以超越其教科书式解法，抵抗超多项式改进。现有将无权版本算法复用于带权问题的方法，唯一途径是采用输入权重的多项式嵌入，但这会引入一个“伪多项式因子（pseudo-polynomial factor）”到运行时间中，对于任意权重实例而言是不切实际的。因此，研究的动机在于找到一种新的方法，可以在不引入伪多项式运行时间的情况下，将无权版本问题的算法成功复用于带权版本的问题。

Method: 本文提出了一种“元算法（meta-algorithm）”来解决带权问题。这个元算法的核心在于，利用 Randolph 和 Węgrzycki 在 ESA 2024 上提出的构造性 Freiman 定理，将具有“小加倍集（small doubling）”特性的输入权重转换为多项式有界的整数。在这一转换完成之后，再应用传统的“多项式嵌入（polynomial embedding）”方法，从而将带权问题的求解问题转化为对无权版本算法的复用，并避免了伪多项式运行时间的引入。

Result: 本文的结果显示，几种著名的、在 $(\min, +)$ 和 $(\max, +)$ 半环上操作的 NP-难问题（如 TSP, Weighted Max-Cut, 和 Edge-Weighted $k$-Clique），当其输入权重集具有“小加倍集（small doubling）”特性时，其时间复杂度与它们的无权版本成比例。通过引入一个新的元算法，该算法使用构造性的 Freiman 定理将输入权重有效地转换为多项式有界整数，从而实现了这一目标，有效地避免了现有“多项式嵌入”方法带来的伪多项式运行时间因子。

Conclusion: 本文介绍了一种新的元算法，用于解决具有小加倍集（small doubling）权重的（min, +）和（max, +）半环上的NP-难问题，例如旅行商问题（TSP）、带权最大割（Weighted Max-Cut）和边带权 $k$-团问题（Edge-Weighted $k$-Clique）。这种方法通过利用 Randolph 和 Węgrzycki 最近的构造性 Freiman 定理，将输入权重转换为多项式有界的整数，从而在应用多项式嵌入之前有效地处理这些权重，使得带权问题的运行时间复杂度与它们的无权版本成比例。这一突破性进展为克服现有方法在任意权重实例上运行时间带来的伪多项式因子限制提供了新的途径。

Abstract: Despite much research, hard weighted problems still resist super-polynomial improvements over their textbook solution. On the other hand, the unweighted versions of these problems have recently witnessed the sought-after speedups. Currently, the only way to repurpose the algorithm of the unweighted version for the weighted version is to employ a polynomial embedding of the input weights. This, however, introduces a pseudo-polynomial factor into the running time, which becomes impractical for arbitrarily weighted instances.
  In this paper, we introduce a new way to repurpose the algorithm of the unweighted problem. Specifically, we show that the time complexity of several well-known NP-hard problems operating over the $(\min, +)$ and $(\max, +)$ semirings, such as TSP, Weighted Max-Cut, and Edge-Weighted $k$-Clique, is proportional to that of their unweighted versions when the set of input weights has small doubling. We achieve this by a meta-algorithm that converts the input weights into polynomially bounded integers using the recent constructive Freiman's theorem by Randolph and Węgrzycki [ESA 2024] before applying the polynomial embedding.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [Word Frequency Counting Based on Serverless MapReduce](https://arxiv.org/abs/2601.00380)
*Hanzhe Li,Bingchen Lin,Mengyuan Xu*

Main category: cs.DC

TL;DR: 该论文与编译器相关，它涉及到 MapReduce 编程模型在无服务器计算平台上的应用和优化，属于计算效率和模型优化范畴。/ 太长不看：本文结合无服务器计算和 MapReduce 模型，研究了在无服务器平台上执行词频统计任务时，Map 和 Reduce 函数数量对执行时间与效率的影响，并通过实验发现增加函数数量可以提高效率，推断出存在最优化的函数数量组合。


<details>
  <summary>Details</summary>
Motivation: 随着对高性能和高效率计算需求的增长，云计算尤其是无服务器计算成为研究热点。同时，MapReduce作为流行的工业界大数据处理模型被广泛应用。本文的动机是结合Function as a Service的无服务器框架和MapReduce的高并发性和鲁棒性，以减少词频统计任务的执行时间并提高效率，并通过实验找出最优数量的Map和Reduce函数。

Method: 本文方法是基于无服务器计算平台上的MapReduce编程模型，通过实验来确定特定任务的最优Map函数和Reduce函数的数量。具体来说，实验对比了不同数量的Map和Reduce函数对相同工作负载的词频统计任务在执行时间上的影响和效率上的提升。

Result: 实验结果表明，在相同的工作负载下，随着Map函数和Reduce函数数量的增加，执行时间以不同的速率减少，程序的整体效率得到提高。研究推断存在最优数量的Map和Reduce函数。

Conclusion: 本文验证了在无服务器计算平台上，MapReduce编程模型中Map和Reduce函数的数量对词频统计任务执行效率的影响，并推断出存在最优数量的Map和Reduce函数组合，可以帮助企业和程序员找到最优化的解决方案。

Abstract: With the increasing demand for high-performance and high-efficiency computing, cloud computing, especially serverless computing, has gradually become a research hotspot in recent years, attracting numerous research attention. Meanwhile, MapReduce, which is a popular big data processing model in the industry, has been widely applied in various fields. Inspired by the serverless framework of Function as a Service and the high concurrency and robustness of MapReduce programming model, this paper focus on combining them to reduce the time span and increase the efficiency when executing the word frequency counting task. In this case, the paper use a MapReduce programming model based on a serverless computing platform to figure out the most optimized number of Map functions and Reduce functions for a particular task. For the same amount of workload, extensive experiments show both execution time reduces and the overall efficiency of the program improves at different rates as the number of map functions and reduce functions increases. This paper suppose the discovery of the most optimized number of map and reduce functions can help cooperations and programmers figure out the most optimized solutions.

</details>


### [5] [Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving](https://arxiv.org/abs/2601.00397)
*Amey Agrawal,Mayank Yadav,Sukrit Kumar,Anirudha Agrawal,Garv Ghai,Souradeep Bera,Elton Pinto,Sirish Gambhira,Mohammad Adain,Kasra Sohrab,Chus Antonanzas,Alexey Tumanov*

Main category: cs.DC

TL;DR: 该论文与编译器和图处理无关，但是涉及到**LLM服务**和**GPU**，可以归类为**系统/性能建模**领域。
Revati是一种时间扭曲模拟器，可以直接在不使用物理GPU的情况下，运行并快速评估真实的LLM服务系统（如vLLM和SGLang）的性能。它通过拦截CUDA调用、虚拟化设备管理和利用预测的内核持续时间进行时间跳跃来加速模拟，同时通过同步协议保持因果关系，实现了低于5%的预测误差和比真实执行快5-17倍的速度。


<details>
  <summary>Details</summary>
Motivation: 高效部署大型语言模型（LLMs）需要测试数百种服务配置，但在GPU集群上评估每一种配置既耗时又昂贵。离散事件模拟器虽然更快、更便宜，但它们要求重新实现服务系统的控制逻辑，随着框架的演进，这成为一个沉重的负担。因此，需要一种既能快速、低成本评估性能，又能复用现有服务系统代码的解决方案。

Method: Revati通过时间扭曲仿真来运行真实的后端服务系统代码。其核心方法包括：1) 拦截CUDA API调用以虚拟化设备管理，使得服务框架无需物理GPU即可运行。2) 不执行GPU内核，而是通过预测的内核持续时间进行时间跳跃（time jumps），快速推进虚拟时间。3) 提出了一种协调协议，用以在分布式进程中同步这些时间跳跃，同时保证因果关系（causality）。

Result: Revati在vLLM和SGLang这两个框架上，跨多个模型和并行配置的预测误差低于5%。同时，它比真实的GPU执行速度快5到17倍。

Conclusion: Revati是一个时间扭曲仿真器，它通过直接执行真实的后端服务系统代码，实现了对LLM服务性能的快速、低成本建模。它在保持高精度的同时，显著提高了模拟速度，为LLM服务的部署和配置优化提供了一个有价值的工具。

Abstract: Deploying LLMs efficiently requires testing hundreds of serving configurations, but evaluating each one on a GPU cluster takes hours and costs thousands of dollars. Discrete-event simulators are faster and cheaper, but they require re-implementing the serving system's control logic -- a burden that compounds as frameworks evolve.
  We present Revati, a time-warp emulator that enables performance modeling by directly executing real serving system code at simulation-like speed. The system intercepts CUDA API calls to virtualize device management, allowing serving frameworks to run without physical GPUs. Instead of executing GPU kernels, it performs time jumps -- fast-forwarding virtual time by predicted kernel durations. We propose a coordination protocol that synchronizes these jumps across distributed processes while preserving causality. On vLLM and SGLang, Revati achieves less than 5% prediction error across multiple models and parallelism configurations, while running 5-17x faster than real GPU execution.

</details>


### [6] [Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure](https://arxiv.org/abs/2601.00530)
*Ravi Teja Pagidoju*

Main category: cs.DC

TL;DR: 否，该论文与DSL、图处理、MLIR、编译器或HLS不相关。本文提供了对Google Cloud Platform (GCP)和Microsoft Azure上零售销售时点系统（POS）工作负载性能和成本的首次全面、代码驱动的比较。研究使用实时API和开源基准测试代码，展示了GCP在响应时间上的优势和Azure在成本效益上的更高表现，并提供了一个框架帮助商家选择云POS方案。


<details>
  <summary>Details</summary>
Motivation: 尽管针对零售工作负载的平台特定性能的实证研究很少，但零售业的数字化转型加速了基于云的销售时点系统（POS）的采用。因此，有必要对POS工作负载在不同主流云平台上的性能和成本进行系统、可重复的比较，以帮助零售商做出明智的决策。

Method: 本文提出了一种系统、可重复的POS工作负载部署比较方法，在Google Cloud Platform (GCP)和Microsoft Azure上进行。方法使用实时API端点和开源基准测试代码。使用免费层级云资源，提供了一种透明的方法来评估POS工作负载，可供小型零售商和研究人员使用。该方法测量了响应延迟、吞吐量和可扩展性等重要性能指标，并根据实际资源使用和当前公共云定价估算运营成本。所有表格和图表均直接由代码输出生成，确保实验数据和结果的一致性。

Result: 分析结果显示，在基线负载下，GCP实现了23.0%的更快响应时间；而Azure在稳态操作中显示出71.9%更高的成本效益。研究还深入分析了导致这些性能和成本差异的架构组件。

Conclusion: 本研究建立了一个强大、开放的零售云应用基准测试方法，并首次对领先云平台上的销售时点系统（POS）独特工作负载进行了全面的、代码驱动的比较。研究表明，在基线负载下，GCP实现了23.0%的更短响应时间，而Azure在稳态操作中显示出71.9%更高的成本效益。研究还探讨了导致这些差异的架构组件，并为考虑采用云POS的商家提供了一个有用的框架。

Abstract: Althoughthereislittleempiricalresearchonplatform-specific performance for retail workloads, the digital transformation of the retail industry has accelerated the adoption of cloud-based Point-of-Sale (POS) systems. This paper presents a systematic, repeatable comparison of POS workload deployments on Google Cloud Platform (GCP) and Microsoft Azure using real-time API endpoints and open-source benchmarking code. Using free-tier cloud resources, we offer a transparent methodology for POS workload evaluation that small retailers and researchers can use. Our approach measures important performance metrics like response latency, throughput, and scalability while estimating operational costs based on actual resource usage and current public cloud pricing because there is no direct billing under free-tier usage. All the tables and figures in this study are generated directly from code outputs, ensuring that the experimental data and the reported results are consistent. Our analysis shows that GCP achieves 23.0% faster response times at baseline load, while Azure shows 71.9% higher cost efficiency for steady-state operations. We look at the architectural components that lead to these differences and provide a helpful framework for merchants considering cloud point-of-sale implementation. This study establishes a strong, open benchmarking methodology for retail cloud applications and offers the first comprehensive, code-driven comparison of workloads unique to point-of-sale systems across leading cloud platforms.

</details>


### [7] [FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding](https://arxiv.org/abs/2601.00644)
*Yuchen Li,Rui Kong,Zhonghao Lyu,Qiyang Li,Xinran Chen,Hengyi Cai,Lingyong Yan,Shuaiqiang Wang,Jiashu Zhao,Guangxu Zhu,Linghe Kong,Guihai Chen,Haoyi Xiong,Dawei Yin*

Main category: cs.DC

TL;DR: 该论文与编译器、HLS、MLIR、DSL或图处理不直接相关，但它与**编译器**领域有间接关系，因为它涉及**大规模语言模型（LLMs）的部署和推理优化**，这通常需要底层编译和优化技术来提高边缘设备的性能。
FlexSpec是一种通信高效的协同推理框架，专为不断演进的边缘-云系统设计，它通过引入一个共享backbone架构来解耦边缘草稿模型和云端目标模型，从而允许静态的边缘部署兼容动态的云端更新，大幅减少了模型同步带来的通信开销；同时，它还开发了一种信道感知自适应推测机制，根据实时无线条件和能耗预算动态调整推测长度，实验证明其在推理效率上优于传统的推测解码方法。


<details>
  <summary>Details</summary>
Motivation: 现有的在移动和边缘计算环境中部署大型语言模型（LLMs）受到有限的设备资源、稀缺的无线带宽以及频繁的模型演进的限制。尽管使用推测解码（SD）的边缘-云协同推理可以减少端到端延迟，但现有的框架依赖于草稿模型和目标模型之间的紧密耦合，导致重复的模型同步引入过多的通信开销，最终限制了SD在边缘环境中的可扩展性。

Method: FlexSpec的核心方法是基于共享backbone架构（shared-backbone architecture），它允许一个单一且静态的边缘草稿模型与一系列不断演进的云端目标模型保持兼容，从而解耦了边缘部署和云端模型更新。在此基础上，FlexSpec开发了一种信道感知自适应推测机制（channel-aware adaptive speculation mechanism），根据实时信道状态信息和设备能耗预算，动态调整推测草稿长度。

Result: FlexSpec在推理效率方面表现出优于传统推测解码（SD）方法的性能。其设计消除了对边缘侧的重复训练或模型下载的需求，大幅减少了通信和维护成本。信道感知自适应推测机制有效适应了时变的无线条件和异构的设备限制。

Conclusion: FlexSpec通过引入共享backbone架构，有效地解耦了边缘和云端模型，解决了现有SD在边缘环境中因模型紧密耦合导致的通信开销大、可扩展性差的问题，并通过自适应推测机制进一步优化了性能。实验证明，FlexSpec在推理效率方面优于传统SD方法。

Abstract: Deploying large language models (LLMs) in mobile and edge computing environments is constrained by limited on-device resources, scarce wireless bandwidth, and frequent model evolution. Although edge-cloud collaborative inference with speculative decoding (SD) can reduce end-to-end latency by executing a lightweight draft model at the edge and verifying it with a cloud-side target model, existing frameworks fundamentally rely on tight coupling between the two models. Consequently, repeated model synchronization introduces excessive communication overhead, increasing end-to-end latency, and ultimately limiting the scalability of SD in edge environments. To address these limitations, we propose FlexSpec, a communication-efficient collaborative inference framework tailored for evolving edge-cloud systems. The core design of FlexSpec is a shared-backbone architecture that allows a single and static edge-side draft model to remain compatible with a large family of evolving cloud-side target models. By decoupling edge deployment from cloud-side model updates, FlexSpec eliminates the need for edge-side retraining or repeated model downloads, substantially reducing communication and maintenance costs. Furthermore, to accommodate time-varying wireless conditions and heterogeneous device constraints, we develop a channel-aware adaptive speculation mechanism that dynamically adjusts the speculative draft length based on real-time channel state information and device energy budgets. Extensive experiments demonstrate that FlexSpec achieves superior performance compared to conventional SD approaches in terms of inference efficiency.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [8] [Enhancing Reliability of STT-MRAM Caches by Eliminating Read Disturbance Accumulation](https://arxiv.org/abs/2601.00450)
*Elham Cheshmikhani,Hamed Farbeh,Hossein Asadi*

Main category: cs.AR

TL;DR: This content has not passed the compliance test and has been hidden.


<details>
  <summary>Details</summary>
Motivation: STT-MRAM 作为 SRAM 的替代品具有高密度、可扩展性、近零泄漏功耗和非易失性等优点，但其可靠性受到高读取干扰错误率的威胁。传统上虽然使用 ECC 来克服读取干扰，但在现代处理器中，为了最小化访问时间，会并行读取目标缓存集中的所有块进行标签比较，而只有被请求的块才进行 ECC 检查。这种在未被请求的块上进行的额外读取，如果没有 ECC 检查，会导致读取干扰错误累积，从而严重降低了缓存的可靠性。因此，需要一种机制来解决并行访问带来的读取干扰累积问题。

Method: 首先，介绍并公式化了读取干扰累积现象，揭示了传统并行访问缓存块会导致错误率显著增加。然后，提出了一种名为“读取错误累积阻止器缓存”（REAP-cache）的简单而有效的方案，该方案旨在完全消除读取干扰累积，同时不影响缓存性能。

Result: 所提出的 REAP-cache 方案能够将缓存的平均无故障时间（MTTF）延长 171 倍，而缓存面积增加小于 1%，能耗增加仅为 2.7%。这表明 REAP-cache 可以在不显著增加开销的情况下，极大地改善 STT-MRAM 缓存的可靠性。

Conclusion: 本文分析了并行缓存块访问在 STT-MRAM 缓存中导致的读取干扰累积现象及其对可靠性的影响。通过提出的 REAP-cache 方案，可以完全消除这种累积，从而显著提高缓存的平均无故障时间（MTTF），同时只带来极小的面积和能耗开销。

Abstract: Spin-Transfer Torque Magnetic RAM (STT-MRAM) as one of the most promising replacements for SRAMs in on-chip cache memories benefits from higher density and scalability, near-zero leakage power, and non-volatility, but its reliability is threatened by high read disturbance error rate. Error-Correcting Codes (ECCs) are conventionally suggested to overcome the read disturbance errors in STT-MRAM caches. By employing aggressive ECCs and checking out a cache block on every read access, a high level of cache reliability is achieved. However, to minimize the cache access time in modern processors, all blocks in the target cache set are simultaneously read in parallel for tags comparison operation and only the requested block is sent out, if any, after checking its ECC. These extra cache block reads without checking their ECCs until requesting the blocks by the processor cause the accumulation of read disturbance error, which significantly degrade the cache reliability. In this paper, we first introduce and formulate the read disturbance accumulation phenomenon and reveal that this accumulation due to conventional parallel accesses of cache blocks significantly increases the cache error rate. Then, we propose a simple yet effective scheme, so-called Read Error Accumulation Preventer cache (REAP-cache), to completely eliminate the accumulation of read disturbances without compromising the cache performance. Our evaluations show that the proposed REAP-cache extends the cache Mean Time To Failure (MTTF) by 171x, while increases the cache area by less than 1% and energy consumption by only 2.7%.

</details>


### [9] [ROBIN: Incremental Oblique Interleaved ECC for Reliability Improvement in STT-MRAM Caches](https://arxiv.org/abs/2601.00456)
*Elham Cheshmikhani,Hamed Farbeh,Hossein Asadi*

Main category: cs.AR

TL;DR: **该论文与以下领域相关**：
* 编译器：否
* HLS：否
* MLIR：否
* DSL：否
* 图处理：否
该论文主要关注的是内存技术（STT-MRAM）及其错误纠正码（ECC）设计，与上述领域无直接关联。

**太长不看（tldr）**：
STT-MRAM作为片上缓存很有潜力，但错误率高。传统ECC因数据相关错误模式而效率低下，导致缓存错误率增加了151.7%。本文提出了一种名为ROBIN的高效ECC配置，能将缓存错误率降低28.6倍以上。


<details>
  <summary>Details</summary>
Motivation: STT-MRAM作为片上缓存的SRAM替代品很有前景，但其高错误率是一个主要的限制因素。传统的错误纠正码（ECC）由于数据相关的错误模式而效率下降，需要更高效的ECC配置来提高纠错能力，降低缓存错误率。

Method: 首先，对传统ECC在STT-MRAM中因数据相关错误模式而效率低下的问题进行了全面的分析。然后，提出了一种名为ROBIN的高效ECC配置，以提高纠错能力。

Result: 评估显示，传统ECC的低效使缓存错误率平均增加了151.7%，而ROBIN将这一数值降低了28.6倍以上。这表明ROBIN显著提高了STT-MRAM的错误纠正能力。

Conclusion: 本文分析了STT-MRAM中传统ECC因数据相关错误模式而效率低下的问题，并提出了一种名为ROBIN的高效ECC配置，显著提高了错误纠正能力，从而降低了缓存错误率。

Abstract: Spin-Transfer Torque Magnetic RAM} (STT-MRAM) is a promising alternative for SRAMs in on-chip cache memories. Besides all its advantages, high error rate in STT-MRAM is a major limiting factor for on-chip cache memories. In this paper, we first present a comprehensive analysis that reveals that the conventional Error-Correcting Codes (ECCs) lose their efficiency due to data-dependent error patterns, and then propose an efficient ECC configuration, so-called ROBIN, to improve the correction capability. The evaluations show that the inefficiency of conventional ECC increases the cache error rate by an average of 151.7% while ROBIN reduces this value by more than 28.6x.

</details>
