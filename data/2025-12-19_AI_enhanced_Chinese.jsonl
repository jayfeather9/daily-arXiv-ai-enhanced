{"id": "2512.15981", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.15981", "abs": "https://arxiv.org/abs/2512.15981", "authors": ["Bardiya Aryanfard", "Monika Henzinger", "David Saulpic", "A. R. Sricharan"], "title": "Improved Lower Bounds for Privacy under Continual Release", "comment": null, "summary": "We study the problem of continually releasing statistics of an evolving dataset under differential privacy. In the event-level setting, we show the first polynomial lower bounds on the additive error for insertions-only graph problems such as maximum matching, degree histogram and $k$-core. This is an exponential improvement on the polylogarithmic lower bounds of Fichtenberger et al.[ESA 2021] for the former two problems, and are the first continual release lower bounds for the latter. Our results run counter to the intuition that the difference between insertions-only vs fully dynamic updates causes the gap between polylogarithmic and polynomial additive error. We show that for maximum matching and $k$-core, allowing small multiplicative approximations is what brings the additive error down to polylogarithmic.\n  Beyond graph problems, our techniques also show that polynomial additive error is unavoidable for Simultaneous Norm Estimation in the insertions-only setting. When multiplicative approximations are allowed, we circumvent this lower bound by giving the first continual mechanism with polylogarithmic additive error under $(1+\u03b6)$ multiplicative approximations, for $\u03b6>0$, for estimating all monotone symmetric norms simultaneously.\n  In the item-level setting, we show polynomial lower bounds on the product of the multiplicative and the additive error of continual mechanisms for a large range of graph problems. To the best of our knowledge, these are the first lower bounds for any differentially private continual release mechanism with multiplicative error. To obtain this, we prove a new lower bound on the product of multiplicative and additive error for 1-Way-Marginals, from which we reduce to continual graph problems. This generalizes the lower bounds of Hardt and Talwar[STOC 2010] and Bun et al.[STOC 2014] on the additive error for mechanisms with no multiplicative error.", "AI": {"tldr": "\u6d89\u53ca\u9886\u57df\uff1a\u672c\u6587\u6d89\u53ca\u5dee\u5206\u9690\u79c1\uff08Differential Privacy\uff09\u3001\u56fe\u5904\u7406\uff08Graph Processing\uff09\u3001\u6570\u636e\u6d41\u7b97\u6cd5\uff08Streaming Algorithms\uff09\u548c\u7b97\u6cd5\u4e0b\u754c\u8bc1\u660e\uff08Lower Bounds\uff09\u3002\u603b\u7ed3\uff1a\u672c\u6587\u7814\u7a76\u4e86\u5dee\u5206\u9690\u79c1\u4e0b\u6301\u7eed\u53d1\u5e03\u6f14\u53d8\u6570\u636e\u96c6\u7edf\u8ba1\u4fe1\u606f\u7684\u673a\u5236\u7684\u8bef\u5dee\u4e0b\u754c\u3002\u5728\u4e8b\u4ef6\u7ea7\u8bbe\u7f6e\u4e2d\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u9488\u5bf9\u4ec5\u63d2\u5165\u56fe\u95ee\u9898\uff08\u5982\u6700\u5927\u5339\u914d\u3001$k$-\u6838\u7b49\uff09\u7684\u52a0\u6027\u8bef\u5dee\u5b58\u5728\u7b2c\u4e00\u4e2a\u591a\u9879\u5f0f\u4e0b\u754c\uff0c\u76f8\u8f83\u4e8e\u5148\u524d\u7ed3\u679c\u662f\u6307\u6570\u7ea7\u6539\u8fdb\u3002\u7814\u7a76\u8fd8\u8868\u660e\uff0c\u5141\u8bb8\u5c0f\u7684\u4e58\u6027\u8fd1\u4f3c\u80fd\u663e\u8457\u964d\u4f4e\u8bef\u5dee\u3002\u5728\u9879\u76ee\u7ea7\u8bbe\u7f6e\u4e2d\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u5927\u91cf\u56fe\u95ee\u9898\u7684\u6301\u7eed\u673a\u5236\u7684\u4e58\u6027\u8bef\u5dee\u548c\u52a0\u6027\u8bef\u5dee\u7684\u4e58\u79ef\u5b58\u5728\u591a\u9879\u5f0f\u4e0b\u754c\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u7406\u89e3\u6301\u7eed\u8bbe\u7f6e\u4e2d\u4fdd\u8bc1\u5dee\u5206\u9690\u79c1\u6240\u9700\u7684\u5185\u5728\u8bef\u5dee\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u7814\u7a76\u5728\u5dee\u5206\u9690\u79c1\uff08DP\uff09\u7ea6\u675f\u4e0b\u6301\u7eed\u53d1\u5e03\u4e0d\u65ad\u6f14\u53d8\u6570\u636e\u96c6\u7edf\u8ba1\u4fe1\u606f\u7684\u673a\u5236\u7684\u8bef\u5dee\u3002\u7279\u522b\u662f\u5728\u56fe\u6570\u636e\u548c\u6d41\u6570\u636e\u573a\u666f\u4e2d\uff0c\u6301\u7eed\u53d1\u5e03\u673a\u5236\u901a\u5e38\u9700\u8981\u6743\u8861\u9690\u79c1\u3001\u5b9e\u7528\u6027\u548c\u6548\u7387\u3002\u4f5c\u8005\u53d1\u73b0\u5f53\u524d\u5173\u4e8e\u4ec5\u63d2\u5165\uff08insertions-only\uff09\u56fe\u95ee\u9898\u7684\u6301\u7eed\u53d1\u5e03\u673a\u5236\u7684\u8bef\u5dee\u754c\u9650\u5b58\u5728\u4e0d\u8db3\uff08\u4f8b\u5982Fichtenberger\u7b49\u4eba\u7684\u591a\u5bf9\u6570\u4e0b\u754c\uff09\uff0c\u5e76\u671f\u671b\u901a\u8fc7\u8bc1\u660e\u66f4\u5f3a\u7684\u591a\u9879\u5f0f\u4e0b\u754c\u6765\u66f4\u597d\u5730\u7406\u89e3\u5728\u8fd9\u79cd\u5177\u6709\u5c40\u90e8\u9690\u79c1\u9650\u5236\u7684\u6d41\u6570\u636e\u8bbe\u7f6e\u4e2d\uff0c\u5c24\u5176\u662f\u56fe\u95ee\u9898\u4e0a\uff0c\u4fdd\u8bc1\u5dee\u5206\u9690\u79c1\u6240\u9700\u7684\u5185\u5728\u8bef\u5dee\u3002\u4f5c\u8005\u8fd8\u5e0c\u671b\u63a2\u7d22\u4e58\u6027\u8fd1\u4f3c\u5bf9\u4e8e\u964d\u4f4e\u8bef\u5dee\u754c\u9650\u7684\u4f5c\u7528\u3002", "method": "\u672c\u6587\u4e3b\u8981\u901a\u8fc7\u8bc1\u660e\u4e0b\u754c\u6765\u5206\u6790\u5dee\u5206\u9690\u79c1\u6301\u7eed\u53d1\u5e03\u673a\u5236\u7684\u8bef\u5dee\u95ee\u9898\u3002\u5728\u4e8b\u4ef6\u7ea7\u8bbe\u7f6e\u4e2d\uff0c\u4f5c\u8005\u6784\u5efa\u4e86\u7528\u4e8e\u6700\u5927\u5339\u914d\u3001\u5ea6\u76f4\u65b9\u56fe\u548c$k$-\u6838\u7684\u5b9e\u4f8b\uff0c\u4ee5\u8bc1\u660e\u52a0\u6027\u8bef\u5dee\u7684\u591a\u9879\u5f0f\u4e0b\u754c\u3002\u901a\u8fc7\u4e0e$1$-Way-Marginals\u7684\u89c4\u7ea6\uff0c\u8bc1\u660e\u4e86\u540c\u65f6\u8303\u6570\u4f30\u8ba1\u7684\u4e0d\u53ef\u907f\u514d\u7684\u591a\u9879\u5f0f\u52a0\u6027\u8bef\u5dee\u3002\u968f\u540e\uff0c\u4f5c\u8005\u4e3a\u540c\u65f6\u8303\u6570\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u6301\u7eed\u673a\u5236\uff0c\u5141\u8bb8\u5c0f\u4e58\u6027\u8fd1\u4f3c\u3002\u5728\u9879\u76ee\u7ea7\u8bbe\u7f6e\u4e2d\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5173\u4e8e1-Way-Marginals\u7684\u4e58\u6027\u8bef\u5dee\u548c\u52a0\u6027\u8bef\u5dee\u4e58\u79ef\u7684\u4e0b\u754c\uff0c\u7136\u540e\u901a\u8fc7\u89c4\u7ea6\u5c06\u5176\u5e94\u7528\u4e8e\u5927\u91cf\u7684\u6301\u7eed\u56fe\u95ee\u9898\u3002", "result": "\u5728\u4e8b\u4ef6\u7ea7\u8bbe\u7f6e\u4e2d\uff1a1. \u8bc1\u660e\u4e86\u4ec5\u63d2\u5165\u56fe\u95ee\u9898\uff08\u6700\u5927\u5339\u914d\u3001\u5ea6\u76f4\u65b9\u56fe\u548c$k$-\u6838\uff09\u7684\u52a0\u6027\u8bef\u5dee\u5b58\u5728\u7b2c\u4e00\u4e2a\u591a\u9879\u5f0f\u4e0b\u754c\uff0c\u8fd9\u76f8\u8f83\u4e8e\u73b0\u6709\u7ed3\u679c\uff08\u5982\u6700\u5927\u5339\u914d\u548c\u5ea6\u76f4\u65b9\u56fe\u7684\u591a\u5bf9\u6570\u4e0b\u754c\uff09\u662f\u6307\u6570\u7ea7\u7684\u6539\u8fdb\u30022. \u5bf9$k$-\u6838\u95ee\u9898\u9996\u6b21\u7ed9\u51fa\u4e86\u6301\u7eed\u53d1\u5e03\u673a\u5236\u7684\u4e0b\u754c\u30023. \u53d1\u73b0\u5bf9\u4e8e\u6700\u5927\u5339\u914d\u548c$k$-\u6838\uff0c\u5141\u8bb8\u5c0f\u7684\u4e58\u6027\u8fd1\u4f3c\u53ef\u4ee5\u5c06\u52a0\u6027\u8bef\u5dee\u964d\u4f4e\u5230\u591a\u5bf9\u6570\u7ea7\u522b\u30024. \u8bc1\u660e\u4e86\u4ec5\u63d2\u5165\u8bbe\u7f6e\u4e0b\u540c\u65f6\u8303\u6570\u4f30\u8ba1\u7684\u4e0d\u53ef\u907f\u514d\u7684\u591a\u9879\u5f0f\u52a0\u6027\u8bef\u5dee\u30025. \u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5177\u6709\u591a\u5bf9\u6570\u52a0\u6027\u8bef\u5dee\u548c$(1+\\zeta)$\u4e58\u6027\u8fd1\u4f3c\u7684\u6301\u7eed\u673a\u5236\uff0c\u7528\u4e8e\u540c\u65f6\u4f30\u8ba1\u6240\u6709\u5355\u8c03\u5bf9\u79f0\u8303\u6570\u3002\u5728\u9879\u76ee\u7ea7\u8bbe\u7f6e\u4e2d\uff1a1. \u8bc1\u660e\u4e86\u5927\u91cf\u56fe\u95ee\u9898\u7684\u6301\u7eed\u673a\u5236\u7684\u4e58\u6027\u8bef\u5dee\u548c\u52a0\u6027\u8bef\u5dee\u7684\u4e58\u79ef\u5b58\u5728\u591a\u9879\u5f0f\u4e0b\u754c\u30022. \u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5173\u4e8e1-Way-Marginals\u7684\u4e58\u6027\u8bef\u5dee\u548c\u52a0\u6027\u8bef\u5dee\u4e58\u79ef\u7684\u4e0b\u754c\uff0c\u6982\u62ec\u4e86Hardt\u548cTalwar\u3001Bun\u7b49\u4eba\u7684\u5de5\u4f5c\u3002\u8fd9\u4e9b\u662f\u9996\u4e2a\u9488\u5bf9\u4efb\u4f55\u5177\u6709\u4e58\u6027\u8bef\u5dee\u7684\u5dee\u5206\u9690\u79c1\u6301\u7eed\u53d1\u5e03\u673a\u5236\u7684\u4e0b\u754c\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u4e8b\u4ef6\u7ea7\u548c\u9879\u76ee\u7ea7\u5dee\u5206\u9690\u79c1\u6301\u7eed\u53d1\u5e03\u673a\u5236\u7684\u4e0b\u754c\u3002\u5728\u4e8b\u4ef6\u7ea7\u8bbe\u7f6e\u4e2d\uff0c\u4f5c\u8005\u9996\u6b21\u8bc1\u660e\u4e86\u9488\u5bf9\u4ec5\u63d2\u5165\u56fe\u95ee\u9898\uff08\u5982\u6700\u5927\u5339\u914d\u3001\u5ea6\u76f4\u65b9\u56fe\u548c$k$-\u6838\uff09\u7684\u52a0\u6027\u8bef\u5dee\u5b58\u5728\u591a\u9879\u5f0f\u4e0b\u754c\uff0c\u8fd9\u6bd4\u73b0\u6709\u7ed3\u679c\u6709\u4e86\u663e\u8457\u7684\u6539\u8fdb\u3002\u4f5c\u8005\u8fd8\u53d1\u73b0\u5728\u5141\u8bb8\u5c0f\u4e58\u6027\u8fd1\u4f3c\u7684\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u5c06\u6700\u5927\u5339\u914d\u548c$k$-\u6838\u7684\u52a0\u6027\u8bef\u5dee\u964d\u4f4e\u5230\u591a\u5bf9\u6570\u7ea7\u522b\u3002\u5bf9\u4e8e\u540c\u65f6\u8303\u6570\u4f30\u8ba1\uff0c\u4f5c\u8005\u7ed9\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5177\u6709\u591a\u5bf9\u6570\u52a0\u6027\u8bef\u5dee\u7684\u6301\u7eed\u673a\u5236\uff0c\u5e76\u5e26\u6709$(1+\\zeta)$\u4e58\u6027\u8fd1\u4f3c\u3002\u5728\u9879\u76ee\u7ea7\u8bbe\u7f6e\u4e2d\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u5927\u91cf\u56fe\u95ee\u9898\u7684\u6301\u7eed\u673a\u5236\u7684\u4e58\u6027\u8bef\u5dee\u548c\u52a0\u6027\u8bef\u5dee\u7684\u4e58\u79ef\u5b58\u5728\u591a\u9879\u5f0f\u4e0b\u754c\uff0c\u5e76\u4e3a\u6b64\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5173\u4e8e1-Way-Marginals\u7684\u4e0b\u754c\u3002\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u7406\u89e3\u5728\u6301\u7eed\u53d1\u5e03\u8bbe\u7f6e\u4e0b\u4fdd\u8bc1\u5dee\u5206\u9690\u79c1\u6240\u9700\u7684\u8bef\u5dee\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u65b0\u89c1\u89e3\u3002"}}
{"id": "2512.16087", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.16087", "abs": "https://arxiv.org/abs/2512.16087", "authors": ["Mikkel Thorup", "Hanzhi Wang"], "title": "Instance Optimality in PageRank Centrality Estimation", "comment": null, "summary": "We study an adaptive variant of a simple, classic algorithm for estimating a vertex's PageRank centrality within a constant relative error, with constant probability. We show that this algorithm is instance-optimal up to a polylogarithmic factor for any directed graph of order $n$ whose maximal in- and out-degrees are at most a constant fraction of $n$. The instance-optimality also extends to graphs in which up to a polylogarithmic number of vertices have unbounded degree, thereby covering all sparse graphs with $\\widetilde{O}(n)$ edges. Finally, we provide a counterexample showing that the algorithm is not instance-optimal for graphs with degrees mostly equal to $n$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\uff08PageRank \u4f30\u8ba1\u7b97\u6cd5\u5728\u6709\u5411\u56fe\u4e0a\u7684\u5e94\u7528\uff09\u76f8\u5173\u3002\u6240\u7814\u7a76\u7684\u81ea\u9002\u5e94 PageRank \u4f30\u8ba1\u7b97\u6cd5\u7684\u5b9e\u4f8b\u6700\u4f18\u6027\u53d6\u51b3\u4e8e\u56fe\u7684\u5ea6\u6570\u5206\u5e03\uff0c\u5bf9\u4e8e\u7a00\u758f\u56fe\u548c\u5ea6\u6570\u53d7\u9650\u56fe\uff0c\u8be5\u7b97\u6cd5\u662f\u5b9e\u4f8b\u6700\u4f18\u7684\uff08\u81f3\u591a\u76f8\u5dee\u4e00\u4e2a\u591a\u9879\u5f0f\u5bf9\u6570\u56e0\u5b50\uff09\uff0c\u4f46\u5bf9\u4e8e\u5ea6\u6570\u5927\u591a\u7b49\u4e8e $n$ \u7684\u56fe\u5219\u4e0d\u7136\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u662f\u7814\u7a76\u4e00\u4e2a\u7b80\u5355\u7684\u3001\u7ecf\u5178\u7684\u4f30\u8ba1\u9876\u70b9 PageRank \u4e2d\u5fc3\u6027\u7684\u7b97\u6cd5\u7684\u81ea\u9002\u5e94\u53d8\u4f53\uff0c\u5e76\u786e\u5b9a\u5176\u5728\u4e0d\u540c\u56fe\u7ed3\u6784\u4e0b\u7684\u5b9e\u4f8b\u6700\u4f18\u6027\uff0c\u4ece\u800c\u7406\u89e3\u8be5\u7b97\u6cd5\u7684\u6027\u80fd\u8fb9\u754c\u3002", "method": "\u672c\u6587\u7814\u7a76\u4e86\u4e00\u4e2a\u7ecf\u5178 PageRank \u4f30\u8ba1\u7b97\u6cd5\u7684\u81ea\u9002\u5e94\u53d8\u4f53\u5728\u4e0d\u540c\u56fe\u7ed3\u6784\u4e0b\u7684\u5b9e\u4f8b\u6700\u4f18\u6027\u3002\u65b9\u6cd5\u662f\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u53cd\u4f8b\u6765\u8bc1\u660e\u5176\u5728\u7279\u5b9a\u56fe\u7c7b\u4e0a\u7684\u5b9e\u4f8b\u6700\u4f18\u6027\uff0c\u4ee5\u53ca\u5728\u5176\u4ed6\u56fe\u7c7b\u4e0a\u5b9e\u4f8b\u6700\u4f18\u6027\u7684\u5931\u6548\u3002", "result": "\u672c\u6587\u8bc1\u660e\u4e86\u6240\u7814\u7a76\u7684 PageRank \u4f30\u8ba1\u7b97\u6cd5\u7684\u81ea\u9002\u5e94\u53d8\u4f53\uff0c\u5bf9\u4e8e\u6700\u5927\u5165\u5ea6\u6216\u51fa\u5ea6\u81f3\u591a\u4e3a $n$ \u7684\u5e38\u6570\u90e8\u5206\u7684\u4efb\u4f55\u6709\u5411\u56fe\uff0c\u4ee5\u53ca\u5305\u542b\u81f3\u591a\u591a\u9879\u5f0f\u5bf9\u6570\u4e2a\u65e0\u754c\u5ea6\u9876\u70b9\u7684\u56fe\uff08\u5305\u62ec\u6240\u6709 $\\widetilde{O}(n)$ \u8fb9\u7684\u7a00\u758f\u56fe\uff09\uff0c\u5728\u8fbe\u5230\u6052\u5b9a\u76f8\u5bf9\u8bef\u5dee\u548c\u6052\u5b9a\u6982\u7387\u7684\u6761\u4ef6\u4e0b\uff0c\u5176\u65f6\u95f4\u590d\u6742\u5ea6\u5728\u591a\u9879\u5f0f\u5bf9\u6570\u56e0\u5b50\u5185\u662f\u5b9e\u4f8b\u6700\u4f18\u7684\u3002\u540c\u65f6\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53cd\u4f8b\uff0c\u8868\u660e\u8be5\u7b97\u6cd5\u5bf9\u4e8e\u5ea6\u6570\u5927\u591a\u7b49\u4e8e $n$ \u7684\u56fe\u4e0d\u662f\u5b9e\u4f8b\u6700\u4f18\u7684\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u56fe\u7684\u5ea6\u6570\u5bf9\u7b97\u6cd5\u5b9e\u4f8b\u6700\u4f18\u6027\u7684\u5f71\u54cd\u3002\u5bf9\u4e8e\u6700\u5927\u5165\u5ea6\u6216\u51fa\u5ea6\u6700\u591a\u4e3a $n$ \u7684\u5e38\u6570\u90e8\u5206\u3001\u4ee5\u53ca\u5305\u542b\u5c11\u8bb8\uff08\u5bf9\u6570\u7ea7\u522b\uff09\u65e0\u754c\u5ea6\u8282\u70b9\u7684\u56fe\uff08\u8986\u76d6\u4e86\u6240\u6709 $\\widetilde{O}(n)$ \u8fb9\u7684\u7a00\u758f\u56fe\uff09\uff0c\u672c\u7b97\u6cd5\u662f\u5b9e\u4f8b\u6700\u4f18\u7684\uff0c\u6700\u591a\u76f8\u5dee\u4e00\u4e2a\u591a\u9879\u5f0f\u5bf9\u6570\u56e0\u5b50\u3002\u4f46\u5bf9\u4e8e\u5ea6\u6570\u5927\u591a\u7b49\u4e8e $n$ \u7684\u56fe\uff0c\u8be5\u7b97\u6cd5\u4e0d\u518d\u662f\u5b9e\u4f8b\u6700\u4f18\u7684\u3002"}}
{"id": "2512.16414", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.16414", "abs": "https://arxiv.org/abs/2512.16414", "authors": ["Jannes Malanowski"], "title": "Conquering the Multiverse: The River Voting Method with Efficient Parallel Universe Tiebreaking", "comment": "This is my Bachelor's Thesis. Based on this thesis we published arXiv:2512.14409", "summary": "Democracy relies on making collective decisions through voting. In addition, voting procedures have further applications, for example in the training of artificial intelligence. An essential criterion for determining the winner of a fair election is that all alternatives are treated equally: this is called neutrality. The established Ranked Pairs voting method cannot simultaneously guarantee neutrality and be computationally tractable for election with ties. River, the recently introduced voting method, shares desirable properties with Ranked Pairs and has further advantages, such as a new property related to resistance against manipulation. Both Ranked Pairs and River use a weighted margin graph to model the election. Ties in the election can lead to edges of equal margin. To order the edges in such a case, a tiebreaking scheme must be employed. Many tiebreaks violate neutrality or other important properties. A tiebreaking scheme that preserves neutrality is Parallel Universe Tiebreaking (PUT). Ranked Pairs with PUT is NP-hard to compute.\n  The main result of this thesis shows that River with PUT can be computed in polynomial worst-case runtime: We can check whether an alternative is a River PUT winner, by running River with a specially constructed ordering of the edges. To construct this ordering, we introduce the semi-River diagram which contains the edges that can appear in any River diagram for some arbitrary tiebreak. On this diagram we can compute the River winners, by applying a variant of Prims algorithm per alternative. Additionally, we give an algorithm improve the previous naive runtime of River from $\\mathcal{O}(n^4)$ to $\\mathcal{O}(n^2 \\log n)$, where n is the number of alternatives.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\uff08Graph Processing\uff09\u548c\u7b97\u6cd5\u4f18\u5316\u76f8\u5173\u3002\u56fe\u5904\u7406\u4e3b\u8981\u4f53\u73b0\u5728 Ranked Pairs \u548c River \u6295\u7968\u65b9\u6cd5\u90fd\u4f7f\u7528\u4e86\u52a0\u6743\u4f18\u52bf\u56fe\uff08weighted margin graph\uff09\u6765\u5efa\u6a21\u9009\u4e3e\uff0c\u5e76\u4e14\u8ba1\u7b97 River \u8d62\u8005\u7684\u8fc7\u7a0b\u6d89\u53ca\u5bf9\u56fe\u4e0a\u7684\u8fb9\u8fdb\u884c\u7279\u5b9a\u6392\u5e8f\u548c\u56fe\u7b97\u6cd5\uff08\u5982\u7c7b Prim \u7b97\u6cd5\uff09\u7684\u5e94\u7528\u3002\nTLDR: Ranked Pairs \u6295\u7968\u6cd5\u5728\u4fdd\u8bc1\u4e2d\u7acb\u6027\uff08\u901a\u8fc7 Parallel Universe Tiebreaking, PUT\uff09\u65f6\u8ba1\u7b97\u8d62\u8005\u662f NP-\u96be\u7684\u3002\u672c\u6587\u8bc1\u660e\u4e86\u65b0\u5174\u7684 River \u6295\u7968\u6cd5\u4e0e PUT \u7ed3\u5408\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u9ad8\u6548\u8ba1\u7b97\u3002\u901a\u8fc7\u5f15\u5165\u534a River \u56fe\u548c\u7c7b\u4f3c Prim \u7b97\u6cd5\u7684\u53d8\u4f53\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\uff0c\u5e76\u5c06 River \u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u4ece $\\mathcal{O}(n^4)$ \u4f18\u5316\u5230 $\\mathcal{O}(n^2 \\log n)$\u3002", "motivation": "\u9009\u4e3e\u6295\u7968\u9700\u8981\u6709\u4e00\u4e2a\u516c\u5e73\u7684\u8d62\u8005\u51b3\u5b9a\u6807\u51c6\u3002\u4e2d\u7acb\u6027\uff08Neutrality\uff09\u662f\u516c\u5e73\u9009\u4e3e\u7684\u5173\u952e\u6807\u51c6\u4e4b\u4e00\uff0c\u8981\u6c42\u6240\u6709\u9009\u9879\u5f97\u5230\u5e73\u7b49\u5bf9\u5f85\u3002\u6392\u540d\u914d\u5bf9\uff08Ranked Pairs, RP\uff09\u662f\u4e00\u79cd\u5df2\u5efa\u7acb\u7684\u6295\u7968\u65b9\u6cd5\uff0c\u4f46\u5728\u5904\u7406\u5e73\u5c40\u65f6\uff0c\u5982\u679c\u4f7f\u7528\u4fdd\u6301\u4e2d\u7acb\u6027\u7684\u5e73\u5c40\u6253\u7834\u65b9\u6848\uff08\u5982\u5e76\u884c\u5b87\u5b99\u5e73\u5c40\u6253\u7834\uff0cPUT\uff09\uff0c\u5219\u8ba1\u7b97\u8d62\u8005\u662f NP-\u96be\u7684\uff0c\u5373\u8ba1\u7b97\u4e0a\u4e0d\u53ef\u884c\u3002River \u662f\u6700\u8fd1\u5f15\u5165\u7684\u3001\u4e0e RP \u5177\u6709\u76f8\u4f3c\u4f18\u70b9\u7684\u6295\u7968\u65b9\u6cd5\uff0c\u5e76\u4e14\u5177\u6709\u62b5\u6297\u64cd\u7eb5\u7b49\u989d\u5916\u4f18\u52bf\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u7814\u7a76 River \u6295\u7968\u65b9\u6cd5\u4e0e PUT \u7ed3\u5408\u65f6\u7684\u8ba1\u7b97\u53ef\u884c\u6027\uff0c\u65e8\u5728\u627e\u5230\u4e00\u79cd\u65e2\u80fd\u4fdd\u6301\u4e2d\u7acb\u6027\u53c8\u80fd\u9ad8\u6548\u8ba1\u7b97\u8d62\u8005\u7684\u65b9\u6cd5\u3002\u540c\u65f6\uff0c\u4e5f\u5e0c\u671b\u63d0\u5347 River \u7b97\u6cd5\u672c\u8eab\u7684\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u672c\u6587\u7684\u8d21\u732e\u5728\u4e8e\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8ba1\u7b97 River+PUT \u83b7\u80dc\u8005\u7684\u65b9\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u591a\u9879\u5f0f\u65f6\u95f4\u590d\u6742\u5ea6\u3002\u5177\u4f53\u65b9\u6cd5\u662f\uff1a1. \u5f15\u5165\u534a River \u56fe\uff08semi-River diagram\uff09\uff0c\u8be5\u56fe\u5305\u542b\u4efb\u610f\u5e73\u5c40\u6253\u7834\u65b9\u6848\u4e0b\u53ef\u80fd\u51fa\u73b0\u5728 River \u56fe\u4e2d\u7684\u8fb9\u30022. \u57fa\u4e8e\u534a River \u56fe\uff0c\u5229\u7528\u4e00\u4e2a\u7ecf\u8fc7\u7279\u6b8a\u6784\u9020\u7684\u8fb9\u6392\u5e8f\u65b9\u6848\u8fd0\u884c River \u7b97\u6cd5\u6765\u68c0\u67e5\u67d0\u4e2a\u9009\u9879\u662f\u5426\u662f\u8d62\u8005\u30023. \u5728\u534a River \u56fe\u4e0a\uff0c\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u9009\u9879\u5e94\u7528 Prim \u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53\u6765\u8ba1\u7b97 River \u83b7\u80dc\u8005\u30024. \u6b64\u5916\uff0c\u672c\u6587\u8fd8\u63d0\u4f9b\u4e86\u4e00\u79cd\u5c06 River \u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u4ece $\\mathcal{O}(n^4)$ \u4f18\u5316\u5230 $\\mathcal{O}(n^2 \\log n)$ \u7684\u6539\u8fdb\u7b97\u6cd5\u3002", "result": "\u4e3b\u8981\u7ed3\u679c\u662f\u8bc1\u660e\u4e86 River \u6295\u7968\u65b9\u6cd5\u4e0e\u5e76\u884c\u5b87\u5b99\u5e73\u5c40\u6253\u7834\uff08PUT\uff09\u7ed3\u5408\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u6700\u574f\u60c5\u51b5\u8fd0\u884c\u65f6\u95f4\u5185\uff08polynomial worst-case runtime\uff09\u8ba1\u7b97\u83b7\u80dc\u8005\u3002\u5177\u4f53\u800c\u8a00\uff0c\u53ef\u4ee5\u901a\u8fc7\u6784\u9020\u7279\u6b8a\u7684\u8fb9\u6392\u5e8f\u6765\u8fd0\u884c River \u7b97\u6cd5\uff0c\u4ece\u800c\u68c0\u67e5\u67d0\u4e2a\u9009\u9879\u662f\u5426\u4e3a River PUT \u8d62\u8005\u3002\u8fd9\u4e00\u8fc7\u7a0b\u901a\u8fc7\u5f15\u5165\u534a River \u56fe\uff08semi-River diagram\uff09\u5b9e\u73b0\uff0c\u8be5\u56fe\u5305\u542b\u4e86\u4efb\u610f\u5e73\u5c40\u6253\u7834\u4e0b\u53ef\u80fd\u51fa\u73b0\u5728 River \u56fe\u4e2d\u7684\u8fb9\u3002\u5728\u534a River \u56fe\u4e0a\uff0c\u901a\u8fc7\u5bf9\u6bcf\u4e2a\u9009\u9879\u5e94\u7528 Prim \u7b97\u6cd5\u7684\u4e00\u4e2a\u53d8\u4f53\u6765\u8ba1\u7b97 River \u8d62\u8005\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u5c06 River \u7b97\u6cd5\u7684\u6734\u7d20\u8fd0\u884c\u65f6\u95f4\u4ece $\\mathcal{O}(n^4)$ \u6539\u8fdb\u5230\u4e86 $\\mathcal{O}(n^2 \\log n)$\uff0c\u5176\u4e2d $n$ \u662f\u9009\u9879\u7684\u6570\u91cf\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u6392\u540d\u914d\u5bf9\uff08Ranked Pairs, RP\uff09\u548c River \u4e24\u79cd\u6295\u7968\u65b9\u6cd5\u5728\u5904\u7406\u5e73\u5c40\u65f6\u5bf9\u4e2d\u7acb\u6027\uff08Neutrality\uff09\u548c\u8ba1\u7b97\u53ef\u884c\u6027\uff08Tractability\uff09\u7684\u5f71\u54cd\u3002RP \u5728\u5e73\u5c40\u4e0b\u65e0\u6cd5\u540c\u65f6\u4fdd\u8bc1\u4e2d\u7acb\u6027\u548c\u53ef\u8ba1\u7b97\u6027\u3002\u800c River \u6295\u7968\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u4e0e\u5e76\u884c\u5b87\u5b99\u5e73\u5c40\u6253\u7834\uff08Parallel Universe Tiebreaking, PUT\uff09\u7ed3\u5408\u65f6\uff0c\u53ef\u4ee5\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8ba1\u7b97\u51fa\u8d62\u8005\uff0c\u89e3\u51b3\u4e86 RP+PUT \u7684 NP-\u96be\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u534a River \u56fe\uff08semi-River diagram\uff09\u5e76\u5e94\u7528 Prim \u7b97\u6cd5\u7684\u53d8\u4f53\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8ba1\u7b97\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u5c06 River \u7b97\u6cd5\u7684\u8fd0\u884c\u65f6\u95f4\u4ece $\\mathcal{O}(n^4)$ \u4f18\u5316\u5230 $\\mathcal{O}(n^2 \\log n)$\uff0c\u63d0\u5347\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6548\u7387\u3002"}}
{"id": "2512.16639", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.16639", "abs": "https://arxiv.org/abs/2512.16639", "authors": ["Gramoz Goranci", "Shaofeng Jiang", "Peter Kiss", "Eva Szilagyi", "Qiaoyuan Yang"], "title": "Fully Dynamic Algorithms for Chamfer Distance", "comment": "NeurIPS 2025", "summary": "We study the problem of computing Chamfer distance in the fully dynamic setting, where two set of points $A, B \\subset \\mathbb{R}^{d}$, each of size up to $n$, dynamically evolve through point insertions or deletions and the goal is to efficiently maintain an approximation to $\\mathrm{dist}_{\\mathrm{CH}}(A,B) = \\sum_{a \\in A} \\min_{b \\in B} \\textrm{dist}(a,b)$, where $\\textrm{dist}$ is a distance measure. Chamfer distance is a widely used dissimilarity metric for point clouds, with many practical applications that require repeated evaluation on dynamically changing datasets, e.g., when used as a loss function in machine learning. In this paper, we present the first dynamic algorithm for maintaining an approximation of the Chamfer distance under the $\\ell_p$ norm for $p \\in \\{1,2 \\}$. Our algorithm reduces to approximate nearest neighbor (ANN) search with little overhead. Plugging in standard ANN bounds, we obtain $(1+\u03b5)$-approximation in $\\tilde{O}(\u03b5^{-d})$ update time and $O(1/\u03b5)$-approximation in $\\tilde{O}(d n^{\u03b5^2} \u03b5^{-4})$ update time. We evaluate our method on real-world datasets and demonstrate that it performs competitively against natural baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e **\u673a\u5668\u5b66\u4e60\uff08Machine Learning\uff09** \u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u660e\u786e\u63d0\u5230 Chamfer \u8ddd\u79bb\u4f5c\u4e3a **\u635f\u5931\u51fd\u6570** \u5728\u673a\u5668\u5b66\u4e60\u4e2d\u5e94\u7528\uff0c\u5e76\u4e14\u7814\u7a76\u52a8\u6001\u70b9\u4e91\u6570\u636e\u3002\n\n**\u592a\u957f\u4e0d\u8bfb\uff08tldr\uff09\u603b\u7ed3\uff1a**\nChamfer \u8ddd\u79bb\u662f\u70b9\u4e91\u76f8\u4f3c\u6027\u7684\u91cd\u8981\u5ea6\u91cf\uff0c\u5728\u673a\u5668\u5b66\u4e60\u7b49\u9886\u57df\u9700\u8981\u5bf9\u52a8\u6001\u53d8\u5316\u7684\u6570\u636e\u96c6\u8fdb\u884c\u91cd\u590d\u8ba1\u7b97\u3002\u672c\u6587\u63d0\u51fa\u4e86\u7b2c\u4e00\u4e2a\u5728\u70b9\u96c6\u52a8\u6001\u6f14\u5316\uff08\u63d2\u5165/\u5220\u9664\uff09\u65f6\uff0c\u9ad8\u6548\u7ef4\u62a4 Chamfer \u8ddd\u79bb\u8fd1\u4f3c\u503c\u7684\u52a8\u6001\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5c06 Chamfer \u8ddd\u79bb\u7684\u7ef4\u62a4\u95ee\u9898\u8f6c\u5316\u4e3a\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u641c\u7d22\uff0c\u7406\u8bba\u4e0a\u5728 $\\ell_p$ \u8303\u6570\u4e0b\uff08$p \\in \\{1, 2\\}$\uff09\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709 ANN \u7b97\u6cd5\u76f8\u5f53\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u754c\u9650\uff0c\u5e76\u88ab\u8bc1\u660e\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e2d\u8868\u73b0\u826f\u597d\u3002", "motivation": "Chamfer \u8ddd\u79bb\u4f5c\u4e3a\u70b9\u4e91 dissimilarity \u7684\u5ea6\u91cf\u6807\u51c6\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u5bf9\u52a8\u6001\u53d8\u5316\u6570\u636e\u96c6\u8fdb\u884c\u91cd\u590d\u8bc4\u4f30\u7684\u5b9e\u9645\u5e94\u7528\u4e2d\uff08\u4f8b\u5982\uff0c\u4f5c\u4e3a\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u635f\u5931\u51fd\u6570\uff09\u3002\u7136\u800c\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u70b9\u96c6\u52a8\u6001\u6f14\u5316\uff08\u901a\u8fc7\u70b9\u63d2\u5165\u6216\u5220\u9664\uff09\u65f6\uff0c\u5982\u4f55\u9ad8\u6548\u5730\u7ef4\u62a4\u8be5\u8ddd\u79bb\u7684\u8fd1\u4f3c\u503c\u662f\u4e00\u4e2a\u672a\u89e3\u51b3\u7684\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u4e3a\u5168\u52a8\u6001\u8bbe\u7f6e\u4e0b\u7684 Chamfer \u8ddd\u79bb\u8ba1\u7b97\u95ee\u9898\u63d0\u4f9b\u7b2c\u4e00\u4e2a\u52a8\u6001\u7b97\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06 Chamfer \u8ddd\u79bb\u7684\u52a8\u6001\u7ef4\u62a4\u95ee\u9898\u8f6c\u5316\u4e3a\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u641c\u7d22\u7684\u52a8\u6001\u7b97\u6cd5\u3002\u901a\u8fc7\u5229\u7528\u73b0\u6709\u7684 ANN \u641c\u7d22\u754c\u9650\uff0c\u8be5\u7b97\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u5bf9 Chamfer \u8ddd\u79bb\u7684 $(1+\\epsilon)$-\u8fd1\u4f3c\u6216 $O(1/\\epsilon)$-\u8fd1\u4f3c\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u7b97\u6cd5\u53d6\u5f97\u4e86\u4ee5\u4e0b\u8fd1\u4f3c\u548c\u65f6\u95f4\u590d\u6742\u5ea6\uff08\u5176\u4e2d $\\tilde{O}$ \u9690\u85cf\u4e86\u5bf9\u6570\u56e0\u5b50\uff09\uff1a\n1. $(1+\\epsilon)$-\u8fd1\u4f3c\uff1a$\\tilde{O}(\\epsilon^{-d})$ \u66f4\u65b0\u65f6\u95f4\u3002\n2. $O(1/\\epsilon)$-\u8fd1\u4f3c\uff1a$\\tilde{O}(d n^{\\epsilon^2} \\epsilon^{-4})$ \u66f4\u65b0\u65f6\u95f4\u3002\n\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u4e0e\u81ea\u7136\u57fa\u7ebf\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u7528\u4e8e\u7ef4\u62a4\u52a8\u6001\u70b9\u96c6\u95f4 Chamfer \u8ddd\u79bb\u8fd1\u4f3c\u503c\u7684\u52a8\u6001\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5c06\u95ee\u9898\u8f6c\u5316\u4e3a\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u641c\u7d22\uff0c\u5e76\u5728\u7406\u8bba\u4e0a\u53d6\u5f97\u4e86\u4e0e\u73b0\u6709\u6700\u5148\u8fdb\u7684 ANN \u7b97\u6cd5\u76f8\u5f53\u7684\u754c\u9650\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u8be5\u65b9\u6cd5\u4e5f\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u4e3a\u5904\u7406\u52a8\u6001\u70b9\u4e91\u6570\u636e\u4e2d\u7684\u76f8\u4f3c\u6027\u5ea6\u91cf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15827", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.15827", "abs": "https://arxiv.org/abs/2512.15827", "authors": ["FNU Vikas", "Paul Gratz", "Daniel Jim\u00e9nez"], "title": "Workload Characterization for Branch Predictability", "comment": "This manuscript is an archival version of work conducted as part of the author's 2020 Master's at Texas A\\&M University under the supervision of Professors Paul Gratz and Daniel A.~Jim\u00e9nez. No part of this work was conducted at, funded by, or related to the author's current employer", "summary": "Conditional branch prediction predicts the likely direction of a conditional branch instruction to support ILP extraction. Branch prediction is a pattern recognition problem that learns mappings between a context to the branch outcome. An accurate predictor reduces the number of instructions executed on the wrong path resulting in an improvement of performance and energy consumption. In this paper, we present a workload characterization methodology for branch prediction. We propose two new workload-driven branch prediction accuracy identifiers -- branch working set size and branch predictability. These parameters are highly correlated with misprediction rates of modern branch prediction schemes (e.g. TAGE and perceptron). We define the branch working set of a trace as a group of most frequently occurring branch contexts, i.e. the 3-part tuple of branch address, and associated global and local history. We analyze the branch working set's size and predictability on a per-trace basis to study its relationship with a modern branch predictor's accuracy. We have characterized 2,451 workload traces into seven branch working set size and nine predictability categories after analyzing their branch behavior. We present further insights into the source of prediction accuracy and favored workload categories for modern branch predictors.", "AI": {"tldr": "This content has not passed the compliance test and has been hidden.", "motivation": "\u5206\u652f\u9884\u6d4b\u662f\u63d0\u9ad8\u6307\u4ee4\u7ea7\u5e76\u884c\u6027\uff08ILP\uff09\u7684\u5173\u952e\u6280\u672f\u3002\u51c6\u786e\u7684\u5206\u652f\u9884\u6d4b\u80fd\u51cf\u5c11\u9519\u8bef\u8def\u5f84\u4e0a\u7684\u6307\u4ee4\u6267\u884c\uff0c\u4ece\u800c\u63d0\u9ad8\u6027\u80fd\u5e76\u964d\u4f4e\u80fd\u8017\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5206\u652f\u9884\u6d4b\u5668\uff08\u5982 TAGE \u548c\u611f\u77e5\u673a\uff09\u7684\u6027\u80fd\u5bf9\u5de5\u4f5c\u8d1f\u8f7d\u7684\u7279\u6027\u975e\u5e38\u654f\u611f\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u5e0c\u671b\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u5206\u6790\u65b9\u6cd5\u548c\u76f8\u5173\u6307\u6807\uff0c\u6765\u6df1\u5165\u7406\u89e3\u548c\u91cf\u5316\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u5bf9\u73b0\u4ee3\u5206\u652f\u9884\u6d4b\u5668\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u8fdb\u800c\u4e3a\u5206\u652f\u9884\u6d4b\u5668\u7684\u8bbe\u8ba1\u548c\u6539\u8fdb\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u652f\u9884\u6d4b\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u5206\u6790\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u7684\u5de5\u4f5c\u8d1f\u8f7d\u9a71\u52a8\u7684\u5206\u652f\u9884\u6d4b\u51c6\u786e\u6027\u6307\u6807\uff1a**\u5206\u652f\u5de5\u4f5c\u96c6\u5927\u5c0f**\uff08branch working set size\uff09\u548c**\u5206\u652f\u53ef\u9884\u6d4b\u6027**\uff08branch predictability\uff09\u3002\u901a\u8fc7\u5c06\u6bcf\u6761\u8f68\u8ff9\u7684\u8fd9\u4e24\u79cd\u7279\u6027\u4e0e\u73b0\u4ee3\u5206\u652f\u9884\u6d4b\u65b9\u6848\uff08\u5982 TAGE \u548c\u611f\u77e5\u673a\uff09\u7684\u9519\u8bef\u9884\u6d4b\u7387\u8fdb\u884c\u6bd4\u8f83\uff0c\u5bf9 2,451 \u6761\u5de5\u4f5c\u8d1f\u8f7d\u8f68\u8ff9\u8fdb\u884c\u4e86\u5206\u7c7b\u548c\u5206\u6790\u3002\u5206\u652f\u5de5\u4f5c\u96c6\u88ab\u5b9a\u4e49\u4e3a\u6700\u5e38\u51fa\u73b0\u7684\u5206\u652f\u4e0a\u4e0b\u6587\uff08\u5305\u62ec\u5206\u652f\u5730\u5740\u3001\u5168\u5c40\u548c\u5c40\u90e8\u5386\u53f2\uff09\u7684\u96c6\u5408\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u5206\u652f\u5de5\u4f5c\u96c6\u5927\u5c0f\u548c\u5206\u652f\u53ef\u9884\u6d4b\u6027\u8fd9\u4e24\u4e2a\u65b0\u6307\u6807\uff0c\u5e76\u8bc1\u660e\u5b83\u4eec\u4e0e\u73b0\u4ee3\u5206\u652f\u9884\u6d4b\u5668\uff08\u5982 TAGE \u548c\u611f\u77e5\u673a\uff09\u7684\u9519\u8bef\u9884\u6d4b\u7387\u9ad8\u5ea6\u76f8\u5173\u3002\u901a\u8fc7\u5bf9 2,451 \u6761\u5de5\u4f5c\u8d1f\u8f7d\u8f68\u8ff9\u7684\u5206\u6790\uff0c\u5c06\u5176\u5206\u7c7b\u4e3a\u4e03\u79cd\u5206\u652f\u5de5\u4f5c\u96c6\u5927\u5c0f\u548c\u4e5d\u79cd\u53ef\u9884\u6d4b\u6027\u7c7b\u522b\u3002\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u7684\u6765\u6e90\uff0c\u5e76\u786e\u5b9a\u4e86\u73b0\u4ee3\u5206\u652f\u9884\u6d4b\u5668\u504f\u7231\u7684\u5de5\u4f5c\u8d1f\u8f7d\u7c7b\u522b\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u8bc4\u4f30\u5206\u652f\u9884\u6d4b\u51c6\u786e\u6027\u7684\u65b0\u65b9\u6cd5\u548c\u6307\u6807\uff0c\u5e76\u5bf9\u73b0\u4ee3\u5206\u652f\u9884\u6d4b\u5668\u8fdb\u884c\u4e86\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u5206\u6790\u3002\u901a\u8fc7\u5206\u6790\u5206\u652f\u5de5\u4f5c\u96c6\u7684\u5927\u5c0f\u548c\u53ef\u9884\u6d4b\u6027\u4e0e\u9884\u6d4b\u5668\u51c6\u786e\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u6539\u8fdb\u672a\u6765\u5206\u652f\u9884\u6d4b\u5668\u7684\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2512.16038", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.16038", "abs": "https://arxiv.org/abs/2512.16038", "authors": ["Eric Simon", "Renato B. Hoffmann", "Lucas Alf", "Dalvan Griebler"], "title": "LOG.io: Unified Rollback Recovery and Data Lineage Capture for Distributed Data Pipelines", "comment": null, "summary": "This paper introduces LOG.io, a comprehensive solution designed for correct rollback recovery and fine-grain data lineage capture in distributed data pipelines. It is tailored for serverless scalable architectures and uses a log-based rollback recovery protocol. LOG.io supports a general programming model, accommodating non-deterministic operators, interactions with external systems, and arbitrary custom code. It is non-blocking, allowing failed operators to recover independently without interrupting other active operators, thereby leveraging data parallelization, and it facilitates dynamic scaling of operators during pipeline execution. Performance evaluations, conducted within the SAP Data Intelligence system, compare LOG.io with the Asynchronous Barrier Snapshotting (ABS) protocol, originally implemented in Flink. Our experiments show that when there are straggler operators in a data pipeline and the throughput of events is moderate (e.g., 1 event every 100 ms), LOG.io performs as well as ABS during normal processing and outperforms ABS during recovery. Otherwise, ABS performs better than LOG.io for both normal processing and recovery. However, we show that in these cases, data parallelization can largely reduce the overhead of LOG.io while ABS does not improve. Finally, we show that the overhead of data lineage capture, at the granularity of the event and between any two operators in a pipeline, is marginal, with less than 1.5% in all our experiments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e**\u56fe\u5904\u7406\uff08\u5206\u5e03\u5f0f\u6570\u636e\u7ba1\u9053\uff09**\u548c**\u7f16\u8bd1\u5668/HLS\uff08\u7f16\u7a0b\u6a21\u578b\u548c\u6027\u80fd\u4f18\u5316\uff09**\u76f8\u5173\u3002\n\n**\u592a\u957f\u4e0d\u770b\u7248 (TL;DR):** \u672c\u6587\u4ecb\u7ecd\u4e86 LOG.io\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u4e3a\u65e0\u670d\u52a1\u5668\u5206\u5e03\u5f0f\u6570\u636e\u7ba1\u9053\u8bbe\u8ba1\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e**\u6b63\u786e\u7684\u65e5\u5fd7\u56de\u6eda\u6062\u590d\u548c\u7ec6\u7c92\u5ea6\u6570\u636e\u6cbf\u88ad\u6355\u83b7**\u3002\u5b83\u652f\u6301**\u901a\u7528\u7f16\u7a0b\u6a21\u578b**\uff0c\u5177\u6709**\u975e\u963b\u585e**\u6062\u590d\u548c**\u52a8\u6001\u6269\u5c55**\u80fd\u529b\u3002\u4e0e Flink \u7684 ABS \u534f\u8bae\u76f8\u6bd4\uff0c\u5f53\u5b58\u5728**\u62d6\u6162\u64cd\u4f5c\u7b26\u4e14\u541e\u5410\u91cf\u9002\u4e2d**\u65f6\uff0cLOG.io \u5728\u6062\u590d\u4e0a\u8868\u73b0\u66f4\u4f18\uff1b\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\uff0c\u867d\u7136 ABS \u66f4\u597d\uff0c\u4f46 LOG.io \u53ef\u4ee5\u901a\u8fc7**\u6570\u636e\u5e76\u884c\u5316**\u663e\u8457\u51cf\u5c11\u5f00\u9500\u3002\u6b64\u5916\uff0c\u6355\u83b7**\u4e8b\u4ef6\u7ea7\u6570\u636e\u6cbf\u88ad\u7684\u5f00\u9500\u5fae\u4e0d\u8db3\u9053**\uff08\u5c0f\u4e8e 1.5%\uff09\u3002", "motivation": "\u5728\u5206\u5e03\u5f0f\u6570\u636e\u7ba1\u9053\u4e2d\uff0c\u9762\u4e34\u7740\u5982\u4f55\u5b9e\u73b0**\u6b63\u786e\u7684\u6545\u969c\u6062\u590d**\uff08\u56de\u6eda\u6062\u590d\uff09\u548c**\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u6cbf\u88ad\u6355\u83b7**\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u65e0\u670d\u52a1\u5668\u53ef\u6269\u5c55\u67b6\u6784\u548c\u9700\u8981\u652f\u6301\u901a\u7528\u7f16\u7a0b\u6a21\u578b\uff08\u5982\u975e\u786e\u5b9a\u6027\u64cd\u4f5c\u7b26\u3001\u5916\u90e8\u4ea4\u4e92\uff09\u7684\u573a\u666f\u4e2d\u3002\u4f20\u7edf\u7684\u6062\u590d\u534f\u8bae\uff08\u5982 ABS\uff09\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\uff08\u4f8b\u5982\u5b58\u5728\u62d6\u6162\u64cd\u4f5c\u7b26\uff09\u53ef\u80fd\u6548\u7387\u4e0d\u9ad8\uff0c\u5e76\u4e14\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u6cbf\u88ad\u80fd\u529b\u3002LOG.io \u7684\u52a8\u673a\u662f\u63d0\u4f9b\u4e00\u4e2a\u7efc\u5408\u3001\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u5176\u4ed6\u6d3b\u52a8\u64cd\u4f5c\u7b26\u7684\u975e\u963b\u585e\u6027\u548c\u7ba1\u9053\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86 LOG.io\uff0c\u8fd9\u662f\u4e00\u4e2a\u7528\u4e8e\u5206\u5e03\u5f0f\u6570\u636e\u7ba1\u9053\u7684\u7efc\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u65e8\u5728\u5b9e\u73b0\u6b63\u786e\u7684**\u56de\u6eda\u6062\u590d**\u548c**\u7ec6\u7c92\u5ea6\u6570\u636e\u6cbf\u88ad\u6355\u83b7**\u3002\u5b83\u4e3a\u65e0\u670d\u52a1\u5668\u53ef\u6269\u5c55\u67b6\u6784\u91cf\u8eab\u5b9a\u5236\uff0c\u4f7f\u7528\u57fa\u4e8e**\u65e5\u5fd7**\u7684\u56de\u6eda\u6062\u590d\u534f\u8bae\u3002LOG.io \u652f\u6301\u4e00\u4e2a**\u901a\u7528\u7f16\u7a0b\u6a21\u578b**\uff0c\u5305\u62ec\u975e\u786e\u5b9a\u6027\u64cd\u4f5c\u7b26\u3001\u4e0e\u5916\u90e8\u7cfb\u7edf\u7684\u4ea4\u4e92\u4ee5\u53ca\u4efb\u610f\u81ea\u5b9a\u4e49\u4ee3\u7801\u3002\u5176\u6062\u590d\u673a\u5236\u662f**\u975e\u963b\u585e**\u7684\uff0c\u5141\u8bb8\u6545\u969c\u64cd\u4f5c\u7b26\u72ec\u7acb\u6062\u590d\uff0c\u5229\u7528**\u6570\u636e\u5e76\u884c\u5316**\uff0c\u5e76\u652f\u6301\u5728\u7ba1\u9053\u6267\u884c\u671f\u95f4**\u52a8\u6001\u6269\u5c55**\u64cd\u4f5c\u7b26\u3002\u6027\u80fd\u8bc4\u4f30\u662f\u5728 SAP Data Intelligence \u7cfb\u7edf\u4e2d\u8fdb\u884c\u7684\uff0cLOG.io \u4e0e\u6700\u521d\u5728 Flink \u4e2d\u5b9e\u73b0\u7684 ABS\uff08\u5f02\u6b65\u5c4f\u969c\u5feb\u7167\uff09\u534f\u8bae\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "result": "\u6027\u80fd\u8bc4\u4f30\u5728 SAP Data Intelligence \u7cfb\u7edf\u4e2d\u8fdb\u884c\uff0cLOG.io \u4e0e ABS \u534f\u8bae\u8fdb\u884c\u4e86\u6bd4\u8f83\uff1a1. **\u5b58\u5728\u62d6\u6162\u64cd\u4f5c\u7b26\u4e14\u4e8b\u4ef6\u541e\u5410\u91cf\u9002\u4e2d**\uff08\u4f8b\u5982\uff0c\u6bcf 100 \u6beb\u79d2 1 \u4e2a\u4e8b\u4ef6\uff09\u65f6\uff0cLOG.io \u5728\u6b63\u5e38\u5904\u7406\u671f\u95f4\u4e0e ABS \u6027\u80fd**\u4e00\u6837\u597d**\uff0c\u4f46\u5728\u6062\u590d\u671f\u95f4**\u4f18\u4e8e** ABS\u30022. **\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b**\uff0cABS \u5728\u6b63\u5e38\u5904\u7406\u548c\u6062\u590d\u65b9\u9762\u90fd**\u4f18\u4e8e** LOG.io\u3002\u7136\u800c\uff0c\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\uff0c**\u6570\u636e\u5e76\u884c\u5316**\u53ef\u4ee5**\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u51cf\u5c11 LOG.io \u7684\u5f00\u9500**\uff0c\u800c ABS \u5219\u6ca1\u6709\u6539\u8fdb\u30023. \u7ec6\u7c92\u5ea6\uff08\u4e8b\u4ef6\u7ea7\u522b\u548c\u4efb\u610f\u4e24\u4e2a\u64cd\u4f5c\u7b26\u4e4b\u95f4\uff09**\u6570\u636e\u6cbf\u88ad\u6355\u83b7\u7684\u5f00\u9500\u5f88\u5c0f**\uff0c\u5728\u6240\u6709\u5b9e\u9a8c\u4e2d\u90fd**\u4f4e\u4e8e 1.5%**\u3002", "conclusion": "LOG.io \u662f\u4e00\u79cd\u5728\u5206\u5e03\u5f0f\u6570\u636e\u7ba1\u9053\u4e2d\u5b9e\u73b0\u6b63\u786e\u56de\u6eda\u6062\u590d\u548c\u7ec6\u7c92\u5ea6\u6570\u636e\u6cbf\u88ad\u6355\u83b7\u7684\u7efc\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u65e0\u670d\u52a1\u5668\u53ef\u6269\u5c55\u67b6\u6784\u3002\u5b83\u91c7\u7528\u57fa\u4e8e\u65e5\u5fd7\u7684\u56de\u6eda\u6062\u590d\u534f\u8bae\uff0c\u652f\u6301\u901a\u7528\u7684\u7f16\u7a0b\u6a21\u578b\uff08\u5305\u62ec\u975e\u786e\u5b9a\u6027\u64cd\u4f5c\u7b26\u3001\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u548c\u4efb\u610f\u81ea\u5b9a\u4e49\u4ee3\u7801\uff09\uff0c\u5e76\u4e14\u5177\u6709\u975e\u963b\u585e\u7279\u6027\uff0c\u5141\u8bb8\u6545\u969c\u64cd\u4f5c\u7b26\u72ec\u7acb\u6062\u590d\u800c\u4e0d\u4e2d\u65ad\u5176\u4ed6\u64cd\u4f5c\u7b26\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u5b58\u5728\u62d6\u6162\u64cd\u4f5c\u7b26\u4e14\u4e8b\u4ef6\u541e\u5410\u91cf\u9002\u4e2d\uff08\u4f8b\u5982\uff0c\u6bcf 100 \u6beb\u79d2 1 \u4e2a\u4e8b\u4ef6\uff09\u7684\u60c5\u51b5\u4e0b\uff0cLOG.io \u5728\u6b63\u5e38\u5904\u7406\u548c\u6062\u590d\u671f\u95f4\u7684\u8868\u73b0\u4e0e ABS \u76f8\u5f53\u6216\u4f18\u4e8e ABS\u3002\u5728\u5176\u4ed6\u60c5\u51b5\u4e0b\uff0cABS \u8868\u73b0\u66f4\u597d\uff0c\u4f46\u6570\u636e\u5e76\u884c\u5316\u53ef\u4ee5\u663e\u8457\u51cf\u5c11 LOG.io \u7684\u5f00\u9500\u800c ABS \u6ca1\u6709\u6539\u8fdb\u3002\u6b64\u5916\uff0cLOG.io \u6355\u83b7\u6570\u636e\u6cbf\u88ad\u7684\u5f00\u9500\u975e\u5e38\u5c0f\u3002\u8fd9\u9879\u7814\u7a76\u4e3a\u5206\u5e03\u5f0f\u6570\u636e\u7ba1\u9053\u7684\u53ef\u9760\u6027\u548c\u53ef\u89c2\u6d4b\u6027\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2512.15766", "categories": ["cs.PL", "cs.AI", "cs.DC", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.15766", "abs": "https://arxiv.org/abs/2512.15766", "authors": ["Yijie Zhi", "Yayu Cao", "Jianhua Dai", "Xiaoyang Han", "Jingwen Pu", "Qingran Wu", "Sheng Cheng", "Ming Cai"], "title": "LOOPRAG: Enhancing Loop Transformation Optimization with Retrieval-Augmented Large Language Models", "comment": "Accepted to ASPLOS 2026", "summary": "Loop transformations are semantics-preserving optimization techniques, widely used to maximize objectives such as parallelism. Despite decades of research, applying the optimal composition of loop transformations remains challenging due to inherent complexities, including cost modeling for optimization objectives. Recent studies have explored the potential of Large Language Models (LLMs) for code optimization. However, our key observation is that LLMs often struggle with effective loop transformation optimization, frequently leading to errors or suboptimal optimization, thereby missing opportunities for performance improvements. To bridge this gap, we propose LOOPRAG, a novel retrieval-augmented generation framework designed to guide LLMs in performing effective loop optimization on Static Control Part. We introduce a parameter-driven method to harness loop properties, which trigger various loop transformations, and generate diverse yet legal example codes serving as a demonstration source. To effectively obtain the most informative demonstrations, we propose a loop-aware algorithm based on loop features, which balances similarity and diversity for code retrieval. To enhance correct and efficient code generation, we introduce a feedback-based iterative mechanism that incorporates compilation, testing and performance results as feedback to guide LLMs. Each optimized code undergoes mutation, coverage and differential testing for equivalence checking. We evaluate LOOPRAG on PolyBench, TSVC and LORE benchmark suites, and compare it against compilers (GCC-Graphite, Clang-Polly, Perspective and ICX) and representative LLMs (DeepSeek and GPT-4). The results demonstrate average speedups over base compilers of up to 11.20$\\times$, 14.34$\\times$, and 9.29$\\times$ for PolyBench, TSVC, and LORE, respectively, and speedups over base LLMs of up to 11.97$\\times$, 5.61$\\times$, and 11.59$\\times$.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u548c\u5faa\u73af\u4f18\u5316\u76f8\u5173\u3002LOOPRAG\u662f\u4e00\u79cd\u65b0\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u6709\u6548\u7684\u5faa\u73af\u4f18\u5316\uff0c\u7279\u522b\u662f\u5728\u9759\u6001\u63a7\u5236\u90e8\u5206\u3002\u5b83\u901a\u8fc7\u53c2\u6570\u9a71\u52a8\u7684\u5faa\u73af\u5c5e\u6027\u3001\u5e73\u8861\u76f8\u4f3c\u6027\u548c\u591a\u6837\u6027\u7684\u5faa\u73af\u611f\u77e5\u68c0\u7d22\u7b97\u6cd5\uff0c\u4ee5\u53ca\u57fa\u4e8e\u53cd\u9988\u7684\u8fed\u4ee3\u673a\u5236\u6765\u514b\u670dLLM\u5728\u5faa\u73af\u4f18\u5316\u4e2d\u6613\u51fa\u9519\u548c\u6b21\u4f18\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5728PolyBench\u3001TSVC\u548cLORE\u4e0a\u7684\u8bc4\u4f30\uff0cLOOPRAG\u663e\u8457\u8d85\u8d8a\u4e86\u4f20\u7edf\u7f16\u8bd1\u5668\u548c\u57fa\u7840LLM\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe14.34\u500d\u7684\u52a0\u901f\u6bd4\u3002", "motivation": "\u5c3d\u7ba1\u5faa\u73af\u53d8\u6362\u662f\u5e7f\u6cdb\u4f7f\u7528\u7684\u4f18\u5316\u6280\u672f\uff0c\u4f46\u9009\u62e9\u6700\u4f73\u7684\u5faa\u73af\u53d8\u6362\u7ec4\u5408\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u90e8\u5206\u539f\u56e0\u662f\u6210\u672c\u5efa\u6a21\u7684\u590d\u6742\u6027\u3002\u867d\u7136\u6700\u8fd1\u7684\u7814\u7a76\u63a2\u7d22\u4e86LLM\u5728\u4ee3\u7801\u4f18\u5316\u4e2d\u7684\u6f5c\u529b\uff0c\u4f46\u4f5c\u8005\u89c2\u5bdf\u5230LLM\u5728\u6709\u6548\u7684\u5faa\u73af\u53d8\u6362\u4f18\u5316\u65b9\u9762\u7ecf\u5e38\u8868\u73b0\u4e0d\u4f73\uff0c\u5bb9\u6613\u51fa\u9519\u6216\u4ea7\u751f\u6b21\u4f18\u7ed3\u679c\u3002\u56e0\u6b64\uff0c\u63d0\u51faLOOPRAG\u6846\u67b6\u65e8\u5728\u901a\u8fc7\u6307\u5bfcLLM\u6765\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\uff0c\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u5faa\u73af\u4f18\u5316\u3002", "method": "LOOPRAG\u662f\u4e00\u79cd\u65b0\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u6307\u5bfcLLM\u5bf9\u9759\u6001\u63a7\u5236\u90e8\u5206\u6267\u884c\u6709\u6548\u7684\u5faa\u73af\u4f18\u5316\u3002\u8be5\u65b9\u6cd5\u5305\u62ec\uff1a1. \u5f15\u5165\u53c2\u6570\u9a71\u52a8\u65b9\u6cd5\uff0c\u5229\u7528\u5faa\u73af\u5c5e\u6027\u89e6\u53d1\u5404\u79cd\u5faa\u73af\u53d8\u6362\uff0c\u751f\u6210\u591a\u6837\u5316\u4e14\u5408\u6cd5\u7684\u793a\u4f8b\u4ee3\u7801\u4f5c\u4e3a\u6f14\u793a\u6e90\u30022. \u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5faa\u73af\u7279\u5f81\u7684\u201c\u5faa\u73af\u611f\u77e5\u201d\u7b97\u6cd5\uff0c\u7528\u4e8e\u68c0\u7d22\u6700\u5177\u4fe1\u606f\u91cf\u7684\u6f14\u793a\uff0c\u5e73\u8861\u4ee3\u7801\u68c0\u7d22\u7684\u76f8\u4f3c\u6027\u548c\u591a\u6837\u6027\u30023. \u5f15\u5165\u57fa\u4e8e\u53cd\u9988\u7684\u8fed\u4ee3\u673a\u5236\uff0c\u5305\u542b\u7f16\u8bd1\u3001\u6d4b\u8bd5\u548c\u6027\u80fd\u7ed3\u679c\u4f5c\u4e3a\u53cd\u9988\u6765\u6307\u5bfcLLM\uff0c\u4ee5\u589e\u5f3a\u4ee3\u7801\u7684\u6b63\u786e\u6027\u548c\u6548\u7387\u30024. \u5bf9\u6bcf\u4e2a\u4f18\u5316\u7684\u4ee3\u7801\u8fdb\u884c\u53d8\u5f02\u3001\u8986\u76d6\u548c\u5dee\u5f02\u6d4b\u8bd5\u4ee5\u8fdb\u884c\u7b49\u4ef7\u6027\u68c0\u67e5\u3002", "result": "\u5728PolyBench\u3001TSVC\u548cLORE\u57fa\u51c6\u5957\u4ef6\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cLOOPRAG\u76f8\u5bf9\u4e8e\u57fa\u7840\u7f16\u8bd1\u5668\uff08GCC-Graphite, Clang-Polly, Perspective\u548cICX\uff09\u83b7\u5f97\u4e86\u663e\u8457\u7684\u5e73\u5747\u52a0\u901f\u6bd4\uff1aPolyBench\u9ad8\u8fbe11.20\u500d\uff0cTSVC\u9ad8\u8fbe14.34\u500d\uff0cLORE\u9ad8\u8fbe9.29\u500d\u3002\u540c\u65f6\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7840LLM\uff08DeepSeek\u548cGPT-4\uff09\uff0c\u52a0\u901f\u6bd4\u4e5f\u9ad8\u8fbe\uff1aPolyBench 11.97\u500d\uff0cTSVC 5.61\u500d\uff0cLORE 11.59\u500d\u3002", "conclusion": "LOOPRAG\u901a\u8fc7\u5f15\u5165\u53c2\u6570\u9a71\u52a8\u7684\u5faa\u73af\u5c5e\u6027\u3001\u5e73\u8861\u76f8\u4f3c\u6027\u548c\u591a\u6837\u6027\u7684\u5faa\u73af\u611f\u77e5\u68c0\u7d22\u7b97\u6cd5\uff0c\u4ee5\u53ca\u57fa\u4e8e\u53cd\u9988\u7684\u8fed\u4ee3\u673a\u5236\uff0c\u6210\u529f\u5730\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u66f4\u6709\u6548\u5730\u8fdb\u884c\u5faa\u73af\u4f18\u5316\uff0c\u4ece\u800c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u7f16\u8bd1\u5668\u548c\u57fa\u7840LLM\u3002\u8fd9\u4e3a\u4ee3\u7801\u4f18\u5316\u9886\u57df\u4e2dLLM\u7684\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u7684\u9053\u8def\u3002"}}
{"id": "2512.16875", "categories": ["cs.DS", "cs.LG", "math.ST", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.16875", "abs": "https://arxiv.org/abs/2512.16875", "authors": ["Chao Gao", "Liren Shan", "Vaidehi Srinivas", "Aravindan Vijayaraghavan"], "title": "Learning Confidence Ellipsoids and Applications to Robust Subspace Recovery", "comment": null, "summary": "We study the problem of finding confidence ellipsoids for an arbitrary distribution in high dimensions. Given samples from a distribution $D$ and a confidence parameter $\u03b1$, the goal is to find the smallest volume ellipsoid $E$ which has probability mass $\\Pr_{D}[E] \\ge 1-\u03b1$. Ellipsoids are a highly expressive class of confidence sets as they can capture correlations in the distribution, and can approximate any convex set. This problem has been studied in many different communities. In statistics, this is the classic minimum volume estimator introduced by Rousseeuw as a robust non-parametric estimator of location and scatter. However in high dimensions, it becomes NP-hard to obtain any non-trivial approximation factor in volume when the condition number $\u03b2$ of the ellipsoid (ratio of the largest to the smallest axis length) goes to $\\infty$. This motivates the focus of our paper: can we efficiently find confidence ellipsoids with volume approximation guarantees when compared to ellipsoids of bounded condition number $\u03b2$?\n  Our main result is a polynomial time algorithm that finds an ellipsoid $E$ whose volume is within a $O(\u03b2^{\u03b3d})$ multiplicative factor of the volume of best $\u03b2$-conditioned ellipsoid while covering at least $1-O(\u03b1/\u03b3)$ probability mass for any $\u03b3< \u03b1$. We complement this with a computational hardness result that shows that such a dependence seems necessary up to constants in the exponent. The algorithm and analysis uses the rich primal-dual structure of the minimum volume enclosing ellipsoid and the geometric Brascamp-Lieb inequality. As a consequence, we obtain the first polynomial time algorithm with approximation guarantees on worst-case instances of the robust subspace recovery problem.", "AI": {"tldr": "\u672c\u6587\u4e0e**\u56fe\u5904\u7406/\u7f16\u8bd1\u5668/HLS/MLIR/DSL**\u4e0d\u76f8\u5173\u3002\n\u672c\u6587\u7814\u7a76\u4e86\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5bfb\u627e\u6700\u5c0f\u4f53\u79ef\u7f6e\u4fe1\u692d\u7403\u7684\u95ee\u9898\u3002\u7531\u4e8e\u9ad8\u7ef4\u60c5\u51b5\u4e0b\u7cbe\u786e\u6c42\u89e3\u6216\u83b7\u5f97\u975e\u5e73\u51e1\u8fd1\u4f3c\u662fNP-hard\u7684\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u5229\u7528\u6700\u5c0f\u4f53\u79ef\u5305\u56f4\u692d\u7403\u7684\u539f\u5bf9\u5076\u7ed3\u6784\u548c\u51e0\u4f55 Brascamp-Lieb \u4e0d\u7b49\u5f0f\uff0c\u5b9e\u73b0\u4e86\u5728\u4f53\u79ef\u4e0a\u6709 $O(\\beta^{\\gamma d})$ \u8fd1\u4f3c\u4fdd\u8bc1\u3001\u6982\u7387\u8986\u76d6\u7387\u8fbe\u5230 $1-O(\\alpha/\\gamma)$ \u7684\u76ee\u6807\u3002\u6b64\u5916\uff0c\u6587\u7ae0\u8bc1\u660e\u4e86\u8fd9\u79cd\u8fd1\u4f3c\u4f9d\u8d56\u5728\u65b0\u63d0\u51fa\u7684\u786c\u5ea6\u7ed3\u679c\u4e2d\u662f\u5728\u6307\u6570\u8303\u56f4\u5185\u5e38\u6570\u56e0\u5b50\u4e0b\u5fc5\u8981\u7684\uff0c\u5e76\u9996\u6b21\u4e3a\u9c81\u68d2\u5b50\u7a7a\u95f4\u6062\u590d\u95ee\u9898\u63d0\u4f9b\u4e86\u5177\u6709\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "motivation": "\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\uff0c\u5bfb\u627e\u6700\u5c0f\u4f53\u79ef\u7f6e\u4fe1\u692d\u7403\u4ee5\u4f30\u8ba1\u5206\u5e03\u7684\u4e2d\u5fc3\u4f4d\u7f6e\u548c\u5206\u6563\u5ea6\u662f\u4e00\u4e2a\u7ecf\u5178\u4e14\u91cd\u8981\u7684\u95ee\u9898\u3002\u7136\u800c\uff0c\u5f53\u692d\u7403\u7684\u6761\u4ef6\u6570 $\\beta$ \u8d8b\u4e8e\u65e0\u7a77\u5927\u65f6\uff0c\u5373\u4f7f\u662f\u975e\u5e73\u51e1\u7684\u8fd1\u4f3c\u56e0\u5b50\u5728\u4f53\u79ef\u4e0a\u4e5f\u662f NP-hard \u7684\u3002\u692d\u7403\u662f\u4e00\u79cd\u9ad8\u5ea6\u8868\u8fbe\u6027\u7684\u7f6e\u4fe1\u96c6\uff0c\u56e0\u4e3a\u5b83\u80fd\u6355\u6349\u5206\u5e03\u4e2d\u7684\u76f8\u5173\u6027\uff0c\u5e76\u80fd\u8fd1\u4f3c\u4efb\u4f55\u51f8\u96c6\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u63a2\u7d22\u5728\u4f53\u79ef\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u9ad8\u6548\u5730\u627e\u5230\u5177\u6709\u6709\u754c\u6761\u4ef6\u6570 $\\beta$ \u7684\u7f6e\u4fe1\u692d\u7403\u3002\u8fd9\u4e2a\u95ee\u9898\u5728\u9ad8\u7ef4\u9c81\u68d2\u4f30\u8ba1\u548c\u9c81\u68d2\u5b50\u7a7a\u95f4\u6062\u590d\u4e2d\u5c24\u5176\u5173\u952e\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5bfb\u627e\u7f6e\u4fe1\u692d\u7403\u3002\u8be5\u7b97\u6cd5\u7684\u6838\u5fc3\u662f\u5229\u7528\u6700\u5c0f\u4f53\u79ef\u5305\u56f4\u692d\u7403\uff08MVEE\uff09\u7684\u4e30\u5bcc\u539f\u5bf9\u5076\u7ed3\u6784\u548c\u51e0\u4f55 Brascamp-Lieb \u4e0d\u7b49\u5f0f\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u7b97\u6cd5\u53ef\u4ee5\u627e\u5230\u4e00\u4e2a\u692d\u7403 $E$\uff0c\u5176\u4f53\u79ef\u4e0e\u5177\u6709\u6709\u754c\u6761\u4ef6\u6570 $\\beta$ \u7684\u6700\u4f73\u692d\u7403\u76f8\u6bd4\uff0c\u5177\u6709 $O(\\beta^{\\gamma d})$ \u7684\u4e58\u6027\u8fd1\u4f3c\u56e0\u5b50\uff0c\u5e76\u4e14\u8986\u76d6\u81f3\u5c11 $1-O(\\alpha/\\gamma)$ \u7684\u6982\u7387\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u901a\u8fc7\u8ba1\u7b97\u786c\u5ea6\u7ed3\u679c\u6765\u8865\u5145\u8bf4\u660e\uff0c\u8bc1\u660e\u4e86\u8fd9\u79cd\u6307\u6570\u7ea7\u7684\u4f9d\u8d56\u5173\u7cfb\u53ef\u80fd\u662f\u5fc5\u8981\u7684\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684\u4e3b\u8981\u7ed3\u679c\u662f\u4e00\u4e2a\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u5b83\u80fd\u627e\u5230\u4e00\u4e2a\u692d\u7403 $E$\uff0c\u8be5\u692d\u7403\u7684\u4f53\u79ef\u4e0e\u6700\u4f73 $\\beta$ \u6761\u4ef6\u692d\u7403\u7684\u4f53\u79ef\u76f8\u6bd4\uff0c\u5728 $O(\\beta^{\\gamma d})$ \u7684\u4e58\u6027\u56e0\u5b50\u5185\uff0c\u540c\u65f6\u8986\u76d6\u81f3\u5c11 $1-O(\\alpha/\\gamma)$ \u7684\u6982\u7387\u8d28\u91cf\uff0c\u5176\u4e2d $\\gamma < \\alpha$\u3002\u7814\u7a76\u8fd8\u901a\u8fc7\u4e00\u4e2a\u8ba1\u7b97\u786c\u5ea6\u7ed3\u679c\u6765\u4f50\u8bc1\uff0c$O(\\beta^{\\gamma d})$\u8fd9\u79cd\u6307\u6570\u4f9d\u8d56\u662f\u5fc5\u8981\u7684\uff08\u8fbe\u5230\u6307\u6570\u4e2d\u7684\u5e38\u6570\uff09\u3002\u6b64\u5916\uff0c\u8fd9\u4e00\u7b97\u6cd5\u8fd8\u4f7f\u5f97\u9c81\u68d2\u5b50\u7a7a\u95f4\u6062\u590d\u95ee\u9898\u5728\u6700\u574f\u60c5\u51b5\u5b9e\u4f8b\u4e0a\u83b7\u5f97\u4e86\u7b2c\u4e00\u4e2a\u5177\u6709\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u9ad8\u7ef4\u7a7a\u95f4\u4e2d\u5bfb\u627e\u7f6e\u4fe1\u692d\u7403\u7684\u95ee\u9898\u3002\u5b83\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u8fd0\u884c\u7684\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u4f53\u79ef\u4e0a\u5177\u6709$O(\\beta^{\\gamma d})$\u7684\u8fd1\u4f3c\u4fdd\u8bc1\uff0c\u5e76\u8986\u76d6\u81f3\u5c11$1-O(\\alpha/\\gamma)$\u7684\u6982\u7387\u8d28\u91cf\u3002\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u6700\u5c0f\u4f53\u79ef\u5305\u56f4\u692d\u7403\u7684\u5bf9\u5076\u7ed3\u6784\u548c\u51e0\u4f55 Brascamp-Lieb \u4e0d\u7b49\u5f0f\u3002\u8fd9\u9879\u5de5\u4f5c\u4e3a\u9ad8\u7ef4\u9c81\u68d2\u4f30\u8ba1\u548c\u5b50\u7a7a\u95f4\u6062\u590d\u95ee\u9898\u63d0\u4f9b\u4e86\u7b2c\u4e00\u4e2a\u5177\u6709\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u591a\u9879\u5f0f\u65f6\u95f4\u7b97\u6cd5\uff0c\u4e3a\u5904\u7406\u9ad8\u7ef4\u6570\u636e\u4e2d\u7684\u76f8\u5173\u6027\u548c\u8fd1\u4f3c\u6027\u95ee\u9898\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.16045", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.16045", "abs": "https://arxiv.org/abs/2512.16045", "authors": ["Vincent T. Lee", "Tanfer Alan", "Sung Kim", "Ecenur Ustun", "Amr Suleiman", "Ajit Krisshna", "Tim Balbekov", "Armin Alaghi", "Richard Newcombe"], "title": "Full System Architecture Modeling for Wearable Egocentric Contextual AI", "comment": "13 pages, 3 tables, 6 figures, technical report", "summary": "The next generation of human-oriented computing will require always-on, spatially-aware wearable devices to capture egocentric vision and functional primitives (e.g., Where am I? What am I looking at?, etc.). These devices will sense an egocentric view of the world around us to observe all human- relevant signals across space and time to construct and maintain a user's personal context. This personal context, combined with advanced generative AI, will unlock a powerful new generation of contextual AI personal assistants and applications. However, designing a wearable system to support contextual AI is a daunting task because of the system's complexity and stringent power constraints due to weight and battery restrictions. To understand how to guide design for such systems, this work provides the first complete system architecture view of one such wearable contextual AI system (Aria2), along with the lessons we have learned through the system modeling and design space exploration process. We show that an end-to-end full system model view of such systems is vitally important, as no single component or category overwhelmingly dominates system power. This means long-range design decisions and power optimizations need to be made in the full system context to avoid running into limits caused by other system bottlenecks (i.e., Amdahl's law as applied to power) or as bottlenecks change. Finally, we reflect on lessons and insights for the road ahead, which will be important toward eventually enabling all-day, wearable, contextual AI systems.", "AI": {"tldr": "This paper is related to **Compiler** and **HLS** by discussing system-level design and optimization for a complex wearable device, which often involves specialized hardware and compilation flows for efficiency. The *system modeling* and *design space exploration* are closely related to how compiler/HLS tools map high-level functions to power/performance-efficient implementations (though the paper does not explicitly detail the compiler structure, the full-system power analysis directly dictates the needs for aggressive optimization by specialized tools). The paper is also broadly related to **edge device/system design** which often leverages efficient **MLIR**-like intermediate representations or specific graph processing techniques for ML tasks. / The paper analyzes the complete system architecture of a wearable contextual AI system (Aria2) and the lessons learned from its design space exploration. Key findings show that no single component dominates system power, necessitating end-to-end full system modeling and long-range design decisions to achieve power efficiency for future all-day wearable AI devices, emphasizing that optimizations must consider the overall system context (Amdahl's law for power).", "motivation": "\u6784\u5efa\u4e0b\u4e00\u4ee3\u9762\u5411\u4eba\u7c7b\u7684\u8ba1\u7b97\u9700\u8981\u5168\u5929\u5019\u3001\u5177\u5907\u7a7a\u95f4\u611f\u77e5\u80fd\u529b\u7684\u53ef\u7a7f\u6234\u8bbe\u5907\u6765\u6355\u6349\u81ea\u6211\u4e2d\u5fc3\u89c6\u89c9\u548c\u529f\u80fd\u6027\u57fa\u672c\u4fe1\u606f\uff0c\u5e76\u4ee5\u6b64\u6784\u5efa\u548c\u7ef4\u62a4\u7528\u6237\u7684\u201c\u4e2a\u4eba\u8bed\u5883\u201d\u3002\u5c06\u8fd9\u79cd\u4e2a\u4eba\u8bed\u5883\u4e0e\u5148\u8fdb\u7684\u751f\u6210\u5f0fAI\u7ed3\u5408\uff0c\u53ef\u4ee5\u89e3\u9501\u5f3a\u5927\u7684\u65b0\u4e00\u4ee3\u60c5\u5883\u5316AI\u4e2a\u4eba\u52a9\u7406\u548c\u5e94\u7528\u3002\u7136\u800c\uff0c\u7531\u4e8e\u7cfb\u7edf\u7684\u590d\u6742\u6027\u548c\u4e25\u683c\u7684\u529f\u8017\u9650\u5236\uff08\u53d7\u9650\u4e8e\u7535\u6c60\u548c\u91cd\u91cf\uff09\uff0c\u8bbe\u8ba1\u652f\u6301\u8fd9\u79cd\u8bed\u5883\u5316AI\u7684\u53ef\u7a7f\u6234\u7cfb\u7edf\u662f\u4e00\u4e2a\u5de8\u5927\u7684\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5982\u4f55\u6307\u5bfc\u6b64\u7c7b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3002", "method": "\u8fd9\u9879\u7814\u7a76\u65b9\u6cd5\u4e0a\u662f\u63d0\u4f9b\u4e00\u4e2a\u5177\u4f53\u7684\u7a7f\u6234\u5f0f\u8bed\u5883\u5316\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff08Aria2\uff09\u7684\u5b8c\u6574\u7cfb\u7edf\u67b6\u6784\u89c6\u56fe\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u5efa\u6a21\u548c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u7684\u8fc7\u7a0b\u6765\u63d0\u53d6\u7ecf\u9a8c\u6559\u8bad\uff0c\u4ece\u800c\u6307\u5bfc\u672a\u6765\u6b64\u7c7b\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3002\u5b83\u7740\u91cd\u4e8e\u7aef\u5230\u7aef\u7684\u5168\u7cfb\u7edf\u89c6\u89d2\u5206\u6790\u529f\u8017\u5206\u5e03\u548c\u8bbe\u8ba1\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u7a7f\u6234\u5f0f\u8bed\u5883\u5316AI\u7cfb\u7edf\uff08Aria2\uff09\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u5e76\u5f97\u51fa\u4e86\u5173\u952e\u7ed3\u679c\uff1a\u7aef\u5230\u7aef\u7684\u5168\u7cfb\u7edf\u6a21\u578b\u89c6\u56fe\u5bf9\u4e8e\u6b64\u7c7b\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3a\u6ca1\u6709\u5355\u4e00\u7ec4\u4ef6\u6216\u7c7b\u522b\u7edd\u5bf9\u4e3b\u5bfc\u7cfb\u7edf\u529f\u8017\u3002\u8fd9\u610f\u5473\u7740\u957f\u671f\u7684\u8bbe\u8ba1\u51b3\u7b56\u548c\u529f\u8017\u4f18\u5316\u5fc5\u987b\u5728\u5b8c\u6574\u7684\u7cfb\u7edf\u8bed\u5883\u4e0b\u8fdb\u884c\uff0c\u4ee5\u907f\u514d\u53d7\u9650\u4e8e\u5176\u4ed6\u7cfb\u7edf\u74f6\u9888\uff08\u5982\u529f\u8017\u9886\u57df\u7684\u963f\u59c6\u8fbe\u5c14\u5b9a\u5f8b\u6216\u74f6\u9888\u8f6c\u79fb\uff09\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7528\u4e8e\u6784\u5efa\u5168\u5929\u5019\u3001\u53ef\u7a7f\u6234\u3001\u8bed\u5883\u5316\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff08\u5982 Aria2\uff09\u7684\u7cfb\u7edf\u67b6\u6784\u89c6\u56fe\u548c\u8bbe\u8ba1\u7ecf\u9a8c\u3002\u6838\u5fc3\u7ed3\u8bba\u662f\uff0c\u5bf9\u4e8e\u6b64\u7c7b\u590d\u6742\u4e14\u529f\u8017\u53d7\u9650\u7684\u7cfb\u7edf\uff0c\u5fc5\u987b\u91c7\u7528\u7aef\u5230\u7aef\u7684\u5168\u7cfb\u7edf\u5efa\u6a21\u548c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u56e0\u4e3a\u7cfb\u7edf\u529f\u8017\u5e76\u975e\u7531\u5355\u4e00\u7ec4\u4ef6\u4e3b\u5bfc\uff0c\u4f18\u5316\u5fc5\u987b\u5728\u6574\u4f53\u7cfb\u7edf\u8bed\u5883\u4e0b\u8fdb\u884c\u3002\u672a\u6765\u7684\u5de5\u4f5c\u9700\u8981\u6301\u7eed\u5173\u6ce8\u8de8\u7ec4\u4ef6\u7684\u534f\u540c\u8bbe\u8ba1\u548c\u529f\u8017\u4f18\u5316\uff0c\u4ee5\u6700\u7ec8\u5b9e\u73b0\u5168\u5929\u5019\u53ef\u7528\u7684\u8bbe\u5907\u3002"}}
{"id": "2512.16056", "categories": ["cs.DC", "cs.NI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.16056", "abs": "https://arxiv.org/abs/2512.16056", "authors": ["Lingfeng Tang", "Daoping Zhang", "Junjie Chen", "Peihao Huang", "Feng Jin", "Chengguang Xu", "Yuxin Chen", "Feiqiang Sun", "Guo Chen"], "title": "MultiPath Transfer Engine: Breaking GPU and Host-Memory Bandwidth Bottlenecks in LLM Services", "comment": null, "summary": "The limited bandwidth of PCIe has emerged as the critical bottleneck for large language model (LLM) performance, such as prefix cache fetching and model switching. Although intra-server multipath data transfer between GPU and host memory is theoretically possible, heterogeneous protocols such as PCIe and NVLink currently limit the bandwidth between host memory and GPUs to that of a single PICe link. This limitation resuals in underutilized intra-server bandwidth. To address this issue, we propose Multipath Memory Access (MMA), a scheme that, to the best of our knowledge, is the first to enalbe efficient multipath data transfer between GPU and host memory. MMA supports seamless deployment via dynamic library injection, enabling LLM applications to benefit from MMA without requiring any code modification. In our testbed, MMA significantly improves the data transfer bandwidth between the GPU and memory, achieving a peak bandwidth of 245 GB/s-representing a 4.62x speedup compared to the natice single-path bandwidth. End-to-end evaluations demonstrate that MMA reduces the time-to-first-token (TTFT) for LLM serving by 1.14x to 2.38x and decreases model-switching latency in vLLM's sleep mode by 1.12x to 2.48x.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\uff08compiler\uff09\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u6d89\u53ca\u5230LLM\u670d\u52a1\u7684\u6027\u80fd\u4f18\u5316\u548c\u7cfb\u7edf\u7ea7\u7684\u6570\u636e\u4f20\u8f93\u673a\u5236\uff0c\u8fd9\u5728\u5e7f\u4e49\u4e0a\u5c5e\u4e8e\u7f16\u8bd1\u548c\u7cfb\u7edf\u4f18\u5316\u7684\u8303\u7574\uff0c\u5c3d\u7ba1\u5b83\u66f4\u4fa7\u91cd\u4e8e**\u7cfb\u7edf\u548c\u786c\u4ef6**\u5c42\u9762\u7684\u4f18\u5316\u3002\u672c\u6587\u63d0\u51fa\u591a\u8def\u5f84\u5185\u5b58\u8bbf\u95ee\uff08MMA\uff09\u65b9\u6848\uff0c\u5229\u7528\u670d\u52a1\u5668\u5185\u591a\u8def\u5f84\u8fde\u63a5\uff08\u5982PCIe\u548cNVLink\uff09\u5b9e\u73b0GPU\u4e0e\u4e3b\u673a\u5185\u5b58\u95f4\u9ad8\u6548\u6570\u636e\u4f20\u8f93\u3002MMA\u901a\u8fc7\u52a8\u6001\u5e93\u6ce8\u5165\uff0c\u65e0\u9700\u4ee3\u7801\u4fee\u6539\u5373\u53ef\u90e8\u7f72\uff0c\u5b9e\u73b0245GB/s\u7684\u4f20\u8f93\u5e26\u5bbd\uff084.62\u500d\u52a0\u901f\uff09\u3002\u7aef\u5230\u7aef\u6d4b\u8bd5\u8868\u660e\uff0cMMA\u5c06LLM\u670d\u52a1\u7684TTFT\u7f29\u77ed1.14x-2.38x\uff0c\u6a21\u578b\u5207\u6362\u5ef6\u8fdf\u964d\u4f4e1.12x-2.48x\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6027\u80fd\u53d7\u5230PCIe\u5e26\u5bbd\u7684\u9650\u5236\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u524d\u7f00\u7f13\u5b58\u83b7\u53d6\u548c\u6a21\u578b\u5207\u6362\u7b49\u573a\u666f\u3002\u867d\u7136\u670d\u52a1\u5668\u5185\u90e8\u7406\u8bba\u4e0a\u5b58\u5728GPU\u4e0e\u4e3b\u673a\u5185\u5b58\u4e4b\u95f4\u7684\u591a\u8def\u5f84\u6570\u636e\u4f20\u8f93\u80fd\u529b\uff0c\u4f46\u5f02\u6784\u534f\u8bae\uff08\u5982PCIe\u548cNVLink\uff09\u7684\u9650\u5236\u5bfc\u81f4\u5b9e\u9645\u5e26\u5bbd\u4ec5\u9650\u4e8e\u5355\u4e2aPCIe\u94fe\u8def\uff0c\u9020\u6210\u670d\u52a1\u5668\u5185\u90e8\u5e26\u5bbd\u7684\u672a\u5145\u5206\u5229\u7528\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5145\u5206\u5229\u7528\u591a\u8def\u5f84\u5e26\u5bbd\u6765\u52a0\u901fGPU\u4e0e\u4e3b\u673a\u5185\u5b58\u4e4b\u95f4\u6570\u636e\u4f20\u8f93\u7684\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u591a\u8def\u5f84\u5185\u5b58\u8bbf\u95ee\uff08Multipath Memory Access, MMA\uff09\u65b9\u6848\u3002MMA\u5229\u7528\u670d\u52a1\u5668\u5185\u7684\u591a\u8def\u5f84\u8fde\u63a5\uff08\u5982PCle\u548cNVLink\uff09\u6765\u5b9e\u73b0GPU\u548c\u4e3b\u673a\u5185\u5b58\u4e4b\u95f4\u7684\u9ad8\u6548\u6570\u636e\u4f20\u8f93\uff0c\u6253\u7834\u4e86\u4f20\u7edf\u5355\u8def\u5f84PCIe\u5e26\u5bbd\u7684\u9650\u5236\u3002\u8be5\u65b9\u6848\u901a\u8fc7\u52a8\u6001\u5e93\u6ce8\u5165\u7684\u65b9\u5f0f\u5b9e\u73b0\uff0c\u65e0\u9700\u4fee\u6539LLM\u5e94\u7528\u7a0b\u5e8f\u4ee3\u7801\u5373\u53ef\u90e8\u7f72\u3002", "result": "\u5728\u6d4b\u8bd5\u73af\u5883\u4e2d\uff0cMMA\u5c06GPU\u4e0e\u5185\u5b58\u4e4b\u95f4\u7684\u6570\u636e\u4f20\u8f93\u5e26\u5bbd\u63d0\u5347\u81f3245 GB/s\uff0c\u76f8\u6bd4\u539f\u751f\u5355\u8def\u5f84\u5e26\u5bbd\u5b9e\u73b0\u4e864.62\u500d\u7684\u52a0\u901f\u3002\u7aef\u5230\u7aef\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cMMA\u5c06LLM\u670d\u52a1\u7684\u9996\u4e2aToken\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u7f29\u77ed\u4e861.14\u500d\u81f32.38\u500d\uff0c\u5e76\u5c06vLLM\u4f11\u7720\u6a21\u5f0f\u4e0b\u7684\u6a21\u578b\u5207\u6362\u5ef6\u8fdf\u964d\u4f4e\u4e861.12\u500d\u81f32.48\u500d\u3002", "conclusion": "MMA\u901a\u8fc7\u52a8\u6001\u5e93\u6ce8\u5165\u7684\u65b9\u5f0f\u5b9e\u73b0\u4e86GPU\u4e0e\u4e3b\u673a\u5185\u5b58\u4e4b\u95f4\u7684\u9ad8\u6548\u591a\u8def\u5f84\u6570\u636e\u4f20\u8f93\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u4f20\u8f93\u5e26\u5bbd\uff0c\u5e76\u5728LLM\u670d\u52a1\u4e2d\u964d\u4f4e\u4e86TTFT\u548c\u6a21\u578b\u5207\u6362\u5ef6\u8fdf\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u89e3\u51b3LLM\u6027\u80fd\u74f6\u9888\u65b9\u9762\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.15788", "categories": ["cs.PL", "cs.FL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.15788", "abs": "https://arxiv.org/abs/2512.15788", "authors": ["Anastasia Mavridou", "Marie Farrell", "Gricel V\u00e1zquez", "Tom Pressburger", "Timothy E. Wang", "Radu Calinescu", "Michael Fisher"], "title": "Automated Formalization of Probabilistic Requirements from Structured Natural Language", "comment": "Official website https://github.com/NASA-SW-VnV/fret/releases/tag/v3.0.0", "summary": "Integrating autonomous and adaptive behavior into software-intensive systems presents significant challenges for software development, as uncertainties in the environment or decision-making processes must be explicitly captured. These challenges are amplified in safety- and mission-critical systems, which must undergo rigorous scrutiny during design and development. Key among these challenges is the difficulty of specifying requirements that use probabilistic constructs to capture the uncertainty affecting these systems. To enable formal analysis, such requirements must be expressed in precise mathematical notations such as probabilistic logics. However, expecting developers to write requirements directly in complex formalisms is unrealistic and highly error-prone. We extend the structured natural language used by NASA's Formal Requirement Elicitation Tool (FRET) with support for the specification of unambiguous and correct probabilistic requirements, and develop an automated approach for translating these requirements into logical formulas. We propose and develop a formal, compositional, and automated approach for translating structured natural-language requirements into formulas in probabilistic temporal logic. To increase trust in our formalizations, we provide assurance that the generated formulas are well-formed and conform to the intended semantics through an automated validation framework and a formal proof. The extended FRET tool enables developers to specify probabilistic requirements in structured natural language, and to automatically translate them into probabilistic temporal logic, making the formal analysis of autonomous and adaptive systems more practical and less error-prone.", "AI": {"tldr": "\u8fd9\u4e2a\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\uff0c\u5b83\u662f\u4e00\u79cd\u7528\u4e8e\u5c06\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\u4e3a\u5f62\u5f0f\u5316\u903b\u8f91\u516c\u5f0f\u7684\u5de5\u5177\uff0c\u53ef\u4ee5\u770b\u4f5c\u662f\u4e00\u79cd\u9ad8\u7ea7\u7684\u8bed\u8a00\u5904\u7406\u548c\u8f6c\u6362\u3002\n\u81ea\u4e3b\u548c\u81ea\u9002\u5e94\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u4f7f\u5f97\u9700\u6c42\u89c4\u7ea6\u975e\u5e38\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u5f62\u5f0f\u5316\u5206\u6790\u7684\u6982\u7387\u9700\u6c42\u65b9\u9762\u3002\u7531\u4e8e\u8981\u6c42\u5f00\u53d1\u4eba\u5458\u76f4\u63a5\u7528\u590d\u6742\u7684\u6982\u7387\u903b\u8f91\u7f16\u5199\u9700\u6c42\u4e0d\u5207\u5b9e\u9645\u4e14\u5bb9\u6613\u51fa\u9519\uff0c\u672c\u6587\u6269\u5c55\u4e86 NASA FRET \u5de5\u5177\uff0c\u4f7f\u5176\u80fd\u591f\u652f\u6301\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u7684\u6982\u7387\u9700\u6c42\u89c4\u7ea6\uff0c\u5e76\u5f00\u53d1\u4e86\u4e00\u79cd\u5f62\u5f0f\u5316\u3001\u7ec4\u5408\u5f0f\u548c\u81ea\u52a8\u5316\u7684\u65b9\u6cd5\uff0c\u5c06\u8fd9\u4e9b\u7ed3\u6784\u5316\u9700\u6c42\u7ffb\u8bd1\u6210\u6982\u7387\u65f6\u6001\u903b\u8f91\u516c\u5f0f\u3002\u901a\u8fc7\u63d0\u4f9b\u81ea\u52a8\u9a8c\u8bc1\u6846\u67b6\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u786e\u4fdd\u4e86\u751f\u6210\u516c\u5f0f\u7684\u6b63\u786e\u6027\u3002\u8fd9\u4f7f\u5f97\u81ea\u4e3b\u548c\u81ea\u9002\u5e94\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u5206\u6790\u66f4\u52a0\u5b9e\u7528\u4e14\u4e0d\u6613\u51fa\u9519\u3002", "motivation": "\u5728\u8f6f\u4ef6\u5bc6\u96c6\u578b\u7cfb\u7edf\u4e2d\u96c6\u6210\u81ea\u4e3b\u548c\u81ea\u9002\u5e94\u884c\u4e3a\u5bf9\u8f6f\u4ef6\u5f00\u53d1\u6784\u6210\u91cd\u5927\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u5173\u952e\u548c\u4efb\u52a1\u5173\u952e\u7cfb\u7edf\u4e2d\uff0c\u56e0\u4e3a\u9700\u8981\u660e\u786e\u6355\u6349\u73af\u5883\u6216\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u3002\u7528\u6982\u7387\u7ed3\u6784\u6765\u6355\u6349\u5f71\u54cd\u8fd9\u4e9b\u7cfb\u7edf\u7684\u4e0d\u786e\u5b9a\u6027\u9700\u6c42\u89c4\u7ea6\u975e\u5e38\u56f0\u96be\u3002\u8981\u6c42\u5f00\u53d1\u4eba\u5458\u76f4\u63a5\u4f7f\u7528\u590d\u6742\u7684\u6982\u7387\u903b\u8f91\u7b49\u5f62\u5f0f\u5316\u8bed\u8a00\u6765\u7f16\u5199\u9700\u6c42\u662f\u4e0d\u73b0\u5b9e\u4e14\u5bb9\u6613\u51fa\u9519\u7684\u3002", "method": "\u6269\u5c55\u4e86 NASA FRET \u5de5\u5177\u4ee5\u652f\u6301\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u7684\u6982\u7387\u9700\u6c42\u89c4\u7ea6\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u81ea\u52a8\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u8fd9\u4e9b\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u8f6c\u5316\uff08\u7ffb\u8bd1\uff09\u4e3a\u6982\u7387\u65f6\u6001\u903b\u8f91\u516c\u5f0f\u3002\u63d0\u51fa\u4e86\u5f62\u5f0f\u5316\u3001\u7ec4\u5408\u5f0f\u548c\u81ea\u52a8\u5316\u7684\u7ffb\u8bd1\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u7684\u9a8c\u8bc1\u6846\u67b6\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\u6765\u63d0\u9ad8\u5bf9\u8f6c\u5316\u7ed3\u679c\u7684\u4fe1\u4efb\u3002", "result": "\u6210\u529f\u6269\u5c55\u4e86 FRET \u5de5\u5177\uff0c\u4f7f\u5176\u80fd\u591f\u652f\u6301\u4f7f\u7528\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u89c4\u7ea6\u65e0\u6b67\u4e49\u4e14\u6b63\u786e\u7684\u6982\u7387\u9700\u6c42\uff0c\u5e76\u80fd\u81ea\u52a8\u5c06\u8fd9\u4e9b\u9700\u6c42\u7ffb\u8bd1\u6210\u6982\u7387\u65f6\u6001\u903b\u8f91\u516c\u5f0f\u3002\u6240\u63d0\u51fa\u7684\u7ffb\u8bd1\u65b9\u6cd5\u662f\u5f62\u5f0f\u5316\u3001\u7ec4\u5408\u5f0f\u548c\u81ea\u52a8\u5316\u7684\u3002\u901a\u8fc7\u81ea\u52a8\u9a8c\u8bc1\u6846\u67b6\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u8bc1\u660e\u4e86\u6240\u751f\u6210\u516c\u5f0f\u7684\u826f\u6784\u6027\u548c\u7b26\u5408\u9884\u671f\u8bed\u4e49\uff0c\u589e\u52a0\u4e86\u5bf9\u5f62\u5f0f\u5316\u7ed3\u679c\u7684\u4fe1\u4efb\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6269\u5c55 NASA \u7684 FRET \u5de5\u5177\uff0c\u4f7f\u5176\u652f\u6301\u7ed3\u6784\u5316\u81ea\u7136\u8bed\u8a00\u7684\u6982\u7387\u9700\u6c42\u89c4\u7ea6\uff0c\u5e76\u5c06\u8fd9\u4e9b\u9700\u6c42\u81ea\u52a8\u7ffb\u8bd1\u6210\u6982\u7387\u65f6\u6001\u903b\u8f91\u516c\u5f0f\uff0c\u4ece\u800c\u4f7f\u81ea\u4e3b\u548c\u81ea\u9002\u5e94\u7cfb\u7edf\u4e2d\u7684\u5f62\u5f0f\u5316\u5206\u6790\u66f4\u52a0\u5b9e\u7528\u4e14\u4e0d\u6613\u51fa\u9519\u3002\u901a\u8fc7\u63d0\u4f9b\u81ea\u52a8\u9a8c\u8bc1\u6846\u67b6\u548c\u5f62\u5f0f\u5316\u8bc1\u660e\uff0c\u786e\u4fdd\u4e86\u751f\u6210\u516c\u5f0f\u7684\u6b63\u786e\u6027\u3002"}}
{"id": "2512.15816", "categories": ["cs.PL", "cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.15816", "abs": "https://arxiv.org/abs/2512.15816", "authors": ["Daragh King", "Vasileios Koutavas", "Laura Kovacs"], "title": "A Neurosymbolic Approach to Loop Invariant Generation via Weakest Precondition Reasoning", "comment": null, "summary": "Loop invariant generation remains a critical bottleneck in automated program verification. Recent work has begun to explore the use of Large Language Models (LLMs) in this area, yet these approaches tend to lack a reliable and structured methodology, with little reference to existing program verification theory. This paper presents NeuroInv, a neurosymbolic approach to loop invariant generation. NeuroInv comprises two key modules: (1) a neural reasoning module that leverages LLMs and Hoare logic to derive and refine candidate invariants via backward-chaining weakest precondition reasoning, and (2) a verification-guided symbolic module that iteratively repairs invariants using counterexamples from OpenJML. We evaluate NeuroInv on a comprehensive benchmark of 150 Java programs, encompassing single and multiple (sequential) loops, multiple arrays, random branching, and noisy code segments. NeuroInv achieves a $99.5\\%$ success rate, substantially outperforming the other evaluated approaches. Additionally, we introduce a hard benchmark of $10$ larger multi-loop programs (with an average of $7$ loops each); NeuroInv's performance in this setting demonstrates that it can scale to more complex verification scenarios.", "AI": {"tldr": "\u672c\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\u3002\u5b83\u63a2\u8ba8\u4e86\u4f7f\u7528\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff08NeuroInv\uff09\u751f\u6210\u5faa\u73af\u4e0d\u53d8\u91cf\uff0c\u8fd9\u662f\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u3002NeuroInv \u7ed3\u5408\u4e86 LLM \u548c\u970d\u5c14\u903b\u8f91\u8fdb\u884c\u4e0d\u53d8\u91cf\u63a8\u5bfc\u548c\u4f18\u5316\uff0c\u5e76\u4f7f\u7528\u9a8c\u8bc1\u5de5\u5177\u7684\u53cd\u4f8b\u8fdb\u884c\u4fee\u590d\u3002\u5728\u5305\u542b 150 \u4e2a Java \u7a0b\u5e8f\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNeuroInv \u53d6\u5f97\u4e86 99.5% \u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u5e76\u663e\u793a\u51fa\u5904\u7406\u66f4\u590d\u6742\u591a\u5faa\u73af\u7a0b\u5e8f\u7684\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5faa\u73af\u4e0d\u53d8\u91cf\u7684\u751f\u6210\u4ecd\u7136\u662f\u81ea\u52a8\u5316\u7a0b\u5e8f\u9a8c\u8bc1\u4e2d\u7684\u5173\u952e\u74f6\u9888\u3002\u5c3d\u7ba1\u6700\u8fd1\u7684\u5de5\u4f5c\u5f00\u59cb\u63a2\u7d22\u5728\u8fd9\u4e00\u9886\u57df\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u5f80\u5f80\u7f3a\u4e4f\u53ef\u9760\u548c\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\u8bba\uff0c\u5e76\u4e14\u5f88\u5c11\u53c2\u8003\u73b0\u6709\u7684\u7a0b\u5e8f\u9a8c\u8bc1\u7406\u8bba\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7ed3\u5408 LLM \u548c\u7a0b\u5e8f\u9a8c\u8bc1\u7406\u8bba\u7684\u3001\u7ed3\u6784\u5316\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u74f6\u9888\u3002", "method": "NeuroInv \u5305\u542b\u4e24\u4e2a\u5173\u952e\u6a21\u5757\uff1a\uff081\uff09\u795e\u7ecf\u63a8\u7406\u6a21\u5757\uff1a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u970d\u5c14\u903b\u8f91\uff08Hoare logic\uff09\uff0c\u901a\u8fc7\u53cd\u5411\u94fe\u5f0f\u6700\u5f31\u524d\u7f6e\u6761\u4ef6\u63a8\u7406\uff08backward-chaining weakest precondition reasoning\uff09\u6765\u63a8\u5bfc\u548c\u4f18\u5316\u5019\u9009\u4e0d\u53d8\u91cf\u3002\uff082\uff09\u9a8c\u8bc1\u5f15\u5bfc\u7684\u7b26\u53f7\u6a21\u5757\uff1a\u5229\u7528\u6765\u81ea OpenJML \u7684\u53cd\u4f8b\uff08counterexamples\uff09\u8fed\u4ee3\u5730\u4fee\u590d\u4e0d\u53d8\u91cf\u3002\u8be5\u65b9\u6cd5\u5728 150 \u4e2a Java \u7a0b\u5e8f\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5305\u62ec\u5355\u5faa\u73af\u548c\u591a\u5faa\u73af\u3001\u591a\u4e2a\u6570\u7ec4\u3001\u968f\u673a\u5206\u652f\u548c\u5e26\u566a\u58f0\u7684\u4ee3\u7801\u6bb5\uff0c\u5e76\u989d\u5916\u5f15\u5165\u4e86 10 \u4e2a\u66f4\u5927\u7684\u591a\u5faa\u73af\u7a0b\u5e8f\u7684\u56f0\u96be\u57fa\u51c6\u3002", "result": "NeuroInv \u5728\u5305\u542b\u5355\u5faa\u73af\u548c\u591a\u5faa\u73af\u3001\u591a\u4e2a\u6570\u7ec4\u3001\u968f\u673a\u5206\u652f\u548c\u5e26\u566a\u58f0\u4ee3\u7801\u6bb5\u7684 150 \u4e2a Java \u7a0b\u5e8f\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u53d6\u5f97\u4e86 99.5% \u7684\u6210\u529f\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u88ab\u8bc4\u4f30\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u5728\u5305\u542b 10 \u4e2a\u5927\u578b\u591a\u5faa\u73af\u7a0b\u5e8f\u7684\u56f0\u96be\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cNeuroInv \u7684\u8868\u73b0\u8bc1\u660e\u4e86\u5176\u53ef\u4ee5\u6269\u5c55\u5230\u66f4\u590d\u6742\u7684\u9a8c\u8bc1\u573a\u666f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684 NeuroInv \u662f\u4e00\u79cd\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408 LLM \u548c\u5f62\u5f0f\u9a8c\u8bc1\u7406\u8bba\uff0c\u5f25\u8865\u4e86\u5148\u524d LLM \u65b9\u6cd5\u5728\u7ed3\u6784\u5316\u548c\u7406\u8bba\u4f9d\u636e\u4e0a\u7684\u4e0d\u8db3\u3002NeuroInv \u5728\u5305\u542b\u5355\u5faa\u73af\u548c\u591a\u5faa\u73af\u7684\u590d\u6742\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86 99.5% \u7684\u6210\u529f\u7387\uff0c\u5e76\u5728\u66f4\u590d\u6742\u7684\u9a8c\u8bc1\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u5176\u53ef\u6269\u5c55\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\uff0c\u8868\u660e\u4e86\u5c06 LLM \u4e0e\u7a0b\u5e8f\u9a8c\u8bc1\u7406\u8bba\u76f8\u7ed3\u5408\u751f\u6210\u5faa\u73af\u4e0d\u53d8\u91cf\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.16066", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.16066", "abs": "https://arxiv.org/abs/2512.16066", "authors": ["Syed Salauddin Mohammad Tariq", "Foyzul Hassan", "Amiangshu Bosu", "Probir Roy"], "title": "Cold-Start Anti-Patterns and Refactorings in Serverless Systems: An Empirical Study", "comment": null, "summary": "Serverless computing simplifies deployment and scaling, yet cold-start latency remains a major performance bottleneck. Unlike prior work that treats mitigation as a black-box optimization, we study cold starts as a developer-visible design problem. From 81 adjudicated issue reports across open-source serverless systems, we derive taxonomies of initialization anti-patterns, remediation strategies, and diagnostic challenges spanning design, packaging, and runtime layers. Building on these insights, we introduce SCABENCH, a reproducible benchmark, and INITSCOPE, a lightweight analysis framework linking what code is loaded with what is executed. On SCABENCH, INITSCOPE improved localization accuracy by up to 40% and reduced diagnostic effort by 64% compared with prior tools, while a developer study showed higher task accuracy and faster diagnosis. Together, these results advance evidence-driven, performance-aware practices for cold-start mitigation in serverless design. Availability: The research artifact is publicly accessible for future studies and improvements.", "AI": {"tldr": "\u672c\u6587\u4e0d\u6d89\u53caDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u3002\nTLDR: Serverless\u8ba1\u7b97\u4e2d\u7684\u51b7\u542f\u52a8\u5ef6\u8fdf\u662f\u4e00\u4e2a\u6027\u80fd\u74f6\u9888\u3002\u672c\u6587\u901a\u8fc7\u5206\u6790\u5f00\u6e90Serverless\u7cfb\u7edf\u7684\u95ee\u9898\u62a5\u544a\uff0c\u5bfc\u51fa\u4e86\u53cd\u6a21\u5f0f\u548c\u8bca\u65ad\u6311\u6218\u7684\u5206\u7c7b\uff0c\u5e76\u63d0\u51fa\u4e86SCABENCH\u57fa\u51c6\u6d4b\u8bd5\u548cINITSCOPE\u5206\u6790\u6846\u67b6\u3002INITSCOPE\u663e\u8457\u63d0\u9ad8\u4e86\u5bf9\u51b7\u542f\u52a8\u95ee\u9898\u7684\u5b9a\u4f4d\u51c6\u786e\u6027\u548c\u8bca\u65ad\u6548\u7387\uff0c\u4fc3\u8fdb\u4e86Serverless\u8bbe\u8ba1\u4e2d\u4ee5\u6027\u80fd\u4e3a\u5bfc\u5411\u7684\u51b7\u542f\u52a8\u7f13\u89e3\u5b9e\u8df5\u3002", "motivation": "Serverless\u8ba1\u7b97\u7684\u51b7\u542f\u52a8\u5ef6\u8fdf\u662f\u4e3b\u8981\u7684\u6027\u80fd\u74f6\u9888\u3002\u4f5c\u8005\u8ba4\u4e3a\u4ee5\u524d\u7684\u5de5\u4f5c\u5c06\u7f13\u89e3\u63aa\u65bd\u89c6\u4e3a\u9ed1\u76d2\u4f18\u5316\uff0c\u800c\u672c\u6587\u65e8\u5728\u5c06\u51b7\u542f\u52a8\u4f5c\u4e3a\u4e00\u4e2a\u5bf9\u5f00\u53d1\u8005\u53ef\u89c1\u7684\u8bbe\u8ba1\u95ee\u9898\u6765\u7814\u7a76\u3002", "method": "\u7814\u7a76\u4e8681\u4efd\u5f00\u6e90Serverless\u7cfb\u7edf\u7684\u95ee\u9898\u62a5\u544a\uff0c\u5bfc\u51fa\u4e86\u521d\u59cb\u5316\u53cd\u6a21\u5f0f\u3001\u4fee\u590d\u7b56\u7565\u548c\u8bca\u65ad\u6311\u6218\u7684\u5206\u7c7b\u6cd5\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u5f15\u5165\u4e86SCABENCH\u53ef\u590d\u73b0\u57fa\u51c6\u6d4b\u8bd5\u548cINITSCOPE\u8f7b\u91cf\u7ea7\u5206\u6790\u6846\u67b6\uff08\u8fde\u63a5\u4ee3\u7801\u52a0\u8f7d\u548c\u6267\u884c\uff09\u3002\u5c06INITSCOPE\u4e0e\u73b0\u6709\u5de5\u5177\u8fdb\u884c\u4e86\u6bd4\u8f83\uff0c\u5e76\u8fdb\u884c\u4e86\u5f00\u53d1\u8005\u7814\u7a76\u3002", "result": "\u5728SCABENCH\u4e0a\uff0cINITSCOPE\u5c06\u5b9a\u4f4d\u51c6\u786e\u6027\u63d0\u9ad8\u4e86\u9ad8\u8fbe40%\uff0c\u4e0e\u73b0\u6709\u5de5\u5177\u76f8\u6bd4\uff0c\u8bca\u65ad\u5de5\u4f5c\u91cf\u51cf\u5c11\u4e8664%\u3002\u5f00\u53d1\u8005\u7814\u7a76\u8868\u660e\uff0c\u5176\u4efb\u52a1\u51c6\u786e\u6027\u66f4\u9ad8\uff0c\u8bca\u65ad\u901f\u5ea6\u66f4\u5feb\u3002\u8fd9\u4e9b\u7ed3\u679c\u4fc3\u8fdb\u4e86\u5728Serverless\u8bbe\u8ba1\u4e2d\u91c7\u7528\u4ee5\u8bc1\u636e\u9a71\u52a8\u3001\u6027\u80fd\u611f\u77e5\u7684\u65b9\u6cd5\u6765\u7f13\u89e3\u51b7\u542f\u52a8\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6df1\u5165\u7814\u7a76\u51b7\u542f\u52a8\u95ee\u9898\uff0c\u63d0\u51fa\u4e86SCABENCH\u57fa\u51c6\u6d4b\u8bd5\u548cINITSCOPE\u8f7b\u91cf\u7ea7\u5206\u6790\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u51b7\u542f\u52a8\u95ee\u9898\u7684\u8bca\u65ad\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u5728Serverless\u8bbe\u8ba1\u4e2d\u91c7\u7528\u4ee5\u8bc1\u636e\u9a71\u52a8\u3001\u6027\u80fd\u611f\u77e5\u7684\u65b9\u6cd5\u6765\u7f13\u89e3\u51b7\u542f\u52a8\u3002"}}
{"id": "2512.16134", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16134", "abs": "https://arxiv.org/abs/2512.16134", "authors": ["Jian Tian", "Shuailong Li", "Yang Cao", "Wenbo Cui", "Minghan Zhu", "Wenkang Wu", "Jianming Zhang", "Yanpeng Wang", "Zhiwen Xiao", "Zhenyu Hou", "Dou Shen"], "title": "Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference", "comment": null, "summary": "The evolution of Large Language Model (LLM) serving towards complex, distributed architectures--specifically the P/D-separated, large-scale DP+EP paradigm--introduces distinct scheduling challenges. Unlike traditional deployments where schedulers can treat instances as black boxes, DP+EP architectures exhibit high internal synchronization costs. We identify that immediate request dispatching in such systems leads to severe in-engine queuing and parallelization bubbles, degrading Time-to-First-Token (TTFT). To address this, we propose Staggered Batch Scheduling (SBS), a mechanism that deliberately buffers requests to form optimal execution batches. This temporal decoupling eliminates internal queuing bubbles without compromising throughput. Furthermore, leveraging the scheduling window created by buffering, we introduce a Load-Aware Global Allocation strategy that balances computational load across DP units for both Prefill and Decode phases. Deployed on a production H800 cluster serving Deepseek-V3, our system reduces TTFT by 30%-40% and improves throughput by 15%-20% compared to state-of-the-art immediate scheduling baselines.", "AI": {"tldr": "\u76f8\u5173\u6027\uff1a\u672c\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL\u3001MLIR\u6216HLS\u65e0\u5173\u3002\u5b83\u4e0e\u56fe\u5904\u7406\u4e0d\u76f4\u63a5\u76f8\u5173\uff0c\u4f46\u4e0e**LLM\u670d\u52a1\u548c\u8c03\u5ea6\uff08\u5c5e\u4e8e\u5e7f\u4e49\u4e0a\u7684\u7f16\u8bd1/\u7cfb\u7edf\u4f18\u5316\u8303\u7574\uff09**\u76f8\u5173\u3002/\n\u592a\u957f\u4e0d\u770b\uff1a\u4e3a\u4e86\u4f18\u5316\u5927\u89c4\u6a21DP+EP\u5206\u5e03\u5f0fLLM\u670d\u52a1\u4e2d\u56fa\u6709\u7684\u9ad8\u540c\u6b65\u6210\u672c\u548c\u8c03\u5ea6\u6548\u7387\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u9519\u5cf0\u6279\u5904\u7406\u8c03\u5ea6\uff08SBS\uff09\u7684\u65b0\u673a\u5236\u3002SBS\u901a\u8fc7\u65f6\u95f4\u89e3\u8026\u5730\u7f13\u51b2\u8bf7\u6c42\u5f62\u6210\u6700\u4f18\u6279\u6b21\uff0c\u5e76\u7ed3\u5408\u8d1f\u8f7d\u611f\u77e5\u5168\u5c40\u5206\u914d\u7b56\u7565\u6765\u6d88\u9664\u5185\u90e8\u6392\u961f\u6c14\u6ce1\uff0c\u6700\u7ec8\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5c06\u9996\u4ee4\u724c\u5ef6\u8fdf\uff08TTFT\uff09\u964d\u4f4e\u4e8630%-40%\uff0c\u5e76\u63d0\u9ad8\u4e8615%-20%\u7684\u541e\u5410\u91cf\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u670d\u52a1\u7684\u6f14\u8fdb\uff0c\u590d\u6742\u7684\u5206\u5e03\u5f0f\u67b6\u6784\uff08\u5982P/D\u5206\u79bb\u3001\u5927\u89c4\u6a21DP+EP\u8303\u5f0f\uff09\u5e26\u6765\u4e86\u4e0e\u4f20\u7edf\u90e8\u7f72\u4e0d\u540c\u7684\u8c03\u5ea6\u6311\u6218\u3002\u4f20\u7edf\u8c03\u5ea6\u7a0b\u5e8f\u5c06\u5b9e\u4f8b\u89c6\u4e3a\u9ed1\u76d2\uff0c\u800cDP+EP\u67b6\u6784\u5177\u6709\u9ad8\u6602\u7684\u5185\u90e8\u540c\u6b65\u6210\u672c\u3002\u4f5c\u8005\u6307\u51fa\uff0c\u5728\u8fd9\u79cd\u7cfb\u7edf\u4e2d\uff0c\u7acb\u5373\u8bf7\u6c42\u5206\u53d1\uff08immediate request dispatching\uff09\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u5f15\u64ce\u5185\u90e8\u6392\u961f\u548c\u5e76\u884c\u5316\u6c14\u6ce1\uff08parallelization bubbles\uff09\uff0c\u4ece\u800c\u964d\u4f4e\u9996\u4ee4\u724c\u751f\u6210\u65f6\u95f4\uff08Time-to-First-Token, TTFT\uff09\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u8c03\u5ea6\u673a\u5236\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u9519\u5cf0\u6279\u5904\u7406\u8c03\u5ea6\uff08Staggered Batch Scheduling, SBS\uff09\u673a\u5236\uff0c\u4f5c\u4e3a\u89e3\u51b3DP+EP\u67b6\u6784\u4e2d\u8c03\u5ea6\u6311\u6218\u7684\u6838\u5fc3\u65b9\u6cd5\u3002SBS\u901a\u8fc7\u6709\u610f\u7f13\u51b2\u8bf7\u6c42\u6765\u5f62\u6210\u6700\u4f18\u6267\u884c\u6279\u6b21\uff0c\u5b9e\u73b0\u4e86\u8bf7\u6c42\u7684\u201c\u65f6\u95f4\u89e3\u8026\u201d\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u7cfb\u7edf\u5185\u90e8\u7684\u6392\u961f\u6c14\u6ce1\uff08queuing bubbles\uff09\u3002\u6b64\u5916\uff0c\u5229\u7528\u7f13\u51b2\u5e26\u6765\u7684\u8c03\u5ea6\u7a97\u53e3\uff0c\u8bba\u6587\u5f15\u5165\u4e86\u8d1f\u8f7d\u611f\u77e5\u5168\u5c40\u5206\u914d\uff08Load-Aware Global Allocation\uff09\u7b56\u7565\uff0c\u7528\u4e8e\u5e73\u8861\u9884\u586b\u5145\uff08Prefill\uff09\u548c\u89e3\u7801\uff08Decode\uff09\u9636\u6bb5\u7684\u8ba1\u7b97\u8d1f\u8f7d\uff0c\u7279\u522b\u662f\u8de8DP\u5355\u5143\u7684\u8d1f\u8f7d\u3002", "result": "\u6240\u63d0\u51fa\u7684\u7cfb\u7edf\u90e8\u7f72\u5728\u4e00\u4e2a\u670d\u52a1Deepseek-V3\u7684\u751f\u4ea7H800\u96c6\u7fa4\u4e0a\uff0c\u4e0e\u6700\u5148\u8fdb\u7684\u5373\u65f6\u8c03\u5ea6\u57fa\u7ebf\u76f8\u6bd4\uff0c\u9996\u4ee4\u724c\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u51cf\u5c11\u4e8630%\u81f340%\uff0c\u541e\u5410\u91cf\u63d0\u9ad8\u4e8615%\u81f320%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u9519\u5cf0\u6279\u5904\u7406\u8c03\u5ea6\uff08SBS\uff09\u673a\u5236\uff0c\u901a\u8fc7\u5f15\u5165\u65f6\u95f4\u89e3\u8026\u548c\u8d1f\u8f7d\u611f\u77e5\u5168\u5c40\u5206\u914d\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5206\u5e03\u5f0fLLM\u670d\u52a1\u4e2dDP+EP\u67b6\u6784\u56fa\u6709\u7684\u9ad8\u5185\u90e8\u540c\u6b65\u6210\u672c\u548c\u8c03\u5ea6\u6311\u6218\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e0d\u727a\u7272\u541e\u5410\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u5927\u5e45\u4f18\u5316\u4e86TTFT\uff0c\u5e76\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2512.16455", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16455", "abs": "https://arxiv.org/abs/2512.16455", "authors": ["Ignacio Heredia", "\u00c1lvaro L\u00f3pez Garc\u00eda", "Germ\u00e1n Molt\u00f3", "Amanda Calatrava", "Valentin Kozlov", "Alessandro Costantini", "Viet Tran", "Mario David", "Daniel San Mart\u00edn", "Marcin P\u0142\u00f3ciennik", "Marta Obreg\u00f3n Ruiz", "Sa\u00fal Fernandez", "Judith S\u00e1inz-Pardo D\u00edaz", "Miguel Caballer", "Caterina Alarc\u00f3n Mar\u00edn", "Stefan Dlugolinsky", "Martin \u0160eleng", "Lisana Berberi", "Khadijeh Alibabaei", "Borja Esteban Sanchis", "Pedro Castro", "Giacinto Donvito", "Diego Aguirre", "Sergio Langarita", "Vicente Rodriguez", "Leonhard Duda", "Andr\u00e9s Heredia Canales", "Susana Rebolledo Ruiz", "Jo\u00e3o Machado", "Giang Nguyen", "Fernando Aguilar G\u00f3mez", "Jaime D\u00edez"], "title": "AI4EOSC: a Federated Cloud Platform for Artificial Intelligence in Scientific Research", "comment": null, "summary": "In this paper, we describe a federated compute platform dedicated to support Artificial Intelligence in scientific workloads. Putting the effort into reproducible deployments, it delivers consistent, transparent access to a federation of physically distributed e-Infrastructures. Through a comprehensive service catalogue, the platform is able to offer an integrated user experience covering the full Machine Learning lifecycle, including model development (with dedicated interactive development environments), training (with GPU resources, annotation tools, experiment tracking, and federated learning support) and deployment (covering a wide range of deployment options all along the Cloud Continuum). The platform also provides tools for traceability and reproducibility of AI models, integrates with different Artificial Intelligence model providers, datasets and storage resources, allowing users to interact with the broader Machine Learning ecosystem. Finally, it is easily customizable to lower the adoption barrier by external communities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001HLS\u3001DSL\u3001MLIR \u65e0\u5173\uff0c\u4f46\u4e0e**\u56fe\u5904\u7406\uff08Graph Processing\uff09**\u65e0\u76f4\u63a5\u5173\u7cfb\uff0c\u4e0e**\u673a\u5668\u5b66\u4e60\uff08ML/AI\uff09**\u5f3a\u76f8\u5173\uff08\u6d89\u53caAI\u6a21\u578b\u3001ML\u751f\u547d\u5468\u671f\u3001\u8054\u90a6\u5b66\u4e60\u7b49\uff09\u548c**\u7f16\u8bd1\u5668/\u57fa\u7840\u8bbe\u65bd\uff08Compiler/Infrastructure\uff09**\u76f8\u5173\uff08\u6d89\u53ca\u6784\u5efa\u4e00\u4e2a\u8054\u90a6\u8ba1\u7b97\u5e73\u53f0\uff0c\u62bd\u8c61\u5e95\u5c42\u57fa\u7840\u8bbe\u65bd\uff09\u3002/\n\u672c\u6587\u63cf\u8ff0\u4e86\u4e00\u4e2a\u8054\u90a6\u8ba1\u7b97\u5e73\u53f0\uff0c\u4e13\u95e8\u7528\u4e8e\u652f\u6301\u79d1\u5b66\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684AI\u5e94\u7528\uff0c\u901a\u8fc7\u6574\u5408\u8de8\u8d8a\u5730\u7406\u5206\u6563\u7684e-Infrastructures\u8d44\u6e90\uff0c\u5728\u4e00\u4e2a\u7edf\u4e00\u7684\u670d\u52a1\u76ee\u5f55\u4e2d\u63d0\u4f9b\u4ece\u6a21\u578b\u5f00\u53d1\u3001\u8bad\u7ec3\uff08\u5305\u62ec\u8054\u90a6\u5b66\u4e60\uff09\u5230\u591a\u6837\u5316\u90e8\u7f72\u7684\u5b8c\u6574\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u652f\u6301\uff0c\u540c\u65f6\u5f3a\u8c03\u5de5\u5177\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u6a21\u578b\u7684\u53ef\u91cd\u590d\u6027\uff0c\u4ee5\u964d\u4f4e\u79d1\u7814\u793e\u533a\u91c7\u7528AI\u7684\u95e8\u69db\u3002", "motivation": "\u79d1\u5b66\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u9700\u8981\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u91cd\u590d\u4e14\u6613\u4e8e\u8bbf\u95ee\u7684\u8ba1\u7b97\u5e73\u53f0\u3002\u7531\u4e8e\u5e95\u5c42\u57fa\u7840\u8bbe\u65bd\uff08e-Infrastructures\uff09\u901a\u5e38\u662f\u5206\u6563\u7684\uff0c\u8fd9\u4e3aAI\u6a21\u578b\u7684\u5f00\u53d1\u3001\u8bad\u7ec3\u548c\u90e8\u7f72\u5e26\u6765\u4e86\u590d\u6742\u6027\u3002\u56e0\u6b64\uff0c\u8be5\u5e73\u53f0\u7684\u52a8\u673a\u662f\u5efa\u7acb\u4e00\u4e2a\u4e13\u7528\u7684\u8054\u90a6\u8ba1\u7b97\u5e73\u53f0\uff0c\u7528\u4e8e\u652f\u6301\u79d1\u5b66AI\uff0c\u63d0\u4f9b\u4e00\u81f4\u3001\u900f\u660e\u7684\u90e8\u7f72\u548c\u5168\u751f\u547d\u5468\u671f\u7684\u673a\u5668\u5b66\u4e60\u652f\u6301\uff0c\u540c\u65f6\u786e\u4fdd\u64cd\u4f5c\u7684\u53ef\u8ffd\u6eaf\u6027\u548c\u6a21\u578b\u7684\u53ef\u91cd\u590d\u6027\u3002", "method": "\u672c\u6587\u63cf\u8ff0\u7684\u662f\u4e00\u4e2a\u8054\u90a6\u8ba1\u7b97\u5e73\u53f0\uff0c\u5176\u65b9\u6cd5\u8bba\u91cd\u70b9\u5728\u4e8e\u96c6\u6210\u548c\u7edf\u4e00\u5206\u5e03\u5f0f\u8d44\u6e90\uff0c\u4ee5\u652f\u6301\u79d1\u5b66\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u3002\u5177\u4f53\u65b9\u6cd5\u5305\u62ec\uff1a1. **\u8054\u90a6\u5316\u90e8\u7f72**\uff1a\u5c06\u5206\u6563\u7684e-Infrastructures\uff08\u7535\u5b50\u57fa\u7840\u8bbe\u65bd\uff09\u6574\u5408\u8d77\u6765\uff0c\u63d0\u4f9b\u7edf\u4e00\u3001\u900f\u660e\u7684\u8bbf\u95ee\u30022. **\u670d\u52a1\u76ee\u5f55**\uff1a\u63d0\u4f9b\u6db5\u76d6\u5b8c\u6574\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u7684\u4e00\u7ad9\u5f0f\u670d\u52a1\uff0c\u5305\u62ec\u6a21\u578b\u5f00\u53d1\u3001\u8bad\u7ec3\uff08\u63d0\u4f9bGPU\u3001\u6807\u6ce8\u5de5\u5177\u3001\u5b9e\u9a8c\u8ddf\u8e2a\u3001\u8054\u90a6\u5b66\u4e60\uff09\u3001\u548c\u90e8\u7f72\uff08\u8986\u76d6\u4e91\u8fde\u7eed\u4f53\u7684\u591a\u79cd\u9009\u9879\uff09\u30023. **\u5de5\u5177\u96c6\u6210**\uff1a\u63d0\u4f9b\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u91cd\u590d\u6027\u5de5\u5177\uff0c\u5e76\u96c6\u6210\u4e0d\u540c\u7684AI\u6a21\u578b\u63d0\u4f9b\u8005\u3001\u6570\u636e\u96c6\u548c\u5b58\u50a8\u8d44\u6e90\uff0c\u4ee5\u8fde\u63a5\u66f4\u5e7f\u6cdb\u7684\u673a\u5668\u5b66\u4e60\u751f\u6001\u7cfb\u7edf\u3002", "result": "\u6240\u63cf\u8ff0\u7684\u5e73\u53f0\u6210\u529f\u5730\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8054\u90a6\u8ba1\u7b97\u89e3\u51b3\u65b9\u6848\uff0c\u4e13\u95e8\u7528\u4e8e\u79d1\u5b66AI\u5de5\u4f5c\u8d1f\u8f7d\u3002\u5176\u6210\u679c\u5305\u62ec\uff1a1. **\u7edf\u4e00\u8bbf\u95ee**\uff1a\u5b9e\u73b0\u4e86\u5bf9\u5206\u6563\u7684e-Infrastructures\u7684\u4e00\u81f4\u3001\u900f\u660e\u8bbf\u95ee\u30022. **\u5168\u5468\u671f\u652f\u6301**\uff1a\u63d0\u4f9b\u4e86\u4ece\u6a21\u578b\u5f00\u53d1\u5230\u8bad\u7ec3\u518d\u5230\u90e8\u7f72\u7684\u5b8c\u6574ML\u670d\u52a1\u76ee\u5f55\u30023. **\u589e\u5f3a\u529f\u80fd**\uff1a\u96c6\u6210\u4e86GPU\u8d44\u6e90\u3001\u8054\u90a6\u5b66\u4e60\u652f\u6301\u3001\u5b9e\u9a8c\u8ddf\u8e2a\u3001\u4ee5\u53ca\u6a21\u578b\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u91cd\u590d\u6027\u5de5\u5177\u30024. **\u751f\u6001\u7cfb\u7edf\u8fde\u63a5**\uff1a\u80fd\u591f\u6574\u5408\u4e0d\u540c\u7684AI\u6a21\u578b\u63d0\u4f9b\u8005\u3001\u6570\u636e\u96c6\u548c\u5b58\u50a8\u8d44\u6e90\u30025. **\u9ad8\u53ef\u5b9a\u5236\u6027**\uff1a\u964d\u4f4e\u4e86\u5916\u90e8\u793e\u533a\u7684\u91c7\u7528\u95e8\u69db\u3002", "conclusion": "\u672c\u6587\u63cf\u8ff0\u7684AI\u5e73\u53f0\u901a\u8fc7\u63d0\u4f9b\u7edf\u4e00\u7684\u63a5\u5165\u70b9\u3001\u5168\u9762\u7684\u670d\u52a1\u76ee\u5f55\u3001\u652f\u6301\u5168\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u4ee5\u53ca\u5f3a\u8c03\u53ef\u8ffd\u6eaf\u6027\u548c\u53ef\u91cd\u590d\u6027\uff0c\u89e3\u51b3\u4e86\u79d1\u5b66\u5de5\u4f5c\u8d1f\u8f7d\u4e2dAI\u5e94\u7528\u7684\u590d\u6742\u6027\u548c\u788e\u7247\u5316\u95ee\u9898\u3002\u5b83\u7684\u8054\u90a6\u5f0f\u67b6\u6784\u548c\u53ef\u5b9a\u5236\u6027\u4e5f\u786e\u4fdd\u4e86\u5e73\u53f0\u80fd\u591f\u9002\u5e94\u591a\u79cd\u79d1\u7814\u793e\u533a\u7684\u9700\u6c42\u5e76\u6613\u4e8e\u96c6\u6210\u3002"}}
{"id": "2512.16473", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.16473", "abs": "https://arxiv.org/abs/2512.16473", "authors": ["En-Ming Huang", "Li-Shang Lin", "Chun-Yi Lee"], "title": "Efficient CPU-GPU Collaborative Inference for MoE-based LLMs on Memory-Limited Systems", "comment": "7 pages, 6 figures, to be published in ASP-DAC 2026", "summary": "Large Language Models (LLMs) have achieved impressive results across various tasks, yet their high computational demands pose deployment challenges, especially on consumer-grade hardware. Mixture of Experts (MoE) models provide an efficient solution through selective activation of parameter subsets, which reduces computation requirements. Despite this efficiency, state-of-the-art MoE models still require substantial memory beyond typical consumer GPU capacities. Traditional offloading methods that transfer model weights between CPU and GPU introduce latency, limiting inference performance. This paper presents a novel CPU-GPU collaborative inference framework that incorporates an expert caching mechanism on the GPU to reduce data transfer requirements and enable faster inference through cache hits. Computations are offloaded to CPU for efficient cache miss handling, which benefits from CPU multithreading optimizations. The evaluations of our framework demonstrate performance improvements and highlight the potential of CPU-GPU collaboration to maximize hardware utilization for single-request inference scenarios on consumer-grade systems. The implementation of our framework is available at https://github.com/elsa-lab/MoE-CPU-GPU-Collaborative-Inference.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6d89\u53ca **compiler** (inference framework / hardware utilization) \u548c **graph processing** (MoE structure can be viewed as a sparse graph-like structure where data flows through selected experts)\u3002\n**\u592a\u957f\u4e0d\u8bfb\uff08TLDR\uff09:** \u9488\u5bf9\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a MoE \u6a21\u578b\u5185\u5b58\u9700\u6c42\u9ad8\u548c\u4f20\u7edf\u5378\u8f7d\u5ef6\u8fdf\u5927\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684 CPU-GPU \u534f\u4f5c\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728 GPU \u4e0a\u5efa\u7acb\u4e13\u5bb6\u7f13\u5b58\u4ee5\u51cf\u5c11\u6570\u636e\u4f20\u8f93\uff0c\u5e76\u5229\u7528 CPU \u591a\u7ebf\u7a0b\u5904\u7406\u7f13\u5b58\u672a\u547d\u4e2d\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86 MoE \u6a21\u578b\u5728\u5355\u8bf7\u6c42\u63a8\u7406\u573a\u666f\u4e2d\u7684\u6027\u80fd\u548c\u786c\u4ef6\u5229\u7528\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u8ba1\u7b97\u9700\u6c42\u9ad8\uff0c\u5c24\u5176\u662f\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u90e8\u7f72\u9762\u4e34\u6311\u6218\u3002\u5c3d\u7ba1\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u6a21\u578b\u901a\u8fc7\u9009\u62e9\u6027\u6fc0\u6d3b\u53c2\u6570\u5b50\u96c6\u63d0\u9ad8\u4e86\u6548\u7387\uff0c\u4f46\u6700\u5148\u8fdb\u7684 MoE \u6a21\u578b\u4ecd\u9700\u8981\u8d85\u51fa\u5178\u578b\u6d88\u8d39\u7ea7 GPU \u5bb9\u91cf\u7684\u5927\u91cf\u5185\u5b58\u3002\u4f20\u7edf\u7684 CPU-GPU \u5378\u8f7d\u65b9\u6cd5\u7531\u4e8e\u5f15\u5165\u4e86\u5ef6\u8fdf\u800c\u9650\u5236\u4e86\u63a8\u7406\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u8be5\u7814\u7a76\u7684\u52a8\u673a\u662f\u5f00\u53d1\u4e00\u79cd\u9ad8\u6548\u7684 CPU-GPU \u534f\u4f5c\u63a8\u7406\u6846\u67b6\uff0c\u4ee5\u514b\u670d\u5185\u5b58\u9650\u5236\u548c\u4f20\u8f93\u5ef6\u8fdf\uff0c\u4f7f\u5f97\u5927\u578b MoE \u6a21\u578b\u80fd\u591f\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fdb\u884c\u9ad8\u6548\u7684\u5355\u8bf7\u6c42\u63a8\u7406\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684 CPU-GPU \u534f\u4f5c\u63a8\u7406\u6846\u67b6\u3002\u6838\u5fc3\u65b9\u6cd5\u662f\u5728 GPU \u4e0a\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e13\u5bb6\u7f13\u5b58\u673a\u5236\uff0c\u7528\u4e8e\u5b58\u50a8\u5e38\u7528\u7684\u4e13\u5bb6\u6a21\u578b\u53c2\u6570\u4ee5\u51cf\u5c11\u6570\u636e\u4f20\u8f93\u3002\u5bf9\u4e8e\u7f13\u5b58\u672a\u547d\u4e2d\u7684\u60c5\u51b5\uff0c\u8ba1\u7b97\u4efb\u52a1\u5c06\u5378\u8f7d\u5230 CPU \u4e0a\uff0c\u5e76\u5229\u7528 CPU \u7684\u591a\u7ebf\u7a0b\u4f18\u5316\u8fdb\u884c\u9ad8\u6548\u5904\u7406\u3002\u8fd9\u79cd\u8bbe\u8ba1\u65e8\u5728\u901a\u8fc7\u51cf\u5c11 CPU \u548c GPU \u4e4b\u95f4\u7684\u6570\u636e\u4f20\u8f93\u91cf\uff0c\u514b\u670d\u4f20\u7edf\u5378\u8f7d\u65b9\u6cd5\u5e26\u6765\u7684\u5ef6\u8fdf\u9650\u5236\uff0c\u4ece\u800c\u63d0\u9ad8 MoE \u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u7684\u63a8\u7406\u6027\u80fd\u3002", "result": "\u8be5\u6846\u67b6\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u4e86\u6027\u80fd\u63d0\u5347\u3002\u8be5\u7814\u7a76\u5f3a\u8c03\u4e86 CPU-GPU \u534f\u4f5c\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u5728\u6d88\u8d39\u7ea7\u7cfb\u7edf\u4e0a\u6700\u5927\u5316\u786c\u4ef6\u5229\u7528\u7387\uff0c\u7279\u522b\u662f\u5728\u5355\u8bf7\u6c42\u63a8\u7406\u573a\u666f\u4e2d\uff0c\u4ee5\u89e3\u51b3\u5927\u578b MoE \u6a21\u578b\u5728\u5185\u5b58\u53d7\u9650\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u90e8\u7f72\u95ee\u9898\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684 CPU-GPU \u534f\u4f5c\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728 GPU \u4e0a\u5f15\u5165\u4e13\u5bb6\u7f13\u5b58\u673a\u5236\uff0c\u5e76\u7ed3\u5408 CPU \u7684\u591a\u7ebf\u7a0b\u4f18\u52bf\u6765\u5904\u7406\u7f13\u5b58\u672a\u547d\u4e2d\uff0c\u6709\u6548\u964d\u4f4e\u4e86 MoE \u6a21\u578b\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fdb\u884c\u5355\u8bf7\u6c42\u63a8\u7406\u65f6\u7684\u5185\u5b58\u548c\u5e26\u5bbd\u9650\u5236\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u6846\u67b6\u5728\u6027\u80fd\u4e0a\u6709\u6240\u63d0\u5347\uff0c\u5e76\u5f3a\u8c03\u4e86 CPU-GPU \u534f\u4f5c\u5728\u6700\u5927\u5316\u786c\u4ef6\u5229\u7528\u7387\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u5927\u578b MoE \u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u3002"}}
