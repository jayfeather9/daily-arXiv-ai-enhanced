<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 3]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.PL](#cs.PL) [Total: 1]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Derandomizing Matrix Concentration Inequalities from Free Probability](https://arxiv.org/abs/2601.08111)
*Robert Wang,Lap Chi Lau,Hong Zhou*

Main category: cs.DS

TL;DR: This content is not related to DSL, graph processing (though it constructs near-Ramanujan graphs as an application, the core focus is not on graph processing methodology), MLIR, compiler, or HLS. The paper designs polynomial-time deterministic algorithms to construct outcomes satisfying sharp matrix concentration inequalities derived from free probability theory, with applications to the matrix Spencer problem and constructing near-Ramanujan graphs.
本文设计了多项式时间确定性算法，用于构造满足自由概率理论推导出的尖锐矩阵集中不等式保证的结果。作为直接的应用，该算法可用于解决矩阵 Spencer 问题和构造近似 Ramanujan 图，证明了自由概率中的概念和技术对于高效计算同样有用。


<details>
  <summary>Details</summary>
Motivation: 最近，利用自由概率理论发展出了尖锐的矩阵集中不等式（如参考文献[BBvH23, BvH24]）。然而，这些不等式通常描述的是存在性或概率性的保证，而不是直接给出如何构造满足这些保证的输出。因此，本文的动机是设计多项式时间确定性算法，以构造出满足这些尖锐矩阵集中不等式保证的结果，从而将自由概率的数学分析工具转化为有效的计算方法。

Method: 本文设计了构造满足自由概率理论推导出的尖锐矩阵集中不等式（例如引用文献[BBvH23, BvH24]）保证的输出结果的确定性多项式时间算法。核心方法是利用自由概率理论的工具，特别是尖锐矩阵集中不等式的构造性变体。通过这种方式，算法具有完全的确定性，避免了随机化和近似的步骤。

Result: 主要结果是设计了多项式时间确定性算法，用于构造满足自由概率理论衍生出的尖锐矩阵集中不等式保证的输出结果。直接的应用包括：1. 获得了矩阵 Spencer 问题的多项式时间确定性算法（参考[BJM23]）。2. 获得了构造近似 Ramanujan 图的多项式时间确定性算法。这些结果证明了自由概率中的概念和技术不仅适用于数学分析，同样可以应用于高效计算。

Conclusion: 本文设计了构造满足自由概率理论衍生出的尖锐矩阵集中不等式保证的输出结果的确定性多项式时间算法。通过自由概率理论的工具，该方法是完全确定性的，保证了算法的构造性，避免了采样、随机化和近似步骤。本文表明自由概率中的概念和技术不仅对数学分析有用，对于高效计算也同样有用。

Abstract: Recently, sharp matrix concentration inequalities~\cite{BBvH23,BvH24} were developed using the theory of free probability. In this work, we design polynomial time deterministic algorithms to construct outcomes that satisfy the guarantees of these inequalities. As direct consequences, we obtain polynomial time deterministic algorithms for the matrix Spencer problem~\cite{BJM23} and for constructing near-Ramanujan graphs. Our proofs show that the concepts and techniques in free probability are useful not only for mathematical analyses but also for efficient computations.

</details>


### [2] [Protrusion Decompositions Revisited: Uniform Lossy Kernels for Reducing Treewidth and Linear Kernels for Hitting Disconnected Minors](https://arxiv.org/abs/2601.08424)
*Roohani Sharma,Michał Włodarczyk*

Main category: cs.DS

TL;DR: 本文与图处理（Graph Processing）相关，具体涉及到参数化复杂性理论中的核化（Kernelization）问题。
**TLDR:** F-Deletion问题是著名的Vertex Cover和Feedback Vertex Set问题的推广，目标是删除$k$个顶点使图中不含图族$F$中的任一子式。已知其多项式内核大小的指数通常依赖于$F$的参数（非均匀性）。本文通过牺牲少量精度（2-近似），成功为Treewidth-d-Deletion问题找到了一个均匀内核（内核大小为$g(d) \cdot k^5$，指数不再依赖$d$），并提出了一种近似因子可任意接近1的核化协议。此外，本文还在更一般的稀疏图类上（F包含平面图且排除拓扑子式）获得了线性内核，放宽了之前定理的限制。


<details>
  <summary>Details</summary>
Motivation: F-Deletion 问题是 Vertex Cover 和 Feedback Vertex Set 的重要推广。前人的工作（Fomin 等人，2012）为 F 包含平面图时提供了多项式内核，但其内核大小 $g(F) \cdot k^{f(F)}$ 对 $k$ 的指数 $f(F)$ 依赖于图族 F。后续工作（Giannapoulou 等人，2017）证明了这种依赖性（非均匀性）在 Treewidth-d-Deletion 这一特例中是不可避免的。
本文的动机在于，尽管无法完全避免这种依赖，但能否通过牺牲少量精度，实现一个不依赖于 F 特有性质的、更“均匀”的核化结果。此外，现有的在稀疏图类上的线性内核结果要求 F 中的所有图都是连通的，本文也旨在消除这一限制。

Method: 本文首先提出了一种用于 Treewidth-d-Deletion 问题的 2-近似核化算法，其内核大小为 $g(d) \cdot k^5$，实现了均匀核化。接着，作者展示了若允许核化协议对一个规模受 $k$ 的均匀多项式限制的实例求解预言机进行 O(1) 次调用，则近似因子可以任意接近 1。最后，作者通过推广了 Kim 等人的核化算法，在 F 包含平面图的稀疏图类（排除拓扑子式的图类）上获得了线性内核，解除了先前定理对 F 中所有图必须是连通图的限制。

Result: 1. **Treewidth-d-Deletion 的 2-近似均匀内核：** 提出了一个用于 Treewidth-d-Deletion 问题的简单 2-近似核化算法，其内核大小为 $g(d) \cdot k^5$，成功实现了 $k$ 的指数不再依赖于 $d$ 的均匀性。
2. **近似因子接近 1 的核化协议：** 证明了如果允许核化协议对一个规模由 $k$ 的均匀多项式界定的实例求解预言机进行 O(1) 次调用，则近似因子可以任意接近 1。
3. **稀疏图类上的线性内核推广：** 在 F 包含平面图的稀疏图类（具体是排除拓扑子式的图类）上获得了线性内核，推广了 Kim 等人的结果，解除了先前定理对 F 中所有图必须是连通的限制。

Conclusion: 本文通过牺牲少许精度，在 Treewidth-d-Deletion 问题上实现了均匀核化，即内核大小的指数不再依赖于图族 F 的特定属性（如 d）。具体来说，对于 Treewidth-d-Deletion 问题，作者提出了一个具有 $g(d) \cdot k^5$ 大小内核的 2-近似核化算法，并在更强的假设下实现了近似因子可任意接近 1 的核化协议。此外，作者还在 F 包含平面图的稀疏图类上获得了线性内核，推广了现有的核化结果。

Abstract: Let F be a finite family of graphs. In the F-Deletion problem, one is given a graph G and an integer k, and the goal is to find k vertices whose deletion results in a graph with no minor from the family F. This may be regarded as a far-reaching generalization of Vertex Cover and Feedback vertex Set. In their seminal work, Fomin, Lokshtanov, Misra & Saurabh [FOCS 2012] gave a polynomial kernel for this problem when the family F contains a planar graph. As the size of their kernel is g(F) * k^{f(F)}, a natural follow-up question was whether the dependence on F in the exponent of k can be avoided. The answer turned out to be negative: Giannapoulou, Jansen, Lokshtanov & Saurabh [TALG 2017] proved that this is already inevitable for the special case of the Treewidth-d-Deletion problem.
  In this work, we show that this non-uniformity can be avoided at the expense of a small loss. First, we present a simple 2-approximate kernelization algorithm for Treewidth-d-Deletion with kernel size g(d) * k^5. Next, we show that the approximation factor can be made arbitrarily close to 1, if we settle for a kernelization protocol with O(1) calls to an oracle that solves instances of size bounded by a uniform polynomial in k.
  We also obtain linear kernels on sparse graph classes when F contains a planar graph, whereas the previously known theorems required all graphs in F to be connected. Specifically, we generalize the kernelization algorithm by Kim, Langer, Paul, Reidl, Rossmanith, Sau & Sikdar [TALG 2015] on graph classes that exclude a topological minor.

</details>


### [3] [FPT Approximations for Connected Maximum Coverage](https://arxiv.org/abs/2601.08639)
*Tanmay Inamdar,Satyabrata Jana,Madhumita Kundu,Daniel Lokshtanov,Saket Saurabh,Meirav Zehavi*

Main category: cs.DS

TL;DR: 该论文与DSL或图处理或MLIR或编译器或HLS不直接相关。论文专注于图论中的算法复杂性理论和参数化近似算法设计，核心是**图处理**领域中的连接性约束覆盖模型分析。
总结：论文提出了一个统一的图论模型——部分连连通红蓝支配集，用于研究带连通性约束的覆盖问题。作者首先划定了该问题的不可近似性边界，然后证明了它关于参数 $t$ 是 FPT 可解的。最主要的贡献是，在双边图排除 $K_{d,d}$ 的条件下，设计了不限制连通图 $G_{conn}$ 的、针对 $t$ 和 $k$ 的 FPT 近似方案，从而明确了此类问题的难度和可近似性之间的界限。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于解决一类具有连通性约束的覆盖问题，这些问题在现有文献中以不同的形式存在，如带连通性约束的最大覆盖、部分支配集和部分顶点覆盖。
核心目标是：
1. **统一建模：** 提出一个统一的数学模型（部分连通红蓝支配集）来描述和概括这些连通性约束的覆盖问题。
2. **界定难度：** 明确这些连通性约束问题的计算复杂性边界，即在何种条件下问题是难解的，在何种条件下是可解或可近似的。
3. **设计高效近似算法：** 在不限制连通图 $G_{conn}$ 的更通用设置下，为该类问题设计有效的固定参数可解（FPT）近似算法。

Method: 论文采用的方法是理论分析和算法设计。
1. **模型统一与建立：** 提出了“部分连通红蓝支配集”（Partial Connected Red-Blue Dominating Set）作为统一模型，它能够涵盖先前研究中的连接变体，如最大覆盖、部分支配集和部分顶点覆盖。
2. **复杂性分析：** 识别并证明了从已知问题继承来的（参数化）不可近似性结果，确定了问题的难解性基线。
3. **固定参数可解性 (FPT) 分析：** 证明了该问题关于参数 $t$ 是固定参数可解的。
4. **参数化近似方案设计：** 在双边图 $G$ 不包含 $K_{d,d}$ 作为子图的限制条件下，针对近似 $t$（支配的蓝点数）和近似 $k$（选择的红点数），设计了（高效的）参数化近似方案（(E)PAS）。值得注意的是，这些近似算法对辅助连通图 $G_{conn}$ 没有施加任何限制。

Result: 论文取得了以下理论结果：
1. **复杂度基线：** 明确了该问题继承自已知子问题的一些（参数化）不可近似性结果，证实了其内禀的计算难度。
2. **FPT 可解性：** 证明了对于参数 $t$（被支配的蓝点数量），部分连通红蓝支配集问题是固定参数可解（FPT）的。
3. **FPT 近似方案：** 当双边图 $G$ 排除 $K_{d,d}$ 作为子图时，论文设计了：
    * **近似 $t$ 的参数化近似方案 (PAS)。**
    * **近似 $k$ 的高效参数化近似方案 (EPAS)。**
    这些近似方案的显著特点是它们对辅助连通图 $G_{conn}$ 没有任何限制，这在算法设计上是一个重要的进步。
4. **难度边界：** 这些结果共同描绘了连通性约束覆盖问题在难度和 FPT-可近似性之间的界限。

Conclusion: 这篇论文重新审视了连通性约束下的覆盖问题，提出了一个统一的模型——部分连通红蓝支配集（Partial Connected Red-Blue Dominating Set）。通过一系列的理论分析，论文明确了该问题的计算复杂性边界。研究发现，该问题存在着不变的（参数化）不可近似性，但同时也展示了在特定参数（如被支配的蓝点数量 $t$）下它是固定参数可解（FPT）的。更重要的是，对于排除 $K_{d,d}$ 作为子图的双边图，论文设计了参数化近似方案，成功地在连通性图中没有额外限制的情况下，为近似 $t$ 和 $k$ 提供了高效的 FPT 近似算法。这些结果为连通性约束覆盖问题的难度和 FPT-可近似性之间划定了明确的界限。

Abstract: We revisit connectivity-constrained coverage through a unifying model, Partial Connected Red-Blue Dominating Set. Given a red-blue bipartite graph $G$ and an auxiliary connectivity graph $G_{conn}$ on red vertices, and integers $k, t$, the task is to find a $k$-sized subset of red vertices that dominates at least $t$ blue vertices, and that induces a connected subgraph in $G_{conn}$. This formulation captures connected variants of Max Coverage, Partial Dominating Set, and Partial Vertex Cover studied in prior literature.
  After identifying (parameterized) inapproximability results inherited from known problems, we first show that the problem is fixed-parameter tractable by $t$. Furthermore, when the bipartite graph excludes $K_{d,d}$ as a subgraph, we design (resp. efficient) parameterized approximation schemes for approximating $t$ (resp. $k$). Notably, these FPT approximations do not impose any restrictions on $G_{conn}$. Together, these results chart the boundary between hardness and FPT-approximability for connectivity-constrained coverage.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [4] [A New Tool to Find Lightweight (And, Xor) Implementations of Quadratic Vectorial Boolean Functions up to Dimension 9](https://arxiv.org/abs/2601.08368)
*Marie Bolzer,Sébastien Duval,Marine Minier*

Main category: cs.AR

TL;DR: 本文涉及编译器和电子设计自动化（EDA）中的电路综合问题，与 DSL、图处理或 MLIR 无直接关系。
它专注于密码学中小规模函数的电路实现，特别是二次函数。

总结：最小化电路实现问题是 NP 难的。现有的电路综合工具面向大规模芯片，而密码学需要针对小规模函数（通常小于 5-6 位）。作者提出了一个更高效的新工具，专门用于实现高达 9 位的二次函数，目标是最小化 AND 门数量且 AND 深度为 1。该工具比现有方法在计算时间上更高效，突破了现有工具的规模限制。


<details>
  <summary>Details</summary>
Motivation: 寻找实现给定功能的最小电路是一个 NP 难问题。现有的电子学综合工具（Synthesizers）主要针对大规模函数（如整个芯片）进行优化。但在密码学领域，重点是小规模函数。现有的小函数实现工具（如基于 DFS 或 SAT 求解器的工具）规模受限，通常只能处理小于 5 位（有时是 6 位，或非常简单的函数），瓶颈在于计算时间过长。因此，需要专门针对小规模函数，特别是二次函数，开发更高效的实现工具。

Method: 本文描述了一种实现二次函数的新工具。该工具专注于在 AND 深度为 1 的约束下，最小化 AND 门的数量，并能处理高达 9 位的二次函数。作者声称该工具比现有工具在计算时间上更高效，允许探索比其他工具更大规模（在 6 位或更少）的实现，并能达到高达 9 位的规模。虽然摘要没有详细说明具体的算法细节，但它将该工具与其他基于 DFS 和 SAT 求解器的现有工具进行了对比。

Result: 开发了一个新的工具，该工具能高效地为高达 9 位的二次函数实现电路，且在 AND 深度为 1 的限制下，最小化 AND门的数量。该工具在计算时间上比现有工具更高效，使得研究更大规模（高达 9 位）的实现成为可能。

Conclusion: 本文提出了一种新的工具，能够高效地为高达 9 位的二次函数实现最小化 AND 门数量的电路，并且在 AND 深度为 1 的限制下。这使得研究更大规模的函数实现成为可能。

Abstract: The problem of finding a minimal circuit to implement a given function is one of the oldest in electronics. It is known to be NP-hard. Still, many tools exist to find sub-optimal circuits to implement a function. In electronics, such tools are known as synthesisers. However, these synthesisers aim to implement very large functions (a whole electronic chip). In cryptography, the focus is on small functions, hence the necessity for new dedicated tools for small functions. Several tools exist to implement small functions. They differ by their algorithmic approach (some are based on Depth-First-Search as introduced by Ullrich in 2011, some are based on SAT-solvers like the tool desgined by Stoffelen in 2016, some non-generic tools use subfield decomposition) and by their optimisation criteria (some optimise for circuit size, others for circuit depth, and some for side-channel-protected implementations). However, these tools are limited to functions operating on less than 5 bits, sometimes 6 bits for quadratic functions, or to very simple functions. The limitation lies in a high computing time. We propose a new tool (The tool is provided alongside the IEEE article with CodeOcean and at https://github.com/seduval/implem-quad-sbox) to implement quadratic functions up to 9 bits within AND-depth 1, minimising the number of AND gates. This tool is more time-efficient than previous ones, allowing to explore larger implementations than others on 6 bits or less and allows to reach larger sizes, up to 9 bits.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [5] [Matrix-PIC: Harnessing Matrix Outer-product for High-Performance Particle-in-Cell Simulations](https://arxiv.org/abs/2601.08277)
*Yizhuo Rao,Xingjian Cui,Jiabin Xie,Shangzhi Pang,Guangnan Feng,Jinhui Wei,Zhiguang Chen,Yutong Lu*

Main category: cs.DC

TL;DR: 相关与否：本论文与 **编译器 (Compiler)** 有微弱的关联，因为它的核心在于针对特定的、新兴的并行硬件架构（MPU-VPU混合SIMD）进行**软件与硬件的协同设计**，并重新设计了算法和数据结构以最大化利用硬件特性，这与编译器优化的目标和部分技术重叠，虽然没有直接讨论编译器的实现。

总结：
Particle-in-Cell (PIC) 模拟中的粒子沉积是性能瓶颈。本文提出了 **MatrixPIC**，这是一个针对现代 CPU 上 **MPU-VPU 混合 SIMD 架构**的 **协同设计（co-design）**方案，旨在通过矩阵化方法加速沉积步骤。MatrixPIC 引入了电流沉积的**块矩阵公式**来匹配 MPU 的外积操作，设计了**混合执行流水线**（MPU 负责高密度累加，VPU 负责数据准备），并采用了基于 gapped packed-memory array 的 $O(1)$ 摊销**增量分拣器**来维护数据局部性。在评估中，MatrixPIC 在 LWFA 模拟的总运行时间上实现了高达 $2.63\times$ 的加速，核心内核比基线加速 $8.7\times$，并达到了理论 CPU 峰值性能的 $83.08\%$，性能远超高度优化的 GPU 实现。这项工作证明了矩阵化协同设计在利用新兴 CPU 架构加速 PIC 模拟方面的有效性。


<details>
  <summary>Details</summary>
Motivation: PIC 模拟的执行时间主要消耗在粒子-网格交互上，其中细粒度原子更新在传统多核 CPU 上成为了主要瓶颈。现代 CPU 架构集成了专门的矩阵处理单元（MPU），支持高效的矩阵外积操作，为克服这一限制提供了新的机会。本文的动机是利用 MPU 架构特点，重新设计 PIC 模拟的沉积步骤，以提高性能。

Method: MatrixPIC 提出了一种矩阵中心执行模型来重新设计 PIC 模拟中的沉积步骤。它主要包括三个方面：1) 电流沉积算法的块矩阵公式（block-matrix formulation），可以自然地映射到 MPU 外积原语；2) 混合执行流水线（hybrid execution pipeline），将基于 MPU 的高密度累加与基于 VPU 的数据准备和控制流相结合；3) 基于 gapped packed-memory array 的 O(1) 摊销增量分拣器（incremental sorter），用于保持数据局部性以实现高效的 MPU 执行。

Result: MatrixPIC 在下一代 HPC 平台上进行了评估，取得了显著的性能提升。在 LWFA 模拟中，总运行时加速比高达 $2.63\times$。对于三阶沉积（核心内核），其比基线加速了 $8.7\times$，比最佳手工优化的 VPU 实现加速了 $2.0\times$。此外，MatrixPIC 达到了理论 CPU 峰值性能的 $83.08\%$，比数据中心 GPU 上高度优化的 CUDA 内核高出近 $2.8\times$。

Conclusion: MatrixPIC 通过矩阵化协同设计，成功利用现代 CPU 上的 MPU-VPU 混合 SIMD 架构，显著加速了 PIC 模拟中的粒子沉积步骤，实现了高性能和高资源利用率。这些结果表明，矩阵化方法对于加速新兴 CPU 架构上的 PIC 模拟是一种有效且可行的方法。

Abstract: Particle-in-Cell (PIC) simulations spend most of their execution time on particle--grid interactions, where fine-grained atomic updates become a major bottleneck on traditional many-core CPUs. Recent CPU architectures integrate specialized Matrix Processing Units (MPUs) that efficiently support matrix outer-product operations, offering new opportunities to overcome this limitation. Leveraging this architectural shift, this work focuses on redesigning the current deposition step of PIC simulations under a matrix-centric execution model.
  We present MatrixPIC, the first holistic co-design of the deposition kernel, data layout, and incremental particle sorting tailored to the hybrid MPU--VPU SIMD model on modern CPUs. MatrixPIC introduces: (i)~a block-matrix formulation of the current deposition algorithm that maps naturally to MPU outer-product primitives; (ii)~a hybrid execution pipeline that combines MPU-based high-density accumulation with VPU-based data preparation and control flow; and (iii)~an $O(1)$-amortized incremental sorter based on a gapped packed-memory array to preserve data locality for efficient MPU execution.
  Evaluated on a next-generation HPC platform, MatrixPIC achieves significant performance gains. In Laser-Wakefield Acceleration (LWFA) simulations, it delivers up to $2.63\times$ speedup in total runtime. For third-order deposition, the core kernel is accelerated by $8.7\times$ over the baseline and $2.0\times$ over the best hand-optimized VPU implementation. Moreover, MatrixPIC reaches $83.08\%$ of theoretical CPU peak performance, nearly $2.8\times$ higher than a highly optimized CUDA kernel on a data center GPU. These results demonstrate the effectiveness of matrix-oriented co-design for accelerating PIC simulations on emerging CPU architectures.

</details>


### [6] [Shifting the Sweet Spot: High-Performance Matrix-Free Method for High-Order Elasticity](https://arxiv.org/abs/2601.08374)
*Dali Chang,Chong Zhang,Kaiqi Zhang,Mingguan Yang,Huiyuan Li,Weiqiang Kong*

Main category: cs.DC

TL;DR: 本文涉及编译器（优化计算内核、宏内核融合策略）或高性能计算优化。本文的动机是解决高阶有限元分析（FEA）中无矩阵（PA）方法的计算性能瓶颈，即现有实现未能充分利用现代CPU架构和张量积单元的特性，导致其性能“甜点”停留在低阶$p \approx 2$，这限制了高阶方法的潜力。为了解决这一问题，作者在MFEM框架内设计并实现了一个高度优化的PA算子，集成了Geometric Multigrid (GMG) 预处理器。采取了多级优化策略，包括用基于张量分解的$O(p^4)$算法替换原始$O(p^6)$算法、利用Voigt对称性减少冗余计算，以及采用宏内核融合（macro-kernel fusion）以提高数据局部性和应对内存带宽瓶颈。实验证明该方法成功将性能“甜点”转移到$p \ge 6$的高阶区域。相比MFEM基线，核心算子加速了7到83倍，端到端性能提升了3.6到16.8倍。


<details>
  <summary>Details</summary>
Motivation: 在高阶有限元弹性力学分析中，虽然无矩阵（PA）方法是解决传统全组装（FA）内存瓶颈的关键技术，但现有实现无法充分利用现代CPU架构和张量积单元的特殊结构，导致其性能“甜点”异常地停留在低阶$p \approx 2$。这种限制严重阻碍了高阶方法的潜力发挥。本文旨在解决这一性能瓶颈，通过深度优化PA算子，将性能“甜点”推向更高阶区域。

Method: 作者设计并实现了一个高度优化的MFEM框架内的PA算子，该算子集成了Geometric Multigrid (GMG) 预处理器。核心优化策略包括：1. 将原始$O(p^6)$的通用算法替换为基于张量分解的高效$O(p^4)$算法。2. 利用Voigt对称性来减少弹性力学问题的冗余计算。3. 采用宏内核融合（macro-kernel fusion）来提高数据局部性并突破内存带宽瓶颈。

Result: 在主流x86和ARM架构上的广泛实验证明：1. 该方法成功将性能“甜点”转移到$p \ge 6$的高阶区域。2. 相比MFEM基线，优化的核心算子（内核）获得了7倍到83倍的加速。3. 完整的端到端求解过程性能提升了3.6倍到16.8倍。

Conclusion: 本文通过对MFEM中PA算子的深度优化，结合Geometric Multigrid (GMG) 预处理器，成功地将高性能计算的“甜点”从低阶$p \approx 2$提升至高阶$p \ge 6$区域。这为在主流CPU硬件上进行大规模、高阶弹性力学有限元仿真提供了一条经验证且高效的实用路径，充分释放了高阶方法的潜力。

Abstract: In high-order finite element analysis for elasticity, matrix-free (PA) methods are a key technology for overcoming the memory bottleneck of traditional Full Assembly (FA). However, existing implementations fail to fully exploit the special structure of modern CPU architectures and tensor-product elements, causing their performance "sweet spot" to anomalously remain at the low order of $p \approx 2$, which severely limits the potential of high-order methods. To address this challenge, we design and implement a highly optimized PA operator within the MFEM framework, deeply integrated with a Geometric Multigrid (GMG) preconditioner. Our multi-level optimization strategy includes replacing the original $O(p^6)$ generic algorithm with an efficient $O(p^4)$ one based on tensor factorization, exploiting Voigt symmetry to reduce redundant computations for the elasticity problem, and employing macro-kernel fusion to enhance data locality and break the memory bandwidth bottleneck. Extensive experiments on mainstream x86 and ARM architectures demonstrate that our method successfully shifts the performance "sweet spot" to the higher-order region of $p \ge 6$. Compared to the MFEM baseline, the optimized core operator (kernel) achieves speedups of 7x to 83x, which translates to a 3.6x to 16.8x end-to-end performance improvement in the complete solution process. This paper provides a validated and efficient practical path for conducting large-scale, high-order elasticity simulations on mainstream CPU hardware.

</details>


### [7] [MixServe: An Automatic Distributed Serving System for MoE Models with Hybrid Parallelism Based on Fused Communication Algorithm](https://arxiv.org/abs/2601.08800)
*Bowen Zhou,Jinrui Jia,Wenhao He,Yong Zhang,Fang Dong*

Main category: cs.DC

TL;DR: This paper is related to compiler and graph processing. The paper addresses the communication bottleneck in distributed serving of Mixture of Experts (MoE) models, proposing MixServe, an automated distributed serving system. MixServe employs a novel TP-EP hybrid parallelism based on a fused All-Reduce (AR) and All-to-All (A2A) communication algorithm to overlap intra-node and inter-node communication. This approach automatically selects the optimal parallel strategy and achieves significant performance gains (up to 3.80x TTFT acceleration and up to 50.3% throughput improvement) over existing methods.


<details>
  <summary>Details</summary>
Motivation: 解决大型 MoE 模型在分布式服务中遇到的通信瓶颈，尤其是跨节点通信瓶颈。现有的基于 All-Reduce (AR) 的张量并行 (TP) 和基于 All-to-All (A2A) 的专家并行 (EP) 存在缺陷：TP 跨节点效率低（受限于节点内高带宽），而 EP 在高并行度时容易遭受负载不平衡。

Method: 提出并实现了 MixServe，这是一个新颖的自动化分布式服务系统。MixServe 首先评估不同并行策略的通信开销，然后自动选择最有效的并行策略。此外，MixServe 引入了基于融合 AR-A2A 通信算法的 TP-EP 混合并行，该算法可以重叠节点内 AR 通信和节点间 A2A 通信。

Result: 实验结果表明，MixServe 在 DeepSeek-R1 和 Qwen3 模型上的推理性能显著优于现有方法：首令牌生成时间 (TTFT) 加速 1.08~3.80 倍，令牌间延迟 (ITL) 加速 1.03~1.66 倍，吞吐量提升 5.2%~50.3%。

Conclusion: MixServe 通过引入 TP-EP 混合并行和融合的 AR-A2A 通信算法，成功解决了分布式 MoE 模型服务中通信瓶颈和并行策略选择问题，实现了显著的性能提升。

Abstract: The Mixture of Experts (MoE) models are emerging as the latest paradigm for Large Language Models (LLMs). However, due to memory constraints, MoE models with billions or even trillions of parameters can only be deployed in multi-GPU or even multi-node & multi-GPU based serving systems. Thus, communication has became a major bottleneck in distributed serving systems, especially inter-node communication. Contemporary distributed MoE models are primarily implemented using all-reduce (AR) based tensor parallelism (TP) and all-to-all (A2A) based expert parallelism (EP). However, TP generally exhibits low inter-node efficiency and is thus confined to high-speed intra-node bandwidth. In contrast, EP tends to suffer from load imbalance, especially when the parallel degree is high.
  In this work, we introduce MixServe, a novel automatic distributed serving system for efficient deployment of MoE models by a novel TP-EP hybrid parallelism based on fused AR-A2A communication algorithm. MixServe begins by evaluating the communication overhead associated with various parallel strategies, taking into account the model hyperparameters and the configurations of network and hardware resources, and then automatically selects the most efficient parallel strategy. Then, we propose the TP-EP hybrid parallelism based on fused AR-A2A communication algorithm that overlaps intra-node AR communication and inter-node A2A communication. Extensive experiments on DeepSeek-R1 and Qwen3 models demonstrate that MixServe achieves superior inference performance, with 1.08~3.80x acceleration in time to first token (TTFT), 1.03~1.66x acceleration in inter-token latency (ITL), and 5.2%~50.3% throughput improvement compared to existing approaches.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [8] [Formalization and Implementation of Safe Destination Passing in Pure Functional Programming Settings](https://arxiv.org/abs/2601.08529)
*Thomas Bagrel*

Main category: cs.PL

TL;DR: 该论文与编译器 (计算模型/语言设计)、图处理 (间接相关，通过大型数据结构遍历) 相关。
太长不看：本文提出了 $\lambda_d$，一个具有目的地传递风格（destination-passing style）的核心 $\lambda$-演算，它通过结合线性类型和年龄系统的模态类型系统保证了目的地传递的类型安全性和极大的灵活性，并使用 Coq 进行了形式化验证。作者将 $\lambda_d$ 适配到纯函数式语言 Haskell 中，证明了其在解决大型数据结构遍历和映射问题时的有效性，有望提高纯函数式程序的性能和表达能力。


<details>
  <summary>Details</summary>
Motivation: 目的地传递风格（Destination-passing style）编程通过引入表示一次写入内存单元地址的“目的地”（destination），允许调用者控制内存管理，从而避免了为返回值分配空间。虽然该风格通常用于系统编程，但在纯函数式编程中，它也能使以往使用不可变数据结构难以或无法表达的程序得以实现。因此，本文的动机在于开发一个具有目的地传递机制的核心 $\lambda$-演算，以最大化这种风格的表达力和灵活性，并在纯函数式语言中安全地应用它，从而提高程序性能和表达能力。

Method: 本文首先提出并形式化了一个带有目的地的核心 $\lambda$-演算 ($\lambda_d$)，该演算的特点是使用模态类型系统，结合了线性类型和年龄系统来管理作用域，以确保目的地传递的安全性。$\lambda_d$ 的类型安全性已通过 Coq 证明助手形式化证明。其次，作者将这一核心演算的概念和机制适配到现有的纯函数式语言 Haskell 中，探索了在类型系统能力较弱的语言中实现安全目的地传递的方法，并进行了原型实现。最后，在 Haskell 原型中验证了其在处理大型数据结构时的性能提升效果。

Result: 本文取得了以下结果：成功开发了一个名为 $\lambda_d$ 的核心 $\lambda$-演算，它比现有的类似系统更具表现力。$\lambda_d$ 通过结合线性类型和年龄系统的模态类型系统，实现了安全灵活的目的地传递。其类型安全性已通过 Coq 证明助手形式化证明。此外，作者将 $\lambda_d$ 的概念成功适配到 Haskell 语言中，尽管初始实现因适应 Haskell 较弱的类型系统而损失了一些灵活性，但后续通过优化设计恢复了大部分灵活性。在 Haskell 中的原型实现显示，在遍历或映射大型数据结构（如列表或数据树）时，采用目的地传递风格编程取得了令人鼓舞的结果。

Conclusion: 本文成功地开发了一个带有目的地的核心 $\lambda$-演算 ($\lambda_d$)，并证明了其类型安全性。随后，作者将该演算适应于 Haskell 语言，展示了在纯函数式编程中采用目的地传递风格的可行性和优势，特别是在处理大型数据结构时的性能潜力。文章肯定了 $\lambda_d$ 在提高函数式程序表达能力和效率方面的价值。

Abstract: Destination-passing style programming introduces destinations, which represent the address of a write-once memory cell. These destinations can be passed as function parameters, allowing the caller to control memory management: the callee simply fills the cell instead of allocating space for a return value. While typically used in systems programming, destination passing also has applications in pure functional programming, where it enables programs that were previously unexpressible using usual immutable data structures.
  In this thesis, we develop a core λ-calculus with destinations, {λ_d}. Our new calculus is more expressive than similar existing systems, with destination passing designed to be as flexible as possible. This is achieved through a modal type system combining linear types with a system of ages to manage scopes, in order to make destination-passing safe. Type safety of our core calculus was proved formally with the Coq proof assistant.
  Then, we see how this core calculus can be adapted into an existing pure functional language, Haskell, whose type system is less powerful than our custom theoretical one. Retaining safety comes at the cost of removing some flexibility in the handling of destinations. We later refine the implementation to recover much of this flexibility, at the cost of increased user complexity.
  The prototype implementation in Haskell shows encouraging results for adopting destination-passing style programming when traversing or mapping over large data structures such as lists or data trees.

</details>
