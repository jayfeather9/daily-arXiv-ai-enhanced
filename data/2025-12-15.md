<div id=toc></div>

# Table of Contents

- [cs.PL](#cs.PL) [Total: 1]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DS](#cs.DS) [Total: 3]


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [1] [The Relative Monadic Metalanguage](https://arxiv.org/abs/2512.11762)
*Jack Liell-Cock,Zev Shirazi,Sam Staton*

Main category: cs.PL

TL;DR: 不是（DSL、图处理、MLIR、编译器、HLS）。
本文将单子元语言推广到相对设置，使用强相对单子提供了完整的语义，并基于此将两种现有程序演算（分级单子元语言和箭头演算）进行推广。具体结果是提出了两种新程序语言LNL-RMM（用于分级单子的线性-非线性语言）和ARMM（用于箭头的计算λ演算式语言），并证明它们分别是原有演算的保守扩展。


<details>
  <summary>Details</summary>
Motivation: 相对单子（Relative Monads）提供了一种受控的计算视图，这启发了作者将现有的计算理论和程序演算（如单子元语言、分级单子、箭头演算）推广到更通用、更受控的相对设置（Relative Setting）。具体动机是：1. 将单子元语言推广到相对设置，并提供完整的语义理论。2. 利用这种新的相对视角，推广并统一现有的两种重要程序演算：分级单子元语言和箭头演算，以获得更通用和表达力更强的语言。

Method: 方法包括：1. 将单子元语言推广到相对设置，并使用强相对单子提供完整的语义。2. 采用相对单子视角，推广两种现有的程序演算：分级单子元语言和箭头演算。3. 引入新的程序语言LNL-RMM（用于分级单子）和ARMM（用于箭头），并提供语义证明它们是保守扩展。具体来说：LNL-RMM采用了线性-非线性语言，并证明其保守扩展了分级单子元语言。ARMM是计算λ演算式的语言，专门用于箭头，被证明保守地扩展了箭头演算。

Result: 1. 成功将单子元语言推广到相对设置，并使用强相对单子（strong relative monads）提供了完整的语义。2. 推广了两种现有程序演算，引入了两种新的程序语言：LNL-RMM（Linear-Non-Linear language for Graded Monads）和ARMM（A language for Arrows based on Computational Lambda Calculus style）。3. **LNL-RMM**：一种用于分级单子的线性-非线性语言，通过语义证明，它是分级单子元语言的保守扩展（conservative extension）。4. **ARMM**：一种类似于计算λ演算式（computational lambda calculus-style）的箭头语言，证明了箭头演算（arrow calculus）是受限的相对单子元语言，并且ARMM保守地扩展了箭头演算。

Conclusion: 本文将单子元语言推广到相对设置，并通过强相对单子提供了完整的语义。通过这种视角，作者将两种现有的程序演算进行推广，得到了LNL-RMM和ARMM两种新语言。LNL-RMM是一种线性非线性语言，用于分级单子，通过语义证明它保守地扩展了分级单子元语言；ARMM是应用于箭头的计算λ演算式语言，它保守地扩展了箭头演算。总的来说，本文通过相对单子理论，为现有的分级单子元语言和箭头演算提供了更通用、更受控的计算视图和语义基础，并提出了新的程序语言来推广它们。

Abstract: Relative monads provide a controlled view of computation. We generalise the monadic metalanguage to a relative setting and give a complete semantics with strong relative monads. Adopting this perspective, we generalise two existing program calculi from the literature. We provide a linear-non-linear language for graded monads, LNL-RMM, along with a semantic proof that it is a conservative extension of the graded monadic metalanguage. Additionally, we provide a complete semantics for the arrow calculus, showing it is a restricted relative monadic metalanguage. This motivates the introduction of ARMM, a computational lambda calculus-style language for arrows that conservatively extends the arrow calculus.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [2] [PD-Swap: Prefill-Decode Logic Swapping for End-to-End LLM Inference on Edge FPGAs via Dynamic Partial Reconfiguration](https://arxiv.org/abs/2512.11550)
*Yifan Zhang,Zhiheng Chen,Ye Qiao,Sitao Huang*

Main category: cs.AR

TL;DR: This paper is related to HLS and Compiler and Graph Processing and MLIR and DSL. The paper is about how to accelerate aggressively quantized Large Language Models (LLMs) on edge FPGAs, especially when dealing with long context lengths. It proposes PD-Swap, a novel LLM accelerator that uses Dynamic Partial Reconfiguration (DPR) to time-multiplex the attention module. This switches between a compute-heavy prefill engine and a bandwidth-optimized decoding engine to address the prefill-decode performance asymmetry. This approach achieves up to 27 tokens/s decoding throughput, outperforming prior works by 1.3x–2.1x without extra area cost.


<details>
  <summary>Details</summary>
Motivation: 现有的激进量化的LLM（如BitNet-style 1.58-bit Transformer）虽然适合部署在低功耗边缘FPGA上，但随着提示词（Prompt）增长至数万个tokens，推理延迟急剧增加，这是因为二次方的预填充成本和快速增长的KV-cache带宽需求。LLM推理存在根本性的预填充-解码不对称性：预填充是计算受限的（Compute-bound），而解码是内存带宽受限的（Memory-bandwidth-bound）。一个静态加速器必须同时为这两种模式配置资源和单一数据流，导致资源利用率低、注意逻辑重复，并受限于LUT/URAM资源，从而限制了模型尺寸和可用上下文长度。作者旨在解决这一不对称性，提高长上下文长度下的解码性能。

Method: 该论文提出了PD-Swap，一种预填充-解码解耦的LLM加速器，利用边缘FPGA上的动态部分重配置（DPR）来时间多路复用注意力模块。核心是通过一个静态的表查找三元矩阵乘法和权重缓冲引擎，以及一个可重配置分区内的两个阶段专用架构：一个计算密集型、令牌并行的预填充引擎，和一个带宽优化、以KV-Cache为中心的解码引擎。通过一个类房顶线模型和设计空间探索，共同优化了可重配置区域大小、并行度以及重配置延迟的隐藏（通过计算延迟）。

Result: PD-Swap实现了高达27个tokens/s的解码吞吐量。它比现有的最先进工作高出1.3倍到2.1倍，尤其是在更长的上下文长度下获得了更大的性能提升。关键在于，它在没有额外面积成本的情况下达到了这些性能提升。

Conclusion: PD-Swap通过动态部分重配置（DPR）来时间复用边缘FPGA上的注意力模块，从而实现预填充和解码两个阶段的解耦加速。它通过一个计算密集型的预填充引擎和一个面向带宽优化的解码引擎，实现了高达27个tokens/s的解码吞吐量，比现有的最先进工作高出1.3倍到2.1倍，特别是在更长的上下文长度下收益更大，且无需额外面积成本。这项工作证明了通过资源时间多路复用的方式，可以在资源受限的边缘硬件上，有效地解决LLM在不同推理阶段性能瓶颈的异构性问题，显著提高了LLM的推理性能和上下文长度支持。

Abstract: Aggressively quantized large language models (LLMs), such as BitNet-style 1.58-bit Transformers with ternary weights, make it feasible to deploy generative AI on low-power edge FPGAs. However, as prompts grow to tens of thousands of tokens, edge hardware performance drops sharply with sequence length due to quadratic prefill cost and rapidly increasing KV-cache bandwidth demands, making inference latency of longer context length a first-order system concern. Recent studies on LLMs expose a fundamental prefill-decode asymmetry: prefill is compute-bound and dominated by dense matrix-matrix operations, whereas decoding is memory-bandwidth-bound and dominated by KV-cache traffic. A static accelerator must provision resources and a single dataflow for both regimes, leading to duplicated attention logic, underutilized fabric, and tight LUT/URAM limits that cap model size and usable context. We propose a prefill--decode disaggregated LLM accelerator, PD-Swap, that uses Dynamic Partial Reconfiguration (DPR) to time-multiplex the attention module on edge FPGAs. The core table-lookup ternary matrix multiplication and weight-buffering engines remain static, while the attention subsystem is a reconfigurable partition with two phase-specialized architectures: a compute-heavy, token-parallel prefill engine and a bandwidth-optimized, KV-cache-centric decoding engine. A roofline-inspired model and design space exploration jointly optimize reconfigurable-region size, parallelism under reconfiguration and routability constraints, and reconfiguration latency is hidden by computation latency. PD-Swap achieves up to 27~tokens/s decoding throughput, outperforming prior state-of-the-art works by 1.3x--2.1x (larger gains at longer context lengths), without extra area cost.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [3] [Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration](https://arxiv.org/abs/2512.11200)
*Adilet Metinov,Gulida M. Kudakeeva,Gulnara D. Kabaeva*

Main category: cs.DC

TL;DR: 该论文与编译器、DSL（代码生成系统）、图处理（虽然未明确提及，但可以联系到编译后端优化或数据流图）相关。其核心在于解决 AI 代码生成系统中的 CPU-GPU 数据传输延迟。
太长不看 (TL;DR): Current AI code generation systems suffer from severe CPU-GPU data transfer bottlenecks. This paper establishes the theoretical foundation for three GPU-native compilation approaches (parallel traditional, neural, and hybrid) to eliminate these transfers, projecting 10-100x speedups in code iteration cycles. It shows that traditional GPU compilation yields 2-5x improvement, neural compilation achieves 10-100x acceleration via massive parallelism, and hybrid approaches offer practical, provably correct deployment paths, supported by a formal probabilistic verification framework.


<details>
  <summary>Details</summary>
Motivation: 当前的 AI 代码生成系统在编译、执行和测试阶段存在显著的 CPU-GPU 数据传输延迟瓶颈，这极大地限制了代码迭代速度。因此，本文的动机在于提出和分析消除这些数据传输的 GPU 原生编译方法，以实现数量级的加速。

Method: 论文通过建立理论基础并推导延迟和能耗界限来分析和证明三种 GPU 原生编译方法（并行传统编译、神经编译、混合架构）在消除 CPU-GPU 数据传输延迟方面的潜力。特别是，论文形式化了概率验证框架，以支持在编译精度和并行探索之间进行权衡。

Result: 研究建立了消除 CPU-GPU 数据传输的 GPU 原生编译方法的理论基础，并推导了其延迟和能耗界限。理论分析表明，代码迭代周期可能实现 10-100 倍的加速。具体结果包括：传统 GPU 编译通过消除传输实现 2-5 倍改进；神经编译通过大规模并行实现 10-100 倍加速；混合方法提供了实用部署路径和正确性保证。论文还形式化了概率验证框架。

Conclusion: 这篇论文提出了消除 AI 代码生成系统中 CPU-GPU 数据传输延迟的 GPU 原生编译方法，并探讨了三种互补的方法：并行传统编译、神经编译和混合架构。通过理论分析和推导的延迟与能耗界限，论文展示了这些方法在代码迭代周期中实现 10-100 倍加速的潜力。论文得出的结论是，传统 GPU 编译主要通过消除数据传输实现 2-5 倍的改进，神经编译通过大规模并行实现 10-100 倍的加速，而混合架构则提供了一个具有正确性保证的实用部署路径。论文还提出了概率验证框架，为权衡编译精度和并行探索提供了理论基础，并讨论了对自改进 AI 系统和未来模拟计算基板的意义。

Abstract: Current AI code generation systems suffer from significant latency bottlenecks due to CPU-GPU data transfers during compilation, execution, and testing phases. We establish theoretical foundations for three complementary approaches to GPU-native compilation that eliminate these transfers: (1) parallel traditional compilation adapted for GPU execution, (2) neural compilation using learned sequence-to-sequence translation with probabilistic verification, and (3) hybrid architectures combining both strategies. We derive latency and energy bounds demonstrating potential speedups of 10-100x for code iteration cycles. Our analysis shows that traditional GPU compilation provides 2-5x improvements through transfer elimination, neural compilation achieves 10-100x speedups via massive parallelism, and hybrid approaches offer practical deployment paths with guaranteed correctness. We formalize the probabilistic verification framework that enables trading compilation accuracy for parallel exploration, and discuss implications for self-improving AI systems and future analog computing substrates.

</details>


### [4] [An Efficient Approach for Energy Conservation in Cloud Computing Environment](https://arxiv.org/abs/2512.10974)
*Sohan Kumar Pande,Sanjaya Kumar Panda,Preeti Ranjan Sahu*

Main category: cs.DC

TL;DR: 该论文与编译器相关部分是云计算中的资源调度，这本质上是系统软件的一部分，其中调度算法的设计与编译器中的资源分配和调度有相似的优化目标。TLDR: 云服务耗能大，现有调度算法未充分考虑不同资源类型。本文提出了一种新的任务调度算法，通过结合CPU、磁盘和I/O的利用率和任务处理时间来计算适应度值，以显式地提高不同类型资源的利用率，从而降低能耗。仿真结果表明，该算法比现有MaxUtil算法更节能。


<details>
  <summary>Details</summary>
Motivation: 云服务消耗大量能源，且现有能源有限并带来温室效应。因此，需要减少云服务提供商的能耗，这对研究社区提出了开发节能算法的挑战。现有的研究主要关注最大化平均资源利用率或最小化最短完工时间（makespan），但没有考虑物理机中存在的不同类型的资源（如CPU、磁盘、I/O）。

Method: 本文提出了一种任务调度算法，该算法通过一个适应度值来选择任务放置的位置，该适应度值是CPU、磁盘和I/O利用率以及任务处理时间的一个函数。通过这种方式，算法明确地提高了不同种类资源的利用率，进而增加了活动资源的利用率。使用合成数据集对所提出的算法和现有算法MaxUtil进行了广泛的仿真。

Result: 仿真结果显示，所提出的算法比MaxUtil算法更节能，消耗更少的能量。

Conclusion: 本文提出了一种考虑CPU、磁盘和I/O等不同资源利用率的新的任务调度算法，并通过仿真证明了该算法在节能方面优于现有的MaxUtil算法。

Abstract: Recent trends of technology have explored a numerous applications of cloud services, which require a significant amount of energy. In the present scenario, most of the energy sources are limited and have a greenhouse effect on the environment. Therefore, it is the need of the hour that the energy consumed by the cloud service providers must be reduced and it is a great challenge to the research community to develop energy-efficient algorithms. To design the same, some researchers tried to maximize the average resource utilization, whereas some researchers tried to minimize the makespan. However, they have not considered different types of resources that are present in the physical machines. In this paper, we propose a task scheduling algorithm, which tries to improve utilization of resources (like CPU, disk, I/O) explicitly, which in turn increases the utilization of active resources. For this, the proposed algorithm uses a fitness value, which is a function of CPU, disk and I/O utilization, and processing time of the task. To demonstrate the performance of the proposed algorithm, extensive simulations are performed on both proposed algorithm and existing algorithm MaxUtil using synthetic datasets. From the simulation results, it can be observed that the proposed algorithm is a better energy-efficient algorithm and consumes less energy than the MaxUtil algorithm.

</details>


### [5] [Seamless Transitions: A Comprehensive Review of Live Migration Technologies](https://arxiv.org/abs/2512.10979)
*Sima Attar-Khorasani,Lincoln Sherpa,Matthias Lieber,Siavash Ghiasvand*

Main category: cs.DC

TL;DR: 该论文与DSL、图处理、MLIR、编译器或HLS不相关。
该论文是对实时迁移（Live Migration）技术的全面综述，集中分析了虚拟机和容器两种主要形式的迁移技术、单元和基础设施，指出了现有综述的不足，探讨了现实世界中的挑战、接受度差异以及迁移目标和操作约束的影响，并为未来的研究提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有的实时迁移综述通常忽视了在现实场景中使用实时迁移技术时所固有的关键技术方面和实际挑战。本文的动机是弥合这一差距，通过全面分析实时迁移技术在多个维度上的现状，尤其是关注容器和虚拟机上的应用和采用差异，以解决现有综述中缺乏的实用性和系统性分析。

Method: 本文采用综合分析和系统回顾的方法，整合了现有文献中探索的各个方面，并从迁移技术、迁移单元和基础设施特性等多个维度对实时迁移技术进行了全面分析。研究侧重于容器和虚拟机两种主要的迁移技术，并通过比较它们之间的采用差异来评估现有技术的现状。文章还分析了迁移目标和操作约束对现有技术可用性和有效性的影响，最终提出了未来的挑战和发展方向。

Result: 本文对实时迁移技术进行了全面的多维度分析，着重探讨了在容器和虚拟机环境中的迁移技术、迁移单元和基础设施特性。分析揭示了这两种方法在采用上的差异，并强调了实时迁移可能因复杂的系统因素和资源需求而难以证明其合理性的情况。通过探索迁移目标和操作约束的影响，文章总结了当前的技术挑战，并为实时迁移的未来发展明确了方向和指导。

Conclusion: 这篇综述总结了现有实时迁移技术的现状，分析了其在虚拟机和容器环境中的应用差异，并探讨了迁移目标和操作约束对其可用性和有效性的影响。文章指出了当前的技术挑战，并为未来的研究和发展提供了指导方向，旨在推动实时迁移技术及其在不同计算环境中的实际应用。

Abstract: Live migration, a technology enabling seamless transition of operational computational entities between various hosts while preserving continuous functionality and client connectivity, has been the subject of extensive research. However, existing reviews often overlook critical technical aspects and practical challenges integral to the usage of live migration techniques in real-world scenarios. This work bridges this gap by integrating the aspects explored in existing reviews together with a comprehensive analysis of live migration technologies across multiple dimensions, with focus on migration techniques, migration units, and infrastructure characteristics. Despite efforts to make live migration widely accessible, its reliance on multiple system factors can create challenges. In certain cases, the complexities and resource demands outweigh the benefits, making its implementation hard to justify. The focus of this work is mainly on container based and virtual machine-based migration technologies, examining the current state of the art and the disparity in adoption between these two approaches. Furthermore, this work explores the impact of migration objectives and operational constraints on the usability and efficacy of existing technologies. By outlining current technical challenges and providing guidelines for future research and development directions, this work serves a dual purpose: first, to equip enthusiasts with a valuable resource on live migration, and second, to contribute to the advancement of live migration technologies and their practical implementation across diverse computing environments.

</details>


### [6] [Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling](https://arxiv.org/abs/2512.10980)
*Akhmadillo Mamirov*

Main category: cs.DC

TL;DR: 关联领域：图处理（GPU 集群上的 AI 训练和部署）。
这篇论文系统地评估了 GPU 集群中碎片化、异构工作负载和静态调度限制导致的低利用率问题。提出了三种动态调度器：混合优先级（HPS）、预测回填（PBS）和智能批处理（SBS），旨在提高多租户 AI 集群的利用率、吞吐量和公平性。在一项包含 1,000 个 AI 作业的模拟中，动态调度器显著优于静态基线（利用率从 45%-67% 提高到 74.6%-78.2%）。其中 HPS 表现最佳，实现了最高的利用率（78.2%）和吞吐量（每小时 25.8 个作业），并将饥饿作业数从最多 156 个减少到 12 个。结果表明，有针对性的透明调度策略是提高异构 AI 集群 GPU 效率的有效途径。


<details>
  <summary>Details</summary>
Motivation: 现代 AI 系统训练和部署对于 GPU 集群的依赖性不断增强，但实际部署的平均利用率仍接近 50%。这种低效主要是由碎片化、异构工作负载以及静态调度策略的局限性造成的。因此，需要新的调度策略来提高多租户 GPU 集群的利用率、公平性和总体吞吐量。

Method: 通过对多租户 GPU 集群上存在的碎片化、异构工作负载和静态调度限制等问题进行系统评估，并提出三种专门的动态调度器：混合优先级调度器（HPS）、预测回填调度器（PBS）和智能批处理调度器（SBS）。使用包含训练、推理和研究工作负载的 1,000 个 AI 作业，在 64-GPU、8 节点集群的受控模拟中评估所有调度器。

Result: 静态基线（FIFO、SJF、Shortest、Shortest-GPU）的 GPU 利用率为 45% 至 67%，每小时处理 12.5 至 18.3 个作业，并经历严重的饥饿现象（多达 156 个作业等待超过 30 分钟）。
动态调度器显著优于这些策略：
1. **HPS** 实现了最高的利用率（78.2%）、最高的吞吐量（每小时 25.8 个作业）和动态方法中最低的公平性方差（457），将饥饿作业数减少到 12 个。
2. **PBS** 改善了碎片化处理，达到了 76.1% 的利用率。
3. **SBS** 提高了结构相似作业的效率，达到了 74.6% 的利用率。

Conclusion: 动态多目标调度器在吞吐量、作业等待时间、公平性方差和饥饿等所有关键指标上始终优于单目标启发式方法。所介绍的针对性且透明的调度策略可以显著提高异构 AI 集群中的 GPU 效率，并为未来的生产调度框架提供了实用的基础。

Abstract: GPU clusters have become essential for training and deploying modern AI systems, yet real deployments continue to report average utilization near 50%. This inefficiency is largely caused by fragmentation, heterogeneous workloads, and the limitations of static scheduling policies. This work presents a systematic evaluation of these issues and introduces three specialized dynamic schedulers: Hybrid Priority (HPS), Predictive Backfill (PBS), and Smart Batch (SBS). These schedulers are designed to improve utilization, fairness, and overall throughput in multi-tenant GPU clusters. We evaluate all schedulers using a controlled simulation of 1,000 AI jobs on a 64-GPU, 8-node cluster that includes a realistic mix of training, inference, and research workloads. Static baselines (FIFO, SJF, Shortest, Shortest-GPU) achieve 45 to 67% GPU utilization and 12.5 to 18.3 jobs per hour and experience severe starvation, with as many as 156 jobs waiting longer than 30 minutes. The dynamic schedulers significantly outperform these policies. HPS achieves the highest utilization (78.2%), highest throughput (25.8 jobs per hour), and the lowest fairness variance among dynamic methods (457), reducing starvation to 12 jobs. PBS improves fragmentation handling and reaches 76.1% utilization, while SBS increases efficiency for structurally similar jobs and reaches 74.6% utilization. Across all key metrics, including throughput, job wait times, fairness variance, and starvation, dynamic multi-objective schedulers consistently outperform single-objective heuristics. These results show that targeted and transparent scheduling strategies can meaningfully increase GPU efficiency in heterogeneous AI clusters and provide a practical foundation for future production scheduling frameworks.

</details>


### [7] [Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems](https://arxiv.org/abs/2512.10987)
*Sumit Chongder*

Main category: cs.DC

TL;DR: 这个论文与DSL或图处理或MLIR或编译器或HLS均不相关。
这个研究比较了集中式分层联邦学习（HFL）和两种分散式联邦学习方法（AFL和CFL）。结果显示，分散式方法（AFL和CFL）在Fashion MNIST和MNIST数据集上的性能，包括精确度、召回率、F1分数和平衡准确率，均优于集中式HFL，表明分散式聚合机制对于增强协同模型训练的性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 联邦学习领域近年来在去中心化方法方面取得了显著进展。集中式分层联邦学习（HFL）面临通信瓶颈和集中式数据聚合带来的隐私问题等挑战。因此，研究的动机是探讨分散式方法，如分散式聚合联邦学习（AFL）和分散式持续联邦学习（CFL），作为HFL的可行且有前景的替代方案，旨在通过比较评估来证明分散式方法的优势，从而促进分布式设备上的协同模型训练。

Method: 本文采用比较研究的方法，通过在Fashion MNIST和MNIST数据集上评估三种不同的联邦学习架构：集中式HFL、分散式AFL和分散式CFL。评估指标包括精确度（precision）、召回率（recall）、F1分数和平衡准确率（balanced accuracy）。通过这些评估，研究人员分析了分散式聚合机制在AFL和CFL中的重要性及其对性能的贡献。

Result: 通过在Fashion MNIST和MNIST数据集上的评估，研究结果表明分散式方法（AFL和CFL）在精确度、召回率、F1分数和平衡准确率等方面均优于集中式HFL。这证明了分散式聚合机制在有效地实现分布式设备上的协同模型训练中的重要性。

Conclusion: 这篇研究论文通过比较集中式分层联邦学习（HFL）与分散式聚合联邦学习（AFL）和分散式持续联邦学习（CFL）架构，得出了分散式方法（AFL和CFL）在联邦学习场景中表现出优于集中式方法（HFL）的性能。研究结果指导研究人员和实践者转向分散式方法，以在协同模型训练场景中获得更高的性能。

Abstract: In recent years, the landscape of federated learning has witnessed significant advancements, particularly in decentralized methodologies. This research paper presents a comprehensive comparison of Centralized Hierarchical Federated Learning (HFL) with Decentralized Aggregated Federated Learning (AFL) and Decentralized Continual Federated Learning (CFL) architectures. While HFL, in its centralized approach, faces challenges such as communication bottlenecks and privacy concerns due to centralized data aggregation, AFL and CFL provide promising alternatives by distributing computation and aggregation processes across devices. Through evaluation of Fashion MNIST and MNIST datasets, this study demonstrates the advantages of decentralized methodologies, showcasing how AFL and CFL outperform HFL in precision, recall, F1 score, and balanced accuracy. The analysis highlights the importance of decentralized aggregation mechanisms in AFL and CFL, which effectively enables collaborative model training across distributed devices. This comparative study contributes valuable insights into the evolving landscape of federated learning, guiding researchers and practitioners towards decentralized methodologies for enhanced performance in collaborative model training scenarios.

</details>


### [8] [RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training](https://arxiv.org/abs/2512.11306)
*Tianyuan Wu,Lunxi Cao,Yining Wei,Wei Gao,Yuheng Zhao,Dakai An,Shaopan Xiong,Zhiqiang Lv,Ju Huang,Siran Yang,Yinghao Yu,Jiamang Wang,Lin Qu,Wei Wang*

Main category: cs.DC

TL;DR: 该论文与 **Graph Processing**、**MLIR**、**DSL**、**HLS** 无直接关系。它与 **Compiler（编译器）** 和 **HLS** 领域有间接联系，因为它们都关注系统和硬件资源调度与优化，但 RollMux 侧重于**分布式集群调度**和**强化学习（RL）系统**优化。

**太长不读 (TLDR)：** 强化学习中的采样-训练分离架构因严格同步而导致集群严重空闲。RollMux 是一种跨集群调度框架，通过允许非依赖作业利用这些空闲时间来恢复效率。它引入了“协同执行组”和两层调度，并利用内存驻留实现快速上下文切换。在生产规模的 GPU 集群上，RollMux 将成本效率提高了 1.84 倍（相对于标准分离）和 1.38 倍（相对于先进共置基线），并实现了 100% 的服务等级目标。


<details>
  <summary>Details</summary>
Motivation: 现有的 Reinforcement Learning (RL) 后训练标准架构是“rollout-training disaggregation”（采样-训练分离），将内存密集型的 rollout 阶段和计算密集型的 training 阶段分别部署到专门的集群以最大化硬件效率。然而，on-policy 算法要求的严格同步会引入严重的“dependency bubbles”（依赖气泡），导致一个集群在等待另一个集群运行依赖阶段时处于空闲状态，极大地降低了硬件利用率和成本效率。本文的动机在于设计一个集群调度框架来重新利用这些空闲时间，从而提升 RL 训练的成本效率和硬件利用率。

Method: RollMux 提出了一个跨集群的调度框架，旨在回收因 on-policy RL 算法中内存密集型 "rollout" 和计算密集型 "training" 阶段严格同步而导致的集群空闲时间（依赖气泡）。其核心方法包括：1. 提出“co-execution group”（协同执行组）抽象，将集群划分为隔离的局部性域。2. 基于该抽象构建两层调度架构：一个**组间调度器**使用保守随机规划优化作业放置；一个**组内调度器**采用可证明最优的轮询调度。3. 强制实施“residency constraint”（驻留约束），确保模型状态缓存于主机内存，实现“warm-star”上下文切换，以最小化作业切换开销。

Result: 通过在包含 328 块 H20 和 328 块 H800 GPU 的生产规模测试平台上进行评估，RollMux 相较于标准分离架构，成本效率提高了 1.84 倍；相较于最先进的共置基线，成本效率提高了 1.38 倍；同时达到了 100% 的服务等级目标（SLO）遵循率。

Conclusion: RollMux is a cluster scheduling framework that reclaims the idle time (dependency bubbles) caused by the strict synchronization between the memory-bound rollout and compute-bound training phases in disaggregated on-policy RL structures, thereby improving hardware utilization and cost efficiency. The key innovations are the co-execution group abstraction, two-tier scheduling architecture, and the residency constraint (warm-star context switching). Evaluation on a production-scale testbed shows that RollMux achieves 1.84x better cost efficiency than standard disaggregation and 1.38x better than state-of-the-art co-located baselines, with 100% SLO attainment.

Abstract: Rollout-training disaggregation is emerging as the standard architecture for Reinforcement Learning (RL) post-training, where memory-bound rollout and compute-bound training are physically disaggregated onto purpose-built clusters to maximize hardware efficiency. However, the strict synchronization required by on-policy algorithms introduces severe dependency bubbles, forcing one cluster to idle while the dependent phase is running on the other. We present RollMux, a cluster scheduling framework that reclaims these bubbles through cross-cluster orchestration. RollMux is built on the insight that the structural idleness of one job can be effectively utilized by the active phase of another. To realize this, we introduce the co-execution group abstraction, which partitions the cluster into isolated locality domains. This abstraction enables a two-tier scheduling architecture: an inter-group scheduler that optimizes job placement using conservative stochastic planning, and an intra-group scheduler that orchestrates a provably optimal round-robin schedule. The group abstraction also imposes a residency constraint, ensuring that massive model states remain cached in host memory to enable "warm-star" context switching. We evaluate RollMux on a production-scale testbed with 328 H20 and 328 H800 GPUs. RollMux improves cost efficiency by 1.84x over standard disaggregation and 1.38x over state-of-the-art co-located baselines, all while achieving 100% SLO attainment.

</details>


### [9] [ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning](https://arxiv.org/abs/2512.11727)
*Yuze He,Ferdi Kossmann,Srinivasan Seshan,Peter Steenkiste*

Main category: cs.DC

TL;DR: 这个论文与图处理、MLIR、编译器或HLS无关，但与**DSL（特定领域语言）**和**编译器**领域有所关联，如果将**视频分析框架**视为一个**特定领域的系统或中间表示层**来优化资源使用和模型重训练过程，尤其是其中涉及的资源管理和调度策略，可能牵涉到特定领域的优化或配置语言。但更直接清晰的关联是与**深度学习系统优化**和**资源管理**相关。
Too long; didn't read: 针对视频分析中每个摄像头单独重训练模型以应对数据漂移导致的高成本问题，ECCO提出了一个资源高效的持续学习框架。它通过识别数据漂移相似的摄像头并将它们分组共享模型重训练，结合动态分组算法、GPU资源分配器和传输控制器，显著降低了计算和通信开销，并在相同资源下提高了重训练准确性或支持了更多的并发摄像头。


<details>
  <summary>Details</summary>
Motivation: 现有的针对每个摄像头单独重训练模型的做法，由于计算和通信成本高昂，难以扩展，而数据漂移通常在相邻摄像头间存在时空相关性。

Method: ECCO提出：（i）轻量级分组算法，动态形成和更新摄像头组；（ii）GPU分配器，动态分配GPU资源以提高准确性和确保公平性；（iii）传输控制器，在每个摄像头配置帧采样并根据分配的GPU资源协调带宽共享。

Result: 与主流基线相比，ECCO在相同计算和通信资源下，重训练准确率提高了6.7%-18.1%，或在相同准确率下支持了3.3倍的并发摄像头。

Conclusion: ECCO通过利用相邻摄像头数据漂移的时空相关性，实现了资源高效的持续学习，显著提高了重训练准确性或支持了更多并发摄像头。

Abstract: Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable. We present ECCO, a new video analytics framework designed for resource-efficient continuous learning. The key insight is that the data drift, which necessitates model retraining, often shows temporal and spatial correlations across nearby cameras. By identifying cameras that experience similar drift and retraining a shared model for them, ECCO can substantially reduce the associated compute and communication costs. Specifically, ECCO introduces: (i) a lightweight grouping algorithm that dynamically forms and updates camera groups; (ii) a GPU allocator that dynamically assigns GPU resources across different groups to improve retraining accuracy and ensure fairness; and (iii) a transmission controller at each camera that configures frame sampling and coordinates bandwidth sharing with other cameras based on its assigned GPU resources. We conducted extensive evaluations on three distinctive datasets for two vision tasks. Compared to leading baselines, ECCO improves retraining accuracy by 6.7%-18.1% using the same compute and communication resources, or supports 3.3 times more concurrent cameras at the same accuracy.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [10] [Scalable Similarity Search over Large Attributed Bipartite Graphs](https://arxiv.org/abs/2512.11606)
*Xi Ou,Longlong Lin,Zeli Wang,Pingpeng Yuan,Rong-Hua Li*

Main category: cs.DS

TL;DR: 关联领域: 图处理 (Graph processing)。
TLDR: 针对现有二部图相似性搜索方法在处理大规模、带属性数据时，精度低和效率差的问题，本文提出了一种新颖的随机游走模型——属性增强的隐藏式个性化PageRank (AHPP)，该模型能同时融合高阶二部结构邻近度和属性相似性。在此基础上，将相似性搜索转化为近似AHPP问题，并提出了两种高效的推式局部近似算法，这些算法具有可证明的近似保证。实验证明AHPP及其算法在真实和合成数据集上都非常有效和高效。


<details>
  <summary>Details</summary>
Motivation: 现有的二部图相似性搜索方法存在以下问题：1. 无法准确捕获二部图的独特结构特性。2. 未能有效融入信息丰富的节点属性，导致性能不佳。3. 计算复杂度高，可扩展性受限，不适用于具有数百万节点和数万属性的大规模图。

Method: 1. 提出“属性增强的隐藏式个性化PageRank”（Attribute-augmented Hidden Personalized PageRank，简称AHPP）模型，这是一个新颖的随机游走模型，用于无缝融合高阶二部结构邻近度和属性相似性。2. 将带属性二部图上的相似性搜索问题，公式化为一个近似的AHPP问题。3. 提出两种高效的推式（push-style）局部近似算法，并提供了可证明的近似保证。

Result: 在真实的和合成的数据集上进行了广泛的实验。实验结果验证了：1. AHPP模型在相似性搜索中的有效性。2. 提出的局部近似算法与十五个竞争方法相比具有高效率。

Conclusion: 我们提出并验证了AHPP模型及其高效的局部近似算法，该方法在保持效率的同时，有效地结合了二部图的结构特性和节点属性，解决了现有方法在有属性二部图相似性搜索中精度和效率不足的问题。

Abstract: Bipartite graphs are widely used to model relationships between entities of different types, where nodes are divided into two disjoint sets. Similarity search, a fundamental operation that retrieves nodes similar to a given query node, plays a crucial role in various real-world applications, including machine learning and graph clustering. However, existing state-of-the-art methods often struggle to accurately capture the unique structural properties of bipartite graphs or fail to incorporate the informative node attributes, leading to suboptimal performance. Besides, their high computational complexity limits scalability, making them impractical for large graphs with millions of nodes and tens of thousands of attributes. To overcome these challenges, we first introduce Attribute-augmented Hidden Personalized PageRank (AHPP), a novel random walk model designed to blend seamlessly both the higher-order bipartite structure proximity and attribute similarity. We then formulate the similarity search over attributed bipartite graphs as an approximate AHPP problem and propose two efficient push-style local algorithms with provable approximation guarantees. Finally, extensive experiments on real-world and synthetic datasets validate the effectiveness of AHPP and the efficiency of our proposed algorithms when compared with fifteen competitors.

</details>


### [11] [New Entropy Measures for Tries with Applications to the XBWT](https://arxiv.org/abs/2512.11618)
*Lorenzo Carfagna,Carlo Tosoni*

Main category: cs.DS

TL;DR: 该论文与编译器、HLS、MLIR、图处理和DSL领域不相关。/
在本论文中，作者引入了两种新的Trie树熵度量（最坏情况熵和经验熵）来克服现有度量未能考虑符号频率和Trie拓扑的限制。这两种度量是字符串熵的自然推广，其中经验熵与算术编码的推广相关，并被用于Trie树的扩展Burrows-Wheeler变换（XBWT）的压缩和高效索引。结果表明，基于新熵度量的XBWT编码在$k$阶经验熵加$o(n)$比特内实现，其空间使用始终小于，在特定情况下甚至渐近小于原始编码，从而提高了Trie结构的存储效率。


<details>
  <summary>Details</summary>
Motivation: 现有Trie树的熵度量（如标准最坏情况熵和标签熵）存在局限性。标准最坏情况熵没有考虑Trie中符号的频率分布，未能反映字符分布偏斜时Trie的可压缩性。而标签熵没有考虑树的拓扑结构，需要额外存储。因此，需要新的熵度量来克服这两个限制，更准确地量化Trie树的存储需求和可压缩性。

Method: 作者通过引入两种新的Trie树熵度量（最坏情况熵和经验熵）来解决现有Trie树熵度量方法的局限性。这些新度量考虑了符号的频率分布和Trie的拓扑结构。经验熵被证明与算术编码的自然推广相关，并用于指导Trie树扩展Burrows-Wheeler变换（XBWT）的压缩和高效索引。

Result: 本文引入的两种新Trie树熵度量（最坏情况熵和经验熵）被证明是字符串熵的自然推广，并具有相似的性质。经验熵与字符串算术编码的自然推广紧密相关。此外，作者证明了Trie树的扩展Burrows-Wheeler变换（XBWT）可以在他们的k阶经验熵加上$o(n)$比特空间内被压缩和高效索引，其中$n$是节点数。这种XBWT编码的空间使用包括Trie拓扑结构，并且对于所有足够小的$k$，该上界同时成立。这种新的XBWT编码总是严格小于原始编码，并且在某些情况下渐近更小。

Conclusion: 本文引入了两种新的Trie树熵度量——最坏情况熵和经验熵，它们克服了现有方法的局限性，成为字符串熵的自然推广。特别是，经验熵与算术编码的推广相关，并且与Trie树的XBWT的压缩和索引紧密相关。这些新的熵度量，尤其是在压缩和索引XBWT方面，实现了比现有方法更小且在某些情况下渐近更小的存储空间，从而提高了Trie结构的存储效率。

Abstract: Entropy quantifies the number of bits required to store objects under certain given assumptions. While this is a well established concept for strings, in the context of tries the state-of-the-art regarding entropies is less developed. The standard trie worst-case entropy considers the set of tries with a fixed number of nodes and alphabet size. However, this approach does not consider the frequencies of the symbols in the trie, thus failing to capture the compressibility of tries with skewed character distributions. On the other hand, the label entropy [FOCS '05], proposed for node-labeled trees, does not take into account the tree topology, which has to be stored separately. In this paper, we introduce two new entropy measures for tries - worst-case and empirical - which overcome the two aforementioned limitations. Notably, our entropies satisfy similar properties of their string counterparts, thereby becoming very natural generalizations of the (simpler) string case. Indeed, our empirical entropy is closely related to the worst-case entropy and is reachable through a natural extension of arithmetic coding from strings to tries. Moreover we show that, similarly to the FM-index for strings [JACM '05], the XBWT of a trie can be compressed and efficiently indexed within our k-th order empirical entropy plus o(n) bits, with n being the number of nodes. Interestingly, the space usage of this encoding includes the trie topology and the upper-bound holds for every k sufficiently small, simultaneously. This XBWT encoding is always strictly smaller than the original one [JACM '09] and we show that in certain cases it is asymptotically smaller.

</details>


### [12] [The parameterized complexity of Strong Conflict-Free Vertex-Connection Colorability](https://arxiv.org/abs/2512.11725)
*Carl Feghali,Hoang-Oanh Le,Van Bang Le*

Main category: cs.DS

TL;DR: 该论文与 DSL、图处理、MLIR、编译器、HLS 无关，但涉及图论和计算复杂性。
太长不读：本文继续研究带有连通性约束的新型图着色问题——强无冲突顶点连接 $k$-着色。作者证明了该问题的判定性在以顶点覆盖数为参数时是固定参数可解的 (FPT)，但同时也证明了在标准的复杂性假设下，即使对于二分图，判定它能否强无冲突 3-可着色不具备多项式核，这与传统 $k$-着色问题的结果形成了鲜明的对比。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是继续研究 Hsieh 等人最近提出的一个新的带有连通性约束的图着色变体——强无冲突顶点连接 $k$-着色问题。这个问题的特点是要求图中任意两个不同的顶点之间都存在一条“无冲突最短路径”（即路径上存在一种颜色恰好出现一次）。作者旨在探究这个问题的计算复杂性，特别是其在参数化复杂度理论下的表现，并将其与传统图着色问题进行对比。

Method: 本文对强无冲突顶点连接 $k$-着色问题进行了复杂性分析，特别是研究了在以顶点覆盖数为参数时的固定参数可解性（FPT）和核化问题。具体来说，证明了判定问题在以顶点覆盖数为参数时是 FPT 的，同时证明了对于 $k=3$ 的情况，即使对于二分图，该问题在标准复杂性假设下不具有多项式核。

Result: 本文的主要结果包括：
1. 强无冲突顶点连接 $k$-着色问题在以顶点覆盖数为参数时是固定参数可解的（FPT）。
2. 在标准复杂性假设 NP $\not\subseteq$ coNP/poly 下，判定一个图 $G$ 是否强无冲突 3-可着色不具备多项式核，即使对于二分图也是如此。
3. 这一多项式核下界结果与传统的 $k$-着色问题形成鲜明对比，传统的 $k$-着色问题在以顶点覆盖数为参数时已知存在多项式核。

Conclusion: 本文延续了强无冲突顶点连接染色的研究，证明了该问题的固定参数可解性，即在以顶点覆盖数为参数时是 FPT 的。然而在标准复杂性假设下（NP $\not\subseteq$ coNP/poly），即使对于二分图，判定一个图是否强无冲突 3-可着色不具备多项式核，这与传统的 $k$-着色问题形成鲜明对比。

Abstract: This paper continues the study of a new variant of graph coloring with a connectivity constraint recently introduced by Hsieh et al. [COCOON 2024]. A path in a vertex-colored graph is called conflict-free if there is a color that appears exactly once on its vertices. A connected graph is said to be strongly conflict-free vertex-connection $k$-colorable if it admits a (proper) vertex $k$-coloring such that any two distinct vertices are connected by a conflict-free shortest path. Among others, we show that deciding, for a given graph $G$ and an integer $k$, whether $G$ is strongly conflict-free $k$-colorable is fixed-parameter tractable when parameterized by the vertex cover number. But under the standard complexity-theoretic assumption NP $\not\subseteq$ coNP/poly, deciding, for a given graph $G$, whether $G$ is strongly conflict-free $3$-colorable does not admit a polynomial kernel, even for bipartite graphs. This kernel lower bound is in stark contrast to the ordinal $k$-Coloring problem which is known to admit a polynomial kernel when parameterized by the vertex cover number.

</details>
