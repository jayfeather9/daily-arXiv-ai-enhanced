<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 3]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.AR](#cs.AR) [Total: 1]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Online Computation of Palindromes and Suffix Trees on Tries](https://arxiv.org/abs/2601.16485)
*Hiroki Shibata,Mitsuru Funakoshi,Takuya Mieno,Masakazu Ishihata,Yuto Nakashima,Shunsuke Inenaga,Hideo Bannai,Masayuki Takeda*

Main category: cs.DS

TL;DR: 这不是与 HLS 相关，也不是与 MLIR 相关，与编译器不直接相关。它与图处理和 DSL 的关系较远。它主要和**字符串算法**和**数据结构**相关，尽管前缀树（Trie）是一种特殊的图结构。

太长不看：本文针对动态前缀树上的最大回文串和不同回文串枚举问题，首次提出了亚二次时间复杂度的在线算法。通过适应 EERTREE 和后缀树等结构，这些算法支持前缀树的叶子节点的动态插入和删除，并为动态前缀树的结构维护提供了独立的在线构建方法。


<details>
  <summary>Details</summary>
Motivation: 现有的研究在线性时间内解决了静态前缀树上的最大回文串和不同回文串的计算问题（Mieno et al., ISAAC 2022）。然而，对于支持叶子节点添加和删除的**动态前缀树**，缺乏有效的回文串枚举算法。因此，本文的动机是首次提出在动态前缀树上枚举回文串的亚二次时间算法，以填补这一空白。

Method: 本文提出了在动态前缀树上枚举最大回文串和不同回文串的算法。对于最大回文串，算法的复杂度为 $O(N \min(\log h, \sigma))$，其中 $N$ 是最大边数，$\sigma$ 是字母表大小，$h$ 是树高。对于不同回文串，开发了基于不同算法框架（如 EERTREE 和前缀树的后缀树）的若干在线算法，以支持叶子节点的插入和删除，并在时间和空间上实现了不同的权衡。附带地，本文还提供了构建输入前缀树的后缀树和 EERTREE 的在线算法。

Result: 本文首次提出了在动态前缀树上枚举回文串的亚二次时间算法。具体来说，计算最大回文串的算法时间复杂度为 $O(N \min(\log h, \sigma))$，空间复杂度为 $O(N)$。对于不同回文串，开发了基于 EERTREE 和前缀树的后缀树的若干在线算法，它们支持叶子节点的插入和删除，并实现了不同的时间与空间平衡。这些算法显著优于次二次时间复杂度的动态解决方案。

Conclusion: 本文提出了首批在动态前缀树上枚举回文串的亚二次时间算法，包括最大回文串和不同回文串的枚举。这些算法主要依赖于对动态前缀树数据结构的适应和对求解回文串结构（如EERTREE和后缀树）的动态维护，显著提高了处理动态字符串集合中回文串问题的效率，并为前缀树的动态结构维护提供了新的工具。

Abstract: We consider the problems of computing maximal palindromes and distinct palindromes in a trie. A trie is a natural generalization of a string, which can be seen as a single-path tree. There is a linear-time offline algorithm to compute maximal palindromes and distinct palindromes in a given (static) trie whose edge-labels are drawn from a linearly-sortable alphabet [Mieno et al., ISAAC 2022]. In this paper, we tackle problems of palindrome enumeration on dynamic tries which support leaf additions and leaf deletions. We propose the first sub-quadratic algorithms to enumerate palindromes in a dynamic trie. For maximal palindromes, we propose an algorithm that runs in $O(N \min(\log h, σ))$ time and uses $O(N)$ space, where $N$ is the maximum number of edges in the trie, $σ$ is the size of the alphabet, and $h$ is the height of the trie. For distinct palindromes, we develop several online algorithms based on different algorithmic frameworks, including approaches using the EERTREE (a.k.a. palindromic tree) and the suffix tree of a trie. These algorithms support leaf insertions and deletions in the trie and achieve different time and space trade-offs. Furthermore, as a by-product, we present online algorithms to construct the suffix tree and the EERTREE of the input trie, which is of independent interest.

</details>


### [2] [Recovering Communities in Structured Random Graphs](https://arxiv.org/abs/2601.16910)
*Michael Kapralov,Luca Trevisan,Weronika Wrzos-Kaminska*

Main category: cs.DS

TL;DR: 这个论文与图处理相关。它研究了在随机采样的图（如超立方图）中恢复大量重叠的稀疏割的问题。它证明了即使存在大量的重叠稀疏割，也可以在渐近最优的采样率下，高概率地近似恢复超立方图的所有$d$个坐标割，并且对于类超立方图可以实现精确恢复。


<details>
  <summary>Details</summary>
Motivation: 现有的研究集中在随机块模型中恢复植入的社群结构，其中预期图的稀疏割集合是不重叠的。但是，当预期图中存在大量重叠的稀疏割时，是否仍可以进行恢复是一个悬而未决的问题。例如，在$d$维超立方体图中有$d$个不同的（平衡）稀疏割。本文旨在回答，在随机采样的超立方体边缘图中，是否可以识别这些割。

Method: 本文通过结合Friedgut、Kalai和Naor关于布尔函数傅里叶变换的研究（其傅里叶变换集中在傅里叶谱的第一级）以及Karger的割计数论证，提出了一个强大的超立方体割稀疏化界限。利用该界限证明了在超立方中存在稀疏割的情况下，仍可进行恢复。

Result: 本文证明了对于采样率$p=C\log d/d$的超立方体随机样本，其中$C$是一个足够大的常数，最稀疏的平衡割以很大概率与某个坐标割$1/\text{poly}(d)$接近。这是渐近最优的，并且允许同时近似恢复所有$d$个割。对于类超立方图的适当采样，可以实现精确恢复。

Conclusion: 本论文证明了，即使在预期图中存在大量重叠的稀疏割，例如在超立方图中的情况，仍然可以恢复这些割。对于超立方体的随机样本，当采样率$p=C\log d/d$时，最稀疏的平衡割与超立方体坐标割高度一致的可能性很高，这与渐近最优结果相符，并允许同时近似恢复所有$d$个割。此外，对于类超立方图的适当采样，可以实现精确恢复。

Abstract: The problem of recovering planted community structure in random graphs has received a lot of attention in the literature on the stochastic block model, where the input is a random graph in which edges crossing between different communities appear with smaller probability than edges induced by communities. The communities themselves form a collection of vertex-disjoint sparse cuts in the expected graph, and can be recovered, often exactly, from a sample as long as a separation condition on the intra- and inter-community edge probabilities is satisfied.
  In this paper, we ask whether the presence of a large number of overlapping sparsest cuts in the expected graph still allows recovery. For example, the $d$-dimensional hypercube graph admits $d$ distinct (balanced) sparsest cuts, one for every coordinate. Can these cuts be identified given a random sample of the edges of the hypercube where each edge is present independently with some probability $p\in (0, 1)$? We show that this is the case, in a very strong sense: the sparsest balanced cut in a sample of the hypercube at rate $p=C\log d/d$ for a sufficiently large constant $C$ is $1/\text{poly}(d)$-close to a coordinate cut with high probability. This is asymptotically optimal and allows approximate recovery of all $d$ cuts simultaneously. Furthermore, for an appropriate sample of hypercube-like graphs recovery can be made exact. The proof is essentially a strong hypercube cut sparsification bound that combines a theorem of Friedgut, Kalai and Naor on boolean functions whose Fourier transform concentrates on the first level of the Fourier spectrum with Karger's cut counting argument.

</details>


### [3] [Conditionally Tight Algorithms for Maximum k-Coverage and Partial k-Dominating Set via Arity-Reducing Hypercuts](https://arxiv.org/abs/2601.16923)
*Nick Fischer,Marvin Künnemann,Mirza Redzic*

Main category: cs.DS

TL;DR: 该论文不涉及DSL、图处理、MLIR、编译器或HLS。

总结：这篇论文重新审视了经典的Maximum $k$-Coverage和Partial $k$-Dominating Set问题，通过精细粒度复杂性理论，解决了两个核心问题。对于Partial $k$-Dominating Set，论文找到了一种新的、依赖于覆盖元素总数$t$（而非总元素数$n$）的算法，并证明了其在$k$-clique和3-uniform hyperclique假设下的条件最优性。对于Maximum $k$-Coverage，论文基于宇宙大小$u$、最大集合大小$s$和最大频率$f$这三个自然参数，确定了一个复杂但同样是条件上最优的运行时间界限。


<details>
  <summary>Details</summary>
Motivation: Maximum $k$-Coverage问题，特别是Partial $k$-Dominating Set，是一个经典的、具有强NP难度的覆盖问题。以往的研究已经建立了紧凑的不可近似性结果和$W[2]$-hard的复杂性，以及$n^{k\pm o(1)}$的最坏情况运行时间。
这篇论文的动机在于挑战和改进这些已有的时间界限：
1. **第一个动机（挑战传统时间界限）：** 想要知道是否可以改进现有基于$n$的运行时间，至少对于Partial $k$-Dominating Set，能否找到一个依赖于$t$（覆盖元素总数）的更快算法，理想情况下是$t^{k\pm O(1)}$。
2. **第二个动机（寻求自然参数的最优性）：** 寻求确定Maximum $k$-Coverage问题在参数$u$（宇宙大小）、$s$（最大集合大小）和$f$（最大频率）下是否有一个更优且自然的最优运行时间。

Method: 论文采用了算法设计和复杂性分析的方法。具体来说：
1. **算法设计：** 针对Partial $k$-Dominating Set问题，论文设计了一个运行时间依赖于被覆盖元素总数$t$的新算法，其复杂度使用矩阵乘法指数$\omega$来表达（如$O(nt + t^{\frac{2\omega}{3} k+O(1)})$）。
2. **精细粒度复杂性分析（Fine-Grained Complexity）：** 论文利用$k$-clique和3-uniform hyperclique假设，证明了所设计算法在条件上是最优的（即匹配上下界）。
3. **参数化（Parameterization）：** 对于更一般的Maximum $k$-Coverage问题，论文引入了宇宙大小$u$、最大集合大小$s$和最大频率$f$作为参数，设计了依赖于这些参数的复杂运行时间的算法，并通过复杂性分析证明了这个复杂时间界限的条件最优性。

Result: 论文成功解决了这两个核心问题，取得了以下结果：
1. **Partial $k$-Dominating Set的加速算法：** 提供了一个依赖于$t$（被覆盖元素总数）的算法，其运行时间为$O(nt + t^{\frac{2\omega}{3} k+O(1)})$（当$\omega\ge 2.25$时）或$O(nt+ t^{\frac{3}{2} k+O(1)})$（当$\omega\le 2.25$时）。更重要的是，基于$k$-clique和3-uniform hyperclique假设，论文得出了与矩阵乘法指数$\omega$无关的、条件上最优的时间界限（Matching upper and lower bounds）。
2. **Maximum $k$-Coverage的条件最优运行时间：** 对于更一般的问题，论文给出了一个非常复杂的运行时间界限，该界限显著依赖于参数$u, s, f$：
$$
\min \left\{ (f\cdot \min\{\sqrt[3]{u}, \sqrt{s}\})^k + \min\{n,f\cdot \min\{\sqrt{u}, s\}\}^{kω/3}, n^k\right\}
\cdot g(k)n^{\pm O(1)}
$$
并且令人惊讶地证明了这个复杂的时间界限也是条件上最优的。

Conclusion: 这篇论文“重新审视”了经典的Maximum $k$-Coverage问题，特别是其特殊情况Partial $k$-Dominating Set。研究者解决了关于加速算法和确定基于自然参数的最优运行时间的两个核心问题。对于Partial $k$-Dominating Set，论文提供了一个基于$t$（覆盖元素总数）的、在条件上最优的算法，并建立了与$k$-clique及3-uniform hyperclique假设相关联的匹配上下界。对于更一般的Maximum $k$-Coverage，论文给出了一个复杂但条件上最优的运行时间界限，这个界限显著依赖于宇宙大小$u$、最大集合大小$s$和最大频率$f$。该研究通过精细粒度复杂性分析的技术，推进了我们对这类问题的可计算性和时间效率的理解。

Abstract: We revisit the classic Maximum $k$-Coverage problem: Determine the largest number $t$ of elements that can be covered by choosing $k$ sets from a given family $\mathcal{F} = \{S_1,\dots, S_n\}$ of a size-$u$ universe. A notable special case is Partial $k$-Dominating Set, where one chooses $k$ vertices in a graph to maximize the number of dominated vertices.
  Extensive research has established strong hardness results for various aspects of Maximum $k$-Coverage, such as tight inapproximability results, $W[2]$-hardness, and a conditionally tight worst-case running time of $n^{k\pm o(1)}$. In this paper we ask: (1) Can this time bound be improved for small $t$, at least for Partial $k$-Dominating Set, ideally to time~$t^{k\pm O(1)}$? (2) More ambitiously, can we even determine the best-possible running time of Maximum $k$-Coverage with respect to the perhaps most natural parameters: the universe size $u$, the maximum set size $s$, and the maximum frequency $f$?
  We successfully resolve both questions. (1) We give an algorithm that solves Partial $k$-Dominating Set in time $O(nt + t^{\frac{2ω}{3} k+O(1)})$ if $ω\ge 2.25$ and time $O(nt+ t^{\frac{3}{2} k+O(1)})$ if $ω\le 2.25$, where $ω\le 2.372$ is the matrix multiplication exponent. From this we derive a time bound that is conditionally optimal, regardless of $ω$, based on the well-established $k$-clique and 3-uniform hyperclique hypotheses from fine-grained complexity. We also obtain matching upper and lower bounds for sparse graphs. To address (2) we design an algorithm for Maximum $k$-Coverage running in time
  $$
  \min \left\{ (f\cdot \min\{\sqrt[3]{u}, \sqrt{s}\})^k + \min\{n,f\cdot \min\{\sqrt{u}, s\}\}^{kω/3}, n^k\right\}
  \cdot g(k)n^{\pm O(1)}, $$ and, surprisingly, further show that this complicated time bound is also conditionally optimal.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [Space Filling Curves is All You Need: Communication-Avoiding Matrix Multiplication Made Simple](https://arxiv.org/abs/2601.16294)
*Evangelos Georganas,Alexander Heinecke,Pradeep Dubey*

Main category: cs.DC

TL;DR: 该论文与**编译器**/**HPC**和**深度学习**优化相关，因为它关注的是通用矩阵乘法（GEMM）这一核心计算的优化，特别是在现代CPU和加速器平台上的性能提升，涉及底层代码生成和性能调优。
太长不看（TLDR）：GEMM是深度学习和HPC的关键，但现有优化（依赖于供应商库）需要针对不同平台和矩阵形状进行繁琐调优。本文重新应用广义空间填充曲线（SFC）来划分矩阵乘法计算空间，实现了一种与平台无关、与形状无关的、天然具有高数据局部性的GEMM方案。该方案易于集成通信避免（CA）算法，并以紧凑代码在多个CPU平台上实现了高达2倍的性能提升，超越了最先进的供应商库。


<details>
  <summary>Details</summary>
Motivation: 通用矩阵乘法（GEMM）是深度学习和HPC高性能计算工作负载的基础。现代具有矩阵乘法加速器的平台具有高FLOP/Byte的机器平衡性，这使得实现最优化的矩阵乘法变得困难。现有的最先进优化方法依赖于供应商库对输入张量布局、并行化方案和缓存分块进行仔细调优，以最小化内存层次结构中的数据移动并最大化吞吐量。然而，**最佳调优设置强烈依赖于具体平台和矩阵形状**，这使得穷尽调优不可行，导致性能出现“玻璃下巴”（即性能脆弱，在特定配置下急剧下降）。作者的动机是找到一种新的、与平台和形状无关的GEMM实现方案，以避免这种繁琐的调优问题。

Method: 本文的核心方法是重新审视并应用空间填充曲线（Space Filling Curves, SFC），特别是广义Hilbert曲线来划分矩阵乘法的计算空间。SFC将多维坐标（如2D）转换为一维坐标（1D），同时保持高维空间中邻近点在一维顺序上的接近性，这天然地带来了高数据局部性。作者基于SFC划分计算工作负载，实现了与平台无关且与矩阵形状无关的矩阵乘法方案。此外，通过将这种基于SFC的工作划分扩展到实现通信避免（CA）算法，通过复制输入张量，可以有效减少关键路径上的通信/数据移动。这种集成方式简洁，代码紧凑。

Result: 作者获得了与平台无关且与形状无关的矩阵乘法方案，该方案内在具有高数据局部性。将基于SFC的工作划分扩展到实现通信避免（CA）算法后，实现了可证明最小化关键路径上通信/数据移动的效果。该实现的代码非常紧凑（约30行代码）。在多个CPU平台上，该方案在各种GEMM形状上取得了最先进的结果，性能优于供应商库，**几何平均加速比最高可达2倍**。

Conclusion: 本文通过将SFC应用于矩阵乘法，提供了一种新的、与平台和形状无关的GEMM实现方案。这种方案能够自动实现高数据局部性，并且易于集成通信避免（CA）算法，最终在多个CPU平台上取得了优于甚至两倍于供应商库的性能提升，证明了SFC在优化深度学习和HPC高性能计算工作负载中的巨大潜力。

Abstract: General Matrix Multiplication (GEMM) is the cornerstone of Deep Learning and HPC workloads; accordingly, academia and industry have heavily optimized this kernel. Modern platforms with matrix multiplication accelerators exhibit high FLOP/Byte machine balance, which makes implementing optimal matrix multiplication challenging. On modern CPU platforms with matrix engines, state-of-the-art vendor libraries tune input tensor layouts, parallelization schemes, and cache blocking to minimize data movement across the memory hierarchy and maximize throughput. However, the best settings for these parameters depend strongly on the target platform (number of cores, memory hierarchy, cache sizes) and on the shapes of the matrices, making exhaustive tuning infeasible; in practice this leads to performance "glass jaws". In this work we revisit space filling curves (SFC) to alleviate the problem of this cumbersome tuning. SFC convert multi-dimensional coordinates (e.g. 2D) into a single dimension (1D), keeping nearby points in the high-dimensional space close in the 1D order. We partition the Matrix Multiplication computation space using recent advancements in generalized SFC (Generalized Hilbert Curves), and we obtain platform-oblivious and shape-oblivious matrix-multiplication schemes that exhibit inherently high degree of data locality. Furthermore, we extend the SFC-based work partitioning to implement Communication-Avoiding (CA) algorithms that replicate the input tensors and provably minimize communication/data-movement on the critical path. The integration of CA-algorithms is seamless and yields compact code (~30 LOC), yet it achieves state-of-the-art results on multiple CPU platforms, outperforming vendor libraries by up to 2x(geometric-mean speedup) for a range of GEMM shapes.

</details>


### [5] [Consensus In Asynchrony](https://arxiv.org/abs/2601.16460)
*Ivan Klianev*

Main category: cs.DC

TL;DR: This content has not passed the compliance test and has been hidden.


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于解决在异步环境中实现确定性容错共识的问题，并调和这一目标的实现与著名的FLP不可能性结果之间的矛盾。作者旨在证明，通过事件同步，可以实现满足安全性和活性的容错共识，并对FLP定理的适用性和前提进行深入的探讨和质疑。

Method: 本文提出了一种基于事件同步的算法来解决确定性容错共识问题。该算法能够实现有效的向量一致性，满足安全性和活性，并能容忍一次崩溃。同时，通过识别两种类型的共识和检查FLP定理的三个隐含假设，来分析和调和FLP不可能性结果。

Result: 该研究的主要结果是提供了一种基于事件同步的算法，它能够在异步环境中终止并达成有效的向量一致性，具备安全性和活性，并能容忍一次崩溃。其次，研究识别了两种类型的共识（数据无关和数据相关），并指出FLP定理的正确性依赖于三个隐含假设，其中第三个假设缺乏实验证据支持。研究暗示FLP不可能性结果并非普遍适用。

Conclusion: 本文通过提出一种基于事件同步的确定性容错共识算法，证明了在异步环境中解决确定性容错共识的可行性。这挑战了FLP不可能性结果，并通过识别不同类型的共识（数据无关和数据相关）以及质疑FLP定理的隐含假设来调和两者。实验结果表明，FLP定理成立所依赖的第三个隐含假设缺乏证据支持。

Abstract: We demonstrate sufficiency of events-based synchronisation for solving deterministic fault-tolerant consensus in asynchrony. Main result is an algorithm that terminates with valid vector agreement, hence operates with safety, liveness, and tolerance to one crash. Reconciling with the FLP impossibility result, we identified: i) existence of two types of agreements: data-independent and data-dependent; and ii) dependence of FLP theorem correctness on three implicit assumptions. Consensus impossibility with data-dependent agreement is contingent on two of them. The theorem-stated impossibility with every agreement type hinges entirely on the third. We provide experimental results showing that the third assumption has no evidence in support.

</details>


### [6] [W4A16 Mixed-Precision Matrix Multiplication on Decoupled Architecture: Kernel Design and Memory Bottleneck Analysis for Ascend NPUs](https://arxiv.org/abs/2601.16536)
*Yuanhong He,Peiyu Niu,Jun Chen,Chenchen Zhang,Chao Yang*

Main category: cs.DC

TL;DR: 该论文与 DSL 或图处理或 MLIR 或编译器或 HLS 相关。具体来说，它与编译器（涉及内核设计和优化，以在特定硬件上实现高效计算）和 MLIR（尽管未直接提及，但其底层优化和部署策略与 MLIR/编译器生态系统密切相关）相关。

**太长不看版总结:** 随着 LLMs 规模扩大，W4A16 量化成为减小内存的关键，但在华为昇腾 910 NPU 上的高效部署因硬件限制（混合精度支持有限，解耦计算架构）而面临挑战。本文提出了首个针对 Ascend 910 NPU 优化的 W4A16 矩阵乘法内核，通过利用向量核进行动态 INT4-to-FP16 反量化、立方体核进行高吞吐量 GEMM，以及 Split-K 并行化来缓解内存延迟。实验结果显示，在 LLM 解码典型场景中，该方法比数据并行方法快 1.01x 至 1.74x。性能瓶颈分析表明，限制 W4A16 最大加速（1.48x）的主要是额外的权重全局内存传输，而非反量化计算本身。这项工作为在各种专用加速器上高效部署量化 LLMs 提供了基础和见解。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的规模不断扩大，纯权重（权重 W4、激活 A16）量化技术成为减少内存占用并维持最低精度损失的关键。然而，在如华为昇腾 910 NPU 等专用加速器上高效部署 W4A16 存在挑战，原因在于其本身对混合精度支持有限以及加速器采用了解耦的计算架构。因此，需要开发一种实用的 W4A16 矩阵乘法内核来解决这些技术障碍，以在昇腾 910 NPU 上实现量化模型的有效部署。

Method: 本文提出了一种针对 Ascend 910 NPU 定制的 W4A16 矩阵乘法内核。其方法包括：利用向量核（Vector Cores）实现即时的 INT4-to-FP16 反量化；利用立方体核（Cube Cores）实现高吞吐量的通用矩阵乘法（GEMM）；采用 Split-K 并行化技术来缓解内存延迟。作者通过性能评估，比较了该方法在不同矩阵形状和批次大小下的表现，并与数据并行方法进行了对比。

Result: 该定制内核在 LLM 解码的典型场景（K >> N）中，性能优于数据并行方法，实现了 1.01x 至 1.74x 的加速。性能分析表明，主要的瓶颈不是反量化计算，而是额外的权重全局内存传输，这导致 W4A16 相较于 PyTorch 中的原生 FP16xFP16 矩阵乘法，最大加速比仅为 1.48x。

Conclusion: 本文设计并实现了一种针对昇腾 910 NPU 优化的 W4A16 矩阵乘法内核，利用向量核进行动态 INT4-to-FP16 反量化，立方体核进行 GEMM 计算，并采用 Split-K 并行化来缓解内存延迟。实验证明，在 K >> N 的典型 LLM 解码场景中，该方法优于数据并行方法，实现了 1.01x 至 1.74x 的加速。研究还发现，主要的性能瓶颈在于额外的全局内存传输，而非反量化计算本身，这限制了 W4A16 相较于原生 FP16xFP16 矩阵乘法在 PyTorch 中最大只能达到 1.48x 的加速。作者认为，他们的研究为在各种领域的专用加速器上高效部署量化大型语言模型奠定了坚实的基础并提供了有益的见解。

Abstract: As Large Language Models (LLMs) scale, weight-only quantization (W4A16: 4-bit weights, 16-bit activations) becomes critical for reducing memory footprint with minimal accuracy loss. However, its efficient deployment on Huawei's Ascend 910 Neural Processing Unit (NPU) is challenging due to limited native mixed-precision support and the accelerator's decoupled compute architecture. To enable quantization on such architecture, we present the first practical W4A16 matrix multiplication kernel tailored for the Ascend 910 NPU. Our design leverages vector cores for on-the-fly INT4-to-FP16 dequantization, cube cores for high-throughput GEMM, and Split-K parallelization to mitigate memory latency. Performance evaluations across diverse matrix shapes and batch sizes show our method outperforms data-parallel approaches when K >> N, a typical scenario in LLM decoding. Specially, our method can achieve a speedup ranging from 1.01x to 1.74x. In addition, our profile reveals the primary bottleneck is not dequantization compution itself, but extra global memory transfer for the weight, making W4A16 only reaching a maximum speedup of 1.48x over native FP16xFP16 matrix multiplication in PyTorch. In the long run, our method lays a solid foundation and provides insightful views for the efficient deployment of quantized large language models on various domain-specific accelerators.

</details>


### [7] [GPU-Accelerated Selected Basis Diagonalization with Thrust for SQD-based Algorithms](https://arxiv.org/abs/2601.16637)
*Jun Doi,Tomonori Shirakawa,Yukio Kawashima,Seiji Yunoki,Hiroshi Horii*

Main category: cs.DC

TL;DR: 相关：编译器 (加速计算过程)；图处理 (无直接关系，但配置和激发生成可能涉及图结构概念)；MLIR (无直接关系)；HLS (无直接关系)；DSL (无直接关系)。总结：SBD 是 SQD 的核心，其迭代对角化是主要的经典计算负载。本文提出了一种使用 Thrust 库的 GPU 加速 SBD 实现。通过重构配置处理、激发生成和矩阵-向量操作等关键组件，以适应细粒度数据并行原语和扁平化的 GPU 友好数据布局，该方法高效利用了现代 GPU 架构。实验结果显示，基于 Thrust 的 SBD 相较于 CPU 执行实现了高达约 40 倍的加速，显著减少了 SQD 迭代的总运行时间。这表明 GPU 原生并行原语是加速基于 SQD 的量子-经典工作流的简单、可移植且高性能的基础。


<details>
  <summary>Details</summary>
Motivation: SBD 在基于样本的量子对角化 (SQD) 中起着核心作用，其中在选定配置子空间中对哈密顿量进行迭代对角化构成了主要的经典计算负载。为了提高计算效率，作者寻求加速 SBD 过程。

Method: 本文提出了一种使用 Thrust 库的 SBD 的 GPU 加速实现。通过围绕细粒度数据并行原语和扁平化的 GPU 友好数据布局来重构关键组件（包括配置处理、激发生成和矩阵-向量操作），该方法有效地利用了现代 GPU 架构。

Result: 基于 Thrust 的 SBD 实现相较于 CPU 执行实现了高达约 40 倍的加速，并显著减少了 SQD 迭代的总运行时间。

Conclusion: 本文表明，基于 Thrust 库的 SBD 的 GPU 加速实现，通过高效利用现代 GPU 架构，为基于 SQD 的量子-经典工作流的加速提供了一个简单、可移植且高性能的基础。

Abstract: Selected Basis Diagonalization (SBD) plays a central role in Sample-based Quantum Diagonalization (SQD), where iterative diagonalization of the Hamiltonian in selected configuration subspaces forms the dominant classical workload. We present a GPU-accelerated implementation of SBD using the Thrust library. By restructuring key components -- including configuration processing, excitation generation, and matrix-vector operations -- around fine-grained data-parallel primitives and flattened GPU-friendly data layouts, the proposed approach efficiently exploits modern GPU architectures. In our experiments, the Thrust-based SBD achieves up to $\sim$40$\times$ speedup over CPU execution and substantially reduces the total runtime of SQD iterations. These results demonstrate that GPU-native parallel primitives provide a simple, portable, and high-performance foundation for accelerating SQD-based quantum-classical workflows.

</details>


### [8] [DataStates-LLM: Scalable Checkpointing for Transformer Models Using Composable State Providers](https://arxiv.org/abs/2601.16956)
*Avinash Maurya,M. Mustafa Rafique,Franck Cappello,Bogdan Nicolae*

Main category: cs.DC

TL;DR: 该论文与编译器、HLS、DSL 或 MLIR 涉及的领域关系不大，但涉及到大规模 **图处理**（特指基于 Transformer 的大模型中 **数据并行和张量并行** 等复杂并行策略下的 **分布式状态管理和优化**）。

随着 LLM 扩展到万亿参数，对分布式训练状态进行检查点（Checkpointing）至关重要。现有的检查点方案因未能处理模型状态的“3D异构性”（内存位置、分片、数据类型）而导致巨大的运行时开销。本文提出了 DataStates-LLM 架构，它利用 State Providers 将状态抽象与数据移动解耦，并通过利用模型参数的不可变性实现“惰性”、非阻塞的异步快照。该方法能有效地整合异构分片，并将元数据序列化与批量张量 I/O 重叠。实验结果表明，DataStates-LLM 将检查点吞吐量提高了高达 4 倍，端到端训练时间减少了高达 2.2 倍。


<details>
  <summary>Details</summary>
Motivation: 随着大型 Transformer 模型（特别是 LLM）扩展到数万亿参数，它们需要在数千个 GPU 上使用复杂的混合并行策略进行训练。检查点这种大规模分布式状态对于韧性、挂起-恢复、调查训练轨迹和解释模型演化至关重要。然而，现有检查点解决方案将模型状态视为不透明的二进制数据块，忽略了底层数据结构的“3D 异构性”（内存位置、碎片化程度、数据类型和序列化要求），导致了显著的运行时开销，如阻塞的设备到主机传输、数据无关的序列化和存储 I/O 竞争。

Method: 提出了一种名为 DataStates-LLM 的新型检查点架构，它利用 State Providers 将状态抽象与数据移动解耦。它利用模型参数在前向和后向传播过程中的不可变性，执行“惰性”、非阻塞的异步快照。通过引入 State Providers，它能有效地整合碎片化的、异构的分片，并将元数据的序列化与批量张量 I/O 重叠进行。

Result: 在多达 256 个 A100-40GB GPU 上对参数量高达 70B 的模型进行评估。结果表明，DataStates-LLM 的检查点吞吐量提高了高达 4 倍，端到端训练时间缩短了高达 2.2 倍，有效地缓解了极端规模 LLM 训练中的序列化和异构性瓶颈。

Conclusion: DataStates-LLM 通过利用模型参数的不可变性实现“惰性”、非阻塞的异步快照，并使用 State Providers 有效地整合异构碎片和重叠元数据序列化与批量张量 I/O，显著提高了大模型训练中的检查点吞吐量和整体训练效率。

Abstract: The rapid growth of Large Transformer-based models, specifically Large Language Models (LLMs), now scaling to trillions of parameters, has necessitated training across thousands of GPUs using complex hybrid parallelism strategies (e.g., data, tensor, and pipeline parallelism). Checkpointing this massive, distributed state is critical for a wide range of use cases, such as resilience, suspend-resume, investigating undesirable training trajectories, and explaining model evolution. However, existing checkpointing solutions typically treat model state as opaque binary blobs, ignoring the ``3D heterogeneity'' of the underlying data structures--varying by memory location (GPU vs. Host), number of ``logical'' objects sharded and split across multiple files, data types (tensors vs. Python objects), and their serialization requirements. This results in significant runtime overheads due to blocking device-to-host transfers, data-oblivious serialization, and storage I/O contention. In this paper, we introduce DataStates-LLM, a novel checkpointing architecture that leverages State Providers to decouple state abstraction from data movement. DataStates-LLM exploits the immutability of model parameters during the forward and backward passes to perform ``lazy'', non-blocking asynchronous snapshots. By introducing State Providers, we efficiently coalesce fragmented, heterogeneous shards and overlap the serialization of metadata with bulk tensor I/O. We evaluate DataStates-LLM on models up to 70B parameters on 256 A100-40GB GPUs. Our results demonstrate that DataStates-LLM achieves up to 4$\times$ higher checkpointing throughput and reduces end-to-end training time by up to 2.2$\times$ compared to state-of-the-art solutions, effectively mitigating the serialization and heterogeneity bottlenecks in extreme-scale LLM training.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [9] [AERO: Adaptive and Efficient Runtime-Aware OTA Updates for Energy-Harvesting IoT](https://arxiv.org/abs/2601.16935)
*Wei Wei,Jingye Xu,Sahidul Islam,Dakai Zhu,Chen Pan,Mimi Xie*

Main category: cs.AR

TL;DR: 该论文与编译器、HLS、MLIR、图处理和DSL不直接相关，但它涉及物联网设备的软件更新和任务调度。/这项研究提出了AERO（Adaptive and Efficient Runtime-Aware OTA update mechanism），一种针对间歇性供电物联网设备的OTA更新机制。AERO将更新任务整合到设备的工作流有向无环图（DAG）中，并将其与常规任务一起调度，同时考虑能量和时间约束，以确保更新与运行时执行的一致性，从而提高了更新的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的OTA更新机制，即使是“实时”更新技术，在间歇性供电的物联网设备上仍然存在挑战，特别是缺乏在更新与运行时执行交互时确保任务执行一致性的机制。由于能量不稳定，传统的OTA更新会中断任务执行并产生显著的开销。

Method: AERO是一种自适应且高效的运行时感知OTA更新机制，它将更新任务集成到设备的有向无环图（DAG）中，并在能量和时间约束下与常规任务一起调度。通过识别受更新影响的执行区域并动态调整依赖关系，AERO确保了更新集成的运行时一致性和对间歇性能源可用性的适应性。

Result: 与现有的“实时”更新方法相比，AERO在代表性工作负载上的实验展示了更高的更新可靠性和效率。

Conclusion: AERO通过将更新任务集成到设备的工作流DAG中并考虑能量和时间约束来调度它们，确保了间歇性供电IoT设备上OTA更新的可靠性和一致性。实验结果证明了其更高的更新可靠性和效率。

Abstract: Energy-harvesting (EH) Internet of Things (IoT) devices operate under intermittent energy availability, which disrupts task execution and makes energy-intensive over-the-air (OTA) updates particularly challenging. Conventional OTA update mechanisms rely on reboots and incur significant overhead, rendering them unsuitable for intermittently powered systems. Recent live OTA update techniques reduce reboot overhead but still lack mechanisms to ensure consistency when updates interact with runtime execution. This paper presents AERO, an Adaptive and Efficient Runtime-Aware OTA update mechanism that integrates update tasks into the device's Directed Acyclic Graph (DAG) and schedules them alongside routine tasks under energy and timing constraints. By identifying update-affected execution regions and dynamically adjusting dependencies, AERO ensures consistent up date integration while adapting to intermittent energy availability. Experiments on representative workloads demonstrate improved update reliability and efficiency compared to existing live update approaches.

</details>
