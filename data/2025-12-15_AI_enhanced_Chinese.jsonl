{"id": "2512.11550", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.11550", "abs": "https://arxiv.org/abs/2512.11550", "authors": ["Yifan Zhang", "Zhiheng Chen", "Ye Qiao", "Sitao Huang"], "title": "PD-Swap: Prefill-Decode Logic Swapping for End-to-End LLM Inference on Edge FPGAs via Dynamic Partial Reconfiguration", "comment": null, "summary": "Aggressively quantized large language models (LLMs), such as BitNet-style 1.58-bit Transformers with ternary weights, make it feasible to deploy generative AI on low-power edge FPGAs. However, as prompts grow to tens of thousands of tokens, edge hardware performance drops sharply with sequence length due to quadratic prefill cost and rapidly increasing KV-cache bandwidth demands, making inference latency of longer context length a first-order system concern. Recent studies on LLMs expose a fundamental prefill-decode asymmetry: prefill is compute-bound and dominated by dense matrix-matrix operations, whereas decoding is memory-bandwidth-bound and dominated by KV-cache traffic. A static accelerator must provision resources and a single dataflow for both regimes, leading to duplicated attention logic, underutilized fabric, and tight LUT/URAM limits that cap model size and usable context. We propose a prefill--decode disaggregated LLM accelerator, PD-Swap, that uses Dynamic Partial Reconfiguration (DPR) to time-multiplex the attention module on edge FPGAs. The core table-lookup ternary matrix multiplication and weight-buffering engines remain static, while the attention subsystem is a reconfigurable partition with two phase-specialized architectures: a compute-heavy, token-parallel prefill engine and a bandwidth-optimized, KV-cache-centric decoding engine. A roofline-inspired model and design space exploration jointly optimize reconfigurable-region size, parallelism under reconfiguration and routability constraints, and reconfiguration latency is hidden by computation latency. PD-Swap achieves up to 27~tokens/s decoding throughput, outperforming prior state-of-the-art works by 1.3x--2.1x (larger gains at longer context lengths), without extra area cost.", "AI": {"tldr": "This paper is related to HLS and Compiler and Graph Processing and MLIR and DSL. The paper is about how to accelerate aggressively quantized Large Language Models (LLMs) on edge FPGAs, especially when dealing with long context lengths. It proposes PD-Swap, a novel LLM accelerator that uses Dynamic Partial Reconfiguration (DPR) to time-multiplex the attention module. This switches between a compute-heavy prefill engine and a bandwidth-optimized decoding engine to address the prefill-decode performance asymmetry. This approach achieves up to 27 tokens/s decoding throughput, outperforming prior works by 1.3x\u20132.1x without extra area cost.", "motivation": "\u73b0\u6709\u7684\u6fc0\u8fdb\u91cf\u5316\u7684LLM\uff08\u5982BitNet-style 1.58-bit Transformer\uff09\u867d\u7136\u9002\u5408\u90e8\u7f72\u5728\u4f4e\u529f\u8017\u8fb9\u7f18FPGA\u4e0a\uff0c\u4f46\u968f\u7740\u63d0\u793a\u8bcd\uff08Prompt\uff09\u589e\u957f\u81f3\u6570\u4e07\u4e2atokens\uff0c\u63a8\u7406\u5ef6\u8fdf\u6025\u5267\u589e\u52a0\uff0c\u8fd9\u662f\u56e0\u4e3a\u4e8c\u6b21\u65b9\u7684\u9884\u586b\u5145\u6210\u672c\u548c\u5feb\u901f\u589e\u957f\u7684KV-cache\u5e26\u5bbd\u9700\u6c42\u3002LLM\u63a8\u7406\u5b58\u5728\u6839\u672c\u6027\u7684\u9884\u586b\u5145-\u89e3\u7801\u4e0d\u5bf9\u79f0\u6027\uff1a\u9884\u586b\u5145\u662f\u8ba1\u7b97\u53d7\u9650\u7684\uff08Compute-bound\uff09\uff0c\u800c\u89e3\u7801\u662f\u5185\u5b58\u5e26\u5bbd\u53d7\u9650\u7684\uff08Memory-bandwidth-bound\uff09\u3002\u4e00\u4e2a\u9759\u6001\u52a0\u901f\u5668\u5fc5\u987b\u540c\u65f6\u4e3a\u8fd9\u4e24\u79cd\u6a21\u5f0f\u914d\u7f6e\u8d44\u6e90\u548c\u5355\u4e00\u6570\u636e\u6d41\uff0c\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u7387\u4f4e\u3001\u6ce8\u610f\u903b\u8f91\u91cd\u590d\uff0c\u5e76\u53d7\u9650\u4e8eLUT/URAM\u8d44\u6e90\uff0c\u4ece\u800c\u9650\u5236\u4e86\u6a21\u578b\u5c3a\u5bf8\u548c\u53ef\u7528\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002\u4f5c\u8005\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u4e0d\u5bf9\u79f0\u6027\uff0c\u63d0\u9ad8\u957f\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u7684\u89e3\u7801\u6027\u80fd\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86PD-Swap\uff0c\u4e00\u79cd\u9884\u586b\u5145-\u89e3\u7801\u89e3\u8026\u7684LLM\u52a0\u901f\u5668\uff0c\u5229\u7528\u8fb9\u7f18FPGA\u4e0a\u7684\u52a8\u6001\u90e8\u5206\u91cd\u914d\u7f6e\uff08DPR\uff09\u6765\u65f6\u95f4\u591a\u8def\u590d\u7528\u6ce8\u610f\u529b\u6a21\u5757\u3002\u6838\u5fc3\u662f\u901a\u8fc7\u4e00\u4e2a\u9759\u6001\u7684\u8868\u67e5\u627e\u4e09\u5143\u77e9\u9635\u4e58\u6cd5\u548c\u6743\u91cd\u7f13\u51b2\u5f15\u64ce\uff0c\u4ee5\u53ca\u4e00\u4e2a\u53ef\u91cd\u914d\u7f6e\u5206\u533a\u5185\u7684\u4e24\u4e2a\u9636\u6bb5\u4e13\u7528\u67b6\u6784\uff1a\u4e00\u4e2a\u8ba1\u7b97\u5bc6\u96c6\u578b\u3001\u4ee4\u724c\u5e76\u884c\u7684\u9884\u586b\u5145\u5f15\u64ce\uff0c\u548c\u4e00\u4e2a\u5e26\u5bbd\u4f18\u5316\u3001\u4ee5KV-Cache\u4e3a\u4e2d\u5fc3\u7684\u89e3\u7801\u5f15\u64ce\u3002\u901a\u8fc7\u4e00\u4e2a\u7c7b\u623f\u9876\u7ebf\u6a21\u578b\u548c\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\uff0c\u5171\u540c\u4f18\u5316\u4e86\u53ef\u91cd\u914d\u7f6e\u533a\u57df\u5927\u5c0f\u3001\u5e76\u884c\u5ea6\u4ee5\u53ca\u91cd\u914d\u7f6e\u5ef6\u8fdf\u7684\u9690\u85cf\uff08\u901a\u8fc7\u8ba1\u7b97\u5ef6\u8fdf\uff09\u3002", "result": "PD-Swap\u5b9e\u73b0\u4e86\u9ad8\u8fbe27\u4e2atokens/s\u7684\u89e3\u7801\u541e\u5410\u91cf\u3002\u5b83\u6bd4\u73b0\u6709\u7684\u6700\u5148\u8fdb\u5de5\u4f5c\u9ad8\u51fa1.3\u500d\u52302.1\u500d\uff0c\u5c24\u5176\u662f\u5728\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u83b7\u5f97\u4e86\u66f4\u5927\u7684\u6027\u80fd\u63d0\u5347\u3002\u5173\u952e\u5728\u4e8e\uff0c\u5b83\u5728\u6ca1\u6709\u989d\u5916\u9762\u79ef\u6210\u672c\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230\u4e86\u8fd9\u4e9b\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "PD-Swap\u901a\u8fc7\u52a8\u6001\u90e8\u5206\u91cd\u914d\u7f6e\uff08DPR\uff09\u6765\u65f6\u95f4\u590d\u7528\u8fb9\u7f18FPGA\u4e0a\u7684\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u4ece\u800c\u5b9e\u73b0\u9884\u586b\u5145\u548c\u89e3\u7801\u4e24\u4e2a\u9636\u6bb5\u7684\u89e3\u8026\u52a0\u901f\u3002\u5b83\u901a\u8fc7\u4e00\u4e2a\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684\u9884\u586b\u5145\u5f15\u64ce\u548c\u4e00\u4e2a\u9762\u5411\u5e26\u5bbd\u4f18\u5316\u7684\u89e3\u7801\u5f15\u64ce\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe27\u4e2atokens/s\u7684\u89e3\u7801\u541e\u5410\u91cf\uff0c\u6bd4\u73b0\u6709\u7684\u6700\u5148\u8fdb\u5de5\u4f5c\u9ad8\u51fa1.3\u500d\u52302.1\u500d\uff0c\u7279\u522b\u662f\u5728\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\u6536\u76ca\u66f4\u5927\uff0c\u4e14\u65e0\u9700\u989d\u5916\u9762\u79ef\u6210\u672c\u3002\u8fd9\u9879\u5de5\u4f5c\u8bc1\u660e\u4e86\u901a\u8fc7\u8d44\u6e90\u65f6\u95f4\u591a\u8def\u590d\u7528\u7684\u65b9\u5f0f\uff0c\u53ef\u4ee5\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u786c\u4ef6\u4e0a\uff0c\u6709\u6548\u5730\u89e3\u51b3LLM\u5728\u4e0d\u540c\u63a8\u7406\u9636\u6bb5\u6027\u80fd\u74f6\u9888\u7684\u5f02\u6784\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86LLM\u7684\u63a8\u7406\u6027\u80fd\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u652f\u6301\u3002"}}
{"id": "2512.11762", "categories": ["cs.PL", "math.CT"], "pdf": "https://arxiv.org/pdf/2512.11762", "abs": "https://arxiv.org/abs/2512.11762", "authors": ["Jack Liell-Cock", "Zev Shirazi", "Sam Staton"], "title": "The Relative Monadic Metalanguage", "comment": "41 pages. Published in Proceedings of the ACM on Programming Languages (POPL 2026)", "summary": "Relative monads provide a controlled view of computation. We generalise the monadic metalanguage to a relative setting and give a complete semantics with strong relative monads. Adopting this perspective, we generalise two existing program calculi from the literature. We provide a linear-non-linear language for graded monads, LNL-RMM, along with a semantic proof that it is a conservative extension of the graded monadic metalanguage. Additionally, we provide a complete semantics for the arrow calculus, showing it is a restricted relative monadic metalanguage. This motivates the introduction of ARMM, a computational lambda calculus-style language for arrows that conservatively extends the arrow calculus.", "AI": {"tldr": "\u4e0d\u662f\uff08DSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS\uff09\u3002\n\u672c\u6587\u5c06\u5355\u5b50\u5143\u8bed\u8a00\u63a8\u5e7f\u5230\u76f8\u5bf9\u8bbe\u7f6e\uff0c\u4f7f\u7528\u5f3a\u76f8\u5bf9\u5355\u5b50\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u8bed\u4e49\uff0c\u5e76\u57fa\u4e8e\u6b64\u5c06\u4e24\u79cd\u73b0\u6709\u7a0b\u5e8f\u6f14\u7b97\uff08\u5206\u7ea7\u5355\u5b50\u5143\u8bed\u8a00\u548c\u7bad\u5934\u6f14\u7b97\uff09\u8fdb\u884c\u63a8\u5e7f\u3002\u5177\u4f53\u7ed3\u679c\u662f\u63d0\u51fa\u4e86\u4e24\u79cd\u65b0\u7a0b\u5e8f\u8bed\u8a00LNL-RMM\uff08\u7528\u4e8e\u5206\u7ea7\u5355\u5b50\u7684\u7ebf\u6027-\u975e\u7ebf\u6027\u8bed\u8a00\uff09\u548cARMM\uff08\u7528\u4e8e\u7bad\u5934\u7684\u8ba1\u7b97\u03bb\u6f14\u7b97\u5f0f\u8bed\u8a00\uff09\uff0c\u5e76\u8bc1\u660e\u5b83\u4eec\u5206\u522b\u662f\u539f\u6709\u6f14\u7b97\u7684\u4fdd\u5b88\u6269\u5c55\u3002", "motivation": "\u76f8\u5bf9\u5355\u5b50\uff08Relative Monads\uff09\u63d0\u4f9b\u4e86\u4e00\u79cd\u53d7\u63a7\u7684\u8ba1\u7b97\u89c6\u56fe\uff0c\u8fd9\u542f\u53d1\u4e86\u4f5c\u8005\u5c06\u73b0\u6709\u7684\u8ba1\u7b97\u7406\u8bba\u548c\u7a0b\u5e8f\u6f14\u7b97\uff08\u5982\u5355\u5b50\u5143\u8bed\u8a00\u3001\u5206\u7ea7\u5355\u5b50\u3001\u7bad\u5934\u6f14\u7b97\uff09\u63a8\u5e7f\u5230\u66f4\u901a\u7528\u3001\u66f4\u53d7\u63a7\u7684\u76f8\u5bf9\u8bbe\u7f6e\uff08Relative Setting\uff09\u3002\u5177\u4f53\u52a8\u673a\u662f\uff1a1. \u5c06\u5355\u5b50\u5143\u8bed\u8a00\u63a8\u5e7f\u5230\u76f8\u5bf9\u8bbe\u7f6e\uff0c\u5e76\u63d0\u4f9b\u5b8c\u6574\u7684\u8bed\u4e49\u7406\u8bba\u30022. \u5229\u7528\u8fd9\u79cd\u65b0\u7684\u76f8\u5bf9\u89c6\u89d2\uff0c\u63a8\u5e7f\u5e76\u7edf\u4e00\u73b0\u6709\u7684\u4e24\u79cd\u91cd\u8981\u7a0b\u5e8f\u6f14\u7b97\uff1a\u5206\u7ea7\u5355\u5b50\u5143\u8bed\u8a00\u548c\u7bad\u5934\u6f14\u7b97\uff0c\u4ee5\u83b7\u5f97\u66f4\u901a\u7528\u548c\u8868\u8fbe\u529b\u66f4\u5f3a\u7684\u8bed\u8a00\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\uff1a1. \u5c06\u5355\u5b50\u5143\u8bed\u8a00\u63a8\u5e7f\u5230\u76f8\u5bf9\u8bbe\u7f6e\uff0c\u5e76\u4f7f\u7528\u5f3a\u76f8\u5bf9\u5355\u5b50\u63d0\u4f9b\u5b8c\u6574\u7684\u8bed\u4e49\u30022. \u91c7\u7528\u76f8\u5bf9\u5355\u5b50\u89c6\u89d2\uff0c\u63a8\u5e7f\u4e24\u79cd\u73b0\u6709\u7684\u7a0b\u5e8f\u6f14\u7b97\uff1a\u5206\u7ea7\u5355\u5b50\u5143\u8bed\u8a00\u548c\u7bad\u5934\u6f14\u7b97\u30023. \u5f15\u5165\u65b0\u7684\u7a0b\u5e8f\u8bed\u8a00LNL-RMM\uff08\u7528\u4e8e\u5206\u7ea7\u5355\u5b50\uff09\u548cARMM\uff08\u7528\u4e8e\u7bad\u5934\uff09\uff0c\u5e76\u63d0\u4f9b\u8bed\u4e49\u8bc1\u660e\u5b83\u4eec\u662f\u4fdd\u5b88\u6269\u5c55\u3002\u5177\u4f53\u6765\u8bf4\uff1aLNL-RMM\u91c7\u7528\u4e86\u7ebf\u6027-\u975e\u7ebf\u6027\u8bed\u8a00\uff0c\u5e76\u8bc1\u660e\u5176\u4fdd\u5b88\u6269\u5c55\u4e86\u5206\u7ea7\u5355\u5b50\u5143\u8bed\u8a00\u3002ARMM\u662f\u8ba1\u7b97\u03bb\u6f14\u7b97\u5f0f\u7684\u8bed\u8a00\uff0c\u4e13\u95e8\u7528\u4e8e\u7bad\u5934\uff0c\u88ab\u8bc1\u660e\u4fdd\u5b88\u5730\u6269\u5c55\u4e86\u7bad\u5934\u6f14\u7b97\u3002", "result": "1. \u6210\u529f\u5c06\u5355\u5b50\u5143\u8bed\u8a00\u63a8\u5e7f\u5230\u76f8\u5bf9\u8bbe\u7f6e\uff0c\u5e76\u4f7f\u7528\u5f3a\u76f8\u5bf9\u5355\u5b50\uff08strong relative monads\uff09\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u8bed\u4e49\u30022. \u63a8\u5e7f\u4e86\u4e24\u79cd\u73b0\u6709\u7a0b\u5e8f\u6f14\u7b97\uff0c\u5f15\u5165\u4e86\u4e24\u79cd\u65b0\u7684\u7a0b\u5e8f\u8bed\u8a00\uff1aLNL-RMM\uff08Linear-Non-Linear language for Graded Monads\uff09\u548cARMM\uff08A language for Arrows based on Computational Lambda Calculus style\uff09\u30023. **LNL-RMM**\uff1a\u4e00\u79cd\u7528\u4e8e\u5206\u7ea7\u5355\u5b50\u7684\u7ebf\u6027-\u975e\u7ebf\u6027\u8bed\u8a00\uff0c\u901a\u8fc7\u8bed\u4e49\u8bc1\u660e\uff0c\u5b83\u662f\u5206\u7ea7\u5355\u5b50\u5143\u8bed\u8a00\u7684\u4fdd\u5b88\u6269\u5c55\uff08conservative extension\uff09\u30024. **ARMM**\uff1a\u4e00\u79cd\u7c7b\u4f3c\u4e8e\u8ba1\u7b97\u03bb\u6f14\u7b97\u5f0f\uff08computational lambda calculus-style\uff09\u7684\u7bad\u5934\u8bed\u8a00\uff0c\u8bc1\u660e\u4e86\u7bad\u5934\u6f14\u7b97\uff08arrow calculus\uff09\u662f\u53d7\u9650\u7684\u76f8\u5bf9\u5355\u5b50\u5143\u8bed\u8a00\uff0c\u5e76\u4e14ARMM\u4fdd\u5b88\u5730\u6269\u5c55\u4e86\u7bad\u5934\u6f14\u7b97\u3002", "conclusion": "\u672c\u6587\u5c06\u5355\u5b50\u5143\u8bed\u8a00\u63a8\u5e7f\u5230\u76f8\u5bf9\u8bbe\u7f6e\uff0c\u5e76\u901a\u8fc7\u5f3a\u76f8\u5bf9\u5355\u5b50\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u8bed\u4e49\u3002\u901a\u8fc7\u8fd9\u79cd\u89c6\u89d2\uff0c\u4f5c\u8005\u5c06\u4e24\u79cd\u73b0\u6709\u7684\u7a0b\u5e8f\u6f14\u7b97\u8fdb\u884c\u63a8\u5e7f\uff0c\u5f97\u5230\u4e86LNL-RMM\u548cARMM\u4e24\u79cd\u65b0\u8bed\u8a00\u3002LNL-RMM\u662f\u4e00\u79cd\u7ebf\u6027\u975e\u7ebf\u6027\u8bed\u8a00\uff0c\u7528\u4e8e\u5206\u7ea7\u5355\u5b50\uff0c\u901a\u8fc7\u8bed\u4e49\u8bc1\u660e\u5b83\u4fdd\u5b88\u5730\u6269\u5c55\u4e86\u5206\u7ea7\u5355\u5b50\u5143\u8bed\u8a00\uff1bARMM\u662f\u5e94\u7528\u4e8e\u7bad\u5934\u7684\u8ba1\u7b97\u03bb\u6f14\u7b97\u5f0f\u8bed\u8a00\uff0c\u5b83\u4fdd\u5b88\u5730\u6269\u5c55\u4e86\u7bad\u5934\u6f14\u7b97\u3002\u603b\u7684\u6765\u8bf4\uff0c\u672c\u6587\u901a\u8fc7\u76f8\u5bf9\u5355\u5b50\u7406\u8bba\uff0c\u4e3a\u73b0\u6709\u7684\u5206\u7ea7\u5355\u5b50\u5143\u8bed\u8a00\u548c\u7bad\u5934\u6f14\u7b97\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u3001\u66f4\u53d7\u63a7\u7684\u8ba1\u7b97\u89c6\u56fe\u548c\u8bed\u4e49\u57fa\u7840\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7a0b\u5e8f\u8bed\u8a00\u6765\u63a8\u5e7f\u5b83\u4eec\u3002"}}
{"id": "2512.11200", "categories": ["cs.DC", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.11200", "abs": "https://arxiv.org/abs/2512.11200", "authors": ["Adilet Metinov", "Gulida M. Kudakeeva", "Gulnara D. Kabaeva"], "title": "Theoretical Foundations of GPU-Native Compilation for Rapid Code Iteration", "comment": "9 pages , 2 tables", "summary": "Current AI code generation systems suffer from significant latency bottlenecks due to CPU-GPU data transfers during compilation, execution, and testing phases. We establish theoretical foundations for three complementary approaches to GPU-native compilation that eliminate these transfers: (1) parallel traditional compilation adapted for GPU execution, (2) neural compilation using learned sequence-to-sequence translation with probabilistic verification, and (3) hybrid architectures combining both strategies. We derive latency and energy bounds demonstrating potential speedups of 10-100x for code iteration cycles. Our analysis shows that traditional GPU compilation provides 2-5x improvements through transfer elimination, neural compilation achieves 10-100x speedups via massive parallelism, and hybrid approaches offer practical deployment paths with guaranteed correctness. We formalize the probabilistic verification framework that enables trading compilation accuracy for parallel exploration, and discuss implications for self-improving AI systems and future analog computing substrates.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL\uff08\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\uff09\u3001\u56fe\u5904\u7406\uff08\u867d\u7136\u672a\u660e\u786e\u63d0\u53ca\uff0c\u4f46\u53ef\u4ee5\u8054\u7cfb\u5230\u7f16\u8bd1\u540e\u7aef\u4f18\u5316\u6216\u6570\u636e\u6d41\u56fe\uff09\u76f8\u5173\u3002\u5176\u6838\u5fc3\u5728\u4e8e\u89e3\u51b3 AI \u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u4e2d\u7684 CPU-GPU \u6570\u636e\u4f20\u8f93\u5ef6\u8fdf\u3002\n\u592a\u957f\u4e0d\u770b (TL;DR): Current AI code generation systems suffer from severe CPU-GPU data transfer bottlenecks. This paper establishes the theoretical foundation for three GPU-native compilation approaches (parallel traditional, neural, and hybrid) to eliminate these transfers, projecting 10-100x speedups in code iteration cycles. It shows that traditional GPU compilation yields 2-5x improvement, neural compilation achieves 10-100x acceleration via massive parallelism, and hybrid approaches offer practical, provably correct deployment paths, supported by a formal probabilistic verification framework.", "motivation": "\u5f53\u524d\u7684 AI \u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u5728\u7f16\u8bd1\u3001\u6267\u884c\u548c\u6d4b\u8bd5\u9636\u6bb5\u5b58\u5728\u663e\u8457\u7684 CPU-GPU \u6570\u636e\u4f20\u8f93\u5ef6\u8fdf\u74f6\u9888\uff0c\u8fd9\u6781\u5927\u5730\u9650\u5236\u4e86\u4ee3\u7801\u8fed\u4ee3\u901f\u5ea6\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u548c\u5206\u6790\u6d88\u9664\u8fd9\u4e9b\u6570\u636e\u4f20\u8f93\u7684 GPU \u539f\u751f\u7f16\u8bd1\u65b9\u6cd5\uff0c\u4ee5\u5b9e\u73b0\u6570\u91cf\u7ea7\u7684\u52a0\u901f\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5efa\u7acb\u7406\u8bba\u57fa\u7840\u5e76\u63a8\u5bfc\u5ef6\u8fdf\u548c\u80fd\u8017\u754c\u9650\u6765\u5206\u6790\u548c\u8bc1\u660e\u4e09\u79cd GPU \u539f\u751f\u7f16\u8bd1\u65b9\u6cd5\uff08\u5e76\u884c\u4f20\u7edf\u7f16\u8bd1\u3001\u795e\u7ecf\u7f16\u8bd1\u3001\u6df7\u5408\u67b6\u6784\uff09\u5728\u6d88\u9664 CPU-GPU \u6570\u636e\u4f20\u8f93\u5ef6\u8fdf\u65b9\u9762\u7684\u6f5c\u529b\u3002\u7279\u522b\u662f\uff0c\u8bba\u6587\u5f62\u5f0f\u5316\u4e86\u6982\u7387\u9a8c\u8bc1\u6846\u67b6\uff0c\u4ee5\u652f\u6301\u5728\u7f16\u8bd1\u7cbe\u5ea6\u548c\u5e76\u884c\u63a2\u7d22\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002", "result": "\u7814\u7a76\u5efa\u7acb\u4e86\u6d88\u9664 CPU-GPU \u6570\u636e\u4f20\u8f93\u7684 GPU \u539f\u751f\u7f16\u8bd1\u65b9\u6cd5\u7684\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u5ef6\u8fdf\u548c\u80fd\u8017\u754c\u9650\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u4ee3\u7801\u8fed\u4ee3\u5468\u671f\u53ef\u80fd\u5b9e\u73b0 10-100 \u500d\u7684\u52a0\u901f\u3002\u5177\u4f53\u7ed3\u679c\u5305\u62ec\uff1a\u4f20\u7edf GPU \u7f16\u8bd1\u901a\u8fc7\u6d88\u9664\u4f20\u8f93\u5b9e\u73b0 2-5 \u500d\u6539\u8fdb\uff1b\u795e\u7ecf\u7f16\u8bd1\u901a\u8fc7\u5927\u89c4\u6a21\u5e76\u884c\u5b9e\u73b0 10-100 \u500d\u52a0\u901f\uff1b\u6df7\u5408\u65b9\u6cd5\u63d0\u4f9b\u4e86\u5b9e\u7528\u90e8\u7f72\u8def\u5f84\u548c\u6b63\u786e\u6027\u4fdd\u8bc1\u3002\u8bba\u6587\u8fd8\u5f62\u5f0f\u5316\u4e86\u6982\u7387\u9a8c\u8bc1\u6846\u67b6\u3002", "conclusion": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u6d88\u9664 AI \u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u4e2d CPU-GPU \u6570\u636e\u4f20\u8f93\u5ef6\u8fdf\u7684 GPU \u539f\u751f\u7f16\u8bd1\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u4e09\u79cd\u4e92\u8865\u7684\u65b9\u6cd5\uff1a\u5e76\u884c\u4f20\u7edf\u7f16\u8bd1\u3001\u795e\u7ecf\u7f16\u8bd1\u548c\u6df7\u5408\u67b6\u6784\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u63a8\u5bfc\u7684\u5ef6\u8fdf\u4e0e\u80fd\u8017\u754c\u9650\uff0c\u8bba\u6587\u5c55\u793a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u5728\u4ee3\u7801\u8fed\u4ee3\u5468\u671f\u4e2d\u5b9e\u73b0 10-100 \u500d\u52a0\u901f\u7684\u6f5c\u529b\u3002\u8bba\u6587\u5f97\u51fa\u7684\u7ed3\u8bba\u662f\uff0c\u4f20\u7edf GPU \u7f16\u8bd1\u4e3b\u8981\u901a\u8fc7\u6d88\u9664\u6570\u636e\u4f20\u8f93\u5b9e\u73b0 2-5 \u500d\u7684\u6539\u8fdb\uff0c\u795e\u7ecf\u7f16\u8bd1\u901a\u8fc7\u5927\u89c4\u6a21\u5e76\u884c\u5b9e\u73b0 10-100 \u500d\u7684\u52a0\u901f\uff0c\u800c\u6df7\u5408\u67b6\u6784\u5219\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6b63\u786e\u6027\u4fdd\u8bc1\u7684\u5b9e\u7528\u90e8\u7f72\u8def\u5f84\u3002\u8bba\u6587\u8fd8\u63d0\u51fa\u4e86\u6982\u7387\u9a8c\u8bc1\u6846\u67b6\uff0c\u4e3a\u6743\u8861\u7f16\u8bd1\u7cbe\u5ea6\u548c\u5e76\u884c\u63a2\u7d22\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u8ba8\u8bba\u4e86\u5bf9\u81ea\u6539\u8fdb AI \u7cfb\u7edf\u548c\u672a\u6765\u6a21\u62df\u8ba1\u7b97\u57fa\u677f\u7684\u610f\u4e49\u3002"}}
{"id": "2512.10974", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10974", "abs": "https://arxiv.org/abs/2512.10974", "authors": ["Sohan Kumar Pande", "Sanjaya Kumar Panda", "Preeti Ranjan Sahu"], "title": "An Efficient Approach for Energy Conservation in Cloud Computing Environment", "comment": null, "summary": "Recent trends of technology have explored a numerous applications of cloud services, which require a significant amount of energy. In the present scenario, most of the energy sources are limited and have a greenhouse effect on the environment. Therefore, it is the need of the hour that the energy consumed by the cloud service providers must be reduced and it is a great challenge to the research community to develop energy-efficient algorithms. To design the same, some researchers tried to maximize the average resource utilization, whereas some researchers tried to minimize the makespan. However, they have not considered different types of resources that are present in the physical machines. In this paper, we propose a task scheduling algorithm, which tries to improve utilization of resources (like CPU, disk, I/O) explicitly, which in turn increases the utilization of active resources. For this, the proposed algorithm uses a fitness value, which is a function of CPU, disk and I/O utilization, and processing time of the task. To demonstrate the performance of the proposed algorithm, extensive simulations are performed on both proposed algorithm and existing algorithm MaxUtil using synthetic datasets. From the simulation results, it can be observed that the proposed algorithm is a better energy-efficient algorithm and consumes less energy than the MaxUtil algorithm.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\u90e8\u5206\u662f\u4e91\u8ba1\u7b97\u4e2d\u7684\u8d44\u6e90\u8c03\u5ea6\uff0c\u8fd9\u672c\u8d28\u4e0a\u662f\u7cfb\u7edf\u8f6f\u4ef6\u7684\u4e00\u90e8\u5206\uff0c\u5176\u4e2d\u8c03\u5ea6\u7b97\u6cd5\u7684\u8bbe\u8ba1\u4e0e\u7f16\u8bd1\u5668\u4e2d\u7684\u8d44\u6e90\u5206\u914d\u548c\u8c03\u5ea6\u6709\u76f8\u4f3c\u7684\u4f18\u5316\u76ee\u6807\u3002TLDR: \u4e91\u670d\u52a1\u8017\u80fd\u5927\uff0c\u73b0\u6709\u8c03\u5ea6\u7b97\u6cd5\u672a\u5145\u5206\u8003\u8651\u4e0d\u540c\u8d44\u6e90\u7c7b\u578b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408CPU\u3001\u78c1\u76d8\u548cI/O\u7684\u5229\u7528\u7387\u548c\u4efb\u52a1\u5904\u7406\u65f6\u95f4\u6765\u8ba1\u7b97\u9002\u5e94\u5ea6\u503c\uff0c\u4ee5\u663e\u5f0f\u5730\u63d0\u9ad8\u4e0d\u540c\u7c7b\u578b\u8d44\u6e90\u7684\u5229\u7528\u7387\uff0c\u4ece\u800c\u964d\u4f4e\u80fd\u8017\u3002\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u6bd4\u73b0\u6709MaxUtil\u7b97\u6cd5\u66f4\u8282\u80fd\u3002", "motivation": "\u4e91\u670d\u52a1\u6d88\u8017\u5927\u91cf\u80fd\u6e90\uff0c\u4e14\u73b0\u6709\u80fd\u6e90\u6709\u9650\u5e76\u5e26\u6765\u6e29\u5ba4\u6548\u5e94\u3002\u56e0\u6b64\uff0c\u9700\u8981\u51cf\u5c11\u4e91\u670d\u52a1\u63d0\u4f9b\u5546\u7684\u80fd\u8017\uff0c\u8fd9\u5bf9\u7814\u7a76\u793e\u533a\u63d0\u51fa\u4e86\u5f00\u53d1\u8282\u80fd\u7b97\u6cd5\u7684\u6311\u6218\u3002\u73b0\u6709\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6700\u5927\u5316\u5e73\u5747\u8d44\u6e90\u5229\u7528\u7387\u6216\u6700\u5c0f\u5316\u6700\u77ed\u5b8c\u5de5\u65f6\u95f4\uff08makespan\uff09\uff0c\u4f46\u6ca1\u6709\u8003\u8651\u7269\u7406\u673a\u4e2d\u5b58\u5728\u7684\u4e0d\u540c\u7c7b\u578b\u7684\u8d44\u6e90\uff08\u5982CPU\u3001\u78c1\u76d8\u3001I/O\uff09\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u901a\u8fc7\u4e00\u4e2a\u9002\u5e94\u5ea6\u503c\u6765\u9009\u62e9\u4efb\u52a1\u653e\u7f6e\u7684\u4f4d\u7f6e\uff0c\u8be5\u9002\u5e94\u5ea6\u503c\u662fCPU\u3001\u78c1\u76d8\u548cI/O\u5229\u7528\u7387\u4ee5\u53ca\u4efb\u52a1\u5904\u7406\u65f6\u95f4\u7684\u4e00\u4e2a\u51fd\u6570\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u7b97\u6cd5\u660e\u786e\u5730\u63d0\u9ad8\u4e86\u4e0d\u540c\u79cd\u7c7b\u8d44\u6e90\u7684\u5229\u7528\u7387\uff0c\u8fdb\u800c\u589e\u52a0\u4e86\u6d3b\u52a8\u8d44\u6e90\u7684\u5229\u7528\u7387\u3002\u4f7f\u7528\u5408\u6210\u6570\u636e\u96c6\u5bf9\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u73b0\u6709\u7b97\u6cd5MaxUtil\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u4eff\u771f\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u6bd4MaxUtil\u7b97\u6cd5\u66f4\u8282\u80fd\uff0c\u6d88\u8017\u66f4\u5c11\u7684\u80fd\u91cf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651CPU\u3001\u78c1\u76d8\u548cI/O\u7b49\u4e0d\u540c\u8d44\u6e90\u5229\u7528\u7387\u7684\u65b0\u7684\u4efb\u52a1\u8c03\u5ea6\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u8bc1\u660e\u4e86\u8be5\u7b97\u6cd5\u5728\u8282\u80fd\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u7684MaxUtil\u7b97\u6cd5\u3002"}}
{"id": "2512.11606", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.11606", "abs": "https://arxiv.org/abs/2512.11606", "authors": ["Xi Ou", "Longlong Lin", "Zeli Wang", "Pingpeng Yuan", "Rong-Hua Li"], "title": "Scalable Similarity Search over Large Attributed Bipartite Graphs", "comment": null, "summary": "Bipartite graphs are widely used to model relationships between entities of different types, where nodes are divided into two disjoint sets. Similarity search, a fundamental operation that retrieves nodes similar to a given query node, plays a crucial role in various real-world applications, including machine learning and graph clustering. However, existing state-of-the-art methods often struggle to accurately capture the unique structural properties of bipartite graphs or fail to incorporate the informative node attributes, leading to suboptimal performance. Besides, their high computational complexity limits scalability, making them impractical for large graphs with millions of nodes and tens of thousands of attributes. To overcome these challenges, we first introduce Attribute-augmented Hidden Personalized PageRank (AHPP), a novel random walk model designed to blend seamlessly both the higher-order bipartite structure proximity and attribute similarity. We then formulate the similarity search over attributed bipartite graphs as an approximate AHPP problem and propose two efficient push-style local algorithms with provable approximation guarantees. Finally, extensive experiments on real-world and synthetic datasets validate the effectiveness of AHPP and the efficiency of our proposed algorithms when compared with fifteen competitors.", "AI": {"tldr": "\u5173\u8054\u9886\u57df: \u56fe\u5904\u7406 (Graph processing)\u3002\nTLDR: \u9488\u5bf9\u73b0\u6709\u4e8c\u90e8\u56fe\u76f8\u4f3c\u6027\u641c\u7d22\u65b9\u6cd5\u5728\u5904\u7406\u5927\u89c4\u6a21\u3001\u5e26\u5c5e\u6027\u6570\u636e\u65f6\uff0c\u7cbe\u5ea6\u4f4e\u548c\u6548\u7387\u5dee\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u968f\u673a\u6e38\u8d70\u6a21\u578b\u2014\u2014\u5c5e\u6027\u589e\u5f3a\u7684\u9690\u85cf\u5f0f\u4e2a\u6027\u5316PageRank (AHPP)\uff0c\u8be5\u6a21\u578b\u80fd\u540c\u65f6\u878d\u5408\u9ad8\u9636\u4e8c\u90e8\u7ed3\u6784\u90bb\u8fd1\u5ea6\u548c\u5c5e\u6027\u76f8\u4f3c\u6027\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u5c06\u76f8\u4f3c\u6027\u641c\u7d22\u8f6c\u5316\u4e3a\u8fd1\u4f3cAHPP\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u9ad8\u6548\u7684\u63a8\u5f0f\u5c40\u90e8\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8fd9\u4e9b\u7b97\u6cd5\u5177\u6709\u53ef\u8bc1\u660e\u7684\u8fd1\u4f3c\u4fdd\u8bc1\u3002\u5b9e\u9a8c\u8bc1\u660eAHPP\u53ca\u5176\u7b97\u6cd5\u5728\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u96c6\u4e0a\u90fd\u975e\u5e38\u6709\u6548\u548c\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u7684\u4e8c\u90e8\u56fe\u76f8\u4f3c\u6027\u641c\u7d22\u65b9\u6cd5\u5b58\u5728\u4ee5\u4e0b\u95ee\u9898\uff1a1. \u65e0\u6cd5\u51c6\u786e\u6355\u83b7\u4e8c\u90e8\u56fe\u7684\u72ec\u7279\u7ed3\u6784\u7279\u6027\u30022. \u672a\u80fd\u6709\u6548\u878d\u5165\u4fe1\u606f\u4e30\u5bcc\u7684\u8282\u70b9\u5c5e\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0d\u4f73\u30023. \u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u53ef\u6269\u5c55\u6027\u53d7\u9650\uff0c\u4e0d\u9002\u7528\u4e8e\u5177\u6709\u6570\u767e\u4e07\u8282\u70b9\u548c\u6570\u4e07\u5c5e\u6027\u7684\u5927\u89c4\u6a21\u56fe\u3002", "method": "1. \u63d0\u51fa\u201c\u5c5e\u6027\u589e\u5f3a\u7684\u9690\u85cf\u5f0f\u4e2a\u6027\u5316PageRank\u201d\uff08Attribute-augmented Hidden Personalized PageRank\uff0c\u7b80\u79f0AHPP\uff09\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u968f\u673a\u6e38\u8d70\u6a21\u578b\uff0c\u7528\u4e8e\u65e0\u7f1d\u878d\u5408\u9ad8\u9636\u4e8c\u90e8\u7ed3\u6784\u90bb\u8fd1\u5ea6\u548c\u5c5e\u6027\u76f8\u4f3c\u6027\u30022. \u5c06\u5e26\u5c5e\u6027\u4e8c\u90e8\u56fe\u4e0a\u7684\u76f8\u4f3c\u6027\u641c\u7d22\u95ee\u9898\uff0c\u516c\u5f0f\u5316\u4e3a\u4e00\u4e2a\u8fd1\u4f3c\u7684AHPP\u95ee\u9898\u30023. \u63d0\u51fa\u4e24\u79cd\u9ad8\u6548\u7684\u63a8\u5f0f\uff08push-style\uff09\u5c40\u90e8\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u8bc1\u660e\u7684\u8fd1\u4f3c\u4fdd\u8bc1\u3002", "result": "\u5728\u771f\u5b9e\u7684\u548c\u5408\u6210\u7684\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\uff1a1. AHPP\u6a21\u578b\u5728\u76f8\u4f3c\u6027\u641c\u7d22\u4e2d\u7684\u6709\u6548\u6027\u30022. \u63d0\u51fa\u7684\u5c40\u90e8\u8fd1\u4f3c\u7b97\u6cd5\u4e0e\u5341\u4e94\u4e2a\u7ade\u4e89\u65b9\u6cd5\u76f8\u6bd4\u5177\u6709\u9ad8\u6548\u7387\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86AHPP\u6a21\u578b\u53ca\u5176\u9ad8\u6548\u7684\u5c40\u90e8\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6548\u7387\u7684\u540c\u65f6\uff0c\u6709\u6548\u5730\u7ed3\u5408\u4e86\u4e8c\u90e8\u56fe\u7684\u7ed3\u6784\u7279\u6027\u548c\u8282\u70b9\u5c5e\u6027\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6709\u5c5e\u6027\u4e8c\u90e8\u56fe\u76f8\u4f3c\u6027\u641c\u7d22\u4e2d\u7cbe\u5ea6\u548c\u6548\u7387\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2512.11618", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.11618", "abs": "https://arxiv.org/abs/2512.11618", "authors": ["Lorenzo Carfagna", "Carlo Tosoni"], "title": "New Entropy Measures for Tries with Applications to the XBWT", "comment": "32 pages, 4 figures", "summary": "Entropy quantifies the number of bits required to store objects under certain given assumptions. While this is a well established concept for strings, in the context of tries the state-of-the-art regarding entropies is less developed. The standard trie worst-case entropy considers the set of tries with a fixed number of nodes and alphabet size. However, this approach does not consider the frequencies of the symbols in the trie, thus failing to capture the compressibility of tries with skewed character distributions. On the other hand, the label entropy [FOCS '05], proposed for node-labeled trees, does not take into account the tree topology, which has to be stored separately. In this paper, we introduce two new entropy measures for tries - worst-case and empirical - which overcome the two aforementioned limitations. Notably, our entropies satisfy similar properties of their string counterparts, thereby becoming very natural generalizations of the (simpler) string case. Indeed, our empirical entropy is closely related to the worst-case entropy and is reachable through a natural extension of arithmetic coding from strings to tries. Moreover we show that, similarly to the FM-index for strings [JACM '05], the XBWT of a trie can be compressed and efficiently indexed within our k-th order empirical entropy plus o(n) bits, with n being the number of nodes. Interestingly, the space usage of this encoding includes the trie topology and the upper-bound holds for every k sufficiently small, simultaneously. This XBWT encoding is always strictly smaller than the original one [JACM '09] and we show that in certain cases it is asymptotically smaller.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001HLS\u3001MLIR\u3001\u56fe\u5904\u7406\u548cDSL\u9886\u57df\u4e0d\u76f8\u5173\u3002/\n\u5728\u672c\u8bba\u6587\u4e2d\uff0c\u4f5c\u8005\u5f15\u5165\u4e86\u4e24\u79cd\u65b0\u7684Trie\u6811\u71b5\u5ea6\u91cf\uff08\u6700\u574f\u60c5\u51b5\u71b5\u548c\u7ecf\u9a8c\u71b5\uff09\u6765\u514b\u670d\u73b0\u6709\u5ea6\u91cf\u672a\u80fd\u8003\u8651\u7b26\u53f7\u9891\u7387\u548cTrie\u62d3\u6251\u7684\u9650\u5236\u3002\u8fd9\u4e24\u79cd\u5ea6\u91cf\u662f\u5b57\u7b26\u4e32\u71b5\u7684\u81ea\u7136\u63a8\u5e7f\uff0c\u5176\u4e2d\u7ecf\u9a8c\u71b5\u4e0e\u7b97\u672f\u7f16\u7801\u7684\u63a8\u5e7f\u76f8\u5173\uff0c\u5e76\u88ab\u7528\u4e8eTrie\u6811\u7684\u6269\u5c55Burrows-Wheeler\u53d8\u6362\uff08XBWT\uff09\u7684\u538b\u7f29\u548c\u9ad8\u6548\u7d22\u5f15\u3002\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u65b0\u71b5\u5ea6\u91cf\u7684XBWT\u7f16\u7801\u5728$k$\u9636\u7ecf\u9a8c\u71b5\u52a0$o(n)$\u6bd4\u7279\u5185\u5b9e\u73b0\uff0c\u5176\u7a7a\u95f4\u4f7f\u7528\u59cb\u7ec8\u5c0f\u4e8e\uff0c\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u751a\u81f3\u6e10\u8fd1\u5c0f\u4e8e\u539f\u59cb\u7f16\u7801\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86Trie\u7ed3\u6784\u7684\u5b58\u50a8\u6548\u7387\u3002", "motivation": "\u73b0\u6709Trie\u6811\u7684\u71b5\u5ea6\u91cf\uff08\u5982\u6807\u51c6\u6700\u574f\u60c5\u51b5\u71b5\u548c\u6807\u7b7e\u71b5\uff09\u5b58\u5728\u5c40\u9650\u6027\u3002\u6807\u51c6\u6700\u574f\u60c5\u51b5\u71b5\u6ca1\u6709\u8003\u8651Trie\u4e2d\u7b26\u53f7\u7684\u9891\u7387\u5206\u5e03\uff0c\u672a\u80fd\u53cd\u6620\u5b57\u7b26\u5206\u5e03\u504f\u659c\u65f6Trie\u7684\u53ef\u538b\u7f29\u6027\u3002\u800c\u6807\u7b7e\u71b5\u6ca1\u6709\u8003\u8651\u6811\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u9700\u8981\u989d\u5916\u5b58\u50a8\u3002\u56e0\u6b64\uff0c\u9700\u8981\u65b0\u7684\u71b5\u5ea6\u91cf\u6765\u514b\u670d\u8fd9\u4e24\u4e2a\u9650\u5236\uff0c\u66f4\u51c6\u786e\u5730\u91cf\u5316Trie\u6811\u7684\u5b58\u50a8\u9700\u6c42\u548c\u53ef\u538b\u7f29\u6027\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5f15\u5165\u4e24\u79cd\u65b0\u7684Trie\u6811\u71b5\u5ea6\u91cf\uff08\u6700\u574f\u60c5\u51b5\u71b5\u548c\u7ecf\u9a8c\u71b5\uff09\u6765\u89e3\u51b3\u73b0\u6709Trie\u6811\u71b5\u5ea6\u91cf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002\u8fd9\u4e9b\u65b0\u5ea6\u91cf\u8003\u8651\u4e86\u7b26\u53f7\u7684\u9891\u7387\u5206\u5e03\u548cTrie\u7684\u62d3\u6251\u7ed3\u6784\u3002\u7ecf\u9a8c\u71b5\u88ab\u8bc1\u660e\u4e0e\u7b97\u672f\u7f16\u7801\u7684\u81ea\u7136\u63a8\u5e7f\u76f8\u5173\uff0c\u5e76\u7528\u4e8e\u6307\u5bfcTrie\u6811\u6269\u5c55Burrows-Wheeler\u53d8\u6362\uff08XBWT\uff09\u7684\u538b\u7f29\u548c\u9ad8\u6548\u7d22\u5f15\u3002", "result": "\u672c\u6587\u5f15\u5165\u7684\u4e24\u79cd\u65b0Trie\u6811\u71b5\u5ea6\u91cf\uff08\u6700\u574f\u60c5\u51b5\u71b5\u548c\u7ecf\u9a8c\u71b5\uff09\u88ab\u8bc1\u660e\u662f\u5b57\u7b26\u4e32\u71b5\u7684\u81ea\u7136\u63a8\u5e7f\uff0c\u5e76\u5177\u6709\u76f8\u4f3c\u7684\u6027\u8d28\u3002\u7ecf\u9a8c\u71b5\u4e0e\u5b57\u7b26\u4e32\u7b97\u672f\u7f16\u7801\u7684\u81ea\u7136\u63a8\u5e7f\u7d27\u5bc6\u76f8\u5173\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86Trie\u6811\u7684\u6269\u5c55Burrows-Wheeler\u53d8\u6362\uff08XBWT\uff09\u53ef\u4ee5\u5728\u4ed6\u4eec\u7684k\u9636\u7ecf\u9a8c\u71b5\u52a0\u4e0a$o(n)$\u6bd4\u7279\u7a7a\u95f4\u5185\u88ab\u538b\u7f29\u548c\u9ad8\u6548\u7d22\u5f15\uff0c\u5176\u4e2d$n$\u662f\u8282\u70b9\u6570\u3002\u8fd9\u79cdXBWT\u7f16\u7801\u7684\u7a7a\u95f4\u4f7f\u7528\u5305\u62ecTrie\u62d3\u6251\u7ed3\u6784\uff0c\u5e76\u4e14\u5bf9\u4e8e\u6240\u6709\u8db3\u591f\u5c0f\u7684$k$\uff0c\u8be5\u4e0a\u754c\u540c\u65f6\u6210\u7acb\u3002\u8fd9\u79cd\u65b0\u7684XBWT\u7f16\u7801\u603b\u662f\u4e25\u683c\u5c0f\u4e8e\u539f\u59cb\u7f16\u7801\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6e10\u8fd1\u66f4\u5c0f\u3002", "conclusion": "\u672c\u6587\u5f15\u5165\u4e86\u4e24\u79cd\u65b0\u7684Trie\u6811\u71b5\u5ea6\u91cf\u2014\u2014\u6700\u574f\u60c5\u51b5\u71b5\u548c\u7ecf\u9a8c\u71b5\uff0c\u5b83\u4eec\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u6210\u4e3a\u5b57\u7b26\u4e32\u71b5\u7684\u81ea\u7136\u63a8\u5e7f\u3002\u7279\u522b\u662f\uff0c\u7ecf\u9a8c\u71b5\u4e0e\u7b97\u672f\u7f16\u7801\u7684\u63a8\u5e7f\u76f8\u5173\uff0c\u5e76\u4e14\u4e0eTrie\u6811\u7684XBWT\u7684\u538b\u7f29\u548c\u7d22\u5f15\u7d27\u5bc6\u76f8\u5173\u3002\u8fd9\u4e9b\u65b0\u7684\u71b5\u5ea6\u91cf\uff0c\u5c24\u5176\u662f\u5728\u538b\u7f29\u548c\u7d22\u5f15XBWT\u65b9\u9762\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5c0f\u4e14\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6e10\u8fd1\u66f4\u5c0f\u7684\u5b58\u50a8\u7a7a\u95f4\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86Trie\u7ed3\u6784\u7684\u5b58\u50a8\u6548\u7387\u3002"}}
{"id": "2512.10979", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10979", "abs": "https://arxiv.org/abs/2512.10979", "authors": ["Sima Attar-Khorasani", "Lincoln Sherpa", "Matthias Lieber", "Siavash Ghiasvand"], "title": "Seamless Transitions: A Comprehensive Review of Live Migration Technologies", "comment": "35 pages, 0 figures", "summary": "Live migration, a technology enabling seamless transition of operational computational entities between various hosts while preserving continuous functionality and client connectivity, has been the subject of extensive research. However, existing reviews often overlook critical technical aspects and practical challenges integral to the usage of live migration techniques in real-world scenarios. This work bridges this gap by integrating the aspects explored in existing reviews together with a comprehensive analysis of live migration technologies across multiple dimensions, with focus on migration techniques, migration units, and infrastructure characteristics. Despite efforts to make live migration widely accessible, its reliance on multiple system factors can create challenges. In certain cases, the complexities and resource demands outweigh the benefits, making its implementation hard to justify. The focus of this work is mainly on container based and virtual machine-based migration technologies, examining the current state of the art and the disparity in adoption between these two approaches. Furthermore, this work explores the impact of migration objectives and operational constraints on the usability and efficacy of existing technologies. By outlining current technical challenges and providing guidelines for future research and development directions, this work serves a dual purpose: first, to equip enthusiasts with a valuable resource on live migration, and second, to contribute to the advancement of live migration technologies and their practical implementation across diverse computing environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u4e0d\u76f8\u5173\u3002\n\u8be5\u8bba\u6587\u662f\u5bf9\u5b9e\u65f6\u8fc1\u79fb\uff08Live Migration\uff09\u6280\u672f\u7684\u5168\u9762\u7efc\u8ff0\uff0c\u96c6\u4e2d\u5206\u6790\u4e86\u865a\u62df\u673a\u548c\u5bb9\u5668\u4e24\u79cd\u4e3b\u8981\u5f62\u5f0f\u7684\u8fc1\u79fb\u6280\u672f\u3001\u5355\u5143\u548c\u57fa\u7840\u8bbe\u65bd\uff0c\u6307\u51fa\u4e86\u73b0\u6709\u7efc\u8ff0\u7684\u4e0d\u8db3\uff0c\u63a2\u8ba8\u4e86\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u6311\u6218\u3001\u63a5\u53d7\u5ea6\u5dee\u5f02\u4ee5\u53ca\u8fc1\u79fb\u76ee\u6807\u548c\u64cd\u4f5c\u7ea6\u675f\u7684\u5f71\u54cd\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u7684\u5b9e\u65f6\u8fc1\u79fb\u7efc\u8ff0\u901a\u5e38\u5ffd\u89c6\u4e86\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u4f7f\u7528\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u65f6\u6240\u56fa\u6709\u7684\u5173\u952e\u6280\u672f\u65b9\u9762\u548c\u5b9e\u9645\u6311\u6218\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\uff0c\u901a\u8fc7\u5168\u9762\u5206\u6790\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u5728\u591a\u4e2a\u7ef4\u5ea6\u4e0a\u7684\u73b0\u72b6\uff0c\u5c24\u5176\u662f\u5173\u6ce8\u5bb9\u5668\u548c\u865a\u62df\u673a\u4e0a\u7684\u5e94\u7528\u548c\u91c7\u7528\u5dee\u5f02\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u7efc\u8ff0\u4e2d\u7f3a\u4e4f\u7684\u5b9e\u7528\u6027\u548c\u7cfb\u7edf\u6027\u5206\u6790\u3002", "method": "\u672c\u6587\u91c7\u7528\u7efc\u5408\u5206\u6790\u548c\u7cfb\u7edf\u56de\u987e\u7684\u65b9\u6cd5\uff0c\u6574\u5408\u4e86\u73b0\u6709\u6587\u732e\u4e2d\u63a2\u7d22\u7684\u5404\u4e2a\u65b9\u9762\uff0c\u5e76\u4ece\u8fc1\u79fb\u6280\u672f\u3001\u8fc1\u79fb\u5355\u5143\u548c\u57fa\u7840\u8bbe\u65bd\u7279\u6027\u7b49\u591a\u4e2a\u7ef4\u5ea6\u5bf9\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u5206\u6790\u3002\u7814\u7a76\u4fa7\u91cd\u4e8e\u5bb9\u5668\u548c\u865a\u62df\u673a\u4e24\u79cd\u4e3b\u8981\u7684\u8fc1\u79fb\u6280\u672f\uff0c\u5e76\u901a\u8fc7\u6bd4\u8f83\u5b83\u4eec\u4e4b\u95f4\u7684\u91c7\u7528\u5dee\u5f02\u6765\u8bc4\u4f30\u73b0\u6709\u6280\u672f\u7684\u73b0\u72b6\u3002\u6587\u7ae0\u8fd8\u5206\u6790\u4e86\u8fc1\u79fb\u76ee\u6807\u548c\u64cd\u4f5c\u7ea6\u675f\u5bf9\u73b0\u6709\u6280\u672f\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\u7684\u5f71\u54cd\uff0c\u6700\u7ec8\u63d0\u51fa\u4e86\u672a\u6765\u7684\u6311\u6218\u548c\u53d1\u5c55\u65b9\u5411\u3002", "result": "\u672c\u6587\u5bf9\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u8fdb\u884c\u4e86\u5168\u9762\u7684\u591a\u7ef4\u5ea6\u5206\u6790\uff0c\u7740\u91cd\u63a2\u8ba8\u4e86\u5728\u5bb9\u5668\u548c\u865a\u62df\u673a\u73af\u5883\u4e2d\u7684\u8fc1\u79fb\u6280\u672f\u3001\u8fc1\u79fb\u5355\u5143\u548c\u57fa\u7840\u8bbe\u65bd\u7279\u6027\u3002\u5206\u6790\u63ed\u793a\u4e86\u8fd9\u4e24\u79cd\u65b9\u6cd5\u5728\u91c7\u7528\u4e0a\u7684\u5dee\u5f02\uff0c\u5e76\u5f3a\u8c03\u4e86\u5b9e\u65f6\u8fc1\u79fb\u53ef\u80fd\u56e0\u590d\u6742\u7684\u7cfb\u7edf\u56e0\u7d20\u548c\u8d44\u6e90\u9700\u6c42\u800c\u96be\u4ee5\u8bc1\u660e\u5176\u5408\u7406\u6027\u7684\u60c5\u51b5\u3002\u901a\u8fc7\u63a2\u7d22\u8fc1\u79fb\u76ee\u6807\u548c\u64cd\u4f5c\u7ea6\u675f\u7684\u5f71\u54cd\uff0c\u6587\u7ae0\u603b\u7ed3\u4e86\u5f53\u524d\u7684\u6280\u672f\u6311\u6218\uff0c\u5e76\u4e3a\u5b9e\u65f6\u8fc1\u79fb\u7684\u672a\u6765\u53d1\u5c55\u660e\u786e\u4e86\u65b9\u5411\u548c\u6307\u5bfc\u3002", "conclusion": "\u8fd9\u7bc7\u7efc\u8ff0\u603b\u7ed3\u4e86\u73b0\u6709\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u7684\u73b0\u72b6\uff0c\u5206\u6790\u4e86\u5176\u5728\u865a\u62df\u673a\u548c\u5bb9\u5668\u73af\u5883\u4e2d\u7684\u5e94\u7528\u5dee\u5f02\uff0c\u5e76\u63a2\u8ba8\u4e86\u8fc1\u79fb\u76ee\u6807\u548c\u64cd\u4f5c\u7ea6\u675f\u5bf9\u5176\u53ef\u7528\u6027\u548c\u6709\u6548\u6027\u7684\u5f71\u54cd\u3002\u6587\u7ae0\u6307\u51fa\u4e86\u5f53\u524d\u7684\u6280\u672f\u6311\u6218\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u7814\u7a76\u548c\u53d1\u5c55\u63d0\u4f9b\u4e86\u6307\u5bfc\u65b9\u5411\uff0c\u65e8\u5728\u63a8\u52a8\u5b9e\u65f6\u8fc1\u79fb\u6280\u672f\u53ca\u5176\u5728\u4e0d\u540c\u8ba1\u7b97\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2512.11725", "categories": ["cs.DS", "cs.CC", "cs.DM", "math.CO"], "pdf": "https://arxiv.org/pdf/2512.11725", "abs": "https://arxiv.org/abs/2512.11725", "authors": ["Carl Feghali", "Hoang-Oanh Le", "Van Bang Le"], "title": "The parameterized complexity of Strong Conflict-Free Vertex-Connection Colorability", "comment": "accepted by DAM (special issue GROW 2024)", "summary": "This paper continues the study of a new variant of graph coloring with a connectivity constraint recently introduced by Hsieh et al. [COCOON 2024]. A path in a vertex-colored graph is called conflict-free if there is a color that appears exactly once on its vertices. A connected graph is said to be strongly conflict-free vertex-connection $k$-colorable if it admits a (proper) vertex $k$-coloring such that any two distinct vertices are connected by a conflict-free shortest path. Among others, we show that deciding, for a given graph $G$ and an integer $k$, whether $G$ is strongly conflict-free $k$-colorable is fixed-parameter tractable when parameterized by the vertex cover number. But under the standard complexity-theoretic assumption NP $\\not\\subseteq$ coNP/poly, deciding, for a given graph $G$, whether $G$ is strongly conflict-free $3$-colorable does not admit a polynomial kernel, even for bipartite graphs. This kernel lower bound is in stark contrast to the ordinal $k$-Coloring problem which is known to admit a polynomial kernel when parameterized by the vertex cover number.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e DSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u3001HLS \u65e0\u5173\uff0c\u4f46\u6d89\u53ca\u56fe\u8bba\u548c\u8ba1\u7b97\u590d\u6742\u6027\u3002\n\u592a\u957f\u4e0d\u8bfb\uff1a\u672c\u6587\u7ee7\u7eed\u7814\u7a76\u5e26\u6709\u8fde\u901a\u6027\u7ea6\u675f\u7684\u65b0\u578b\u56fe\u7740\u8272\u95ee\u9898\u2014\u2014\u5f3a\u65e0\u51b2\u7a81\u9876\u70b9\u8fde\u63a5 $k$-\u7740\u8272\u3002\u4f5c\u8005\u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u7684\u5224\u5b9a\u6027\u5728\u4ee5\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u65f6\u662f\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\u7684 (FPT)\uff0c\u4f46\u540c\u65f6\u4e5f\u8bc1\u660e\u4e86\u5728\u6807\u51c6\u7684\u590d\u6742\u6027\u5047\u8bbe\u4e0b\uff0c\u5373\u4f7f\u5bf9\u4e8e\u4e8c\u5206\u56fe\uff0c\u5224\u5b9a\u5b83\u80fd\u5426\u5f3a\u65e0\u51b2\u7a81 3-\u53ef\u7740\u8272\u4e0d\u5177\u5907\u591a\u9879\u5f0f\u6838\uff0c\u8fd9\u4e0e\u4f20\u7edf $k$-\u7740\u8272\u95ee\u9898\u7684\u7ed3\u679c\u5f62\u6210\u4e86\u9c9c\u660e\u7684\u5bf9\u6bd4\u3002", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u662f\u7ee7\u7eed\u7814\u7a76 Hsieh \u7b49\u4eba\u6700\u8fd1\u63d0\u51fa\u7684\u4e00\u4e2a\u65b0\u7684\u5e26\u6709\u8fde\u901a\u6027\u7ea6\u675f\u7684\u56fe\u7740\u8272\u53d8\u4f53\u2014\u2014\u5f3a\u65e0\u51b2\u7a81\u9876\u70b9\u8fde\u63a5 $k$-\u7740\u8272\u95ee\u9898\u3002\u8fd9\u4e2a\u95ee\u9898\u7684\u7279\u70b9\u662f\u8981\u6c42\u56fe\u4e2d\u4efb\u610f\u4e24\u4e2a\u4e0d\u540c\u7684\u9876\u70b9\u4e4b\u95f4\u90fd\u5b58\u5728\u4e00\u6761\u201c\u65e0\u51b2\u7a81\u6700\u77ed\u8def\u5f84\u201d\uff08\u5373\u8def\u5f84\u4e0a\u5b58\u5728\u4e00\u79cd\u989c\u8272\u6070\u597d\u51fa\u73b0\u4e00\u6b21\uff09\u3002\u4f5c\u8005\u65e8\u5728\u63a2\u7a76\u8fd9\u4e2a\u95ee\u9898\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u7279\u522b\u662f\u5176\u5728\u53c2\u6570\u5316\u590d\u6742\u5ea6\u7406\u8bba\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u5c06\u5176\u4e0e\u4f20\u7edf\u56fe\u7740\u8272\u95ee\u9898\u8fdb\u884c\u5bf9\u6bd4\u3002", "method": "\u672c\u6587\u5bf9\u5f3a\u65e0\u51b2\u7a81\u9876\u70b9\u8fde\u63a5 $k$-\u7740\u8272\u95ee\u9898\u8fdb\u884c\u4e86\u590d\u6742\u6027\u5206\u6790\uff0c\u7279\u522b\u662f\u7814\u7a76\u4e86\u5728\u4ee5\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u65f6\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\u6027\uff08FPT\uff09\u548c\u6838\u5316\u95ee\u9898\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u8bc1\u660e\u4e86\u5224\u5b9a\u95ee\u9898\u5728\u4ee5\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u65f6\u662f FPT \u7684\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u5bf9\u4e8e $k=3$ \u7684\u60c5\u51b5\uff0c\u5373\u4f7f\u5bf9\u4e8e\u4e8c\u5206\u56fe\uff0c\u8be5\u95ee\u9898\u5728\u6807\u51c6\u590d\u6742\u6027\u5047\u8bbe\u4e0b\u4e0d\u5177\u6709\u591a\u9879\u5f0f\u6838\u3002", "result": "\u672c\u6587\u7684\u4e3b\u8981\u7ed3\u679c\u5305\u62ec\uff1a\n1. \u5f3a\u65e0\u51b2\u7a81\u9876\u70b9\u8fde\u63a5 $k$-\u7740\u8272\u95ee\u9898\u5728\u4ee5\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u65f6\u662f\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\u7684\uff08FPT\uff09\u3002\n2. \u5728\u6807\u51c6\u590d\u6742\u6027\u5047\u8bbe NP $\\not\\subseteq$ coNP/poly \u4e0b\uff0c\u5224\u5b9a\u4e00\u4e2a\u56fe $G$ \u662f\u5426\u5f3a\u65e0\u51b2\u7a81 3-\u53ef\u7740\u8272\u4e0d\u5177\u5907\u591a\u9879\u5f0f\u6838\uff0c\u5373\u4f7f\u5bf9\u4e8e\u4e8c\u5206\u56fe\u4e5f\u662f\u5982\u6b64\u3002\n3. \u8fd9\u4e00\u591a\u9879\u5f0f\u6838\u4e0b\u754c\u7ed3\u679c\u4e0e\u4f20\u7edf\u7684 $k$-\u7740\u8272\u95ee\u9898\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\uff0c\u4f20\u7edf\u7684 $k$-\u7740\u8272\u95ee\u9898\u5728\u4ee5\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u65f6\u5df2\u77e5\u5b58\u5728\u591a\u9879\u5f0f\u6838\u3002", "conclusion": "\u672c\u6587\u5ef6\u7eed\u4e86\u5f3a\u65e0\u51b2\u7a81\u9876\u70b9\u8fde\u63a5\u67d3\u8272\u7684\u7814\u7a76\uff0c\u8bc1\u660e\u4e86\u8be5\u95ee\u9898\u7684\u56fa\u5b9a\u53c2\u6570\u53ef\u89e3\u6027\uff0c\u5373\u5728\u4ee5\u9876\u70b9\u8986\u76d6\u6570\u4e3a\u53c2\u6570\u65f6\u662f FPT \u7684\u3002\u7136\u800c\u5728\u6807\u51c6\u590d\u6742\u6027\u5047\u8bbe\u4e0b\uff08NP $\\not\\subseteq$ coNP/poly\uff09\uff0c\u5373\u4f7f\u5bf9\u4e8e\u4e8c\u5206\u56fe\uff0c\u5224\u5b9a\u4e00\u4e2a\u56fe\u662f\u5426\u5f3a\u65e0\u51b2\u7a81 3-\u53ef\u7740\u8272\u4e0d\u5177\u5907\u591a\u9879\u5f0f\u6838\uff0c\u8fd9\u4e0e\u4f20\u7edf\u7684 $k$-\u7740\u8272\u95ee\u9898\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\u3002"}}
{"id": "2512.10980", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10980", "abs": "https://arxiv.org/abs/2512.10980", "authors": ["Akhmadillo Mamirov"], "title": "Reducing Fragmentation and Starvation in GPU Clusters through Dynamic Multi-Objective Scheduling", "comment": null, "summary": "GPU clusters have become essential for training and deploying modern AI systems, yet real deployments continue to report average utilization near 50%. This inefficiency is largely caused by fragmentation, heterogeneous workloads, and the limitations of static scheduling policies. This work presents a systematic evaluation of these issues and introduces three specialized dynamic schedulers: Hybrid Priority (HPS), Predictive Backfill (PBS), and Smart Batch (SBS). These schedulers are designed to improve utilization, fairness, and overall throughput in multi-tenant GPU clusters. We evaluate all schedulers using a controlled simulation of 1,000 AI jobs on a 64-GPU, 8-node cluster that includes a realistic mix of training, inference, and research workloads. Static baselines (FIFO, SJF, Shortest, Shortest-GPU) achieve 45 to 67% GPU utilization and 12.5 to 18.3 jobs per hour and experience severe starvation, with as many as 156 jobs waiting longer than 30 minutes. The dynamic schedulers significantly outperform these policies. HPS achieves the highest utilization (78.2%), highest throughput (25.8 jobs per hour), and the lowest fairness variance among dynamic methods (457), reducing starvation to 12 jobs. PBS improves fragmentation handling and reaches 76.1% utilization, while SBS increases efficiency for structurally similar jobs and reaches 74.6% utilization. Across all key metrics, including throughput, job wait times, fairness variance, and starvation, dynamic multi-objective schedulers consistently outperform single-objective heuristics. These results show that targeted and transparent scheduling strategies can meaningfully increase GPU efficiency in heterogeneous AI clusters and provide a practical foundation for future production scheduling frameworks.", "AI": {"tldr": "\u5173\u8054\u9886\u57df\uff1a\u56fe\u5904\u7406\uff08GPU \u96c6\u7fa4\u4e0a\u7684 AI \u8bad\u7ec3\u548c\u90e8\u7f72\uff09\u3002\n\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86 GPU \u96c6\u7fa4\u4e2d\u788e\u7247\u5316\u3001\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u548c\u9759\u6001\u8c03\u5ea6\u9650\u5236\u5bfc\u81f4\u7684\u4f4e\u5229\u7528\u7387\u95ee\u9898\u3002\u63d0\u51fa\u4e86\u4e09\u79cd\u52a8\u6001\u8c03\u5ea6\u5668\uff1a\u6df7\u5408\u4f18\u5148\u7ea7\uff08HPS\uff09\u3001\u9884\u6d4b\u56de\u586b\uff08PBS\uff09\u548c\u667a\u80fd\u6279\u5904\u7406\uff08SBS\uff09\uff0c\u65e8\u5728\u63d0\u9ad8\u591a\u79df\u6237 AI \u96c6\u7fa4\u7684\u5229\u7528\u7387\u3001\u541e\u5410\u91cf\u548c\u516c\u5e73\u6027\u3002\u5728\u4e00\u9879\u5305\u542b 1,000 \u4e2a AI \u4f5c\u4e1a\u7684\u6a21\u62df\u4e2d\uff0c\u52a8\u6001\u8c03\u5ea6\u5668\u663e\u8457\u4f18\u4e8e\u9759\u6001\u57fa\u7ebf\uff08\u5229\u7528\u7387\u4ece 45%-67% \u63d0\u9ad8\u5230 74.6%-78.2%\uff09\u3002\u5176\u4e2d HPS \u8868\u73b0\u6700\u4f73\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5229\u7528\u7387\uff0878.2%\uff09\u548c\u541e\u5410\u91cf\uff08\u6bcf\u5c0f\u65f6 25.8 \u4e2a\u4f5c\u4e1a\uff09\uff0c\u5e76\u5c06\u9965\u997f\u4f5c\u4e1a\u6570\u4ece\u6700\u591a 156 \u4e2a\u51cf\u5c11\u5230 12 \u4e2a\u3002\u7ed3\u679c\u8868\u660e\uff0c\u6709\u9488\u5bf9\u6027\u7684\u900f\u660e\u8c03\u5ea6\u7b56\u7565\u662f\u63d0\u9ad8\u5f02\u6784 AI \u96c6\u7fa4 GPU \u6548\u7387\u7684\u6709\u6548\u9014\u5f84\u3002", "motivation": "\u73b0\u4ee3 AI \u7cfb\u7edf\u8bad\u7ec3\u548c\u90e8\u7f72\u5bf9\u4e8e GPU \u96c6\u7fa4\u7684\u4f9d\u8d56\u6027\u4e0d\u65ad\u589e\u5f3a\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u7684\u5e73\u5747\u5229\u7528\u7387\u4ecd\u63a5\u8fd1 50%\u3002\u8fd9\u79cd\u4f4e\u6548\u4e3b\u8981\u662f\u7531\u788e\u7247\u5316\u3001\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u4ee5\u53ca\u9759\u6001\u8c03\u5ea6\u7b56\u7565\u7684\u5c40\u9650\u6027\u9020\u6210\u7684\u3002\u56e0\u6b64\uff0c\u9700\u8981\u65b0\u7684\u8c03\u5ea6\u7b56\u7565\u6765\u63d0\u9ad8\u591a\u79df\u6237 GPU \u96c6\u7fa4\u7684\u5229\u7528\u7387\u3001\u516c\u5e73\u6027\u548c\u603b\u4f53\u541e\u5410\u91cf\u3002", "method": "\u901a\u8fc7\u5bf9\u591a\u79df\u6237 GPU \u96c6\u7fa4\u4e0a\u5b58\u5728\u7684\u788e\u7247\u5316\u3001\u5f02\u6784\u5de5\u4f5c\u8d1f\u8f7d\u548c\u9759\u6001\u8c03\u5ea6\u9650\u5236\u7b49\u95ee\u9898\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e76\u63d0\u51fa\u4e09\u79cd\u4e13\u95e8\u7684\u52a8\u6001\u8c03\u5ea6\u5668\uff1a\u6df7\u5408\u4f18\u5148\u7ea7\u8c03\u5ea6\u5668\uff08HPS\uff09\u3001\u9884\u6d4b\u56de\u586b\u8c03\u5ea6\u5668\uff08PBS\uff09\u548c\u667a\u80fd\u6279\u5904\u7406\u8c03\u5ea6\u5668\uff08SBS\uff09\u3002\u4f7f\u7528\u5305\u542b\u8bad\u7ec3\u3001\u63a8\u7406\u548c\u7814\u7a76\u5de5\u4f5c\u8d1f\u8f7d\u7684 1,000 \u4e2a AI \u4f5c\u4e1a\uff0c\u5728 64-GPU\u30018 \u8282\u70b9\u96c6\u7fa4\u7684\u53d7\u63a7\u6a21\u62df\u4e2d\u8bc4\u4f30\u6240\u6709\u8c03\u5ea6\u5668\u3002", "result": "\u9759\u6001\u57fa\u7ebf\uff08FIFO\u3001SJF\u3001Shortest\u3001Shortest-GPU\uff09\u7684 GPU \u5229\u7528\u7387\u4e3a 45% \u81f3 67%\uff0c\u6bcf\u5c0f\u65f6\u5904\u7406 12.5 \u81f3 18.3 \u4e2a\u4f5c\u4e1a\uff0c\u5e76\u7ecf\u5386\u4e25\u91cd\u7684\u9965\u997f\u73b0\u8c61\uff08\u591a\u8fbe 156 \u4e2a\u4f5c\u4e1a\u7b49\u5f85\u8d85\u8fc7 30 \u5206\u949f\uff09\u3002\n\u52a8\u6001\u8c03\u5ea6\u5668\u663e\u8457\u4f18\u4e8e\u8fd9\u4e9b\u7b56\u7565\uff1a\n1. **HPS** \u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5229\u7528\u7387\uff0878.2%\uff09\u3001\u6700\u9ad8\u7684\u541e\u5410\u91cf\uff08\u6bcf\u5c0f\u65f6 25.8 \u4e2a\u4f5c\u4e1a\uff09\u548c\u52a8\u6001\u65b9\u6cd5\u4e2d\u6700\u4f4e\u7684\u516c\u5e73\u6027\u65b9\u5dee\uff08457\uff09\uff0c\u5c06\u9965\u997f\u4f5c\u4e1a\u6570\u51cf\u5c11\u5230 12 \u4e2a\u3002\n2. **PBS** \u6539\u5584\u4e86\u788e\u7247\u5316\u5904\u7406\uff0c\u8fbe\u5230\u4e86 76.1% \u7684\u5229\u7528\u7387\u3002\n3. **SBS** \u63d0\u9ad8\u4e86\u7ed3\u6784\u76f8\u4f3c\u4f5c\u4e1a\u7684\u6548\u7387\uff0c\u8fbe\u5230\u4e86 74.6% \u7684\u5229\u7528\u7387\u3002", "conclusion": "\u52a8\u6001\u591a\u76ee\u6807\u8c03\u5ea6\u5668\u5728\u541e\u5410\u91cf\u3001\u4f5c\u4e1a\u7b49\u5f85\u65f6\u95f4\u3001\u516c\u5e73\u6027\u65b9\u5dee\u548c\u9965\u997f\u7b49\u6240\u6709\u5173\u952e\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5355\u76ee\u6807\u542f\u53d1\u5f0f\u65b9\u6cd5\u3002\u6240\u4ecb\u7ecd\u7684\u9488\u5bf9\u6027\u4e14\u900f\u660e\u7684\u8c03\u5ea6\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5f02\u6784 AI \u96c6\u7fa4\u4e2d\u7684 GPU \u6548\u7387\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u751f\u4ea7\u8c03\u5ea6\u6846\u67b6\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2512.10987", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.10987", "abs": "https://arxiv.org/abs/2512.10987", "authors": ["Sumit Chongder"], "title": "Evaluation Framework for Centralized and Decentralized Aggregation Algorithm in Federated Systems", "comment": "13 pages, 14 figures, 2 tables", "summary": "In recent years, the landscape of federated learning has witnessed significant advancements, particularly in decentralized methodologies. This research paper presents a comprehensive comparison of Centralized Hierarchical Federated Learning (HFL) with Decentralized Aggregated Federated Learning (AFL) and Decentralized Continual Federated Learning (CFL) architectures. While HFL, in its centralized approach, faces challenges such as communication bottlenecks and privacy concerns due to centralized data aggregation, AFL and CFL provide promising alternatives by distributing computation and aggregation processes across devices. Through evaluation of Fashion MNIST and MNIST datasets, this study demonstrates the advantages of decentralized methodologies, showcasing how AFL and CFL outperform HFL in precision, recall, F1 score, and balanced accuracy. The analysis highlights the importance of decentralized aggregation mechanisms in AFL and CFL, which effectively enables collaborative model training across distributed devices. This comparative study contributes valuable insights into the evolving landscape of federated learning, guiding researchers and practitioners towards decentralized methodologies for enhanced performance in collaborative model training scenarios.", "AI": {"tldr": "\u8fd9\u4e2a\u8bba\u6587\u4e0eDSL\u6216\u56fe\u5904\u7406\u6216MLIR\u6216\u7f16\u8bd1\u5668\u6216HLS\u5747\u4e0d\u76f8\u5173\u3002\n\u8fd9\u4e2a\u7814\u7a76\u6bd4\u8f83\u4e86\u96c6\u4e2d\u5f0f\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff08HFL\uff09\u548c\u4e24\u79cd\u5206\u6563\u5f0f\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff08AFL\u548cCFL\uff09\u3002\u7ed3\u679c\u663e\u793a\uff0c\u5206\u6563\u5f0f\u65b9\u6cd5\uff08AFL\u548cCFL\uff09\u5728Fashion MNIST\u548cMNIST\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\uff0c\u5305\u62ec\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548c\u5e73\u8861\u51c6\u786e\u7387\uff0c\u5747\u4f18\u4e8e\u96c6\u4e2d\u5f0fHFL\uff0c\u8868\u660e\u5206\u6563\u5f0f\u805a\u5408\u673a\u5236\u5bf9\u4e8e\u589e\u5f3a\u534f\u540c\u6a21\u578b\u8bad\u7ec3\u7684\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002", "motivation": "\u8054\u90a6\u5b66\u4e60\u9886\u57df\u8fd1\u5e74\u6765\u5728\u53bb\u4e2d\u5fc3\u5316\u65b9\u6cd5\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002\u96c6\u4e2d\u5f0f\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff08HFL\uff09\u9762\u4e34\u901a\u4fe1\u74f6\u9888\u548c\u96c6\u4e2d\u5f0f\u6570\u636e\u805a\u5408\u5e26\u6765\u7684\u9690\u79c1\u95ee\u9898\u7b49\u6311\u6218\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u7684\u52a8\u673a\u662f\u63a2\u8ba8\u5206\u6563\u5f0f\u65b9\u6cd5\uff0c\u5982\u5206\u6563\u5f0f\u805a\u5408\u8054\u90a6\u5b66\u4e60\uff08AFL\uff09\u548c\u5206\u6563\u5f0f\u6301\u7eed\u8054\u90a6\u5b66\u4e60\uff08CFL\uff09\uff0c\u4f5c\u4e3aHFL\u7684\u53ef\u884c\u4e14\u6709\u524d\u666f\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u65e8\u5728\u901a\u8fc7\u6bd4\u8f83\u8bc4\u4f30\u6765\u8bc1\u660e\u5206\u6563\u5f0f\u65b9\u6cd5\u7684\u4f18\u52bf\uff0c\u4ece\u800c\u4fc3\u8fdb\u5206\u5e03\u5f0f\u8bbe\u5907\u4e0a\u7684\u534f\u540c\u6a21\u578b\u8bad\u7ec3\u3002", "method": "\u672c\u6587\u91c7\u7528\u6bd4\u8f83\u7814\u7a76\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728Fashion MNIST\u548cMNIST\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u4e09\u79cd\u4e0d\u540c\u7684\u8054\u90a6\u5b66\u4e60\u67b6\u6784\uff1a\u96c6\u4e2d\u5f0fHFL\u3001\u5206\u6563\u5f0fAFL\u548c\u5206\u6563\u5f0fCFL\u3002\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u7cbe\u786e\u5ea6\uff08precision\uff09\u3001\u53ec\u56de\u7387\uff08recall\uff09\u3001F1\u5206\u6570\u548c\u5e73\u8861\u51c6\u786e\u7387\uff08balanced accuracy\uff09\u3002\u901a\u8fc7\u8fd9\u4e9b\u8bc4\u4f30\uff0c\u7814\u7a76\u4eba\u5458\u5206\u6790\u4e86\u5206\u6563\u5f0f\u805a\u5408\u673a\u5236\u5728AFL\u548cCFL\u4e2d\u7684\u91cd\u8981\u6027\u53ca\u5176\u5bf9\u6027\u80fd\u7684\u8d21\u732e\u3002", "result": "\u901a\u8fc7\u5728Fashion MNIST\u548cMNIST\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\uff0c\u7814\u7a76\u7ed3\u679c\u8868\u660e\u5206\u6563\u5f0f\u65b9\u6cd5\uff08AFL\u548cCFL\uff09\u5728\u7cbe\u786e\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\u548c\u5e73\u8861\u51c6\u786e\u7387\u7b49\u65b9\u9762\u5747\u4f18\u4e8e\u96c6\u4e2d\u5f0fHFL\u3002\u8fd9\u8bc1\u660e\u4e86\u5206\u6563\u5f0f\u805a\u5408\u673a\u5236\u5728\u6709\u6548\u5730\u5b9e\u73b0\u5206\u5e03\u5f0f\u8bbe\u5907\u4e0a\u7684\u534f\u540c\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8fd9\u7bc7\u7814\u7a76\u8bba\u6587\u901a\u8fc7\u6bd4\u8f83\u96c6\u4e2d\u5f0f\u5206\u5c42\u8054\u90a6\u5b66\u4e60\uff08HFL\uff09\u4e0e\u5206\u6563\u5f0f\u805a\u5408\u8054\u90a6\u5b66\u4e60\uff08AFL\uff09\u548c\u5206\u6563\u5f0f\u6301\u7eed\u8054\u90a6\u5b66\u4e60\uff08CFL\uff09\u67b6\u6784\uff0c\u5f97\u51fa\u4e86\u5206\u6563\u5f0f\u65b9\u6cd5\uff08AFL\u548cCFL\uff09\u5728\u8054\u90a6\u5b66\u4e60\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u96c6\u4e2d\u5f0f\u65b9\u6cd5\uff08HFL\uff09\u7684\u6027\u80fd\u3002\u7814\u7a76\u7ed3\u679c\u6307\u5bfc\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u8f6c\u5411\u5206\u6563\u5f0f\u65b9\u6cd5\uff0c\u4ee5\u5728\u534f\u540c\u6a21\u578b\u8bad\u7ec3\u573a\u666f\u4e2d\u83b7\u5f97\u66f4\u9ad8\u7684\u6027\u80fd\u3002"}}
{"id": "2512.11306", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.11306", "abs": "https://arxiv.org/abs/2512.11306", "authors": ["Tianyuan Wu", "Lunxi Cao", "Yining Wei", "Wei Gao", "Yuheng Zhao", "Dakai An", "Shaopan Xiong", "Zhiqiang Lv", "Ju Huang", "Siran Yang", "Yinghao Yu", "Jiamang Wang", "Lin Qu", "Wei Wang"], "title": "RollMux: Phase-Level Multiplexing for Disaggregated RL Post-Training", "comment": "17 pages, 15 figures", "summary": "Rollout-training disaggregation is emerging as the standard architecture for Reinforcement Learning (RL) post-training, where memory-bound rollout and compute-bound training are physically disaggregated onto purpose-built clusters to maximize hardware efficiency. However, the strict synchronization required by on-policy algorithms introduces severe dependency bubbles, forcing one cluster to idle while the dependent phase is running on the other. We present RollMux, a cluster scheduling framework that reclaims these bubbles through cross-cluster orchestration. RollMux is built on the insight that the structural idleness of one job can be effectively utilized by the active phase of another. To realize this, we introduce the co-execution group abstraction, which partitions the cluster into isolated locality domains. This abstraction enables a two-tier scheduling architecture: an inter-group scheduler that optimizes job placement using conservative stochastic planning, and an intra-group scheduler that orchestrates a provably optimal round-robin schedule. The group abstraction also imposes a residency constraint, ensuring that massive model states remain cached in host memory to enable \"warm-star\" context switching. We evaluate RollMux on a production-scale testbed with 328 H20 and 328 H800 GPUs. RollMux improves cost efficiency by 1.84x over standard disaggregation and 1.38x over state-of-the-art co-located baselines, all while achieving 100% SLO attainment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e **Graph Processing**\u3001**MLIR**\u3001**DSL**\u3001**HLS** \u65e0\u76f4\u63a5\u5173\u7cfb\u3002\u5b83\u4e0e **Compiler\uff08\u7f16\u8bd1\u5668\uff09** \u548c **HLS** \u9886\u57df\u6709\u95f4\u63a5\u8054\u7cfb\uff0c\u56e0\u4e3a\u5b83\u4eec\u90fd\u5173\u6ce8\u7cfb\u7edf\u548c\u786c\u4ef6\u8d44\u6e90\u8c03\u5ea6\u4e0e\u4f18\u5316\uff0c\u4f46 RollMux \u4fa7\u91cd\u4e8e**\u5206\u5e03\u5f0f\u96c6\u7fa4\u8c03\u5ea6**\u548c**\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7cfb\u7edf**\u4f18\u5316\u3002\n\n**\u592a\u957f\u4e0d\u8bfb (TLDR)\uff1a** \u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u91c7\u6837-\u8bad\u7ec3\u5206\u79bb\u67b6\u6784\u56e0\u4e25\u683c\u540c\u6b65\u800c\u5bfc\u81f4\u96c6\u7fa4\u4e25\u91cd\u7a7a\u95f2\u3002RollMux \u662f\u4e00\u79cd\u8de8\u96c6\u7fa4\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u5141\u8bb8\u975e\u4f9d\u8d56\u4f5c\u4e1a\u5229\u7528\u8fd9\u4e9b\u7a7a\u95f2\u65f6\u95f4\u6765\u6062\u590d\u6548\u7387\u3002\u5b83\u5f15\u5165\u4e86\u201c\u534f\u540c\u6267\u884c\u7ec4\u201d\u548c\u4e24\u5c42\u8c03\u5ea6\uff0c\u5e76\u5229\u7528\u5185\u5b58\u9a7b\u7559\u5b9e\u73b0\u5feb\u901f\u4e0a\u4e0b\u6587\u5207\u6362\u3002\u5728\u751f\u4ea7\u89c4\u6a21\u7684 GPU \u96c6\u7fa4\u4e0a\uff0cRollMux \u5c06\u6210\u672c\u6548\u7387\u63d0\u9ad8\u4e86 1.84 \u500d\uff08\u76f8\u5bf9\u4e8e\u6807\u51c6\u5206\u79bb\uff09\u548c 1.38 \u500d\uff08\u76f8\u5bf9\u4e8e\u5148\u8fdb\u5171\u7f6e\u57fa\u7ebf\uff09\uff0c\u5e76\u5b9e\u73b0\u4e86 100% \u7684\u670d\u52a1\u7b49\u7ea7\u76ee\u6807\u3002", "motivation": "\u73b0\u6709\u7684 Reinforcement Learning (RL) \u540e\u8bad\u7ec3\u6807\u51c6\u67b6\u6784\u662f\u201crollout-training disaggregation\u201d\uff08\u91c7\u6837-\u8bad\u7ec3\u5206\u79bb\uff09\uff0c\u5c06\u5185\u5b58\u5bc6\u96c6\u578b\u7684 rollout \u9636\u6bb5\u548c\u8ba1\u7b97\u5bc6\u96c6\u578b\u7684 training \u9636\u6bb5\u5206\u522b\u90e8\u7f72\u5230\u4e13\u95e8\u7684\u96c6\u7fa4\u4ee5\u6700\u5927\u5316\u786c\u4ef6\u6548\u7387\u3002\u7136\u800c\uff0con-policy \u7b97\u6cd5\u8981\u6c42\u7684\u4e25\u683c\u540c\u6b65\u4f1a\u5f15\u5165\u4e25\u91cd\u7684\u201cdependency bubbles\u201d\uff08\u4f9d\u8d56\u6c14\u6ce1\uff09\uff0c\u5bfc\u81f4\u4e00\u4e2a\u96c6\u7fa4\u5728\u7b49\u5f85\u53e6\u4e00\u4e2a\u96c6\u7fa4\u8fd0\u884c\u4f9d\u8d56\u9636\u6bb5\u65f6\u5904\u4e8e\u7a7a\u95f2\u72b6\u6001\uff0c\u6781\u5927\u5730\u964d\u4f4e\u4e86\u786c\u4ef6\u5229\u7528\u7387\u548c\u6210\u672c\u6548\u7387\u3002\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u8bbe\u8ba1\u4e00\u4e2a\u96c6\u7fa4\u8c03\u5ea6\u6846\u67b6\u6765\u91cd\u65b0\u5229\u7528\u8fd9\u4e9b\u7a7a\u95f2\u65f6\u95f4\uff0c\u4ece\u800c\u63d0\u5347 RL \u8bad\u7ec3\u7684\u6210\u672c\u6548\u7387\u548c\u786c\u4ef6\u5229\u7528\u7387\u3002", "method": "RollMux \u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u96c6\u7fa4\u7684\u8c03\u5ea6\u6846\u67b6\uff0c\u65e8\u5728\u56de\u6536\u56e0 on-policy RL \u7b97\u6cd5\u4e2d\u5185\u5b58\u5bc6\u96c6\u578b \"rollout\" \u548c\u8ba1\u7b97\u5bc6\u96c6\u578b \"training\" \u9636\u6bb5\u4e25\u683c\u540c\u6b65\u800c\u5bfc\u81f4\u7684\u96c6\u7fa4\u7a7a\u95f2\u65f6\u95f4\uff08\u4f9d\u8d56\u6c14\u6ce1\uff09\u3002\u5176\u6838\u5fc3\u65b9\u6cd5\u5305\u62ec\uff1a1. \u63d0\u51fa\u201cco-execution group\u201d\uff08\u534f\u540c\u6267\u884c\u7ec4\uff09\u62bd\u8c61\uff0c\u5c06\u96c6\u7fa4\u5212\u5206\u4e3a\u9694\u79bb\u7684\u5c40\u90e8\u6027\u57df\u30022. \u57fa\u4e8e\u8be5\u62bd\u8c61\u6784\u5efa\u4e24\u5c42\u8c03\u5ea6\u67b6\u6784\uff1a\u4e00\u4e2a**\u7ec4\u95f4\u8c03\u5ea6\u5668**\u4f7f\u7528\u4fdd\u5b88\u968f\u673a\u89c4\u5212\u4f18\u5316\u4f5c\u4e1a\u653e\u7f6e\uff1b\u4e00\u4e2a**\u7ec4\u5185\u8c03\u5ea6\u5668**\u91c7\u7528\u53ef\u8bc1\u660e\u6700\u4f18\u7684\u8f6e\u8be2\u8c03\u5ea6\u30023. \u5f3a\u5236\u5b9e\u65bd\u201cresidency constraint\u201d\uff08\u9a7b\u7559\u7ea6\u675f\uff09\uff0c\u786e\u4fdd\u6a21\u578b\u72b6\u6001\u7f13\u5b58\u4e8e\u4e3b\u673a\u5185\u5b58\uff0c\u5b9e\u73b0\u201cwarm-star\u201d\u4e0a\u4e0b\u6587\u5207\u6362\uff0c\u4ee5\u6700\u5c0f\u5316\u4f5c\u4e1a\u5207\u6362\u5f00\u9500\u3002", "result": "\u901a\u8fc7\u5728\u5305\u542b 328 \u5757 H20 \u548c 328 \u5757 H800 GPU \u7684\u751f\u4ea7\u89c4\u6a21\u6d4b\u8bd5\u5e73\u53f0\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cRollMux \u76f8\u8f83\u4e8e\u6807\u51c6\u5206\u79bb\u67b6\u6784\uff0c\u6210\u672c\u6548\u7387\u63d0\u9ad8\u4e86 1.84 \u500d\uff1b\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u7684\u5171\u7f6e\u57fa\u7ebf\uff0c\u6210\u672c\u6548\u7387\u63d0\u9ad8\u4e86 1.38 \u500d\uff1b\u540c\u65f6\u8fbe\u5230\u4e86 100% \u7684\u670d\u52a1\u7b49\u7ea7\u76ee\u6807\uff08SLO\uff09\u9075\u5faa\u7387\u3002", "conclusion": "RollMux is a cluster scheduling framework that reclaims the idle time (dependency bubbles) caused by the strict synchronization between the memory-bound rollout and compute-bound training phases in disaggregated on-policy RL structures, thereby improving hardware utilization and cost efficiency. The key innovations are the co-execution group abstraction, two-tier scheduling architecture, and the residency constraint (warm-star context switching). Evaluation on a production-scale testbed shows that RollMux achieves 1.84x better cost efficiency than standard disaggregation and 1.38x better than state-of-the-art co-located baselines, with 100% SLO attainment."}}
{"id": "2512.11727", "categories": ["cs.DC", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.11727", "abs": "https://arxiv.org/abs/2512.11727", "authors": ["Yuze He", "Ferdi Kossmann", "Srinivasan Seshan", "Peter Steenkiste"], "title": "ECCO: Leveraging Cross-Camera Correlations for Efficient Live Video Continuous Learning", "comment": null, "summary": "Recent advances in video analytics address real-time data drift by continuously retraining specialized, lightweight DNN models for individual cameras. However, the current practice of retraining a separate model for each camera suffers from high compute and communication costs, making it unscalable. We present ECCO, a new video analytics framework designed for resource-efficient continuous learning. The key insight is that the data drift, which necessitates model retraining, often shows temporal and spatial correlations across nearby cameras. By identifying cameras that experience similar drift and retraining a shared model for them, ECCO can substantially reduce the associated compute and communication costs. Specifically, ECCO introduces: (i) a lightweight grouping algorithm that dynamically forms and updates camera groups; (ii) a GPU allocator that dynamically assigns GPU resources across different groups to improve retraining accuracy and ensure fairness; and (iii) a transmission controller at each camera that configures frame sampling and coordinates bandwidth sharing with other cameras based on its assigned GPU resources. We conducted extensive evaluations on three distinctive datasets for two vision tasks. Compared to leading baselines, ECCO improves retraining accuracy by 6.7%-18.1% using the same compute and communication resources, or supports 3.3 times more concurrent cameras at the same accuracy.", "AI": {"tldr": "\u8fd9\u4e2a\u8bba\u6587\u4e0e\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u65e0\u5173\uff0c\u4f46\u4e0e**DSL\uff08\u7279\u5b9a\u9886\u57df\u8bed\u8a00\uff09**\u548c**\u7f16\u8bd1\u5668**\u9886\u57df\u6709\u6240\u5173\u8054\uff0c\u5982\u679c\u5c06**\u89c6\u9891\u5206\u6790\u6846\u67b6**\u89c6\u4e3a\u4e00\u4e2a**\u7279\u5b9a\u9886\u57df\u7684\u7cfb\u7edf\u6216\u4e2d\u95f4\u8868\u793a\u5c42**\u6765\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\u548c\u6a21\u578b\u91cd\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u5c24\u5176\u662f\u5176\u4e2d\u6d89\u53ca\u7684\u8d44\u6e90\u7ba1\u7406\u548c\u8c03\u5ea6\u7b56\u7565\uff0c\u53ef\u80fd\u7275\u6d89\u5230\u7279\u5b9a\u9886\u57df\u7684\u4f18\u5316\u6216\u914d\u7f6e\u8bed\u8a00\u3002\u4f46\u66f4\u76f4\u63a5\u6e05\u6670\u7684\u5173\u8054\u662f\u4e0e**\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf\u4f18\u5316**\u548c**\u8d44\u6e90\u7ba1\u7406**\u76f8\u5173\u3002\nToo long; didn't read: \u9488\u5bf9\u89c6\u9891\u5206\u6790\u4e2d\u6bcf\u4e2a\u6444\u50cf\u5934\u5355\u72ec\u91cd\u8bad\u7ec3\u6a21\u578b\u4ee5\u5e94\u5bf9\u6570\u636e\u6f02\u79fb\u5bfc\u81f4\u7684\u9ad8\u6210\u672c\u95ee\u9898\uff0cECCO\u63d0\u51fa\u4e86\u4e00\u4e2a\u8d44\u6e90\u9ad8\u6548\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6\u3002\u5b83\u901a\u8fc7\u8bc6\u522b\u6570\u636e\u6f02\u79fb\u76f8\u4f3c\u7684\u6444\u50cf\u5934\u5e76\u5c06\u5b83\u4eec\u5206\u7ec4\u5171\u4eab\u6a21\u578b\u91cd\u8bad\u7ec3\uff0c\u7ed3\u5408\u52a8\u6001\u5206\u7ec4\u7b97\u6cd5\u3001GPU\u8d44\u6e90\u5206\u914d\u5668\u548c\u4f20\u8f93\u63a7\u5236\u5668\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u901a\u4fe1\u5f00\u9500\uff0c\u5e76\u5728\u76f8\u540c\u8d44\u6e90\u4e0b\u63d0\u9ad8\u4e86\u91cd\u8bad\u7ec3\u51c6\u786e\u6027\u6216\u652f\u6301\u4e86\u66f4\u591a\u7684\u5e76\u53d1\u6444\u50cf\u5934\u3002", "motivation": "\u73b0\u6709\u7684\u9488\u5bf9\u6bcf\u4e2a\u6444\u50cf\u5934\u5355\u72ec\u91cd\u8bad\u7ec3\u6a21\u578b\u7684\u505a\u6cd5\uff0c\u7531\u4e8e\u8ba1\u7b97\u548c\u901a\u4fe1\u6210\u672c\u9ad8\u6602\uff0c\u96be\u4ee5\u6269\u5c55\uff0c\u800c\u6570\u636e\u6f02\u79fb\u901a\u5e38\u5728\u76f8\u90bb\u6444\u50cf\u5934\u95f4\u5b58\u5728\u65f6\u7a7a\u76f8\u5173\u6027\u3002", "method": "ECCO\u63d0\u51fa\uff1a\uff08i\uff09\u8f7b\u91cf\u7ea7\u5206\u7ec4\u7b97\u6cd5\uff0c\u52a8\u6001\u5f62\u6210\u548c\u66f4\u65b0\u6444\u50cf\u5934\u7ec4\uff1b\uff08ii\uff09GPU\u5206\u914d\u5668\uff0c\u52a8\u6001\u5206\u914dGPU\u8d44\u6e90\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u786e\u4fdd\u516c\u5e73\u6027\uff1b\uff08iii\uff09\u4f20\u8f93\u63a7\u5236\u5668\uff0c\u5728\u6bcf\u4e2a\u6444\u50cf\u5934\u914d\u7f6e\u5e27\u91c7\u6837\u5e76\u6839\u636e\u5206\u914d\u7684GPU\u8d44\u6e90\u534f\u8c03\u5e26\u5bbd\u5171\u4eab\u3002", "result": "\u4e0e\u4e3b\u6d41\u57fa\u7ebf\u76f8\u6bd4\uff0cECCO\u5728\u76f8\u540c\u8ba1\u7b97\u548c\u901a\u4fe1\u8d44\u6e90\u4e0b\uff0c\u91cd\u8bad\u7ec3\u51c6\u786e\u7387\u63d0\u9ad8\u4e866.7%-18.1%\uff0c\u6216\u5728\u76f8\u540c\u51c6\u786e\u7387\u4e0b\u652f\u6301\u4e863.3\u500d\u7684\u5e76\u53d1\u6444\u50cf\u5934\u3002", "conclusion": "ECCO\u901a\u8fc7\u5229\u7528\u76f8\u90bb\u6444\u50cf\u5934\u6570\u636e\u6f02\u79fb\u7684\u65f6\u7a7a\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u9ad8\u6548\u7684\u6301\u7eed\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u91cd\u8bad\u7ec3\u51c6\u786e\u6027\u6216\u652f\u6301\u4e86\u66f4\u591a\u5e76\u53d1\u6444\u50cf\u5934\u3002"}}
