<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 5]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.AR](#cs.AR) [Total: 4]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [On the Complexity of Signed Roman Domination](https://arxiv.org/abs/2512.02083)
*Sangam Balchandar Reddy*

Main category: cs.DS

TL;DR: 该论文与图处理相关。
太长不看版：带符号罗马支配（SRD）问题是一个图论优化问题，旨在找到最小权重的带符号罗马支配函数。本文证明了 SRD 问题在分裂图上仍是 NP-完全的，并在参数化复杂性方面取得了系列结果：以权重为参数是 W[2]-hard（在二分图上），以反馈点集数为参数是 W[1]-hard。同时，提出一个以邻域多样性（和点覆盖数）为参数的 FPT 算法，并证明了以点覆盖数为参数不存在多项式核（除非 coNP $\subseteq$ NP/poly）。


<details>
  <summary>Details</summary>
Motivation: 带符号罗马支配（SRD）问题是一个已知的 NP-完全问题，即使在二分图和平面图上也是如此。本文的动机是深入探究这个问题的计算复杂性，特别是在更具限制性的图类上（如分裂图）的经典复杂性，并从参数化复杂性的角度，理解不同图结构参数对问题可解性的影响，以期找到在某些参数下可高效求解的方法（FPT）或证明其内在的困难性（W-hard）。

Method: 本文主要采用复杂性理论和图算法设计的方法。首先，通过归约证明了带符号罗马支配函数问题在分裂图上的 NP-完全性。接着，应用参数化复杂性理论，通过设计规约或展示硬度证明，来研究问题在不同结构参数下的复杂性，例如权重、反馈点集数、树宽、邻域多样性、点覆盖数等。具体包括证明 W[2]-hard 和 W[1]-hard，以及设计 FPT 算法。最后，利用核化理论证明了不存在多项式核的结果。

Result: 本文在理论复杂性方面取得了多项重要结果：1. 证明了 SRD 问题在分裂图上仍然是 NP-完全的。2. 在参数化复杂性方面，证明了在二分图上以目标权重为参数，问题是 W[2]-hard 的。3. 证明了以反馈点集数（因此也包括树宽和团宽）为参数，问题是 W[1]-hard 的。4. 在积极方面，提出了一个以邻域多样性（以及点覆盖数）为参数的 FPT 算法。5. 证明了该问题不存在以点覆盖数为参数的多项式核，除非 coNP $\subseteq$ NP/poly。

Conclusion: 本文研究了带符号罗马支配函数（Signed Roman Dominating Function, SRDF）问题，确定了该问题在分裂图上仍然是 NP-完全的。在参数化复杂性方面，证明了该问题在二分图上以目标权重为参数是 W[2]-hard 的，以反馈点集、树宽或团宽为参数是 W[1]-hard 的。同时，在正面上，提出了一个以邻域多样性（以及点覆盖数）为参数的 FPT 算法。最后，通过证明该问题不存在以点覆盖数为参数的多项式核（除非 coNP $\subseteq$ NP/poly），完善了结果。这些结果全面地探讨了 SRD 问题的计算复杂性，无论是在经典复杂性还是参数化复杂性方面。

Abstract: Given a graph $G = (V, E)$, a signed Roman dominating function is a function $f: V \rightarrow \{-1, 1, 2\}$ such that for every vertex $u \in V$: $\sum_{v \in N[u]} f(v) \geq 1$ and for every vertex $u \in V$ with $f(u) = -1$, there exists a vertex $v \in N(u)$ with $f(v) = 2$. The weight of a signed Roman dominating function $f$ is $\sum_{u \in V} f(u)$. The objective of \srd{} (SRD) problem is to compute a signed Roman dominating function with minimum weight. The problem is known to be NP-complete even when restricted to bipartite graphs and planar graphs. In this paper, we advance the complexity study by showing that the problem remains NP-complete on split graphs. In the realm of parameterized complexity, we prove that the problem is W[2]-hard parameterized by weight, even on bipartite graphs. We further show that the problem is W[1]-hard parameterized by feedback vertex set number (and hence also when parameterized by treewidth or clique-width). On the positive side, we present an FPT algorithm parameterized by neighbourhood diversity (and by vertex cover number). Finally, we complement this result by proving that the problem does not admit a polynomial kernel parameterized by vertex cover number unless coNP $\subseteq$ NP/poly.

</details>


### [2] [Markov Chains Approximate Message Passing](https://arxiv.org/abs/2512.02384)
*Amit Rajaraman,David X. Wu*

Main category: cs.DS

TL;DR: 该论文与 DSL、图处理、MLIR、编译器或 HLS 无关。

尽管马尔可夫链蒙特卡洛（MCMC）算法在贝叶斯推断中表现出近乎最优的性能，但其理论支持仍具挑战。本文研究了棘波维格纳推断问题，将退火后验上的 Glauber 动力学恢复性能与贝叶斯最优的近似消息传递（AMP）算法联系起来。通过分析辅助的受限高斯动力学（RGD），研究证明 RGD 可简化为反映 AMP 演化的一维递归，并能从暖启动快速收敛到不动点以恢复贝叶斯最优性能。此外，在 SK 模型混合结果的条件下，本文恢复了非平凡推断的相变。


<details>
  <summary>Details</summary>
Motivation: 马尔可夫链蒙特卡洛（MCMC）算法在各种贝叶斯推断设置中被观察到接近最优性能，但缺乏严谨的理论支持来证实这些观察结果，这激发了本文的研究。本文旨在通过理论分析棘波维格纳推断问题中 Glauber 动力学的恢复性能，并将其与已知的贝叶斯最优算法（AMP）联系起来，以提供 MCMC 性能的理论依据。

Method: 本文通过研究经典棘波维格纳推断问题，将 Glauber 动力学在退火后验上的恢复性能与近似消息传递（AMP）算法的性能联系起来。核心方法是分析一个称为受限高斯动力学（RGD）的辅助马尔可夫链。具体包括：1. 证明 RGD 可简化为反映 AMP 迭代演化的一维递归。2. 证明 RGD 从暖启动开始能快速收敛到相关性空间中的不动点。3. 在 SK 模型混合结果的假设下，分析了非平凡推断的相变。

Result: 本文取得了以下结果：1. 受限高斯动力学（RGD）可以简化为一个有效的一维递归，该递归反映了近似消息传递（AMP）迭代的演化。2. 从“暖启动”开始，RGD 能在相关性空间中迅速收敛到一个不动点，这在应用于后验时恢复了贝叶斯最优性能。3. 假设 SK 模型广泛接受的混合结果成立，本文恢复了非平凡推断的相变。

Conclusion: 本文研究了 Glauber 动力学在退火后验上的恢复性能，并将其与已知能达到贝叶斯最优性能的近似消息传递（AMP）算法的性能联系起来。研究表明，辅助的受限高斯动力学（RGD）可以简化为反映 AMP 迭代演化的一维递归，并且 RGD 从“暖启动”开始能快速收敛到相关性空间中的不动点，从而恢复贝叶斯最优性能。在假设 SK 模型混合结果成立的条件下，还能恢复出非平凡推断的相变。这些结果为理解 MCMC 算法在贝叶斯推断中的近乎最优性能提供了理论支持。

Abstract: Markov chain Monte Carlo algorithms have long been observed to obtain near-optimal performance in various Bayesian inference settings. However, developing a supporting theory that make these studies rigorous has proved challenging.
  In this paper, we study the classical spiked Wigner inference problem, where one aims to recover a planted Boolean spike from a noisy matrix measurement. We relate the recovery performance of Glauber dynamics on the annealed posterior to the performance of Approximate Message Passing (AMP), which is known to achieve Bayes-optimal performance. Our main results rely on the analysis of an auxiliary Markov chain called restricted Gaussian dynamics (RGD). Concretely, we establish the following results:
  1. RGD can be reduced to an effective one-dimensional recursion which mirrors the evolution of the AMP iterates.
  2. From a warm start, RGD rapidly converges to a fixed point in correlation space, which recovers Bayes-optimal performance when run on the posterior.
  3. Conditioned on widely believed mixing results for the SK model, we recover the phase transition for non-trivial inference.

</details>


### [3] [New Bounds for Circular Trace Reconstruction](https://arxiv.org/abs/2512.02412)
*Arnav Burudgunte,Paul Valiant,Hongao Wang*

Main category: cs.DS

TL;DR: 关联领域：无。
太长不读：轨迹重构是给定一个未知二进制字符串 $x$，通过一个通道重复返回 $x$ 的“轨迹”来恢复 $x$，其中 $x$ 的每个位都以一定概率被随机删除，问需要多少条轨迹？最佳已知上界和下界之间存在巨大的指数级差距。本文研究了圆周轨迹重构变体，其中轨迹除了随机删除外，还会经历一个随机循环移位。我们证明了圆周轨迹重构的改进下界为 $\tilde{\Omega}(n^5)$，超过了此前最佳的线性情况下的 $\tilde{\Omega}(n^{3/2})$ 和圆周情况下的 $\tilde{\Omega}(n^3)$。该下界是通过构建两对常量数量非零元素的稀疏字符串 $x, y$ 的轨迹无法区分来证明的。我们还解决了稀疏字符串在循环删除通道下的重构难度，利用傅里叶技术证明了重构任意常数稀疏字符串仅需 $\tilde{O}(n^6)$ 条轨迹，远低于一般字符串在圆周删除通道中的指数级上界 $\exp(\tilde{O}(n^{1/3}))$。这表明新的算法或新的下界必须关注非稀疏的字符串。


<details>
  <summary>Details</summary>
Motivation: “轨迹重构”问题中，已知最佳上界和下界之间存在指数级的差距。圆周轨迹重构是该问题的一个变体，通过引入随机循环移位和随机删除，希望能激发或揭示缩小这一差距的新方法。本文旨在改进圆周轨迹重构问题的已知下界，并探讨稀疏字符串在循环删除通道下的重构难度。

Method: 本文采用构建不易区分的稀疏字符串对的方法来证明圆周轨迹重构的改进下界 $\tilde{\Omega}(n^5)$。对于稀疏字符串的重构上界 $\tilde{O}(n^6)$，本文使用了傅里叶技术进行证明。

Result: 本文将圆周轨迹重构的下界改进至 $\tilde{\Omega}(n^5)$，而此前已知的最佳下界在线性情况下为 $\tilde{\Omega}(n^{3/2})$，在圆周情况下为 $\tilde{\Omega}(n^3)$。此外，本文证明了在循环删除通道中，重构任意常数稀疏字符串仅需 $\tilde{O}(n^6)$ 条轨迹，而在圆周删除通道中，重构一般字符串的上界为 $\exp(\tilde{O}(n^{1/3}))$。

Conclusion: 本文研究了圆周轨迹重构变体问题，并证明了重构稀疏度为常数的字符串所需的轨迹数量上界为 $\tilde{O}(n^6)$ 次，下界为 $\tilde{\Omega}(n^5)$ 次，这与一般字符串在圆周删除通道中的指数级上界形成了鲜明对比，表明了未来算法或下界的研究应着重于非稀疏的字符串。

Abstract: The ''trace reconstruction'' problem asks, given an unknown binary string $x$ and a channel that repeatedly returns ''traces'' of $x$ with each bit randomly deleted with some probability $p$, how many traces are needed to recover $x$? There is an exponential gap between the best known upper and lower bounds for this problem. Many variants of the model have been introduced in hopes of motivating or revealing new approaches to narrow this gap. We study the variant of circular trace reconstruction introduced by Narayanan and Ren (ITCS 2021), in which traces undergo a random cyclic shift in addition to random deletions.
  We show an improved lower bound of $\tildeΩ(n^5)$ for circular trace reconstruction. This contrasts with the (previously) best known lower bounds of $\tildeΩ(n^3)$ in the circular case and $\tildeΩ(n^{3/2})$ in the linear case. Our bound shows the indistinguishability of traces from two sparse strings $x,y$ that each have a constant number of nonzeros. Can this technique be extended significantly? How hard is it to reconstruct a sparse string $x$ under a cyclic deletion channel? We resolve these questions by showing, using Fourier techniques, that $\tilde{O}(n^6)$ traces suffice for reconstructing any constant-sparse string in a circular deletion channel, in contrast to the upper bound of $\exp(\tilde{O}(n^{1/3}))$ for general strings in the circular deletion channel. This shows that new algorithms or new lower bounds must focus on non-constant-sparse strings.

</details>


### [4] [Approximation schemes for covering and packing mixed-integer programs with a fixed number of constraints](https://arxiv.org/abs/2512.02571)
*Kobe Grobben,Phablo F. S. Moura,Hande Yaman*

Main category: cs.DS

TL;DR: The paper is related to graph processing (knapsack problem, facility location, supplier selection which can be modeled as graphs or related to resource allocation problems on graphs).
This paper presents an algorithmic study of covering mixed-integer linear programming (MILP) problems, which include classical cover problems like multidimensional knapsack and facility location. The authors first analyze the properties of the associated polytope's vertices and use them to decompose the problem into instances of the multidimensional knapsack cover with a single continuous variable per dimension. This decomposition leads to the design of the first polynomial-time approximation scheme (PTAS) for the problem with a fixed number of constraints. Furthermore, for the single-constraint case, they propose a fully polynomial-time approximation scheme (FPTAS) and an approximate linear programming formulation, improving on the previous best 2-approximation algorithm. Finally, a perfect compact formulation is shown for the case where all variables have identical bounds, with analogous results for packing and assignment variants.


<details>
  <summary>Details</summary>
Motivation: 对一类涵盖经典覆盖问题（如多维背包、设施选址和供应商选择）的覆盖混合整数线性规划问题进行算法研究，并填补现有近似算法的空白。特别是缺乏针对这类一般覆盖混合整数规划的近似方案。

Method: 1. 分析相关多面体顶点的性质。
2. 将问题分解为带有一个连续变量的多维背包覆盖问题实例。
3. 利用分解设计具有固定约束数量问题的多项式时间近似方案（PTAS）。
4. 针对单约束情况设计完全多项式时间近似方案（FPTAS）和一个近似线性规划公式。
5. 推导所有变量具有相同上下界情况的完美紧凑公式。
6. 将相似的结果推广到问题的打包和分配变体。

Result: 1. 对于具有固定约束数量的问题，设计了首个多项式时间近似方案（PTAS）。
2. 对于单约束情况，设计了完全多项式时间近似方案（FPTAS）和一个近似线性规划公式，改进了先前提出的单连续变量背包覆盖问题的最优 2-近似算法。
3. 推导了所有变量具有相同上下界情况的完美紧凑公式。
4. 相似的结果被推广到了问题的打包和分配变体。

Conclusion: 本文对一类覆盖混合整数线性规划问题进行了算法研究，涵盖了多维背包、设施选址和供应商选择等经典覆盖问题。通过分析相关多面体顶点的性质，将问题分解为带有一个连续变量的多维背包覆盖问题实例，并基于此设计了具有固定约束数量问题的多项式时间近似方案（PTAS），这是针对此类覆盖混合整数规划的首次近似方案。此外，本文还针对单约束情况设计了完全多项式时间近似方案（FPTAS）和一个近似线性规划公式，改进了先前提出的单连续变量背包覆盖问题的最优 2-近似算法。最后，本文展示了所有变量具有相同上下界情况的完美紧凑公式，并将相似的结果推广到了问题的打包和分配变体。

Abstract: This paper presents an algorithmic study of a class of covering mixed-integer linear programming problems which encompasses classic cover problems, including multidimensional knapsack, facility location and supplier selection problems. We first show some properties of the vertices of the associated polytope, which are then used to decompose the problem into instances of the multidimensional knapsack cover problem with a single continuous variable per dimension. The proposed decomposition is used to design a polynomial-time approximation scheme for the problem with a fixed number of constraints. To the best of our knowledge, this is the first approximation scheme for such a general class of covering mixed-integer programs. Moreover, we design a fully polynomial-time approximation scheme and an approximate linear programming formulation for the case with a single constraint. These results improve upon the previously best-known 2-approximation algorithm for the knapsack cover problem with a single continuous variable. Finally, we show a perfect compact formulation for the case where all variables have the same lower and upper bounds. Analogous results are derived for the packing and assignment variants of the problem.

</details>


### [5] [The Support of Bin Packing is Exponential](https://arxiv.org/abs/2512.02758)
*Klaus Jansen,Lis Pirotton,Malte Tutas*

Main category: cs.DS

TL;DR: This content has not passed the compliance test and has been hidden.


<details>
  <summary>Details</summary>
Motivation: 经典装箱问题 (Bin Packing) 的解的支持集大小（即不同填充方式的箱子数量）是一个重要的复杂度度量。先前工作给出了上界 $2^d$。本文的动机是建立一个紧密的下界，以更好地理解和界定具有 $d$ 种尺寸的装箱问题的解结构复杂性，并揭示这如何影响现有算法的时间复杂度。

Method: 作者开发了一种新的技术，能够将具有多个约束的等式受限整数线性规划 (ILP) 聚合为一个仅有一个约束的等效 ILP。与现有技术不同的是，该技术能够将变量的上限集成到结果约束中。通过这种技术，作者建立了装箱问题解的支持集大小的下界。

Result: 本文的主要结果证明了具有 $d$ 种不同尺寸物品的装箱问题，其解的支持集（即不同填充方式的箱子数量）的下界是 $2^{\Omega(d)}$。这个下界与已知的上界 $2^d$ 在常数因子上匹配。这一发现直接对 Goemans and Rothvoss (SODA '14), Jansen and Klein (SODA '17) 和 Jansen and Solis-Oba (IPCO '10) 等装箱算法的时间复杂度分析产生了影响。

Conclusion: 本文证明了具有 $d$ 种不同尺寸物品的经典装箱问题，其解的支持集大小的下界是 $2^{\Omega(d)}$。这一结果与现有上界 $2^d$ 在常数因子上匹配。这一结果直接影响了多种装箱算法的时间复杂度，并为解决一般整数线性规划和 $d$ 维背包问题提供了一个新的技术工具。

Abstract: Consider the classical Bin Packing problem with $d$ different item sizes $s_i$ and amounts of items $a_i.$ The support of a Bin Packing solution is the number of differently filled bins. In this work, we show that the lower bound on the support of this problem is $2^{Ω(d)}$. Our lower bound matches the upper bound of $2^d$ given by Eisenbrand and Shmonin [Oper.Research Letters '06] up to a constant factor. This result has direct implications for the time complexity of several Bin Packing algorithms, such as Goemans and Rothvoss [SODA '14], Jansen and Klein [SODA '17] and Jansen and Solis-Oba [IPCO '10]. To achieve our main result, we develop a technique to aggregate equality constrained ILPs with many constraints into an equivalent ILP with one constraint. Our technique contrasts existing aggregation techniques as we manage to integrate upper bounds on variables into the resulting constraint. We believe this technique can be useful for solving general ILPs or the $d$-dimensional knapsack problem.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [6] [Pushing Tensor Accelerators Beyond MatMul in a User-Schedulable Language](https://arxiv.org/abs/2512.02371)
*Yihong Zhang,Derek Gerstmann,Andrew Adams,Maaz Bin Safeer Ahmad*

Main category: cs.PL

TL;DR: 该论文与编译器和 DSL（Halide 是一种特定领域的语言，即 DSL）相关。
太长不看（TLDR）：现代 CPU 和 GPU 中的张量加速器（如 Tensor Cores）难以编程，主要局限于传统机器学习和科学计算。本文提出使用基于 Halide 的编译器技术，通过一个灵活的基于等价饱和的张量指令选择器来解决编程难题，从而将张量加速器的应用扩展到图像处理等领域。实验结果表明，与未利用加速器的基线相比，图像处理流水线实现了显著加速，例如在 Nvidia RTX 4070 上，一个下采样程序实现了 6.1 倍的加速。


<details>
  <summary>Details</summary>
Motivation: 张量加速器（如现代 CPU 和 GPU 中的张量核心）难以编程，导致开发人员主要依赖供应商提供的内核库。这限制了张量加速器的使用范围，主要局限于传统的机器学习（ML）和科学计算工作负载。本文的动机是证明张量加速器可以提高超越简单矩阵乘法（MatMul）变体的应用程序的性能（例如图像处理流水线，它们可以被视为矩阵上的线性变换），并通过编译器技术解决编程难度问题，从而拓宽张量加速器的应用领域。

Method: 本文采用了一种基于编译器的技术来解决张量加速器难以编程的问题。具体来说，它利用了 Halide 这一用户可调度的语言来简洁地表达操作，并实现了一个灵活的基于等价饱和（equality saturation）的张量指令选择器（tensor instruction selector）。该选择器支持连接到 CPU 和 GPU 的张量加速器，并兼容现有的调度操作（例如生产者-消费者融合）。这种方法使得开发人员能够用较少的代码行数来编写各种利用加速器的应用。

Result: 本文的结果显示，通过使用他们提出的系统，张量加速器的应用潜力得到了展示，超越了传统领域。通过在实现的图像处理流水线（例如滤波、重采样和去噪）中利用张量加速器，与未利用加速器的基线相比，实现了显著的加速。例如，在一个 Nvidia RTX 4070 GPU 上，一个利用 Tensor Cores 的下采样程序实现了 6.1 倍的加速。

Conclusion: 本文通过一个灵活的基于等价饱和的张量指令选择器，将 Halide 语言及其现有的调度操作与张量加速器结合起来，降低了编程难度，使开发人员能够为多种应用场景（例如图像处理）编写利用加速器的代码。结果显示，与未利用加速器的基线相比，实现了显著的加速，例如在 Nvidia RTX 4070 GPU 上，一个下采样程序实现了 6.1 倍的加速。总的来说，本文成功地拓展了张量加速器的应用范围，使其超越了传统的机器学习和科学计算领域。

Abstract: Tensor accelerators now represent a growing share of compute resources in modern CPUs and GPUs. However, they are hard to program, leading developers to use vendor-provided kernel libraries that support tensor accelerators. As a result, the usage of tensor accelerators is limited to the provided interface, mainly designed for traditional ML and scientific computing workloads.
  In this paper, we show that tensor accelerators can improve the performance of applications beyond simple variants of MatMul. For example, many image processing pipelines are linear transformations over matrices in disguise and can therefore utilize such specialized hardware. This is nonetheless hindered by the difficulties in programming tensor accelerators. We tackle this problem with compiler-based techniques. We use the Halide user-schedulable language and express operations as Halide algorithms succinctly. To this end, we implement a flexible tensor instruction selector based on equality saturation. The tensor instruction selector supports both CPU- and GPU-attached tensor accelerators and works with existing scheduling operations (e.g., producer-consumer fusion). Together, this enables developers to write diverse accelerator-leveraging applications in a few dozen lines.
  Using our system, we demonstrate the potential of tensor accelerators beyond their traditional domains. We implement several image processing pipelines (e.g., filtering, resampling, and denoising) in our system and evaluate them against non-accelerator-leveraging baselines. We show that these pipelines can achieve significant speedups. For example, a downsampling routine is sped up by $6.1\times$ by utilizing Tensor Cores on an Nvidia RTX 4070 GPU.

</details>


### [7] [Probabilistic energy profiler for statically typed JVM-based programming languages](https://arxiv.org/abs/2512.02738)
*Joel Nyholm,Wojciech Mostowski,Christoph Reichenbach*

Main category: cs.PL

TL;DR: 该论文与编译器、DSL、图处理、MLIR、HLS 均不直接相关。

太长不读摘要：能源消耗是软件开发中的一个重要关注点。现有方法在粒度上（非源代码语句级别）和准确性上（仅估计 CPU 消耗且使用点估计）存在局限。本文提出了一种新的方法论，专门针对 Java/Scala 等基于 JVM 的静态类型语言，通过测量**字节码模式**的能源消耗，并使用**贝叶斯统计**构建**统计模型**来预测能源消耗。模型考虑了**数据大小、数据类型、操作**和**硬件设备**四个关键因素。实验证明所有因素均有影响，特别是设备差异和操作/数据类型，并且该方法对未见程序的能源预测**具有高准确性**，验证了其有效性。该能源模型可供未来的验证工具使用。


<details>
  <summary>Details</summary>
Motivation: 能源消耗日益成为一个重要问题，开发者需要详细的软件能源消耗数据来缓解问题。现有的方法通常关注更广泛的范围（如特定函数或程序），而不是源代码语句级别，并且主要通过点估计来估算 CPU 的能源消耗，忽略了其他硬件影响，限制了统计推理和可解释性。因此，需要一种新的方法来解决仅测量 CPU 消耗和使用点估计的局限性。

Method: 开发了一种新的方法论，用于预测静态类型、基于 JVM 的编程语言（如 Java 和 Scala）的能源使用。核心方法是测量字节码模式（即编程语言源代码语句到 Java 字节码表示的转换）的能源消耗。利用这些能源测量，使用贝叶斯统计构建了一个统计模型，该模型能够通过统计分布进行能源消耗预测，并分析个体因素。模型包含四个因素：静态获取的数据大小、数据类型、操作，以及关于代码执行硬件平台的设备信息。通过为 Java 实现该方法并对未见过的程序进行评估来验证方法论。

Result: 四个因素（数据大小、数据类型、操作、设备）都被观察到对能源消耗有影响。值得注意的是，即使是同一型号的设备也可能在能源消耗上有所不同，并且操作和数据类型会导致消耗差异。实验结果表明，程序的能源预测与程序的实际能源消耗非常接近，验证了该方法的有效性。

Conclusion: 我们提出了一种新的方法论，用于构建软件能源消耗模型。该模型基于对 Java 字节码模式的能源测量，并使用贝叶斯统计方法进行建模，从而能够以统计分布的形式预测能源消耗，并分析数据大小、数据类型、操作和硬件设备等个体因素的影响。实验验证了该方法在预测 Java 程序能源消耗方面的有效性，并揭示了所有因素，特别是硬件设备差异和操作/数据类型对能源消耗的重要性。这项工作为未来如验证工具等利用能源模型的应用奠定了基础。

Abstract: Energy consumption is a growing concern in several fields, from mobile devices to large data centers. Developers need detailed data on the energy consumption of their software to mitigate consumption issues. Previous approaches have a broader focus, such as on specific functions or programs, rather than source code statements. They primarily focus on estimating the CPU's energy consumption using point estimates, thereby disregarding other hardware effects and limiting their use for statistical reasoning and explainability. We developed a novel methodology to address the limitations of measuring only the CPU's consumption and using point estimates, focusing on predicting the energy usage of statically typed JVM-based programming languages, such as Java and Scala. We measure the energy consumption of Bytecode patterns, the translation from the programming language's source code statement to their Java Bytecode representation. With the energy measurements, we construct a statistical model using Bayesian statistics, which allows us to predict the energy consumption through statistical distributions and analyze individual factors. The model includes three factors we obtain statically from the code: data size, data type, operation, and one factor about the hardware platform the code executes on: device. To validate our methodology, we implemented it for Java and evaluated its energy predictions on unseen programs. We observe that all four factors are influential, notably that two devices of the same model may differ in energy consumption and that the operations and data types cause consumption differences. The experiments also show that the energy prediction of programs closely follows the program's real energy consumption, validating our approach. Our work presents a methodology for constructing an energy model that future work, such as verification tools, can use for their energy estimates.

</details>


### [8] [Lumos: Let there be Language Model System Certification](https://arxiv.org/abs/2512.02966)
*Isha Chaudhary,Vedaant Jain,Avaljot Singh,Kavya Sachdeva,Sayan Ranu,Gagandeep Singh*

Main category: cs.PL

TL;DR: 该论文与 DSL 和图处理相关。
**太长不看（TLDR）:** Lumos 是首个用于规范和形式化认证语言模型系统（LMS）行为的“可原理化”框架。它是一个命令式、基于图的概率编程 DSL，允许通过图结构定义独立同分布的提示分布，并集成统计认证器进行认证。Lumos 仅用少量构造块就能编码复杂的关系和时间规格。研究者利用 Lumos 开发了自动驾驶 VLM 的安全规格，并发现最先进的 VLM (Qwen-VL) 在特定危险场景下的安全失败率至少为 90%，证明了 Lumos 在发现关键安全缺陷方面的有效性和必要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型系统（LMS）的广泛应用和快速发展，确保其行为安全（特别是面对不断变化的安全威胁）变得至关重要。然而，现有的 LMS 认证方法缺乏一个“可原理化”（principled）、可形式化验证且易于扩展的框架来准确地指定和系统地认证 LMS 的行为，尤其是在处理复杂的提示分布和关系/时间规格时。因此，需要一个系统性的、基于语言的框架来填补这一空白，推动 LMS 认证的更广泛应用。

Method: Lumos 是一个命令式的概率编程 DSL，运行在图结构之上。它通过图结构提供了对提示分布的结构化视图，并从采样的子图中形成随机提示。Lumos 的核心方法包括：
1. **DSL 设计：** 引入可组合的结构来编码复杂的现有和新颖的 LMS 规格，包括关系和时间规格。
2. **形式化语义：** 提供了混合（操作和指称）语义，以严格解释规格。
3. **集成统计认证器：** 通过与统计认证器的集成，支持对任意提示分布下的 LMS 进行认证。
4. **实际应用：** 利用 Lumos 开发自动驾驶场景下视觉-语言模型（VLM）的首个安全规格，并用其揭示现有 VLM 的关键安全缺陷。

Result: 1. **框架的有效性：** Lumos 能够仅使用少量可组合的结构来编码现有复杂的 LMS 规格以及新的特性，例如自动驾驶场景下 VLM 的首个安全规格。
2. **发现关键安全缺陷：** 使用 Lumos 开发的安全规格，研究人员发现最新的 VLM (Qwen-VL) 在雨天右转场景中，产生不正确和不安全的响应的概率至少为 90%，揭示了重大的安全风险。
3. **可模块化和可扩展性：** Lumos 的模块化结构允许轻松修改规格，使其能够跟上快速演变的安全威胁。
4. **故障案例生成能力：** 结果表明，用 Lumos 编写的规格程序能够有效地找到最先进 LMS 所表现出的特定故障案例。
5. **形式化基础：** 提供了混合语义，为规格的解释提供了严格的基础。

Conclusion: Lumos 是首个系统且可扩展的基于语言的模型系统行为规范和认证框架，为更广泛地采用 LMS 认证奠定了基础。它通过提供一种结构化的、可形式化验证的规格语言，解决了现有 LMS 认证在准确性和可扩展性方面的不足。

Abstract: We introduce the first principled framework, Lumos, for specifying and formally certifying Language Model System (LMS) behaviors. Lumos is an imperative probabilistic programming DSL over graphs, with constructs to generate independent and identically distributed prompts for LMS. It offers a structured view of prompt distributions via graphs, forming random prompts from sampled subgraphs. Lumos supports certifying LMS for arbitrary prompt distributions via integration with statistical certifiers. We provide hybrid (operational and denotational) semantics for Lumos, providing a rigorous way to interpret the specifications. Using only a small set of composable constructs, Lumos can encode existing LMS specifications, including complex relational and temporal specifications. It also facilitates specifying new properties - we present the first safety specifications for vision-language models (VLMs) in autonomous driving scenarios developed with Lumos. Using these, we show that the state-of-the-art VLM Qwen-VL exhibits critical safety failures, producing incorrect and unsafe responses with at least 90% probability in right-turn scenarios under rainy driving conditions, revealing substantial safety risks. Lumos's modular structure allows easy modification of the specifications, enabling LMS certification to stay abreast with the rapidly evolving threat landscape. We further demonstrate that specification programs written in Lumos enable finding specific failure cases exhibited by state-of-the-art LMS. Lumos is the first systematic and extensible language-based framework for specifying and certifying LMS behaviors, paving the way for a wider adoption of LMS certification.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [9] [DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications](https://arxiv.org/abs/2512.02300)
*Haoyu Zheng,Shouwei Gao,Jie Ren,Wenqian Dong*

Main category: cs.DC

TL;DR: 本论文与编译器领域相关，因为它关注优化内存访问及其对计算性能的影响，这在高性能计算（HPC）环境中与编译器的内存管理和优化密切相关，尽管它主要是一个系统级框架。

太长不读：DOLMA是一个面向HPC应用的**数据对象级内存解耦框架**，它通过**智能地识别和卸载数据到远程内存**、**量化分析决定本地内存大小**，并利用**双缓冲区设计实现远程内存预取**，从而在最小化性能下降（<16%）的同时，显著减少本地内存使用（平均高达63%），有效解决了远程内存访问在高计算强度HPC应用中的性能挑战。


<details>
  <summary>Details</summary>
Motivation: HPC系统中的内存解耦（Memory disaggregation）在扩展内存容量和提高利用率方面具有潜力。然而，访问远程内存的性能开销是一个重大挑战，对于计算密集型的HPC应用尤其如此，因为它们的执行时间对数据局部性高度敏感。本工作旨在解决这一挑战，利用内存解耦的优势，同时最小化对应用性能的损害。

Method: DOLMA框架通过以下方法实现内存解耦：1. 智能识别并卸载数据对象到远程内存。2. 提供量化分析来决定合适的本地内存大小。3. 利用HPC应用中典型的可预测内存访问模式，通过双缓冲区设计实现远程内存预取。4. 仔细平衡本地和远程内存的使用，并维持多线程并发性。

Result: DOLMA在评估了八个HPC工作负载和计算内核后，相对于基线，能够将性能下降限制在16%以内，同时平均本地内存使用量减少了高达63%。

Conclusion: DOLMA通过平衡本地和远程内存的使用，并保持多线程并发，为HPC应用提供了一个灵活且高效的利用内存解耦的解决方案，同时对应用性能的影响最小。实验结果显示，相对于基线，DOLMA能够将性能下降限制在16%以内，同时平均本地内存使用量减少了高达63%。

Abstract: Memory disaggregation is promising to scale memory capacity and improves utilization in HPC systems. However, the performance overhead of accessing remote memory poses a significant chal- lenge, particularly for compute-intensive HPC applications where execution times are highly sensitive to data locality. In this work, we present DOLMA, a Data Object Level M emory dis Aggregation framework designed for HPC applications. DOLMA intelligently identifies and offloads data objects to remote memory, while pro- viding quantitative analysis to decide a suitable local memory size. Furthermore, DOLMA leverages the predictable memory access patterns typical in HPC applications and enables remote memory prefetch via a dual-buffer design. By carefully balancing local and remote memory usage and maintaining multi-thread concurrency, DOLMA provides a flexible and efficient solution for leveraging dis- aggregated memory in HPC domains while minimally compromis- ing application performance. Evaluating with eight HPC workloads and computational kernels, DOLMA limits performance degrada- tion to less than 16% while reducing local memory usage by up to 63%, on average.

</details>


### [10] [Solutions for Distributed Memory Access Mechanism on HPC Clusters](https://arxiv.org/abs/2512.02546)
*Jan Meizner,Maciej Malawski*

Main category: cs.DC

TL;DR: 该论文涉及图处理、编译器、HLS、MLIR、DSL中的 **无**。
本文在两个不同的HPC集群上，评估了基于共享存储和MPI的分布式系统远程内存访问机制的性能，并与本地内存访问进行了比较。研究发现，特别是通过Infiniband和Slingshot上的MPI实现的远程访问性能与本地内存访问性能相近，这对主要的医疗用例非常有益。


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于探索和评估在分布式系统中，实现高效远程内存访问的不同机制，特别是为了满足医疗用例等领域的性能需求。

Method: 本文通过在一个分布式系统中的两个不同的HPC集群上，评估了基于共享存储和基于MPI（通过Infiniband和Slingshot）的远程内存访问解决方案，并将其性能与本地内存访问进行了比较。

Result: 研究发现，对于远程内存访问，特别是那些由MPI支持的方案，其结果与本地内存访问的结果相似。这表明通过MPI等机制可以实现与本地内存访问相媲美的高效远程内存访问。

Conclusion: 本文评估了在基于高性能计算（HPC）集群的分布式系统中，远程内存访问的各种机制，并发现特别是基于MPI（通过Infiniband和Slingshot）的远程内存访问的结果与本地内存访问的结果相近。这表明在分布式环境特别是医疗应用场景中，可以通过这些技术实现高效的内存访问。

Abstract: Paper presents and evaluates various mechanisms for remote access to memory in distributed systems based on two distinct HPC clusters. We are comparing solutions based on the shared storage and MPI (over Infiniband and Slingshot) to the local memory access. This paper also mentions medical use-cases that would mostly benefit from the described solution. We have found out that results for remote access esp. backed by MPI are similar to local memory access.

</details>


### [11] [Offloading Artificial Intelligence Workloads across the Computing Continuum by means of Active Storage Systems](https://arxiv.org/abs/2512.02646)
*Alex Barceló,Sebastián A. Cajas Ordoñez,Jaydeep Samanta,Andrés L. Suárez-Cetrulo,Romila Ghosh,Ricardo Simón Carbajo,Anna Queralt*

Main category: cs.DC

TL;DR: 相关性：该论文与编译器（广义上的优化和异构设备上的资源管理与分配策略）、图处理（未直接提及，但分布式数据管理和计算可能涉及）、MLIR（未直接提及，但异构计算的抽象和优化相关）、DSL（未直接提及，但软件架构和库的使用可能涉及）或HLS（未直接提及，但异构加速和资源高效利用相关）领域具有一定的相关性，主要在AI工作负载分布式管理和资源优化方面。TLDR：针对传统云架构处理AI工作数据量的效率低下和现有框架缺乏适应性问题，本文提出了一种集成主动存储（dataClay）的软件架构，用于在计算连续体中无缝分发AI工作负载。实验证明，该方法通过将计算嵌入存储架构来减少数据传输开销，显著提高了内存效率和训练速度，为分布式AI部署提供了更具可扩展性和资源效率的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统云计算架构难以有效处理AI驱动数据的大量和高速增长，导致存储、计算和数据移动效率低下。同时，现有的分布式AI框架缺乏计算连续体所需的灵活性和适应性，尤其在设备异构性和快速变化的AI算法和模型方面。因此，需要一种更高效的数据管理策略，特别是将主动存储系统集成到计算连续体中，以优化AI工作负载分布。

Method: 本文提出了一种软件架构，旨在跨计算连续体无缝分发AI工作负载，并使用主流Python库和主动存储平台dataClay进行了实现。通过实验评估了该方法在内存消耗、存储需求、训练时间、以及跨不同设备的执行效率等方面的性能和权衡。

Result: 通过主动存储实现工作负载的卸载显著提高了内存效率和训练速度，同时保持了准确性。实验结果表明，该方法在提高AI工作负载分布式部署的可扩展性和资源效率方面具有巨大潜力。

Conclusion: 主动存储通过将计算嵌入到存储架构中，显著提升了AI工作负载的分布式部署效率和资源利用率。它在内存效率和训练速度方面的改进表明其有潜力彻底改变AI工作负载管理，使分布式AI部署更具可扩展性和资源效率，并降低了领域专家和应用开发者的使用门槛。

Abstract: The increasing demand for artificial intelligence (AI) workloads across diverse computing environments has driven the need for more efficient data management strategies. Traditional cloud-based architectures struggle to handle the sheer volume and velocity of AI-driven data, leading to inefficiencies in storage, computation, and data movement. This paper explores the integration of active storage systems within the computing continuum to optimize AI workload distribution.
  By embedding computation directly into storage architectures, active storage is able to reduce data transfer overhead, enhancing performance and improving resource utilization. Other existing frameworks and architectures offer mechanisms to distribute certain AI processes across distributed environments; however, they lack the flexibility and adaptability that the continuum requires, both regarding the heterogeneity of devices and the rapid-changing algorithms and models being used by domain experts and researchers.
  This article proposes a software architecture aimed at seamlessly distributing AI workloads across the computing continuum, and presents its implementation using mainstream Python libraries and dataClay, an active storage platform. The evaluation shows the benefits and trade-offs regarding memory consumption, storage requirements, training times, and execution efficiency across different devices. Experimental results demonstrate that the process of offloading workloads through active storage significantly improves memory efficiency and training speeds while maintaining accuracy. Our findings highlight the potential of active storage to revolutionize AI workload management, making distributed AI deployments more scalable and resource-efficient with a very low entry barrier for domain experts and application developers.

</details>


### [12] [Distributed and Autonomic Minimum Spanning Trees](https://arxiv.org/abs/2512.02683)
*Luiz A. Rodrigues,Elias P. Duarte,Luciana Arantes*

Main category: cs.DC

TL;DR: 部分涉及图处理（最小生成树）。
该论文提出了一个自主算法，用于在分布式系统中构建和维护一个可扩展的、容错的最小生成树，以解决传统“一对多”广播带来的可扩展性问题和重负荷。该算法利用 VCube 虚拟拓扑作为故障检测器，保证了生成树上每个顶点的入度及树深度均不大于 $log_2 n$。该算法具有动态创建和透明重建的能力，基于此算法还提出了尽力而为广播和可靠广播两种新的广播算法，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在分布式系统中，传统的“一对多”广播通信策略可扩展性差，会对发送方造成沉重负担。因此，需要一种更具可扩展性的方法来在分布式系统中实现高效的消息广播。本文的动机是提出一种能自主构建和维护一个可扩展的最小生成树的算法来解决这一问题。

Method: 本文提出了一种自主算法，用于构建和维护一个连接分布式系统中 $n$ 个进程的最小生成树。该算法基于 VCube 虚拟拓扑，利用 VCube 作为故障检测器来构建和维护树。算法保证了生成树中每个顶点的入度以及树的深度均不大于 $log_2 n$。基于此算法，作者还提出了两种广播算法，分别用于尽力而为广播和可靠广播。通过仿真实验对算法进行了验证，并与其他替代方案进行了比较。

Result: 本文提出了一种自主算法，能够构建一个具有良好可扩展性的最小生成树，并保证树中每个顶点的入度及树深度不大于 $log_2 n$。所有进程正确时，每个进程的度恰好是 $log_2 n$。该生成树可以从任一源进程动态创建，并在进程失败或恢复时透明重建，具有很强的容错能力。基于此生成树，提出了尽力而为广播和可靠广播两种算法。仿真结果证明了所提出算法的有效性，并与其他替代方案进行了比较。

Conclusion: 本文提出了一种能够自主构建和维护一个分布式系统中所有进程之间连接的、具有可扩展性的最小生成树的算法。该算法确保了生成树上每个顶点的入度及树的深度均不超自过 $log_2 n$，当所有进程正确时，每个进程的度恰好为 $log_2 n$。该算法具有容错性，可以在进程失败或恢复时进行透明重建，且至多 $n-1$ 个进程失败时仍能保持正确进程之间的连通。基于此算法，作者还提出了两种广播算法，分别用于尽力而为广播和可靠广播。

Abstract: The most common strategy for enabling a process in a distributed system to broadcast a message is one-to-all communication. However, this approach is not scalable, as it places a heavy load on the sender. This work presents an autonomic algorithm that enables the $n$ processes in a distributed system to build and maintain a spanning tree connecting themselves. In this context, processes are the vertices of the spanning tree. By definition, a spanning tree connects all processes without forming cycles. The proposed algorithm ensures that every vertex in the spanning tree has both an in-degree and the tree depth of at most $log_2 n$. When all processes are correct, the degree of each process is exactly $log_2 n$. A spanning tree is dynamically created from any source process and is transparently reconstructed as processes fail or recover. Up to $n-1$ processes can fail, and the correct processes remain connected through a scalable, functioning spanning tree. To build and maintain the tree, processes use the VCube virtual topology, which also serves as a failure detector. Two broadcast algorithms based on the autonomic spanning tree algorithm are presented: one for best-effort broadcast and one for reliable broadcast. Simulation results are provided, including comparisons with other alternatives.

</details>


### [13] [Designing FAIR Workflows at OLCF: Building Scalable and Reusable Ecosystems for HPC Science](https://arxiv.org/abs/2512.02818)
*Sean R. Wilkinson,Patrick Widener,Sarp Oral,Rafael Ferreira da Silva*

Main category: cs.DC

TL;DR: 该论文与 DSL、图处理、MLIR、编译器或 HLS **无关**。
本摘要讨论了高性能计算（HPC）中心在提升科学研究数字工件（如软件和工作流）共享和重用方面的挑战，因为这些工件往往与特定中心的环境紧密耦合，导致重复工作。为解决此问题，作者们提倡 HPC 中心应借鉴 FAIR 原则，特别是基于 EOSC-Life FAIR Workflows Collaboratory 架构，并提出一个定制化的模型：强调使**单个工作流组件**实现 FAIR，而非关注整个工作流。这一组件化的策略旨在构建一个跨学科的 FAIR 生态系统，以提升计算组件的发现和重用效率，从而最大化科学研究的长期价值。


<details>
  <summary>Details</summary>
Motivation: 高性能计算（HPC）中心的用户开发的数字工件（如软件和工作流）通常与特定的硬件、软件环境和安全要求紧密耦合，导致这些工件难以在不同用户和不同中心之间共享和重用。这种“紧耦合”的做法导致了大量重复性工作，因为许多用户需要独立地为常见问题创建类似的解决方案。现有的 FAIR（Findable, Accessible, Interoperable, Reusable）倡议虽有进展，但多局限于特定的研究社区和学科领域，形成了“信息孤岛”，限制了跨领域的合作。因此，**需要**更统一和系统化的方案来解决 HPC 环境中的共享和重用挑战，以最大化科学研究的效率和长期价值。

Method: 本文通过提出一个“量身定制”的模型来解决 HPC 领域中数字工件共享和重用困难的问题。该方法的核心是：1. **借鉴**欧洲开放科学云（EOSC）中 EOSC-Life FAIR Workflows Collaboratory 的架构经验。2. **调整**该架构以适应 HPC 的具体需求。3. **重点**是建立一个强调使**单个工作流组件（individual workflow components）**实现 FAIR（可发现、可访问、可互操作、可重用）的基础设施，而非关注整个工作流，以更好地支持 HPC 用户多样化的需求并提升其数字遗产的长期价值。

Result: 本文提出的模型强调了 HPC 中心应通过设计相应的基础设施，积极地促进一个能够跨多个学科支持研究的 FAIR 生态系统。具体来说，通过采用**基于组件**的方法，即重点关注如何使**单个工作流组件**实现 FAIR（通过使用丰富的元数据和社区标准），可以有效地提升计算组件的发现、共享和重用能力。这被认为是一种比关注整个工作流更适应 HPC 用户多样化和演进需求的有效方法，从而最大化用户工作的长期科学价值。

Conclusion: 本文提出，高性能计算（HPC）中心应在推动跨学科的 FAIR 生态系统方面发挥更积极的作用。通过借鉴 EOSC-Life 的经验，作者们提出了一个针对 HPC 需求定制的模型，该模型特别强调了使**单个工作流组件**实现 FAIR 的重要性。这种基于组件的方法旨在更好地支持 HPC 用户多样化和不断变化的需求，同时最大化其工作的长期价值。其最终目标是使 HPC 研发成果更易于发现、共享和重用，从而减少重复性工作并促进更广泛的科学合作。

Abstract: High Performance Computing (HPC) centers provide advanced infrastructure that enables scientific research at extreme scale. These centers operate with hardware configurations, software environments, and security requirements that differ substantially from most users' local systems. As a result, users often develop customized digital artifacts that are tightly coupled to a given HPC center. This practice can lead to significant duplication of effort as multiple users independently create similar solutions to common problems. The FAIR Principles offer a framework to address these challenges. Initially designed to improve data stewardship, the FAIR approach has since been extended to encompass software, workflows, models, and infrastructure. By encouraging the use of rich metadata and community standards, FAIR practices aim to make digital artifacts easier to share and reuse, both within and across scientific domains. Many FAIR initiatives have emerged within individual research communities, often aligned by discipline (e.g. bioinformatics, earth sciences). These communities have made progress in adopting FAIR practices, but their domain-specific nature can lead to silos that limit broader collaboration. Thus, we propose that HPC centers play a more active role in fostering FAIR ecosystems that support research across multiple disciplines. This requires designing infrastructure that enables researchers to discover, share, and reuse computational components more effectively. Here, we build on the architecture of the European Open Science Cloud (EOSC) EOSC-Life FAIR Workflows Collaboratory to propose a model tailored to the needs of HPC. Rather than focusing on entire workflows, we emphasize the importance of making individual workflow components FAIR. This component-based approach better supports the diverse and evolving needs of HPC users while maximizing the long-term value of their work.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [14] [Microbenchmarking NVIDIA's Blackwell Architecture: An in-depth Architectural Analysis](https://arxiv.org/abs/2512.02189)
*Aaron Jarmusch,Sunita Chandrasekaran*

Main category: cs.AR

TL;DR: 关联分析：该论文与DSL、图形处理、MLIR、编译器或HLS均不直接相关，它专注于GPU架构性能评估和底层优化。
太长不看(TLDR)：NVIDIA Blackwell (B200) GPU在架构上进行了重大升级，包括第五代Tensor Core和Tensor Memory等。本文贡献了一个开源微基准测试套件，对B200与H200进行系统性评估，结果显示B200在混合精度吞吐量上提高了1.56倍，能效提高了42%，且内存访问延迟减少了58%，这为优化算法和指导未来GPU设计提供了关键洞察。


<details>
  <summary>Details</summary>
Motivation: 随着GPU架构的快速发展以满足百亿亿次级计算和机器学习的需求，架构创新对不同工作负载的性能影响尚未被充分理解。特别是NVIDIA Blackwell (B200) 引入了显著的新特性，但缺乏系统性的方法来量化这些改进，从而阻碍了应用开发者做出明智的架构决策和新的GPU设计方向。作者旨在通过提供一套开源微基准测试套件来填补这一空白。

Method: 作者开发了一个开源微基准测试套件，用以系统性地评估Blackwell (B200) GPU的各项新特性。具体方法包括：研究B200相较于H200的内存子系统、Tensor Core管线和浮点精度（FP32、FP16、FP8、FP6、FP4）。通过评估密集/稀疏GEMM、transformer推理和训练等工作负载来量化性能和能效的提升，并分析内存访问延迟的减少。

Result: Blackwell (B200) 相较于H200的主要结果如下：
1. **张量核心(Tensor Core)增强：** 在混合精度吞吐量上实现了1.56倍的提升。
2. **能效：** 能源效率提高了42%。
3. **内存子系统：** 缓存未命中时的内存访问延迟减少了58%。
这些发现从根本上改变了最优算法的设计策略，并为应用开发者提供了优化洞察。

Conclusion: 本文分析了NVIDIA Blackwell (B200) GPU相对于H200的架构进步，并提供了开源微基准测试套件。研究表明，B200在混合精度吞吐量上提升了1.56倍，能效提高了42%；缓存未命中时的内存访问延迟降低了58%，这为应用开发者提供了重要的优化指导，并能指导未来的GPU设计方向。

Abstract: As GPU architectures rapidly evolve to meet the overcoming demands of exascale computing and machine learning, the performance implications of architectural innovations remain poorly understood across diverse workloads. NVIDIA's Blackwell (B200) generation introduce significant architectural advances including the 5th generation tensor cores, tensor memory (TMEM), decompression engine (DE), and dual chips; however systematic methodologies for quantifying these improvements lag behind hardware development cycles. We contribute an open-source microbenchmark suite that offers practical insights into optimizing workloads to fully utilize the rich feature sets of the modern GPU architecture. This work aims to enable application developers make informed architectural decisions and guide future GPU design directions.
  Our work studies Blackwell GPUs, compares them to H200 generation with regards to the memory subsystem, tensor core pipeline and floating-point precisions (FP32, FP16, FP8, FP6, FP4). Our systematic evaluation of dense/sparse GEMM, transformer inference, and training workloads demonstrate that B200's tensor core enhancements achieves 1.56x higher mixed-precision throughput and 42% better energy efficiency than H200. Our memory analysis reveals 58% reduction in memory access latency in cache-misses, fundamentally changing optimal algorithm design strategies.

</details>


### [15] [Near-Memory Architecture for Threshold-Ordinal Surface-Based Corner Detection of Event Cameras](https://arxiv.org/abs/2512.02346)
*Hongyang Shang,An Guo,Shuai Dong,Junyi Yang,Ye Ke,Arindam Basu*

Main category: cs.AR

TL;DR: 否。
事件相机（EBCs）在边缘设备上部署角点检测算法（如基于TOS的算法）时面临显著延迟，本文提出了一种近内存架构（NM-TOS）来解决这一问题。NM-TOS采用读写解耦的8T SRAM单元和流水线技术优化TOS更新，并通过软硬件协同优化和DVFS技术降低延迟和能耗。与传统数字实现相比，NM-TOS显著降低了延迟（最高24.7倍）和能耗（最高6.6倍），同时保持了合理的检测性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机（EBCs）因其高速度和低功耗而被广泛应用于监控和自动驾驶。角点是事件驱动计算机视觉中的重要低级特征。虽然已开发出利用TOS（Threshold-Ordinal Surface）等事件表示的新算法进行角点检测，但在资源受限的边缘设备上实现这些算法时，存在显著的延迟问题，这抵消了EBCs的优势。因此，需要一种高效的硬件实现来解决这一挑战。

Method: 本文提出了一种面向高效TOS更新的近内存架构（NM-TOS）。该架构采用了读写解耦的8T SRAM单元，并通过流水线技术优化了TOS补丁的更新速度。此外，还采用了软硬件协同优化的外围电路和动态电压与频率缩放（DVFS）技术，以进一步降低功耗和延迟。

Result: 与传统的数字实现相比，本文提出的架构在Vdd = 1.2 V时，延迟/能耗降低了24.7倍/1.2倍；在Vdd = 0.6 V时，延迟/能耗降低了1.93倍/6.6倍，均基于65nm CMOS工艺。蒙特卡洛模拟证实了电路运行的鲁棒性。在角点检测评估中，对于两个流行的EBC数据集，在0.6 V电压下，精确召回曲线下面积（AUC）仅有0.027和0.015的轻微下降。

Conclusion: 本文提出了一种面向高效TOS更新的近内存架构（NM-TOS），通过采用读写解耦的8T SRAM单元和流水线优化补丁更新速度。 NM-TOS显著降低了基于事件相机的角点检测算法的延迟和能耗，同时在降低电压时保持了合理的性能和鲁棒性。这种架构有望克服资源受限边缘设备上事件驱动计算机视觉算法部署的挑战。

Abstract: Event-based Cameras (EBCs) are widely utilized in surveillance and autonomous driving applications due to their high speed and low power consumption. Corners are essential low-level features in event-driven computer vision, and novel algorithms utilizing event-based representations, such as Threshold-Ordinal Surface (TOS), have been developed for corner detection. However, the implementation of these algorithms on resource-constrained edge devices is hindered by significant latency, undermining the advantages of EBCs. To address this challenge, a near-memory architecture for efficient TOS updates (NM-TOS) is proposed. This architecture employs a read-write decoupled 8T SRAM cell and optimizes patch update speed through pipelining. Hardware-software co-optimized peripheral circuits and dynamic voltage and frequency scaling (DVFS) enable power and latency reductions. Compared to traditional digital implementations, our architecture reduces latency/energy by 24.7x/1.2x at Vdd = 1.2 V or 1.93x/6.6x at Vdd = 0.6 V based on 65nm CMOS process. Monte Carlo simulations confirm robust circuit operation, demonstrating zero bit error rate at operating voltages above 0.62 V, with only 0.2% at 0.61 V and 2.5% at 0.6 V. Corner detection evaluation using precision-recall area under curve (AUC) metrics reveals minor AUC reductions of 0.027 and 0.015 at 0.6 V for two popular EBC datasets.

</details>


### [16] [SAT-MapIt: A SAT-based Modulo Scheduling Mapper for Coarse Grain Reconfigurable Architectures](https://arxiv.org/abs/2512.02875)
*Cristian Tirelli,Lorenzo Ferretti,Laura Pozzi*

Main category: cs.AR

TL;DR: 关联：编译器（Compilation）、图处理（Graph Algorithms, Data-Flow Graph）、DSL（指代循环），HLS或MLIR未提及；图处理或编译器更相关。Too long; didn't read: Coarse-Grain Reconfigurable Arrays (CGRAs) 的性能依赖于高质量的循环映射。现有技术使用模调度和最大团枚举。本文提出了一种基于 SAT 的 CGRA 循环映射方法 SAT-MapIt，它使用“内核移动性调度”（KMS）将映射问题表述为一系列布尔约束，并利用 SAT 求解器高效地探索解空间。SAT-MapIt 采用迭代方式尝试最小化 II (Iteration Interval)。实验结果表明，SAT-MapIt 在 47.72% 的基准测试中优于现有技术，有时能发现更小的 II，甚至能在现有工具失败时找到有效映射。


<details>
  <summary>Details</summary>
Motivation: CGRA 的加速性能高度依赖于映射质量，而现有最先进的基于模调度（Modulo Scheduling）和图算法（如最大团枚举）的编译技术在有效探索解空间方面可能存在不足，需要更高效地解决 CGRA 循环映射问题，以最小化迭代间隔（II）。

Method: 提出了一种名为 SAT-MapIt 的基于 SAT 的编译方法。该方法引入了 ad-hoc 的“内核移动性调度”（KMS），结合数据流图和 CGRA 架构信息，生成描述给定 II 映射所有约束的布尔语句集。然后使用 SAT 求解器迭代地找到有效的映射，如果找不到，则增加 II，重新生成 KMS 和约束并再次求解。

Result: SAT-MapIt 在 47.72% 的基准测试中获得了优于现有技术的结果，包括找到更小的 II，甚至在现有技术无法找到有效映射时成功找到了映射。

Conclusion: SAT-MapIt 在寻找 CGRA 最佳循环映射方面优于现有技术，在 47.72% 的基准测试中获得了更好的结果，包括实现更小的迭代间隔（II）。

Abstract: Coarse-Grain Reconfigurable Arrays (CGRAs) are emerging low-power architectures aimed at accelerating compute-intensive application loops. The acceleration that a CGRA can ultimately provide, however, heavily depends on the quality of the mapping, i.e. on how effectively the loop is compiled onto the given platform. State of the Art compilation techniques achieve mapping through modulo scheduling, a strategy which attempts to minimize the II (Iteration Interval) needed to execute a loop, and they do so usually through well known graph algorithms, such as Max-Clique Enumeration.
  We address the mapping problem through a SAT formulation, instead, and thus explore the solution space more effectively than current SoA tools. To formulate the SAT problem, we introduce an ad-hoc schedule called the \textit{kernel mobility schedule} (KMS), which we use in conjunction with the data-flow graph and the architectural information of the CGRA in order to create a set of boolean statements that describe all constraints to be obeyed by the mapping for a given II. We then let the SAT solver efficiently navigate this complex space. As in other SoA techniques, the process is iterative: if a valid mapping does not exist for the given II, the II is increased and a new KMS and set of constraints is generated and solved.
  Our experimental results show that SAT-MapIt obtains better results compared to SoA alternatives in $47.72\%$ of the benchmarks explored: sometimes finding a lower II, and others even finding a valid mapping when none could previously be found.

</details>


### [17] [Mapping code on Coarse Grained Reconfigurable Arrays using a SAT solver](https://arxiv.org/abs/2512.02884)
*Cristian Tirelli,Laura Pozzi*

Main category: cs.AR

TL;DR: 本文涉及到的领域包括：**编译器**（通过研究编译过程和调度改进加速器性能），**图处理**（Data Flow Graph DFG的应用），**HLS**（CGRA作为一种加速器架构，与HLS目标有相似性）。太长不看版：本文提出了一种基于SAT公式化的CGRA映射新方法，引入Kernel Mobility Schedule来编码所有可能的映射。实验证明，该方法在降低编译时间的同时，能为计算密集型工作负载实现更低迭代间隔（II）和更高质量的映射，从而有效提升加速器性能。


<details>
  <summary>Details</summary>
Motivation: CGRA作为协处理器常用于加速循环等计算密集型工作负载。加速效果取决于硬件设计和编译质量，其中最新的编译技术利用模调度来最小化迭代间隔（II），以利用架构并行性并减少执行时间。本文的动力在于通过为任何给定的拓扑找到最低的II，从而改进编译过程。

Method: 提出了一种将CGRA映射问题建模为可满足性（SAT）问题的方法。引入了一种新的调度机制，称为Kernel Mobility Schedule，用于在给定的数据流图（DFG）和迭代间隔（II）下，编码所有可能的映射。这种调度机制结合CGRA的架构信息，生成所有必要的约束条件，以寻找有效的映射。

Result: 实验结果表明，与现有的最先进（SoA）技术相比，该方法不仅平均减少了编译时间，而且获得了更高质量的映射（更低的II）。

Conclusion: 本文通过将CGRA的映射问题建模为SAT问题，并引入Kernel Mobility Schedule来捕捉所有可能的映射，从而改进了编译过程。实验结果证明，该方法在降低编译时间的同时，还能得到比现有技术更高质量的映射，实现了更低的迭代间隔（II）。

Abstract: Emerging low-powered architectures like Coarse-Grain Reconfigurable Arrays (CGRAs) are becoming more common. Often included as co-processors, they are used to accelerate compute-intensive workloads like loops. The speedup obtained is defined by the hardware design of the accelerator and by the quality of the compilation. State of the art (SoA) compilation techniques leverage modulo scheduling to minimize the Iteration Interval (II), exploit the architecture parallelism and, consequentially, reduce the execution time of the accelerated workload. In our work, we focus on improving the compilation process by finding the lowest II for any given topology, through a satisfiability (SAT) formulation of the mapping problem. We introduce a novel schedule, called Kernel Mobility Schedule, to encode all the possible mappings for a given Data Flow Graph (DFG) and for a given II. The schedule is used together with the CGRA architectural information to generate all the constraints necessary to find a valid mapping. Experimental results demonstrate that our method not only reduces compilation time on average but also achieves higher quality mappings compared to existing SoA techniques.

</details>
