<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 1]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Enhancing LUT-based Deep Neural Networks Inference through Architecture and Connectivity Optimization](https://arxiv.org/abs/2601.09773)
*Binglei Lou,Ruilin Wu,Philip Leong*

Main category: cs.AR

TL;DR: 该论文与**DSL**（无）、**Graph Processing**（无）、**MLIR**（无）、**Compiler**（无）、**HLS**（无）、**FPGA**（有，涉及DNN在FPGA上的部署）相关。

SparseLUT 提出了一个用于基于查找表（LUT-based）DNN的全面框架，通过聚合多个 PolyLUT 子神经元（架构优化）和非贪婪的连接稀疏性训练算法（训练优化），解决了现有 LUT-DNN 存在的 LUT 尺寸指数增长和低效稀疏连接问题。结果显示，SparseLUT 在保持或提高准确性的同时，显著减少了 LUT 消耗（最高 13.9 倍）和推理延迟（最高 1.6 倍），为资源受限的边缘设备上的高效 DNN 部署提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于查找表（LUT）的DNN（如LogicNets, PolyLUT, NeuraLUT）在部署到资源受限的FPGA等边缘设备时，面临两个关键挑战：LUT尺寸呈指数增长和随机稀疏连接效率低下。本文旨在开发一个全面的框架SparseLUT，以在保持高准确性的同时，解决这些挑战，实现延迟、功耗和硬件资源使用之间的平衡。

Method: SparseLUT框架结合了两种正交优化：1. **架构增强：** 通过加法器聚合多个PolyLUT子神经元，以降低LUT消耗和推理延迟。2. **训练优化：** 引入一种非贪婪的训练算法，通过选择性地剪枝不重要的输入和策略性地再增长更有效的输入来优化神经元连接性，从而提高准确性，且不增加额外的面积和延迟开销。

Result: SparseLUT取得了显著的改进：1. **LUT消耗：** 相比现有技术，LUT消耗减少了2.0x-13.9x。2. **推理延迟：** 推理延迟降低了1.2x-1.6x。3. **准确性：** 在保持可比准确性(架构优化)或交付一致的准确性提高(训练优化)方面表现出色。例如，在MNIST上准确性提高了2.13%，在Jet Substructure Classification上提高了0.94%。这些改进没有带来额外的面积和延迟开销（指训练优化部分）。

Conclusion: SparseLUT通过架构优化（聚合PolyLUT子神经元的加法器）和训练优化（非贪婪的稀疏连接剪枝和再增长）有效地解决了现有LUT-DNN在LUT尺寸和稀疏连接效率上的挑战。这使其在保持甚至提高准确性的同时，显著减少了LUT消耗（2.0x-13.9x）和推理延迟（1.2x-1.6x），为FPGA上的高效DNN部署提供了一个有前景的解决方案。

Abstract: Deploying deep neural networks (DNNs) on resource-constrained edge devices such as FPGAs requires a careful balance among latency, power, and hardware resource usage, while maintaining high accuracy. Existing Lookup Table (LUT)-based DNNs -- such as LogicNets, PolyLUT, and NeuraLUT -- face two critical challenges: the exponential growth of LUT size and inefficient random sparse connectivity. This paper presents SparseLUT, a comprehensive framework that addresses these challenges through two orthogonal optimizations. First, we propose an architectural enhancement that aggregates multiple PolyLUT sub-neurons via an adder, significantly reducing LUT consumption by 2.0x-13.9x and lowering inference latency by 1.2x-1.6x, all while maintaining comparable accuracy. Building upon this foundation, we further introduce a non-greedy training algorithm that optimizes neuron connectivity by selectively pruning less significant inputs and strategically regrowing more effective ones. This training optimization, which incurs no additional area and latency overhead, delivers consistent accuracy improvements across benchmarks -- achieving up to a 2.13% gain on MNIST and 0.94% on Jet Substructure Classification compared to existing LUT-DNN approaches.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [2] [Improved Algorithms for Fair Matroid Submodular Maximization](https://arxiv.org/abs/2601.09860)
*Sepideh Mahabadi,Sherry Sarkar,Jakub Tarnawski*

Main category: cs.DS

TL;DR: 该论文与ML相关（子模最大化受拟阵约束、公平性）。
该论文提出了一个新的近似算法，用于解决公平单调拟阵子模最大化问题，该算法在保持常数因子近似比的同时，保证在期望上能实现接近完全公平的约束（损失因子仅为1-ε），解决了现有算法在公平性约束保证上损失较大的问题，并通过实证评估证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 子模最大化受拟阵约束是机器学习中的一个核心问题。随着算法越来越多地应用于涉及敏感属性的决策制定，强制公平性以避免偏见和歧视变得至关重要。现有用于公平拟阵子模最大化的近似算法，在公平性保证方面只能满足一个松弛版本（损失因子为2，即只能保证找到所需数量的一半），特别是在关键的 $\ell=1$ 情况（对应于完美匹配约束）下没有可证明的保证。因此，需要开发能够更紧密地满足公平性约束的算法。

Method: 提出了一种新的近似算法，用于解决公平单调拟阵子模最大化问题。该算法能够以常数因子近似比，将公平性下界约束的损失因子控制在 $(1-\varepsilon)$ 内（其中 $\varepsilon>0$ 是一个常数）。

Result: 提出了一种新的算法，该算法在公平单调拟阵子模最大化问题上实现了新的权衡。对于任意常数 $\varepsilon>0$，该算法提供了一个常数因子近似，并在期望上，公平性下界约束的损失因子仅为 $(1-\varepsilon)$，从而实现了接近完全公平的保证。在包括集群、推荐和覆盖任务在内的标准真实世界数据集上的实证评估证明了该方法的实际有效性。

Conclusion: 本文提出了一种新的近似算法，旨在解决公平单调拟阵子模最大化问题中，现有算法在公平性约束松弛上损失较大的问题。新算法在保持常数因子近似比的同时，能够使公平性下界约束的损失因子任意接近于1（即接近完全公平）。实验结果表明了该方法在现实世界数据集上的有效性。

Abstract: Submodular maximization subject to matroid constraints is a central problem with many applications in machine learning. As algorithms are increasingly used in decision-making over datapoints with sensitive attributes such as gender or race, it is becoming crucial to enforce fairness to avoid bias and discrimination. Recent work has addressed the challenge of developing efficient approximation algorithms for fair matroid submodular maximization. However, the best algorithms known so far are only guaranteed to satisfy a relaxed version of the fairness constraints that loses a factor 2, i.e., the problem may ask for $\ell$ elements with a given attribute, but the algorithm is only guaranteed to find $\lfloor \ell/2 \rfloor$. In particular, there is no provable guarantee when $\ell=1$, which corresponds to a key special case of perfect matching constraints.
  In this work, we achieve a new trade-off via an algorithm that gets arbitrarily close to full fairness. Namely, for any constant $\varepsilon>0$, we give a constant-factor approximation to fair monotone matroid submodular maximization that in expectation loses only a factor $(1-\varepsilon)$ in the lower-bound fairness constraint. Our empirical evaluation on a standard suite of real-world datasets -- including clustering, recommendation, and coverage tasks -- demonstrates the practical effectiveness of our methods.

</details>


### [3] [UFO Trees: Practical and Provably-Efficient Parallel Batch-Dynamic Trees](https://arxiv.org/abs/2601.10706)
*Quinten De Man,Atharva Sharma,Kishen N Gowda,Laxman Dhulipala*

Main category: cs.DS

TL;DR: 该论文与图处理（动态树是图的一种特殊形式）相关。
UFO树是一种新型的并行批量动态树数据结构，它既能与Link-Cut树竞争顺序性能，又首次支持工作高效的并行批量动态更新和广泛的查询功能；实验证明，UFO树在顺序和并行环境下都是支持广泛查询的最快动态树结构，且具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 动态树问题是一个基础性问题，需要维护在边更新下的树结构并支持连通性或路径查询等操作。传统的Link-Cut树虽然已被发现是目前最快的顺序动态数据结构，但它不支持并行批量动态更新，并且在支持的查询种类上存在限制。因此，需要一种新的动态树数据结构，能够在保持高性能的同时，支持并行批量更新和更广泛的查询功能。

Method: 本文设计并引入了一种新的并行批量动态树数据结构——UFO树。UFO树基于其能够支持工作高效的并行批量动态更新和广泛的查询功能设计。作者通过理论分析，证明了Link-Cut树和UFO树的强大实践性能的一个关键原因在于它们能够在低直径树上以亚对数时间执行更新和查询。作者还对UFO树进行了优化的C++实现，并与其它十种动态树实现（包括一些新的实现）在一系列合成和真实世界的、不同直径和大小的基准测试中进行了广泛的实验研究。

Result: 实验结果表明，在顺序和并行设置中，UFO树是支持广泛查询的动态树数据结构中速度最快的。UFO树的新实现空间占用低，并可以轻松扩展到十亿级别的输入规模。理论分析和实验都支持了其在低直径树上具有亚对数时间操作的优异性能。

Conclusion: UFO树是一种新的并行批量动态树数据结构，它在保持与现有最好的顺序动态树数据结构（如Link-Cut树）相竞争的性能的同时，显著扩展了所支持的查询功能和更新模式。其关键优势在于支持高效的并行批量动态更新，以及在低直径树上实现亚对数时间的操作。实验证明，UFO树在顺序和并行环境下，对于支持广泛查询的动态树数据结构中速度最快，具有低空间占用和良好的可扩展性，使其成为构建复杂动态图算法的有前景的组件。

Abstract: The dynamic trees problem is to maintain a tree under edge updates while supporting queries like connectivity queries or path queries. Despite the first data structure for this fundamental problem -- the link-cut tree -- being invented 40 years ago, our experiments reveal that they are still the fastest sequential data structure for the problem. However, link-cut trees cannot support parallel batch-dynamic updates and have limitations on the kinds of queries they support.
  In this paper, we design a new parallel batch-dynamic trees data structure called UFO trees that simultaneously supports a wide range of query functionality, supports work-efficient parallel batch-dynamic updates, and is competitive with link-cut trees when run sequentially. We prove that a key reason for the strong practical performance of both link-cut trees and UFO trees is that they can perform updates and queries in sub-logarithmic time for low-diameter trees. We perform an experimental study of our optimized C++ implementations of UFO trees with ten other dynamic tree implementations, several of which are new, in a broad benchmark of both synthetic and real-world trees of varying diameter and size. Our results show that, in both sequential and parallel settings, UFO trees are the fastest dynamic tree data structure that supports a wide range of queries. Our new implementation of UFO trees has low space usage and easily scales to billion-size inputs, making it a promising building block for implementing more complex dynamic graph algorithms in practice.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [4] [From Dynamic to Lexical: A Comparative Exploration of Scoping Rules in SAS and R](https://arxiv.org/abs/2601.09808)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 这个论文**不相关**于DSL、图处理、MLIR、编译器或HLS。
TLDR: 本文分析和比较了编程语言SAS的动态作用域（基于符号表，运行时搜索）和R的词法作用域（基于环境，基于函数定义），通过示例说明了它们对代码行为的影响，并提出了在两种语言中检查和控制变量作用域以优化编程实践的方法和策略。


<details>
  <summary>Details</summary>
Motivation: 变量作用域是编程语言中决定变量可访问性和范围的核心机制，对代码效率和组织至关重要。本文的动机是深入比较SAS的动态作用域和R的词法作用域，帮助程序员理解这些作用域策略的区别及其对代码行为的影响，从而优化变量管理，提升编程实践。

Method: 本文通过对比分析SAS（动态作用域，使用符号表并在运行时动态搜索活动的宏层）和R（词法作用域，使用环境并在函数定义结构的基础上解析变量）的作用域规则，并通过实例进行说明。此外，文章还介绍了在SAS的符号表和R的环境中检查变量的方法，以及在两种语言中控制变量作用域的策略。

Result: 本文清晰地界定了SAS的动态作用域（基于符号表，运行时动态搜索）和R的词法作用域（基于环境，基于函数定义结构解析变量）的区别，并通过实例展示了这些差异对代码行为的具体影响。文章还提供了在两种语言中检查变量作用域（如在SAS中检查符号表，在R中检查环境）以及控制变量作用域的实用方法和策略。

Conclusion: 本文对比了SAS的动态作用域和R的词法作用域，并通过实例说明了它们对代码行为的影响。文章还提供了在两种语言中检查和控制变量作用域的方法和策略，旨在帮助程序员优化变量管理，提高编程效率和代码可靠性。

Abstract: Variable scoping dictates how and where variables are accessible within programming languages, playing a crucial role in code efficiency and organization. This paper examines the distinct scoping rules in SAS and R, focusing on SAS's dynamic scoping and R's lexical scoping. In SAS, dynamic scoping utilizes symbol tables, resolving variables at runtime by dynamically searching through active macro layers. R, in contrast, employs lexical scoping, using environments to resolve variables based on the structure in which functions are defined. Illustrative examples highlight the differences between these scoping strategies, showcasing their impact on code behavior. Additionally, the paper outlines methods for inspecting variables in SAS's symbol tables and R's environments, offering practical insights for debugging and optimization. Strategies for controlling variable scope in both languages are discussed, enhancing code precision and reliability. This exploration equips programmers with critical understanding to optimize variable management, improving their programming practices in SAS and R.

</details>


### [5] [Lazy Evaluation: A Comparative Analysis of SAS MACROs and R Functions](https://arxiv.org/abs/2601.09839)
*Chen Ling,Yachen Wang*

Main category: cs.PL

TL;DR: 本文与 DSL、图处理、MLIR、编译器或 HLS 无关。

惰性求值是一种可以优化代码执行效率的强大技术，在 R 等现代编程语言中常用于函数参数。本文首次深入探讨并比较了 R 函数（基于 Promise，按需调用）和 SAS MACROs（基于符号表，按名调用）中的惰性求值机制。通过分析它们在内存使用和求值策略上的差异，本文阐明了其对程序性能和结果的影响，旨在帮助程序员在制药行业等领域加速从 SAS 向 R 的过渡，从而优化代码以提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 惰性求值是一种强大的代码优化技术，它通过延迟求值直到结果被需要时才进行，从而提高执行效率。然而，惰性求值在 SAS 中的应用尚未得到广泛探索。鉴于制药行业等领域正加速从 SAS 向 R 的转变，理解这两种语言中惰性求值的机制对于程序员优化代码、提升编程能力至关重要。

Method: 本文采用比较分析的方法，对 R 语言中基于 Promise（延迟求值、按需调用）和 SAS 宏中基于符号表（存储参数、按名调用）的惰性求值机制进行了详细的探讨和对比，并通过实例说明了这些差异对程序效率和结果的影响。

Result: R 语言的惰性求值由 Promise 数据结构驱动，采用“按需调用”（call-by-need）策略，延迟求值且在需要前不占用内存；而 SAS 通过符号表实现惰性求值，采用“按名调用”（call-by-name）策略，将参数存储在内存中。这些策略上的差异会对 R 函数和 SAS 宏的执行结果产生显著影响。理解这些差异有助于提升编程效率和性能。

Conclusion: 本文通过对 R 和 SAS 宏中惰性求值机制的比较分析，揭示了两种语言在惰性求值策略上的差异及其对程序执行效率和结果的影响。本文的见解旨在帮助程序员在制药行业等领域加速从 SAS 到 R 的过渡，提升在这两种语言中的编程能力和性能。

Abstract: Lazy evaluation is a powerful technique that can optimize code execution by deferring evaluations until their results are required, thus enhancing efficiency. In most modern programming languages, like R, lazy evaluation is commonly applied to function arguments. However, the application of lazy evaluation in SAS has not been extensively explored. This paper focuses on the mechanisms of lazy evaluation in SAS MACROs and R functions, offering a comparative analysis of the underlying principles that drive these processes.
  R's lazy evaluation is driven by a data structure called Promise, which postpones evaluation and does not occupy memory until the value is needed, utilizing a call-by-need strategy. SAS, on the other hand, achieves lazy evaluation through its symbol tables, employing memory to store parameters, and operates on a call-by-name basis. These discrepancies in lazy evaluation strategies can notably impact the results of R functions and SAS MACROs. By examining these distinct approaches, the paper illuminates the impact of lazy evaluation on programming efficiency, supported by illustrative examples. As the shift from SAS to R becomes increasingly prevalent in the pharmaceutical industry, understanding these techniques enables programmers to optimize their code for greater efficacy. This exploration serves as a guide to enhance programming capabilities and performance in both languages.

</details>


### [6] [Outrunning Big KATs: Efficient Decision Procedures for Variants of GKAT](https://arxiv.org/abs/2601.09986)
*Cheng Zhang,Qiancheng Fu,Hang Ji,Ines Santacruz Del Valle,Alexandra Silva,Marco Gaboardi*

Main category: cs.PL

TL;DR: 该论文与编译器（通过控制流转换的验证）、图处理（自动机和等价性判断）相关。
该论文提出了几种利用“即时”符号技术和SAT求解器对GKAT（Generalized Kleene Algebra with Tests）自动机进行迹等价性（trace equivalence）判断的高效决策过程，并设计了用于验证控制流转换的实用系统CF-GKAT的符号导数。作者使用Rust实现了这些算法并在随机生成和真实世界的基准上进行了评估，结果显示性能比现有实现提高了数量级，并且成功发现了一个行业标准反编译器Ghidra中的错误，突显了该方法的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的GKAT自动机等价性判断方法可能效率不够高，因此需要开发更高效的决策过程。同时，需要证明这些高效决策过程在处理实际系统中的控制流转换问题的有效性和实用性。

Method: 本文方法基于对GKAT自动机的等价性判断，核心在于利用“即时”的符号技术并结合SAT求解器。为了应用于实际系统，作者设计了CF-GKAT（一种基于GKAT的实用系统）的符号导数，并使用Rust语言实现这些算法。

Result: 本文提出的算法在性能上取得了显著的提升，相对于现有的KAT和CF-GKAT实现，观察到了提高了数量级的性能改进。此外，通过实际应用，发现了行业标准反编译器Ghidra中的一个错误，证明了这些系统的实用性。

Conclusion: 本文提出了一种通过利用符号技术和SAT求解器对GKAT自动机进行等价性判断的高效决策过程。这带来了比现有实现显著的性能提升，并且证明了这种方法在实际应用中的有效性，甚至可以发现行业标准软件中的错误。

Abstract: This paper presents several efficient decision procedures for trace equivalence of GKAT automata, which make use of on-the-fly symbolic techniques via SAT solvers. To demonstrate applicability of our algorithms, we designed symbolic derivatives for CF-GKAT, a practical system based on GKAT designed to validate control-flow transformations. We implemented the algorithms in Rust and evaluated them on both randomly generated benchmarks and real-world control-flow transformations. Indeed, we observed order-of-magnitude performance improvements against existing implementations for both KAT and CF-GKAT. Notably, our experiments also revealed a bug in Ghidra, an industry-standard decompiler, highlighting the practical viability of these systems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [7] [Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment](https://arxiv.org/abs/2601.10177)
*Ziting Zhang,Kai Wan,Minquan Cheng,Shuo Shao,Giuseppe Caire*

Main category: cs.DC

TL;DR: 该论文与 DSL、图处理、MLIR、编译器或 HLS 不相关。这篇论文研究了异构分布式线性可分离计算问题，其任务函数涉及$K_c$个线性组合的$K$个消息。与现有同构设置不同，本文考虑了任意异构数据分配（工人持有不同数量的数据集，且分配固定），目标是表征任务函数的可计算维度与通信成本之间的基本权衡。作者提出了普适的计算方案和逆定理界限，并在某些参数范围内，在整数和分数通信成本约束下，它们是吻合的。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式线性可分离计算工作主要集中在同构环境中（即每个工作节点持有相同数量的数据集），数据分配由数据中心精心设计和控制（如循环分配）。本文的动机是研究更一般、更实际的异构设置：工人持有的数据集数量可能不同（异构），并且这种分配是预先给定的（任意），从而表征任务函数的可计算维度和通信成本之间的基本权衡。

Method: 本文通过表征数据分配的结构，提出了一个普适的计算方案（universal computing scheme）和一个普适的逆定理界限（universal converse bound），用于在整数通信成本下表征任务函数的可计算维度与通信成本之间的基本权衡。随后，将该计算方案和逆定理界限扩展到分数通信成本的情况。

Result: 在任意异构数据分配下，本文提出了普适的计算方案和逆定理界限，在整数通信成本约束下，它们在某些参数范围内是吻合的。这种权衡关系已扩展到分数通信成本的情况。

Conclusion: 本文研究了异构分布式线性可分离计算问题，并提出了普适的计算方案和相应的逆定理界限，用以表征在任意异构数据分配下，任务函数的可计算维度与通信成本之间的基本权衡。在某些参数范围内，所提出的方案和界限是一致的。

Abstract: Distributed linearly separable computation is a fundamental problem in large-scale distributed systems, requiring the computation of linearly separable functions over different datasets across distributed workers. This paper studies a heterogeneous distributed linearly separable computation problem, including one master and N distributed workers. The linearly separable task function involves Kc linear combinations of K messages, where each message is a function of one dataset. Distinguished from the existing homogeneous settings that assume each worker holds the same number of datasets, where the data assignment is carefully designed and controlled by the data center (e.g., the cyclic assignment), we consider a more general setting with arbitrary heterogeneous data assignment across workers, where `arbitrary' means that the data assignment is given in advance and `heterogeneous' means that the workers may hold different numbers of datasets. Our objective is to characterize the fundamental tradeoff between the computable dimension of the task function and the communication cost under arbitrary heterogeneous data assignment. Under the constraint of integer communication costs, for arbitrary heterogeneous data assignment, we propose a universal computing scheme and a universal converse bound by characterizing the structure of data assignment, where they coincide under some parameter regimes. We then extend the proposed computing scheme and converse bound to the case of fractional communication costs.

</details>
