{"id": "2601.20921", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.20921", "abs": "https://arxiv.org/abs/2601.20921", "authors": ["Faruk Alpay", "Levent Sarioglu"], "title": "Stochastic Indexing Primitives for Non-Deterministic Molecular Archives", "comment": "18 pages, 2 figures", "summary": "Random access remains a central bottleneck in DNA-based data storage. Existing systems typically retrieve records by PCR enrichment or other multi-step biochemical procedures, which do not naturally support fast, massively parallel, content-addressable queries.\n  We introduce the Holographic Bloom Filter (HBF), a probabilistic indexing primitive that stores key-pointer associations as a single high-dimensional memory vector. HBF binds a key vector and a value (pointer) vector using circular convolution and superposes bindings across all records. A query decodes by correlating the memory with the query key and selecting the best matching value using a margin-based decision rule.\n  We give construction and decoding algorithms and a probabilistic analysis under explicit noise models (memory corruption and query/key mismatches). The analysis provides concentration bounds for match and non-match score distributions, explicit threshold and margin settings for a top K decoder, and exponential error decay in the vector dimension under standard randomness assumptions.\n  HBF offers a concrete, analyzable alternative to pointer-chasing molecular data structures, enabling one-shot associative retrieval while quantifying trade-offs among dimensionality, dataset size, and noise."}
{"id": "2601.21202", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.21202", "abs": "https://arxiv.org/abs/2601.21202", "authors": ["Andrew Au"], "title": "Exact (n + 2) Comparison Complexity for the N-Repeated Element Problem", "comment": null, "summary": "This paper establishes the exact comparison complexity of finding an element repeated $n$ times in a $2n$-element array containing $n+1$ distinct values, under the equality-comparison model with $O(1)$ extra space. We present a simple deterministic algorithm performing exactly $n+2$ comparisons and prove this bound tight: any correct algorithm requires at least $n+2$ comparisons in the worst case. The lower bound follows from an adversary argument using graph-theoretic structure. Equality queries build an inequality graph $I$; its complement $P$ (potential-equalities) must contain either two disjoint $n$-cliques or one $(n+1)$-clique to maintain ambiguity. We show these structures persist up through $n+1$ comparisons via a \"pillar matching\" construction and edge-flip reconfiguration, but fail at $n+2$. This result provides a concrete, self-contained demonstration of exact lower-bound techniques, bridging toy problems with nontrivial combinatorial reasoning."}
{"id": "2601.21237", "categories": ["cs.DS", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21237", "abs": "https://arxiv.org/abs/2601.21237", "authors": ["Aaron Li", "Ian Zhang"], "title": "Quantifying Noise in Language Generation", "comment": null, "summary": "Kleinberg and Mullainathan recently proposed a formal framework for studying the phenomenon of language generation, called language generation in the limit. In this model, an adversary gives an enumeration of example strings from an unknown target language, and the algorithm is tasked with correctly generating unseen strings from the target language within finite time. Refined notions of non-uniform and uniform generation were later introduced by Li, Raman, and Tewari (2025), and a noisy model was introduced by Raman and Raman (2025), which allows the adversary to insert extraneous strings. A natural question in the noisy model is to quantify the effect of noise, by studying the impact of each additional extraneous string. We show two complementary results in this setting. We first show that for both uniform and non-uniform generation, a single noisy string strictly reduces the set of collections that can be generated, thus answering an open question in Raman and Raman (2025). Then, we show for both uniform and non-uniform generation that generation with a single noisy string is equivalent to generation with any finite amount of noise, sharply contrasting with the strict hierarchy for noisy generation in the limit shown by Bai, Panigrahi, and Zhang (2026). Finally, we leverage our previous results to provide the first known characterization for non-uniform noise-dependent generatability."}
{"id": "2601.21423", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.21423", "abs": "https://arxiv.org/abs/2601.21423", "authors": ["Léo Colisson Palais", "Jean-Guillaume Dumas", "Alexis Galan", "Bruno Grenet", "Aude Maignan"], "title": "Algorithms for the local and the global postage stamp problem", "comment": null, "summary": "We consider stamps with different values (denominations) and same dimensions, and an envelope with a fixed maximum number of stamp positions. The local postage stamp problem is to find the smallest value that cannot be realized by the sum of the stamps on the envelope. The global postage stamp problem is to find the set of denominations that maximize that smallest value for a fixed number of distinct denominations. The local problem is NP-hard and we propose here a novel algorithm that improves on both the time complexity bound and the amount of required memory.  We also propose a polynomial approximation algorithm for the global problem together with its complexity analysis. Finally we show that our algorithms allow to improve secure multi-party computations on sets via a more efficient homomorphic evaluation of polynomials on ciphered values."}
{"id": "2601.21842", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.21842", "abs": "https://arxiv.org/abs/2601.21842", "authors": ["Jan-Willem Roorda"], "title": "Optimal Software Pipelining using an SMT-Solver", "comment": null, "summary": "Software Pipelining is a classic and important loop-optimization for VLIW processors. It improves instruction-level parallelism by overlapping multiple iterations of a loop and executing them in parallel. Typically, it is implemented using heuristics. In this paper, we present an optimal software pipeliner based on a Satisfiability Modulo Theories (SMT) Solver. We show that our approach significantly outperforms heuristic algorithms and hand-optimization. Furthermore, we show how the solver can be used to give feedback to programmers and processor designers on why a software pipelined schedule of a certain initiation interval is not feasible."}
{"id": "2601.21090", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.21090", "abs": "https://arxiv.org/abs/2601.21090", "authors": ["Mohammad Walid Charrwi", "Zaid Hussain"], "title": "Deep Reinforcement Learning for Fault-Adaptive Routing in Eisenstein-Jacobi Interconnection Topologies", "comment": null, "summary": "The increasing density of many-core architectures necessitates interconnection networks that are both high-performance and fault-resilient. Eisenstein-Jacobi (EJ) networks, with their symmetric 6-regular topology, offer superior topological properties but challenge traditional routing heuristics under fault conditions. This paper evaluates three routing paradigms in faulty EJ environments: deterministic Greedy Adaptive Routing, theoretically optimal Dijkstra's algorithm, and a reinforcement learning (RL)-based approach. Using a multi-objective reward function to penalize fault proximity and reward path efficiency, the RL agent learns to navigate around clustered failures that typically induce dead-ends in greedy geometric routing. Dijkstra's algorithm establishes the theoretical performance ceiling by computing globally optimal paths with complete topology knowledge, revealing the true connectivity limits of faulty networks. Quantitative analysis at nine faulty nodes shows greedy routing catastrophically degrades to 10% effective reachability and packet delivery, while Dijkstra proves 52-54% represents the topological optimum. The RL agent achieves 94% effective reachability and 91% packet delivery, making it suitable for distributed deployment. Furthermore, throughput evaluations demonstrate that RL sustains over 90% normalized throughput across all loads, actually outperforming Dijkstra under congestion through implicit load balancing strategies. These results establish RL-based adaptive policies as a practical solution that bridges the gap between greedy's efficiency and Dijkstra's optimality, providing robust, self-healing communication in fault-prone interconnection networks without requiring the global topology knowledge or computational overhead of optimal algorithms."}
{"id": "2601.21222", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.21222", "abs": "https://arxiv.org/abs/2601.21222", "authors": ["Tenglong Li", "Jindong Li", "Guobin Shen", "Dongcheng Zhao", "Qian Zhang", "Yi Zeng"], "title": "FireFly-P: FPGA-Accelerated Spiking Neural Network Plasticity for Robust Adaptive Control", "comment": "5 pages, 4 figures. Accepted for lecture presentation at the 2026 IEEE International Symposium on Circuits and Systems (ISCAS 2026)", "summary": "Spiking Neural Networks (SNNs) offer a biologically plausible learning mechanism through synaptic plasticity, enabling unsupervised adaptation without the computational overhead of backpropagation. To harness this capability for robotics, this paper presents FireFly-P, an FPGA-based hardware accelerator that implements a novel plasticity algorithm for real-time adaptive control. By leveraging on-chip plasticity, our architecture enhances the network's generalization, ensuring robust performance in dynamic and unstructured environments. The hardware design achieves an end-to-end latency of just 8~$μ$s for both inference and plasticity updates, enabling rapid adaptation to unseen scenarios. Implemented on a tiny Cmod A7-35T FPGA, FireFly-P consumes only 0.713~W and $\\sim$10K~LUTs, making it ideal for power- and resource-constrained embedded robotic platforms. This work demonstrates that hardware-accelerated SNN plasticity is a viable path toward enabling adaptive, low-latency, and energy-efficient control systems."}
{"id": "2601.21457", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.21457", "abs": "https://arxiv.org/abs/2601.21457", "authors": ["Tomer Adar", "Yahel Hotam", "Amit Levi"], "title": "When Local and Non-Local Meet: Quadratic Improvement for Edge Estimation with Independent Set Queries", "comment": null, "summary": "We study the problem of estimating the number of edges in an unknown graph. We consider a hybrid model in which an algorithm may issue independent set, degree, and neighbor queries. We show that this model admits strictly more efficient edge estimation than either access type alone. Specifically, we give a randomized algorithm that outputs a $(1\\pm\\varepsilon)$-approximation of the number of edges using $O\\left(\\min\\left(\\sqrt{m}, \\sqrt{\\frac{n}{\\sqrt{m}}}\\right)\\cdot\\frac{\\log n}{\\varepsilon^{5/2}}\\right)$ queries, and prove a nearly matching lower bound.\n  In contrast, prior work shows that in the local query model (Goldreich and Ron, \\textit{Random Structures \\& Algorithms} 2008) and in the independent set query model (Beame \\emph{et al.} ITCS 2018, Chen \\emph{et al.} SODA 2020), edge estimation requires $\\widetildeΘ(n/\\sqrt{m})$ queries in the same parameter regimes. Our results therefore yield a quadratic improvement in the hybrid model, and no asymptotically better improvement is possible."}
{"id": "2601.21146", "categories": ["cs.DC", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.21146", "abs": "https://arxiv.org/abs/2601.21146", "authors": ["Francesco Paladino", "Shulu Li", "Edward A. Lee"], "title": "Maxwait: A Generalized Mechanism for Distributed Time-Sensitive Systems", "comment": null, "summary": "Distributed time-sensitive systems must balance timing requirements (availability) and consistency in the presence of communication delays and synchronization uncertainty. This paper presents maxwait, a simple coordination mechanism with surprising generality that makes these tradeoffs explicit and configurable. We demonstrate that this mechanism subsumes classical distributed system methods such as PTIDES, Chandy-and-Misra with or without null messages, Jefferson's Time-Warp, and Lamport's time-based fault detection, while enabling real-time behavior in distributed cyber-physical applications. The mechanism can also realize many commonly used distributed system patterns, including logical execution time (LET), publish and subscribe, actors, conflict-free replicated data types (CRDTs), and remote procedure calls with futures. More importantly, it adds to these mechanisms better control over timing, bounded time fault detection, and the option of making them more deterministic, all within a single semantic framework. Implemented as an extension of the Lingua Franca coordination language, maxwait enforces logical-time consistency when communication latencies are bounded and provides structured fault handling when bounds are violated."}
{"id": "2601.21584", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2601.21584", "abs": "https://arxiv.org/abs/2601.21584", "authors": ["Pin-Han Ho", "Limei Peng", "Yiming Miao", "Xu Fan", "Kairan Liang", "Haoran Mei", "Wei Duan"], "title": "Frequency as Aperture: Enabling Embeddable Near-Field Sensing for 6G Wireless Radios", "comment": null, "summary": "Integrated sensing and communication (ISAC) is expected to be natively supported by future 6G wireless radios, yet most mmWave sensing solutions still rely on dedicated radar hardware incompatible with cost and power constrained wireless nodes. This article introduces Frequency-as-Aperture (FaA), a wireless-first sensing paradigm that repurposes inherent frequency agility into a virtual sensing aperture, enabling near-field perception with minimal RF front end complexity. Using a single RF chain and a frequency-scanning leaky-wave antenna, FaA achieves two dimensional spatial sensing by reusing the local oscillator (LO) frequency sweep already employed for wideband communication. From a wireless-system perspective, this shifts spatial sampling from the antenna domain to the frequency domain, embedding radar-grade spatial fingerprints directly into the communication RF chain. A case study shows that FaA provides fine angular and range discrimination with low power consumption and unit cost, demonstrating significantly higher architectural efficiency than conventional multi-channel MIMO based sensing under identical physical and spectral constraints. These results indicate that near-field sensing can be seamlessly integrated into frequency-agile wireless radios, enabling hardware-efficient, embeddable, and privacy-preserving ISAC nodes for smart homes, wearables, and industrial edge deployments."}
{"id": "2601.21652", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.21652", "abs": "https://arxiv.org/abs/2601.21652", "authors": ["Jingyang Zhao", "Mingyu Xiao"], "title": "Improved Approximations for Dial-a-Ride Problems", "comment": null, "summary": "The multi-vehicle dial-a-ride problem (mDaRP) is a fundamental vehicle routing problem with pickups and deliveries, widely applicable in ride-sharing, economics, and transportation. Given a set of $n$ locations, $h$ vehicles of identical capacity $λ$ located at various depots, and $m$ ride requests each defined by a source and a destination, the goal is to plan non-preemptive routes that serve all requests while minimizing the total travel distance, ensuring that no vehicle carries more than $λ$ passengers at any time. The best-known approximation ratio for the mDaRP remains $\\mathcal{O}(\\sqrtλ\\log m)$.\n  We propose two simple algorithms: the first achieves the same approximation ratio of $\\mathcal{O}(\\sqrtλ\\log m)$ with improved running time, and the second attains an approximation ratio of $\\mathcal{O}(\\sqrt{\\frac{m}λ})$. A combination of them yields an approximation ratio of $\\mathcal{O}(\\sqrt[4]{n}\\log^{\\frac{1}{2}}n)$ under $m=Θ(n)$. Moreover, for the case $m\\gg n$, by extending our algorithms, we derive an $\\mathcal{O}(\\sqrt{n\\log n})$-approximation algorithm, which also improves the current best-known approximation ratio of $\\mathcal{O}(\\sqrt{n}\\log^2n)$ for the classic (single-vehicle) DaRP, obtained by Gupta et al. (ACM Trans. Algorithms, 2010)."}
{"id": "2601.21198", "categories": ["cs.DC", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.21198", "abs": "https://arxiv.org/abs/2601.21198", "authors": ["Yuchen Yang", "Yaru Zhao", "Pu Yang", "Shaowei Wang", "Zhi-Hua Zhou"], "title": "ZipMoE: Efficient On-Device MoE Serving via Lossless Compression and Cache-Affinity Scheduling", "comment": null, "summary": "While Mixture-of-Experts (MoE) architectures substantially bolster the expressive power of large-language models, their prohibitive memory footprint severely impedes the practical deployment on resource-constrained edge devices, especially when model behavior must be preserved without relying on lossy quantization. In this paper, we present ZipMoE, an efficient and semantically lossless on-device MoE serving system. ZipMoE exploits the synergy between the hardware properties of edge devices and the statistical redundancy inherent to MoE parameters via a caching-scheduling co-design with provable performance guarantee. Fundamentally, our design shifts the paradigm of on-device MoE inference from an I/O-bound bottleneck to a compute-centric workflow that enables efficient parallelization. We implement a prototype of ZipMoE and conduct extensive experiments on representative edge computing platforms using popular open-source MoE models and real-world workloads. Our evaluation reveals that ZipMoE achieves up to $72.77\\%$ inference latency reduction and up to $6.76\\times$ higher throughput than the state-of-the-art systems."}
{"id": "2601.21660", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.21660", "abs": "https://arxiv.org/abs/2601.21660", "authors": ["Jingyang Zhao", "Mingyu Xiao"], "title": "Improved Approximations for the Unsplittable Capacitated Vehicle Routing Problem", "comment": null, "summary": "The capacitated vehicle routing problem (CVRP) is one of the most extensively studied problems in combinatorial optimization. In this problem, we are given a depot and a set of customers, each with a demand, embedded in a metric space. The objective is to find a set of tours, each starting and ending at the depot, operated by the capacititated vehicle at the depot to serve all customers, such that all customers are served, and the total travel cost is minimized. We consider the unplittable variant, where the demand of each customer must be served entirely by a single tour. Let $α$ denote the current best-known approximation ratio for the metric traveling salesman problem. The previous best approximation ratio was $α+1+\\ln 2+δ<3.1932$ for a small constant $δ>0$ (Friggstad et al., Math. Oper. Res. 2025), which can be further improved by a small constant using the result of Blauth, Traub, and Vygen (Math. Program. 2023). In this paper, we propose two improved approximation algorithms. The first algorithm focuses on the case of fixed vehicle capacity and achieves an approximation ratio of $α+1+\\ln\\bigl(2-\\frac{1}{2}y_0\\bigr)<3.0897$, where $y_0>0.39312$ is the unique root of $\\ln\\bigl(2-\\frac{1}{2}y\\bigr)=\\frac{3}{2}y$. The second algorithm considers general vehicle capacity and achieves an approximation ratio of $α+1+y_1+\\ln\\left(2-2y_1\\right)+δ<3.1759$ for a small constant $δ>0$, where $y_1>0.17458$ is the unique root of $\\frac{1}{2} y_1+ 6 (1-y_1)\\bigl(1-e^{-\\frac{1}{2} y_1}\\bigr) =\\ln\\left(2-2y_1\\right)$. Both approximations can be further improved by a small constant using the result of Blauth, Traub, and Vygen (Math. Program. 2023)."}
{"id": "2601.21286", "categories": ["cs.DC", "cs.DB"], "pdf": "https://arxiv.org/pdf/2601.21286", "abs": "https://arxiv.org/abs/2601.21286", "authors": ["Adithya Bhat", "Harshal Bhadreshkumar Shah", "Mohsen Minaei"], "title": "Ira: Efficient Transaction Replay for Distributed Systems", "comment": null, "summary": "In primary-backup replication, consensus latency is bounded by the time for backup nodes to replay (re-execute) transactions proposed by the primary. In this work, we present Ira, a framework to accelerate backup replay by transmitting compact \\emph{hints} alongside transaction batches. Our key insight is that the primary, having already executed transactions, possesses knowledge of future access patterns which is exactly the information needed for optimal replay.\n  We use Ethereum for our case study and present a concrete protocol, Ira-L, within our framework to improve cache management of Ethereum block execution. The primaries implementing Ira-L provide hints that consist of the working set of keys used in an Ethereum block and one byte of metadata per key indicating the table to read from, and backups use these hints for efficient block replay.\n  We evaluated Ira-L against the state-of-the-art Ethereum client reth over two weeks of Ethereum mainnet activity ($100,800$ blocks containing over $24$ million transactions). Our hints are compact, adding a median of $47$ KB compressed per block ($\\sim5\\%$ of block payload). We observe that the sequential hint generation and block execution imposes a $28.6\\%$ wall-time overhead on the primary, though the direct cost from hints is $10.9\\%$ of execution time; all of which can be pipelined and parallelized in production deployments. On the backup side, we observe that Ira-L achieves a median per-block speedup of $25\\times$ over baseline reth. With $16$ prefetch threads, aggregate replay time drops from $6.5$ hours to $16$ minutes ($23.6\\times$ wall-time speedup)."}
{"id": "2601.21989", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.21989", "abs": "https://arxiv.org/abs/2601.21989", "authors": ["Edith Cohen", "Elena Gribelyuk", "Jelani Nelson", "Uri Stemmer"], "title": "Adaptively Robust Resettable Streaming", "comment": null, "summary": "We study algorithms in the resettable streaming model, where the value of each key can either be increased or reset to zero. The model is suitable for applications such as active resource monitoring with support for deletions and machine unlearning. We show that all existing sketches for this model are vulnerable to adaptive adversarial attacks that apply even when the sketch size is polynomial in the length of the stream.\n  To overcome these vulnerabilities, we present the first adaptively robust sketches for resettable streams that maintain polylogarithmic space complexity in the stream length. Our framework supports (sub) linear statistics including $L_p$ moments for $p\\in[0,1]$ (in particular, Cardinality and Sum) and Bernstein statistics. We bypass strong impossibility results known for linear and composable sketches by designing dedicated streaming sketches robustified via Differential Privacy. Unlike standard robustification techniques, which provide limited benefits in this setting and still require polynomial space in the stream length, we leverage the Binary Tree Mechanism for continual observation to protect the sketch's internal randomness. This enables accurate prefix-max error guarantees with polylogarithmic space."}
{"id": "2601.21758", "categories": ["cs.DC", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.21758", "abs": "https://arxiv.org/abs/2601.21758", "authors": ["Bronislav Sidik", "Chaya Levi", "Joseph Kampeas"], "title": "EWSJF: An Adaptive Scheduler with Hybrid Partitioning for Mixed-Workload LLM Inference", "comment": null, "summary": "Serving Large Language Models (LLMs) under mixed workloads--short, latency-sensitive interactive queries alongside long, throughput-oriented batch requests--poses a fundamental scheduling challenge. Standard First-Come, First-Served (FCFS) policies suffer from severe head-of-line blocking, leading to high tail latency and underutilized hardware. We introduce EWSJF (Effective Workload-based Shortest Job First), an adaptive request-level scheduler that learns workload structure in real time to jointly improve fairness and throughput. EWSJF operates upstream of execution-level schedulers and integrates four components: (1) Refine-and-Prune, an unsupervised partitioning algorithm that discovers performance-homogeneous request groups; (2) Dynamic Queue Routing for assigning requests to these groups; (3) Density-Weighted Scoring, a context-aware prioritization function balancing urgency and fairness; and (4) Bayesian Meta-Optimization, which continuously tunes scoring and partitioning parameters based on live performance feedback. Implemented in vLLM, EWSJF improves end-to-end throughput by over 30% and reduces average Time-To-First-Token for short requests by up to 4x compared to FCFS. These results demonstrate that adaptive, learning-based request scheduling is a critical missing layer for efficient and responsive LLM serving. Implementation available at https://anonymous.4open.science/r/vllm_0110-32D8."}
{"id": "2601.21855", "categories": ["cs.DC", "cs.DB", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.21855", "abs": "https://arxiv.org/abs/2601.21855", "authors": ["Chuan-Chi Lai"], "title": "Self-Adaptive Probabilistic Skyline Query Processing in Distributed Edge Computing via Deep Reinforcement Learning", "comment": "12 pages, 4 figures, manuscript submitted to IEEE Transactions on Emerging Topics in Computing", "summary": "In the era of the Internet of Everything (IoE), the exponential growth of sensor-generated data at the network edge renders efficient Probabilistic Skyline Query (PSKY) processing a critical challenge. Traditional distributed PSKY methodologies predominantly rely on pre-defined static thresholds to filter local candidates. However, these rigid approaches are fundamentally ill-suited for the highly volatile and heterogeneous nature of edge computing environments, often leading to either severe communication bottlenecks or excessive local computational latency. To resolve this resource conflict, this paper presents SA-PSKY, a novel Self-Adaptive framework designed for distributed edge-cloud collaborative systems. We formalize the dynamic threshold adjustment problem as a continuous Markov Decision Process (MDP) and leverage a Deep Deterministic Policy Gradient (DDPG) agent to autonomously optimize filtering intensities in real-time. By intelligently analyzing multi-dimensional system states, including data arrival rates, uncertainty distributions, and instantaneous resource availability, our framework effectively minimizes a joint objective function of computation and communication costs. Comprehensive experimental evaluations demonstrate that SA-PSKY consistently outperforms state-of-the-art static and heuristic baselines. Specifically, it achieves a reduction of up to 60\\% in communication overhead and 40\\% in total response time, while ensuring robust scalability across diverse data distributions."}
{"id": "2601.21935", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.21935", "abs": "https://arxiv.org/abs/2601.21935", "authors": ["Tom Yates", "Yuzhou Cheng", "Ignacio Alzugaray", "Danyal Akarca", "Pedro A. M. Mediano", "Andrew J. Davison"], "title": "Belief Propagation Converges to Gaussian Distributions in Sparsely-Connected Factor Graphs", "comment": "Preprint. Under review. 25 pages (including Appendix). 8 Figures", "summary": "Belief Propagation (BP) is a powerful algorithm for distributed inference in probabilistic graphical models, however it quickly becomes infeasible for practical compute and memory budgets. Many efficient, non-parametric forms of BP have been developed, but the most popular is Gaussian Belief Propagation (GBP), a variant that assumes all distributions are locally Gaussian. GBP is widely used due to its efficiency and empirically strong performance in applications like computer vision or sensor networks - even when modelling non-Gaussian problems. In this paper, we seek to provide a theoretical guarantee for when Gaussian approximations are valid in highly non-Gaussian, sparsely-connected factor graphs performing BP (common in spatial AI). We leverage the Central Limit Theorem (CLT) to prove mathematically that variables' beliefs under BP converge to a Gaussian distribution in complex, loopy factor graphs obeying our 4 key assumptions. We then confirm experimentally that variable beliefs become increasingly Gaussian after just a few BP iterations in a stereo depth estimation task."}
