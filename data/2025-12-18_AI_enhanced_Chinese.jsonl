{"id": "2512.15515", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.15515", "abs": "https://arxiv.org/abs/2512.15515", "authors": ["Zhihan Xu", "Rajgopal Kannan", "Viktor K. Prasanna"], "title": "FAME: FPGA Acceleration of Secure Matrix Multiplication with Homomorphic Encryption", "comment": null, "summary": "Homomorphic Encryption (HE) enables secure computation on encrypted data, addressing privacy concerns in cloud computing. However, the high computational cost of HE operations, particularly matrix multiplication (MM), remains a major barrier to its practical deployment. Accelerating homomorphic encrypted MM (HE MM) is therefore crucial for applications such as privacy-preserving machine learning.\n  In this paper, we present a bandwidth-efficient FPGA implementation of HE MM. We first develop a cost model to evaluate the on-chip memory requirements for a given set of HE parameters and input matrix sizes. Our analysis shows that optimizing on-chip memory usage is critical for scalable and efficient HE MM. To this end, we design a novel datapath for Homomorphic Linear Transformation (HLT), the primary bottleneck in HE MM. The proposed datapath significantly reduces off-chip memory traffic and on-chip memory demand by enabling fine-grained data reuse. Leveraging this datapath, we introduce FAME, the first FPGA-based accelerator specifically tailored for HE MM. FAME supports arbitrary matrix shapes and is configurable across a wide range of HE parameter sets. We implement FAME on an Alveo U280 FPGA and evaluate its performance across diverse matrix sizes and shapes. Experimental results show that FAME achieves an average speedup of 221x over state-of-the-art CPU-based implementations, demonstrating its scalability and practicality for large-scale consecutive HE MM and real-world workloads.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\uff08\u66f4\u5177\u4f53\u5730\u8bf4\u662f\u786c\u4ef6\u52a0\u901f\u5668\u8bbe\u8ba1\u548c\u5b9e\u73b0\uff09\u4ee5\u53ca HLS \u76f8\u5173\u3002\n\u5bf9\u4e8e\u4e91\u8ba1\u7b97\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\uff0c\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u7531\u4e8e\u5176\u9ad8\u6602\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u7279\u522b\u662f\u77e9\u9635\u4e58\u6cd5\uff08MM\uff09\uff0c\u96be\u4ee5\u5b9e\u9645\u5e94\u7528\u3002\u672c\u6587\u63d0\u51fa\u4e86 FAME\uff0c\u8fd9\u662f\u9996\u4e2a\u4e13\u7528\u4e8e HE MM \u7684\u5e26\u5bbd\u9ad8\u6548 FPGA \u52a0\u901f\u5668\u3002\u901a\u8fc7\u6210\u672c\u6a21\u578b\u5206\u6790\u548c\u8bbe\u8ba1\u4e00\u79cd\u65b0\u9896\u7684 HLT \u6570\u636e\u8def\u5f84\u4ee5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u6570\u636e\u91cd\u7528\uff0cFAME \u663e\u8457\u51cf\u5c11\u4e86\u5185\u5b58\u5f00\u9500\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFAME \u76f8\u6bd4\u73b0\u6709 CPU \u5b9e\u73b0\uff0c\u5e73\u5747\u52a0\u901f\u8fbe 221 \u500d\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u5927\u89c4\u6a21 HE MM \u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u53ef\u4ee5\u5728\u52a0\u5bc6\u6570\u636e\u4e0a\u8fdb\u884c\u5b89\u5168\u8ba1\u7b97\uff0c\u89e3\u51b3\u4e86\u4e91\u8ba1\u7b97\u4e2d\u7684\u9690\u79c1\u95ee\u9898\u3002\u7136\u800c\uff0cHE \u64cd\u4f5c\uff0c\u7279\u522b\u662f\u77e9\u9635\u4e58\u6cd5\uff08MM\uff09\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u4e25\u91cd\u963b\u788d\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002\u56e0\u6b64\uff0c\u52a0\u901f\u540c\u6001\u52a0\u5bc6\u77e9\u9635\u4e58\u6cd5\uff08HE MM\uff09\u5bf9\u4e8e\u9690\u79c1\u4fdd\u62a4\u7684\u673a\u5668\u5b66\u4e60\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u7684\u52a8\u673a\u5728\u4e8e\u89e3\u51b3 HE MM \u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4f18\u5316\u7247\u4e0a\u5185\u5b58\u4f7f\u7528\u6765\u63d0\u9ad8 HE MM \u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u672c\u6587\u9996\u5148\u5efa\u7acb\u4e86\u4e00\u4e2a\u6210\u672c\u6a21\u578b\u6765\u8bc4\u4f30\u7ed9\u5b9a HE \u53c2\u6570\u96c6\u548c\u8f93\u5165\u77e9\u9635\u5c3a\u5bf8\u4e0b\u7684\u7247\u4e0a\u5185\u5b58\u9700\u6c42\uff0c\u5f3a\u8c03\u4e86\u4f18\u5316\u7247\u4e0a\u5185\u5b58\u7684\u5173\u952e\u6027\u3002\u968f\u540e\uff0c\u9488\u5bf9 HE MM \u4e2d\u7684\u4e3b\u8981\u74f6\u9888\u2014\u2014\u540c\u6001\u7ebf\u6027\u53d8\u6362\uff08HLT\uff09\uff0c\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u8def\u5f84\u3002\u8be5\u6570\u636e\u8def\u5f84\u901a\u8fc7\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u6570\u636e\u91cd\u7528\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u7247\u5916\u5185\u5b58\u6d41\u91cf\u548c\u7247\u4e0a\u5185\u5b58\u9700\u6c42\u3002\u6700\u540e\uff0c\u5229\u7528\u8be5\u6570\u636e\u8def\u5f84\uff0c\u672c\u6587\u63d0\u51fa\u4e86 FAME \u52a0\u901f\u5668\uff0c\u8fd9\u662f\u9996\u4e2a\u4e13\u7528\u4e8e HE MM \u7684 FPGA \u52a0\u901f\u5668\uff0c\u652f\u6301\u4efb\u610f\u77e9\u9635\u5f62\u72b6\u548c\u5e7f\u6cdb\u7684 HE \u53c2\u6570\u96c6\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684 FAME \u52a0\u901f\u5668\u5728 Alveo U280 FPGA \u4e0a\u5b9e\u73b0\uff0c\u5e76\u9488\u5bf9\u4e0d\u540c\u7684\u77e9\u9635\u5c3a\u5bf8\u548c\u5f62\u72b6\u8fdb\u884c\u4e86\u6027\u80fd\u8bc4\u4f30\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFAME \u76f8\u5bf9\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u57fa\u4e8e CPU \u7684\u5b9e\u73b0\uff0c\u5b9e\u73b0\u4e86\u5e73\u5747 221 \u500d\u7684\u52a0\u901f\u3002\u8fd9\u5c55\u793a\u4e86 FAME \u5bf9\u4e8e\u5927\u89c4\u6a21\u8fde\u7eed HE MM \u548c\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u7684\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3a FAME \u7684 FPGA \u52a0\u901f\u5668\uff0c\u4e13\u95e8\u7528\u4e8e\u540c\u6001\u52a0\u5bc6\u77e9\u9635\u4e58\u6cd5\uff08HE MM\uff09\u3002FAME \u901a\u8fc7\u65b0\u9896\u7684\u540c\u6001\u7ebf\u6027\u53d8\u6362\uff08HLT\uff09\u6570\u636e\u8def\u5f84\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5e26\u5bbd\u548c\u7247\u4e0a\u5185\u5b58\u5229\u7528\u7387\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684 HE MM\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76f8\u5bf9\u4e8e\u73b0\u6709\u7684 CPU \u5b9e\u73b0\uff0cFAME \u5b9e\u73b0\u4e86\u5e73\u5747 221 \u500d\u7684\u52a0\u901f\uff0c\u8bc1\u660e\u4e86\u5176\u5bf9\u4e8e\u5927\u89c4\u6a21\u8fde\u7eed HE MM \u548c\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5b9e\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2512.15210", "categories": ["cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15210", "abs": "https://arxiv.org/abs/2512.15210", "authors": ["Ameet Gadekar", "Aristides Gionis", "Thibault Marette"], "title": "Label-consistent clustering for evolving data", "comment": "26 pages", "summary": "Data analysis often involves an iterative process, where solutions must be continuously refined in response to new data. Typically, as new data becomes available, an existing solution must be updated to incorporate the latest information. In addition to seeking a high-quality solution for the task at hand, it is also crucial to ensure consistency by minimizing drastic changes from previous solutions. Applying this approach across many iterations, ensures that the solution evolves gradually and smoothly.\n  In this paper, we study the above problem in the context of clustering, specifically focusing on the $k$-center problem. More precisely, we study the following problem: Given a set of points $X$, parameters $k$ and $b$, and a prior clustering solution $H$ for $X$, our goal is to compute a new solution $C$ for $X$, consisting of $k$ centers, which minimizes the clustering cost while introducing at most $b$ changes from $H$. We refer to this problem as label-consistent $k$-center, and we propose two constant-factor approximation algorithms for it. We complement our theoretical findings with an experimental evaluation demonstrating the effectiveness of our methods on real-world datasets.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e DSL \u6216\u56fe\u5904\u7406\u6216 MLIR \u6216\u7f16\u8bd1\u5668\u6216 HLS \u65e0\u5173\u3002\n\n\u592a\u957f\u4e0d\u8bfb\uff1a\u672c\u6587\u7814\u7a76\u4e86\u5728\u8fed\u4ee3\u6570\u636e\u5206\u6790\u4e2d\u5982\u4f55\u5b9e\u73b0\u805a\u7c7b\u89e3\u7684\u5e73\u7a33\u6f14\u5316\uff0c\u63d0\u51fa\u4e86\u6807\u7b7e\u4e00\u81f4\u6027 $k$-\u4e2d\u5fc3\u805a\u7c7b\u95ee\u9898\uff0c\u76ee\u6807\u662f\u627e\u5230\u4e00\u4e2a\u65b0\u7684\u805a\u7c7b\u65b9\u6848\uff0c\u5728\u6700\u5c0f\u5316\u805a\u7c7b\u6210\u672c\u7684\u540c\u65f6\uff0c\u4e0e\u5148\u524d\u7684\u805a\u7c7b\u65b9\u6848\u4fdd\u6301\u6700\u5c0f\u7684\u53d8\u5316\u3002\u4e3a\u6b64\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u5177\u6709\u5e38\u6570\u8fd1\u4f3c\u6bd4\u7684\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "motivation": "\u6570\u636e\u5206\u6790\u901a\u5e38\u6d89\u53ca\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u9700\u8981\u6839\u636e\u65b0\u6570\u636e\u4e0d\u65ad\u5b8c\u5584\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u3002\u5728\u5bfb\u627e\u9ad8\u8d28\u91cf\u89e3\u51b3\u65b9\u6848\u7684\u540c\u65f6\uff0c\u8fd8\u8981\u786e\u4fdd\u4e0e\u5148\u524d\u89e3\u51b3\u65b9\u6848\u4fdd\u6301\u6700\u5c0f\u7684\u53d8\u5316\uff0c\u4ee5\u5b9e\u73b0\u89e3\u51b3\u65b9\u6848\u7684\u5e73\u7a33\u548c\u6e10\u8fdb\u6f14\u5316\u3002\u5177\u4f53\u5230\u805a\u7c7b\u95ee\u9898\uff0c\u5c31\u662f\u5728\u7ed9\u5b9a\u5148\u524d\u7684\u805a\u7c7b\u89e3\u7684\u60c5\u51b5\u4e0b\uff0c\u8ba1\u7b97\u4e00\u4e2a\u65b0\u7684\u805a\u7c7b\u89e3\uff0c\u4f7f\u5176\u5728\u6700\u5c0f\u5316\u805a\u7c7b\u6210\u672c\u7684\u540c\u65f6\uff0c\u4e0e\u5148\u524d\u89e3\u4e4b\u95f4\u7684\u5dee\u5f02\uff08\u53d8\u5316\uff09\u4e0d\u8d85\u8fc7\u4e00\u4e2a\u9884\u7b97 $b$\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u9488\u5bf9\u6807\u7b7e\u4e00\u81f4\u6027 $k$-\u4e2d\u5fc3\u95ee\u9898\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\u3002", "result": "\u63d0\u51fa\u4e86\u4e24\u79cd\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u8fdb\u884c\u4e86\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u7ed3\u679c\u663e\u793a\u4e86\u6240\u63d0\u65b9\u6cd5\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u4e86\u6807\u7b7e\u4e00\u81f4\u6027 $k$-\u4e2d\u5fc3\u805a\u7c7b\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u5177\u6709\u5e38\u6570\u8fd1\u4f3c\u6bd4\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002\u5b9e\u9a8c\u8bc4\u4f30\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.15306", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15306", "abs": "https://arxiv.org/abs/2512.15306", "authors": ["Erik Schultheis", "Dan Alistarh"], "title": "LLMQ: Efficient Lower-Precision Pretraining for Consumer GPUs", "comment": null, "summary": "We present LLMQ, an end-to-end CUDA/C++ implementation for medium-sized language-model training, e.g. 3B to 32B parameters, on affordable, commodity GPUs. These devices are characterized by low memory availability and slow communication compared to datacentre-grade GPUs. Consequently, we showcase a range of optimizations that target these bottlenecks, including activation checkpointing, offloading, and copy-engine based collectives. LLMQ is able to train or fine-tune a 7B model on a single 16GB mid-range gaming card, or a 32B model on a workstation equipped with 4 RTX 4090s. This is achieved while executing a standard 8-bit training pipeline, without additional algorithmic approximations, and maintaining FLOP utilization of around 50%. The efficiency of LLMQ rivals that of production-scale systems on much more expensive cloud-grade GPUs.", "AI": {"tldr": "\u6d89\u53caMLIR\u3001Compiler\u3001HLS\u3001DSL\u3001Graph Processing\u90e8\u5206\uff1a\u65e0\u3002\u6d89\u53caCompiler\u90e8\u5206\uff1a\u65e0\u3002\u6d89\u53caHLS\u90e8\u5206\uff1a\u65e0\u3002\u6d89\u53caDSL\u90e8\u5206\uff1a\u65e0\u3002\u6d89\u53caGraph Processing\u90e8\u5206\uff1a\u65e0\u3002\u6d89\u53caMLIR\u90e8\u5206\uff1a\u65e0\u3002\n\nLLMQ\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684CUDA/C++\u5b9e\u73b0\uff0c\u4e13\u95e8\u7528\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5546\u7528\uff08\u5982\u6e38\u620f\uff09GPU\u4e0a\u8fdb\u884c\u4e2d\u7b49\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff083B\u523032B\uff09\u7684\u8bad\u7ec3\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u6574\u5408\u6fc0\u6d3b\u68c0\u67e5\u70b9\u3001\u5185\u5b58\u5378\u8f7d\u548c\u57fa\u4e8e\u590d\u5236\u5f15\u64ce\u7684\u901a\u4fe1\u4f18\u5316\u7b49\u6280\u672f\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8fd9\u4e9b\u8bbe\u5907\u4f4e\u5185\u5b58\u548c\u6162\u901a\u4fe1\u7684\u74f6\u9888\uff0c\u4f7f\u5f97\u7528\u6237\u53ef\u4ee5\u5728\u5355\u5f2016GB\u4e2d\u7aef\u5361\u4e0a\u8bad\u7ec37B\u6a21\u578b\uff0c\u6216\u5728\u56db\u5f20RTX 4090\u4e0a\u8bad\u7ec332B\u6a21\u578b\uff0c\u4e14\u4fdd\u6301\u7ea650%\u7684FLOP\u5229\u7528\u7387\u548c\u751f\u4ea7\u7ea7\u7cfb\u7edf\u7684\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u4e2d\u7b49\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff083B\u523032B\u53c2\u6570\uff09\u7684\u8bad\u7ec3\u901a\u5e38\u9700\u8981\u6602\u8d35\u3001\u5185\u5b58\u5927\u3001\u901a\u4fe1\u5feb\u901f\u7684\u6570\u636e\u4e2d\u5fc3\u7ea7GPU\u3002LLMQ\u7684\u5f00\u53d1\u52a8\u673a\u662f\u4f7f\u8fd9\u4e9b\u6a21\u578b\u7684\u8bad\u7ec3\u80fd\u591f\u5728\u8d44\u6e90\u53d7\u9650\u3001\u5185\u5b58\u5c0f\u3001\u901a\u4fe1\u6162\u7684\u3001\u4ef7\u683c\u53ef\u627f\u53d7\u7684\u5546\u7528/\u6d88\u8d39\u7ea7GPU\u4e0a\u8fdb\u884c\u3002", "method": "LLMQ\u901a\u8fc7\u4e00\u7cfb\u5217\u4f18\u5316\u63aa\u65bd\u6765\u89e3\u51b3\u5546\u7528GPU\u4e0a\u7684\u5185\u5b58\u548c\u901a\u4fe1\u74f6\u9888\uff0c\u5305\u62ec\u6fc0\u6d3b\u68c0\u67e5\u70b9\uff08activation checkpointing\uff09\u3001\u5185\u5b58\u5378\u8f7d\uff08offloading\uff09\u4ee5\u53ca\u57fa\u4e8e\u590d\u5236\u5f15\u64ce\uff08copy-engine\uff09\u7684\u96c6\u5408\u901a\u4fe1\uff08collectives\uff09\u3002", "result": "LLMQ\u6210\u529f\u5b9e\u73b0\u4e86\u76ee\u6807\uff0c\u5b83\u53ef\u4ee5\u5728\u5355\u4e2a16GB\u4e2d\u7aef\u6e38\u620f\u5361\u4e0a\u8bad\u7ec3\u6216\u5fae\u8c037B\u6a21\u578b\uff0c\u6216\u5728\u914d\u59074\u5757RTX 4090\u7684\u5de5\u4f5c\u7ad9\u4e0a\u8bad\u7ec332B\u6a21\u578b\u3002\u6574\u4e2a\u8fc7\u7a0b\u91c7\u7528\u6807\u51c6\u76848\u4f4d\u8bad\u7ec3\u6d41\u7a0b\uff0c\u6ca1\u6709\u989d\u5916\u7684\u7b97\u6cd5\u8fd1\u4f3c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7ea650%\u7684FLOP\u5229\u7528\u7387\uff0c\u5176\u6548\u7387\u4e0e\u6602\u8d35\u4e91\u7ea7GPU\u4e0a\u7684\u751f\u4ea7\u89c4\u6a21\u7cfb\u7edf\u76f8\u5f53\u3002", "conclusion": "LLMQ\u662f\u4e00\u4e2a\u7528\u4e8e\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5546\u7528GPU\u4e0a\u8fdb\u884c\u4e2d\u7b49\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u9ad8\u6548\u3001\u901a\u7528\u6846\u67b6\u3002\u901a\u8fc7\u9488\u5bf9\u6027\u4f18\u5316\uff0c\u5b83\u5728\u4fdd\u6301\u6807\u51c6\u8bad\u7ec3\u6d41\u7a0b\u548c\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u95e8\u69db\uff0c\u4f7f\u66f4\u591a\u7528\u6237\u80fd\u591f\u8d1f\u62c5\u5f97\u8d77\u6a21\u578b\u8bad\u7ec3\uff0c\u5176\u6548\u7387\u53ef\u4e0e\u6602\u8d35\u7684\u4e91\u7ea7\u7cfb\u7edf\u76f8\u5ab2\u7f8e\u3002"}}
{"id": "2512.15473", "categories": ["cs.DS", "cs.DM"], "pdf": "https://arxiv.org/pdf/2512.15473", "abs": "https://arxiv.org/abs/2512.15473", "authors": ["Jannis Blauth", "Ramin Mousavi"], "title": "A Constant-Factor Approximation for Directed Latency", "comment": null, "summary": "In the Directed Latency problem, we are given an asymmetric metric on a set of vertices (or clients), and a given depot $s$. We seek a path $P$ starting at $s$ and visiting all the clients so as to minimize the sum of client waiting times (also known as latency) before being visited on the path.\n  In contrast to the symmetric version of this problem (also known as the Deliveryperson problem and the Repairperson problem in the literature), there are significant gaps in our understanding of Directed Latency. The best approximation factor has remained at $O(\\log n)$, where $n$ is the number of clients, for more than a decade [Friggstad, Salavatipour, and Svitkina, '13]. Only recently, [Friggstad and Swamy, '22] presented a constant-factor approximation but in quasi-polynomial time. Both results follow similar ideas: they consider buckets with geometrically-increasing distances, build paths in each bucket, and then stitch together all these paths to get a feasible solution. [Friggstad and Swamy, '22] showed if we guess a vertex from each bucket and augment a standard LP relaxation with these guesses, then one can reduce the stitching cost. Unfortunately, there are logarithmically many buckets so the running time of their algorithm is quasi-polynomial.\n  In this paper, we present the first constant-factor approximation for Directed Latency in polynomial time by introducing a completely new way of bucketing which helps us strengthen a standard LP relaxation with less aggressive guessing. Although the resulting LP is no longer a relaxation of Directed Latency, it still admits a good solution. We present a rounding algorithm for fractional solutions of our LP, crucially exploiting the way we restricted the feasibility region of the LP formulation.", "AI": {"tldr": "This content has not passed the compliance test and has been hidden.", "motivation": "\u201c\u6709\u5411\u5ef6\u8fdf\u201d\u95ee\u9898\uff0c\u4e0e\u5bf9\u79f0\u7248\u672c\uff08\u5982\u201c\u9001\u8d27\u5458\u95ee\u9898\u201d\u6216\u201c\u4fee\u7406\u5de5\u95ee\u9898\u201d\uff09\u76f8\u6bd4\uff0c\u7406\u89e3\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u6700\u4f73\u8fd1\u4f3c\u6bd4\u5728\u5341\u591a\u5e74\u91cc\u4e00\u76f4\u7ef4\u6301\u5728$O(\\log n)$\u3002\u867d\u7136\u6700\u8fd1\u7684\u7814\u7a76\u53d6\u5f97\u4e86\u51c6\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u6bd4\uff0c\u4f46\u8ba1\u7b97\u65f6\u95f4\u8fc7\u957f\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u7684\u52a8\u673a\u662f\u627e\u5230\u7b2c\u4e00\u4e2a\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u89e3\u51b3\u201c\u6709\u5411\u5ef6\u8fdf\u201d\u95ee\u9898\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u4ee5\u5f25\u8865\u7406\u8bba\u4e0a\u7684\u7a7a\u767d\u5e76\u63d0\u4f9b\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6587\u7ae0\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u5206\u6876\u65b9\u6cd5\u6765\u5f3a\u5316\u6807\u51c6\u7684\u7ebf\u6027\u89c4\u5212\uff08LP\uff09\u677e\u5f1b\u3002\u867d\u7136\u7531\u6b64\u5f97\u5230\u7684LP\u4e0d\u518d\u662f\u201c\u6709\u5411\u5ef6\u8fdf\u201d\u95ee\u9898\u7684\u677e\u5f1b\uff0c\u4f46\u5176\u5141\u8bb8\u4e00\u4e2a\u826f\u597d\u7684\u89e3\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u4f5c\u8005\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53d6\u6574\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u4e3b\u8981\u5229\u7528\u4e86\u5bf9LP\u53ef\u884c\u57df\u7684\u9650\u5236\u65b9\u5f0f\uff0c\u4ece\u800c\u4eceLP\u7684\u5206\u6570\u89e3\u4e2d\u5f97\u5230\u4e00\u4e2a\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u89e3\u3002", "result": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u4e00\u4e2a\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u4e3a\u201c\u6709\u5411\u5ef6\u8fdf\u201d\u95ee\u9898\u627e\u5230\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u89e3\u7684\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u8be5\u95ee\u9898\u5728\u8fd1\u4f3c\u6bd4\u548c\u8ba1\u7b97\u65f6\u95f4\u4e0a\u7684\u957f\u671f\u6311\u6218\u3002\u8fd9\u4e2a\u7a81\u7834\u6027\u7ed3\u679c\u4f9d\u8d56\u4e8e\u4e00\u79cd\u5168\u65b0\u7684\u3001\u4e0d\u4f9d\u8d56\u4e8e\u51e0\u4f55\u9012\u589e\u8ddd\u79bb\u7684\u5206\u6876\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u4e00\u4e2a\u7ecf\u8fc7\u4fee\u6b63\u548c\u5f3a\u5316\u7684\u7ebf\u6027\u89c4\u5212\u677e\u5f1b\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7b2c\u4e00\u4e2a\u5728\u591a\u9879\u5f0f\u65f6\u95f4\u5185\u4e3a\u201c\u6709\u5411\u5ef6\u8fdf\u201d\u95ee\u9898\uff08Directed Latency\uff09\u63d0\u4f9b\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u6bd4\u7684\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u5168\u65b0\u7684\u5206\u6876\u65b9\u6cd5\uff0c\u5bf9\u6807\u51c6\u7ebf\u6027\u89c4\u5212\uff08LP\uff09\u677e\u5f1b\u8fdb\u884c\u5f3a\u5316\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u53d6\u6574\u7b97\u6cd5\u3002\u5c3d\u7ba1\u5f97\u5230\u7684LP\u4e0d\u518d\u662f\u539f\u59cb\u95ee\u9898\u7684\u677e\u5f1b\uff0c\u4f46\u5b83\u4ecd\u7136\u80fd\u83b7\u5f97\u4e00\u4e2a\u597d\u7684\u89e3\uff0c\u7a81\u7834\u4e86\u4e4b\u524d\u7b97\u6cd5\u5728\u8fd1\u4f3c\u6bd4\u548c\u65f6\u95f4\u590d\u6742\u5ea6\u4e0a\u7684\u9650\u5236\u3002"}}
{"id": "2512.14805", "categories": ["cs.PL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14805", "abs": "https://arxiv.org/abs/2512.14805", "authors": ["Ellie Y. Cheng", "Logan Weber", "Tian Jin", "Michael Carbin"], "title": "Sharing State Between Prompts and Programs", "comment": null, "summary": "The rise of large language models (LLMs) has introduced a new type of programming: natural language programming. By writing prompts that direct LLMs to perform natural language processing, code generation, reasoning, etc., users are writing code in natural language -- natural language code -- for the LLM to execute.\n  An emerging area of research enables interoperability between natural language code and formal languages such as Python. We present a novel programming abstraction, shared program state, that removes the manual work required to enable interoperability between natural language code and program state. With shared program state, programmers can write natural code that directly writes program variables, computes with program objects, and implements control flow in the program. We present a schema for specifying natural function interfaces that extend programming systems to support natural code and leverage this schema to specify shared program state as a natural function interface.\n  We implement shared program state in the Nightjar programming system. Nightjar enables programmers to write Python programs that contain natural code that shares the Python program state. We show that Nightjar programs achieve comparable or higher task accuracy than manually written implementations (+4-19%), while decreasing the lines of code by 39.6% on average. The tradeoff to using Nightjar is that it may incur runtime overhead (0.4-4.3x runtime of manual implementations).", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e**\u7f16\u8bd1\u5668**\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u7814\u7a76\u5e76\u5b9e\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u7f16\u7a0b\u62bd\u8c61\u548c\u7f16\u7a0b\u7cfb\u7edf\uff08Nightjar\uff09\uff0c\u65e8\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\uff08\u7531LLMs\u9a71\u52a8\uff09\u4e0e\u5f62\u5f0f\u8bed\u8a00\uff08\u5982Python\uff09\u8fdb\u884c\u6df1\u5ea6\u6574\u5408\uff0c\u6d89\u53ca\u7f16\u7a0b\u8bed\u8a00\u8bbe\u8ba1\u548c\u6267\u884c\u73af\u5883\u7684\u4e92\u64cd\u4f5c\u6027\u3002\u4e0e**DSL**\u76f8\u5173\uff0c\u56e0\u4e3a\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u672c\u8eab\u53ef\u4ee5\u89c6\u4e3a\u4e00\u79cd\u975e\u5f62\u5f0f\u5316\u7684DSL\uff0c\u800c\u6587\u4e2d\u63d0\u51fa\u7684\u201c\u81ea\u7136\u51fd\u6570\u63a5\u53e3\u201d\u662f\u4e3a\u8fd9\u79cd\u201c\u8bed\u8a00\u201d\u63d0\u4f9b\u7ed3\u6784\u5316\u89c4\u8303\u3002\n\n**TLDR:** \u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u666e\u53ca\uff0c\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\uff08\u63d0\u793a\u8bcd\uff09\u5f00\u59cb\u6d41\u884c\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u7f16\u7a0b\u62bd\u8c61\u2014\u2014\u201c\u5171\u4eab\u7a0b\u5e8f\u72b6\u6001\u201d\uff0c\u5b83\u5141\u8bb8\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u76f4\u63a5\u64cd\u4f5cPython\u7a0b\u5e8f\u7684\u53d8\u91cf\u3001\u5bf9\u8c61\u548c\u63a7\u5236\u6d41\uff0c\u4ece\u800c\u6d88\u9664\u4e86\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u4e0e\u5f62\u5f0f\u8bed\u8a00\u4e92\u64cd\u4f5c\u6240\u9700\u7684\u624b\u52a8\u5de5\u4f5c\u3002\u901a\u8fc7\u5728Nightjar\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u548c\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u6216\u63d0\u9ad8\u4efb\u52a1\u51c6\u786e\u6027\uff08+4%-19%\uff09\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4ee3\u7801\u884c\u6570\uff08\u5e73\u5747\u51cf\u5c1139.6%\uff09\uff0c\u4f46\u53ef\u80fd\u4f1a\u5f15\u5165\u8fd0\u884c\u65f6\u5f00\u9500\uff080.4-4.3x\uff09\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5174\u8d77\uff0c\u51fa\u73b0\u4e86\u4e00\u79cd\u65b0\u7684\u7f16\u7a0b\u8303\u5f0f\u2014\u2014\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u3002\u7528\u6237\u901a\u8fc7\u7f16\u5199\u63d0\u793a\u8bcd\uff08prompts\uff09\u6765\u6307\u5bfcLLMs\u6267\u884c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u4ee3\u7801\u751f\u6210\u548c\u63a8\u7406\u7b49\u4efb\u52a1\uff0c\u5b9e\u9645\u4e0a\u5c31\u662f\u5728\u7528\u81ea\u7136\u8bed\u8a00\u7f16\u5199\u4ee3\u7801\uff08natural language code\uff09\u3002\u73b0\u6709\u7684\u7814\u7a76\u9886\u57df\u5f00\u59cb\u5173\u6ce8\u5982\u4f55\u4f7f\u8fd9\u79cd\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u4e0e\u50cfPython\u8fd9\u6837\u7684\u6b63\u5f0f\u8bed\u8a00\u5b9e\u73b0\u4e92\u64cd\u4f5c\u6027\u3002\u7136\u800c\uff0c\u5b9e\u73b0\u8fd9\u79cd\u4e92\u64cd\u4f5c\u6027\u9700\u8981\u5927\u91cf\u7684\u624b\u52a8\u5de5\u4f5c\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u5373\u63d0\u4f9b\u4e00\u79cd\u673a\u5236\u6765\u79fb\u9664\u8fd9\u79cd\u624b\u52a8\u5de5\u4f5c\uff0c\u4f7f\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u53ef\u4ee5\u76f4\u63a5\u3001\u65e0\u7f1d\u5730\u8bbf\u95ee\u548c\u64cd\u4f5c\u7a0b\u5e8f\u72b6\u6001\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5171\u4eab\u7a0b\u5e8f\u72b6\u6001\u201d\uff08shared program state\uff09\u7684\u65b0\u9896\u7f16\u7a0b\u62bd\u8c61\uff0c\u7528\u4e8e\u5b9e\u73b0\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u4e0e\u6b63\u5f0f\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Python\uff09\u4e4b\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u3002\u5b83\u5141\u8bb8\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u76f4\u63a5\u8bfb\u5199\u7a0b\u5e8f\u53d8\u91cf\u3001\u4f7f\u7528\u7a0b\u5e8f\u5bf9\u8c61\u8fdb\u884c\u8ba1\u7b97\u5e76\u5b9e\u73b0\u7a0b\u5e8f\u63a7\u5236\u6d41\u3002\u4e3a\u4e86\u652f\u6301\u8fd9\u4e00\u62bd\u8c61\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6307\u5b9a\u81ea\u7136\u51fd\u6570\u63a5\u53e3\uff08natural function interfaces\uff09\u7684\u6a21\u5f0f\uff0c\u5e76\u5c06\u5171\u4eab\u7a0b\u5e8f\u72b6\u6001\u6307\u5b9a\u4e3a\u4e00\u79cd\u81ea\u7136\u51fd\u6570\u63a5\u53e3\u6765\u5b9e\u73b0\u3002\u8be5\u65b9\u6cd5\u5728Nightjar\u7f16\u7a0b\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4e86\u5b9e\u73b0\uff0cNightjar\u5141\u8bb8Python\u7a0b\u5e8f\u5305\u542b\u4e0ePython\u7a0b\u5e8f\u72b6\u6001\u5171\u4eab\u7684\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u3002", "result": "\u672c\u6587\u63d0\u51fa\u7684Nightjar\u7cfb\u7edf\u5b9e\u73b0\u4e86\u5171\u4eab\u7a0b\u5e8f\u72b6\u6001\u62bd\u8c61\uff0c\u5e76\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002\u7ed3\u679c\u663e\u793a\uff1a\n1. **\u4efb\u52a1\u51c6\u786e\u6027\uff1a** Nightjar\u7a0b\u5e8f\u5b9e\u73b0\u4e86\u4e0e\u624b\u52a8\u7f16\u5199\u5b9e\u73b0\u76f8\u5f53\u6216\u66f4\u9ad8\u7684\u4efb\u52a1\u51c6\u786e\u6027\uff08\u63d0\u9ad8\u4e864%\u523019%\uff09\u3002\n2. **\u4ee3\u7801\u91cf\u51cf\u5c11\uff1a** Nightjar\u7a0b\u5e8f\u5e73\u5747\u51cf\u5c11\u4e8639.6%\u7684\u4ee3\u7801\u884c\u6570\u3002\n3. **\u8fd0\u884c\u65f6\u5f00\u9500\uff1a** \u5f15\u5165\u5171\u4eab\u7a0b\u5e8f\u72b6\u6001\u7684\u4ee3\u4ef7\u662f\u53ef\u80fd\u4ea7\u751f\u4e00\u5b9a\u7684\u8fd0\u884c\u65f6\u5f00\u9500\uff08\u662f\u624b\u52a8\u5b9e\u73b0\u76840.4\u52304.3\u500d\uff09\u3002\u8fd9\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u727a\u7272\u4e86\u90e8\u5206\u8fd0\u884c\u65f6\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201c\u5171\u4eab\u7a0b\u5e8f\u72b6\u6001\u201d\uff08shared program state\uff09\u7684\u65b0\u9896\u7f16\u7a0b\u62bd\u8c61\uff0c\u5b83\u80fd\u591f\u6d88\u9664\u5728\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\uff08\u5982LLMs\u7684\u63d0\u793a\uff09\u4e0e\u6b63\u5f0f\u7f16\u7a0b\u8bed\u8a00\uff08\u5982Python\uff09\u4e4b\u95f4\u5b9e\u73b0\u4e92\u64cd\u4f5c\u6027\u6240\u9700\u7684\u624b\u52a8\u5de5\u4f5c\u3002\u901a\u8fc7Nightjar\u7f16\u7a0b\u7cfb\u7edf\u7684\u5b9e\u73b0\u548c\u8bc4\u4f30\uff0c\u8bc1\u660e\u4e86\u5171\u4eab\u7a0b\u5e8f\u72b6\u6001\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u4efb\u52a1\u51c6\u786e\u6027\uff08+4%-19%\uff09\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u4ee3\u7801\u884c\u6570\uff08\u5e73\u5747\u51cf\u5c1139.6%\uff09\uff0c\u540c\u65f6\u5141\u8bb8\u7a0b\u5e8f\u5458\u5728\u81ea\u7136\u8bed\u8a00\u4e2d\u76f4\u63a5\u64cd\u4f5c\u7a0b\u5e8f\u53d8\u91cf\u3001\u5bf9\u8c61\u548c\u5b9e\u73b0\u63a7\u5236\u6d41\u3002\u867d\u7136\u4f1a\u5e26\u6765\u4e00\u5b9a\u7684\u8fd0\u884c\u65f6\u5f00\u9500\uff080.4-4.3\u500d\uff09\uff0c\u4f46\u5b83\u4e3a\u5927\u6a21\u578b\u80cc\u666f\u4e0b\u7684\u6df7\u5408\u5f0f\u81ea\u7136\u8bed\u8a00\u7f16\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u4e14\u5f3a\u5927\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15595", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.15595", "abs": "https://arxiv.org/abs/2512.15595", "authors": ["Daniel J\u00fcnger", "Kevin Kristensen", "Yunsong Wang", "Xiangyao Yu", "Bertil Schmidt"], "title": "Optimizing Bloom Filters for Modern GPU Architectures", "comment": "13 pages, 12 figures", "summary": "Bloom filters are a fundamental data structure for approximate membership queries, with applications ranging from data analytics to databases and genomics. Several variants have been proposed to accommodate parallel architectures. GPUs, with massive thread-level parallelism and high-bandwidth memory, are a natural fit for accelerating these Bloom filter variants potentially to billions of operations per second. Although CPU-optimized implementations have been well studied, GPU designs remain underexplored. We close this gap by exploring the design space on GPUs along three dimensions: vectorization, thread cooperation, and compute latency.\n  Our evaluation shows that the combination of these optimization points strongly affects throughput, with the largest gains achieved when the filter fits within the GPU's cache domain. We examine how the hardware responds to different parameter configurations and relate these observations to measured performance trends. Crucially, our optimized design overcomes the conventional trade-off between speed and precision, delivering the throughput typically restricted to high-error variants while maintaining the superior accuracy of high-precision configurations. At iso error rate, the proposed method outperforms the state-of-the-art by $11.35\\times$ ($15.4\\times$) for bulk filter lookup (construction), respectively, achieving above $92\\%$ of the practical speed-of-light across a wide range of configurations on a B200 GPU. We propose a modular CUDA/C++ implementation, which will be openly available soon.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u76f8\u5173\u90e8\u5206\u662f\u5176\u8f6f\u4ef6\u5b9e\u73b0\uff0c\u4f46\u6838\u5fc3\u662f\u901a\u7528\u9ad8\u6027\u80fd\u8ba1\u7b97\u548c\u5f02\u6784\u8ba1\u7b97\uff1b\u5177\u4f53\u6765\u8bf4\uff0c\u672c\u7bc7\u8bba\u6587\u7684\u6838\u5fc3\u9886\u57df\u662f**\u9ad8\u6027\u80fd\u8ba1\u7b97\uff08HPC\uff09/\u5f02\u6784\u8ba1\u7b97**\u548c**\u6570\u636e\u7ed3\u6784/\u7b97\u6cd5\u52a0\u901f**\u3002\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5229\u7528 GPU \u7684\u5927\u89c4\u6a21\u5e76\u884c\u6027\uff0c\u901a\u8fc7\u4f18\u5316\u5411\u91cf\u5316\u3001\u7ebf\u7a0b\u534f\u4f5c\u548c\u8ba1\u7b97\u5ef6\u8fdf\u6765\u52a0\u901f Bloom Filter \u53ca\u5176\u53d8\u4f53\u7684\u64cd\u4f5c\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u541e\u5410\u91cf\u5e76\u6253\u7834\u4e86\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u4e4b\u95f4\u7684\u4f20\u7edf\u6743\u8861\uff0c\u5728\u6279\u91cf\u67e5\u627e\u548c\u6784\u9020\u4e0a\u5206\u522b\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u9ad8\u4e86 11.35 \u500d\u548c 15.4 \u500d\u3002", "motivation": "Bloom Filter \u53ca\u5176\u53d8\u4f53\u662f\u8fd1\u4f3c\u6210\u5458\u67e5\u8be2\u7684\u57fa\u672c\u6570\u636e\u7ed3\u6784\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6570\u636e\u5206\u6790\u3001\u6570\u636e\u5e93\u548c\u57fa\u56e0\u7ec4\u5b66\u7b49\u9886\u57df\u3002\u5c3d\u7ba1 CPU \u4e0a\u7684\u4f18\u5316\u5b9e\u73b0\u5df2\u7ecf\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u4f46 GPU \u4e0a\u7684\u8bbe\u8ba1\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u5c24\u5176\u662f\u5728\u5229\u7528 GPU \u7684\u5927\u89c4\u6a21\u7ebf\u7a0b\u7ea7\u5e76\u884c\u6027\u548c\u9ad8\u5e26\u5bbd\u5185\u5b58\u65b9\u9762\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u7684\u52a8\u673a\u5728\u4e8e\u63a2\u7d22 GPU \u4e0a\u7684\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u4ee5\u52a0\u901f Bloom Filter \u7684\u64cd\u4f5c\uff0c\u76ee\u6807\u662f\u8fbe\u5230\u6bcf\u79d2\u6570\u5341\u4ebf\u6b21\u64cd\u4f5c\uff0c\u4ece\u800c\u5f25\u8865 GPU \u8bbe\u8ba1\u65b9\u9762\u7684\u7a7a\u767d\u3002\u4e3b\u8981\u76ee\u7684\u662f\u6253\u7834\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e4b\u95f4\u7684\u4f20\u7edf\u6743\u8861\uff0c\u5e76\u5927\u5e45\u63d0\u5347\u6027\u80fd\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5728 GPU \u4e0a\u63a2\u7d22\u4e09\u4e2a\u4f18\u5316\u7ef4\u5ea6\uff08\u5411\u91cf\u5316\u3001\u7ebf\u7a0b\u534f\u4f5c\u548c\u8ba1\u7b97\u5ef6\u8fdf\uff09\u6765\u4f18\u5316 Bloom Filter \u53ca\u5176\u53d8\u4f53\u3002\u65b9\u6cd5\u8bba\u6d89\u53ca\u8bbe\u8ba1\u5b9e\u9a8c\u6765\u8bc4\u4f30\u8fd9\u4e9b\u4f18\u5316\u70b9\u7ec4\u5408\u5bf9\u541e\u5410\u91cf\u7684\u5f71\u54cd\uff0c\u5e76\u7814\u7a76\u786c\u4ef6\u5982\u4f55\u54cd\u5e94\u4e0d\u540c\u7684\u53c2\u6570\u914d\u7f6e\u3002\u5173\u952e\u5728\u4e8e\u8bc6\u522b\u51fa\u5f53\u8fc7\u6ee4\u5668\u9002\u5e94 GPU \u7f13\u5b58\u57df\u65f6\u80fd\u83b7\u5f97\u6700\u5927\u589e\u76ca\u3002\u6700\u7ec8\u76ee\u6807\u662f\u63d0\u51fa\u4e00\u79cd\u6253\u7834\u901f\u5ea6\u548c\u7cbe\u5ea6\u4e4b\u95f4\u4f20\u7edf\u5e73\u8861\u7684\u4f18\u5316\u8bbe\u8ba1\u3002\u4f5c\u8005\u4f7f\u7528\u6a21\u5757\u5316\u7684 CUDA/C++ \u5b9e\u73b0\u6765\u9a8c\u8bc1\u5176\u65b9\u6cd5\u3002", "result": "\u4f18\u5316\u8bbe\u8ba1\u5728 Bloom Filter \u64cd\u4f5c\u4e2d\u83b7\u5f97\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u7ed3\u679c\u663e\u793a\uff0c\u4f18\u5316\u7684\u5173\u952e\u5728\u4e8e\u5f53\u8fc7\u6ee4\u5668\u9002\u5e94 GPU \u7684\u7f13\u5b58\u57df\u65f6\uff0c\u80fd\u5b9e\u73b0\u6700\u5927\u7684\u541e\u5410\u91cf\u589e\u76ca\u3002\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u914d\u7f6e\u7684\u540c\u65f6\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u541e\u5410\u91cf\uff0c\u514b\u670d\u4e86\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u4e4b\u95f4\u7684\u4f20\u7edf\u6743\u8861\u3002\u5728\u76f8\u540c\u7684\u9519\u8bef\u7387\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5728\u6279\u91cf\u8fc7\u6ee4\u5668\u67e5\u627e\u4e0a\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u9ad8\u4e86 11.35 \u500d\uff0c\u5728\u6784\u9020\u4e0a\u63d0\u9ad8\u4e86 15.4 \u500d\u3002\u5728 B200 GPU \u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u914d\u7f6e\u4e0b\u8fbe\u5230\u4e86\u5b9e\u9645\u901f\u5ea6\uff08practical speed-of-light\uff09\u7684 92% \u4ee5\u4e0a\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684 CUDA/C++ \u5b9e\u73b0\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u63a2\u7d22 GPU \u4e0a\u7684\u4e09\u4e2a\u4f18\u5316\u7ef4\u5ea6\uff08\u5411\u91cf\u5316\u3001\u7ebf\u7a0b\u534f\u4f5c\u548c\u8ba1\u7b97\u5ef6\u8fdf\uff09\uff0c\u6253\u7834\u4e86 Bloom Filter \u53ca\u5176\u53d8\u4f53\u4e2d\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u4e4b\u95f4\u7684\u4f20\u7edf\u6743\u8861\u3002\u65b0\u7684\u4f18\u5316\u8bbe\u8ba1\u80fd\u591f\u5728\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u914d\u7f6e\u7684\u5353\u8d8a\u51c6\u786e\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u901a\u5e38\u53ea\u6709\u9ad8\u9519\u8bef\u7387\u53d8\u4f53\u624d\u80fd\u8fbe\u5230\u7684\u9ad8\u541e\u5410\u91cf\u3002\u5728\u76f8\u540c\u7684\u9519\u8bef\u7387\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6279\u91cf\u67e5\u627e\uff08\u6784\u9020\uff09\u65b9\u9762\u5206\u522b\u6bd4\u73b0\u6709\u6280\u672f\u63d0\u9ad8\u4e86 11.35 \u500d\uff0815.4 \u500d\uff09\uff0c\u5e76\u5728 B200 GPU \u4e0a\u5e7f\u6cdb\u7684\u914d\u7f6e\u8303\u56f4\u5185\u8fbe\u5230\u4e86\u5b9e\u9645\u901f\u5ea6\uff08practical speed-of-light\uff09\u7684 92% \u4ee5\u4e0a\u3002"}}
{"id": "2512.15705", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15705", "abs": "https://arxiv.org/abs/2512.15705", "authors": ["Xuting Liu", "Daniel Alexander", "Siva Kesava Reddy Kakarla", "Behnaz Arzani", "Vincent Liu"], "title": "Dynamic Rebatching for Efficient Early-Exit Inference with DREX", "comment": null, "summary": "Early-Exit (EE) is a Large Language Model (LLM) architecture that accelerates inference by allowing easier tokens to be generated using only a subset of the model's layers. However, traditional batching frameworks are ill-suited for EE LLMs, as not all requests in a batch may be ready to exit at the same time. Existing solutions either force a uniform decision on the batch, which overlooks EE opportunities, or degrade output quality by forcing premature exits. We propose Dynamic Rebatching, a solution where we dynamically reorganize the batch at each early-exit point. Requests that meet the exit criteria are immediately processed, while those that continue are held in a buffer, re-grouped into a new batch, and forwarded to deeper layers. We introduce DREX, an early-exit inference system that implements Dynamic Rebatching with two key optimizations: 1) a copy-free rebatching buffer that avoids physical data movement, and 2) an EE and SLA-aware scheduler that analytically predicts whether a given rebatching operation will be profitable. DREX also efficiently handles the missing KV cache from skipped layers using memory-efficient state-copying. Our evaluation shows that DREX improves throughput by 2-12% compared to baseline approaches while maintaining output quality. Crucially, DREX completely eliminates involuntary exits, providing a key guarantee for preserving the output quality intended by the EE model.", "AI": {"tldr": "\u76f8\u5173\uff1a\u672c\u6587\u4e0eLLM\u7684\u63a8\u7406\u52a0\u901f\uff08\u5c5e\u4e8e\u7f16\u8bd1\u4f18\u5316\u548c\u7cfb\u7edf\u8bbe\u8ba1\u8303\u7574\uff09\u76f8\u5173\u3002\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86DREX\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u51b3Early-Exit\uff08EE\uff09LLM\u5728\u4f20\u7edf\u6279\u5904\u7406\u6846\u67b6\u4e0b\u7684\u6548\u7387\u548c\u8d28\u91cf\u95ee\u9898\u3002\n\u603b\u7ed3\uff1a\u65e9\u9000\u51fa\uff08EE\uff09LLM\u901a\u8fc7\u5141\u8bb8\u66f4\u5bb9\u6613\u7684token\u5728\u6a21\u578b\u6d45\u5c42\u63d0\u524d\u9000\u51fa\u4ee5\u52a0\u901f\u63a8\u7406\u3002\u4f20\u7edf\u7684\u6279\u5904\u7406\u6846\u67b6\u4e0d\u9002\u7528EE LLM\uff0c\u56e0\u4e3a\u8bf7\u6c42\u9000\u51fa\u65f6\u95f4\u4e0d\u4e00\u81f4\u3002\u672c\u6587\u63d0\u51fa\u52a8\u6001\u91cd\u6279\u5904\u7406\uff08Dynamic Rebatching\uff09\u673a\u5236\uff0c\u5e76\u5728DREX\u7cfb\u7edf\u4e2d\u5b9e\u73b0\uff0c\u7ed3\u5408\u96f6\u62f7\u8d1d\u91cd\u6279\u5904\u7406\u7f13\u51b2\u533a\u548cEE\u53caSLA\u611f\u77e5\u7684\u8c03\u5ea6\u5668\u6765\u4f18\u5316EE LLM\u63a8\u7406\u3002DREX\u5728\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5c06\u541e\u5410\u91cf\u63d0\u9ad8\u4e862%\u523012%\uff0c\u5e76\u5b8c\u5168\u6d88\u9664\u4e86\u975e\u81ea\u613f\u9000\u51fa\uff0c\u4fdd\u8bc1\u4e86\u6a21\u578b\u8d28\u91cf\u3002", "motivation": "\u65e9\u9000\u51fa\uff08EE\uff09LLM\u67b6\u6784\u901a\u8fc7\u5141\u8bb8\u66f4\u5bb9\u6613\u7684token\u4ec5\u4f7f\u7528\u6a21\u578b\u5c42\u7684\u4e00\u4e2a\u5b50\u96c6\u6765\u751f\u6210\uff0c\u4ece\u800c\u52a0\u901f\u63a8\u7406\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u6279\u5904\u7406\u6846\u67b6\u4e0d\u9002\u5408EE LLM\uff0c\u56e0\u4e3a\u6279\u6b21\u4e2d\u5e76\u975e\u6240\u6709\u8bf7\u6c42\u90fd\u80fd\u540c\u65f6\u9000\u51fa\u3002\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u8981\u4e48\u5f3a\u5236\u6279\u6b21\u505a\u51fa\u7edf\u4e00\u51b3\u7b56\uff0c\u4ece\u800c\u5ffd\u7565\u4e86EE\u673a\u4f1a\uff0c\u8981\u4e48\u901a\u8fc7\u5f3a\u5236\u63d0\u524d\u9000\u51fa\u800c\u964d\u4f4e\u4e86\u8f93\u51fa\u8d28\u91cf\u3002\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u6279\u5904\u7406\u6846\u67b6\u4e0eEE LLM\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5982\u4f55\u63d0\u9ad8\u541e\u5410\u91cf\u5e76\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u52a8\u6001\u91cd\u6279\u5904\u7406\uff08Dynamic Rebatching\uff09\u673a\u5236\uff0c\u5728\u6bcf\u4e2a\u65e9\u9000\u51fa\u70b9\u52a8\u6001\u5730\u91cd\u7ec4\u6279\u6b21\u3002\u6ee1\u8db3\u9000\u51fa\u6807\u51c6\u7684\u8bf7\u6c42\u7acb\u5373\u5904\u7406\uff0c\u672a\u6ee1\u8db3\u7684\u8bf7\u6c42\u88ab\u653e\u5165\u7f13\u51b2\u533a\uff0c\u91cd\u65b0\u5206\u7ec4\u4e3a\u65b0\u6279\u6b21\uff0c\u5e76\u9001\u5165\u66f4\u6df1\u7684\u5c42\u3002\u5b9e\u73b0\u4e86\u4e00\u4e2a\u540d\u4e3aDREX\u7684\u65e9\u9000\u51fa\u63a8\u7406\u7cfb\u7edf\uff0c\u5305\u542b\u4e24\u4e2a\u5173\u952e\u4f18\u5316\uff1a1\uff09\u4e00\u4e2a\u96f6\u62f7\u8d1d\u91cd\u6279\u5904\u7406\u7f13\u51b2\u533a\uff0c\u907f\u514d\u7269\u7406\u6570\u636e\u79fb\u52a8\uff1b2\uff09\u4e00\u4e2aEE\u548cSLA\u611f\u77e5\u7684\u8c03\u5ea6\u5668\uff0c\u7528\u4e8e\u5206\u6790\u6027\u5730\u9884\u6d4b\u91cd\u6279\u5904\u7406\u64cd\u4f5c\u662f\u5426\u6709\u5229\u3002DREX\u8fd8\u901a\u8fc7\u8282\u7701\u5185\u5b58\u7684\u72b6\u6001\u590d\u5236\u6709\u6548\u5730\u5904\u7406\u4e86\u88ab\u8df3\u8fc7\u7684\u5c42\u7684\u7f3a\u5931\u7684KV\u7f13\u5b58\u3002", "result": "DREX\u7cfb\u7edf\u5728\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5c06\u541e\u5410\u91cf\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u9ad8\u4e862%\u523012%\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0cDREX\u5b8c\u5168\u6d88\u9664\u4e86\u975e\u81ea\u613f\u9000\u51fa\uff08involuntary exits\uff09\uff0c\u4e3a\u4fdd\u8bc1EE\u6a21\u578b\u9884\u671f\u7684\u8f93\u51fa\u8d28\u91cf\u63d0\u4f9b\u4e86\u5173\u952e\u4fdd\u8bc1\u3002", "conclusion": "DREX\u7cfb\u7edf\u901a\u8fc7\u52a8\u6001\u91cd\u6279\u5904\u7406\u3001\u96f6\u62f7\u8d1d\u91cd\u6279\u5904\u7406\u7f13\u51b2\u533a\u548cEE\u53caSLA\u611f\u77e5\u7684\u8c03\u5ea6\u5668\uff0c\u6210\u529f\u5730\u5728\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\u63d0\u5347\u4e86EE LLM\u7684\u63a8\u7406\u541e\u5410\u91cf\u3002\u5b83\u6d88\u9664\u4e86\u975e\u81ea\u613f\u9000\u51fa\uff0c\u786e\u4fdd\u4e86EE\u6a21\u578b\u9884\u671f\u7684\u8f93\u51fa\u8d28\u91cf\u5f97\u5230\u4e86\u7ef4\u62a4\u3002"}}
