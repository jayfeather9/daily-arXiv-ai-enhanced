{"id": "2601.09114", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09114", "abs": "https://arxiv.org/abs/2601.09114", "authors": ["Yufan Xia", "Marco De La Pierre", "Amanda S. Barnard", "Giuseppe Maria Junior Barca"], "title": "A Machine Learning Approach Towards Runtime Optimisation of Matrix Multiplication", "comment": "2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS)", "summary": "The GEneral Matrix Multiplication (GEMM) is one of the essential algorithms in scientific computing. Single-thread GEMM implementations are well-optimised with techniques like blocking and autotuning. However, due to the complexity of modern multi-core shared memory systems, it is challenging to determine the number of threads that minimises the multi-thread GEMM runtime. We present a proof-of-concept approach to building an Architecture and Data-Structure Aware Linear Algebra (ADSALA) software library that uses machine learning to optimise the runtime performance of BLAS routines. More specifically, our method uses a machine learning model on-the-fly to automatically select the optimal number of threads for a given GEMM task based on the collected training data. Test results on two different HPC node architectures, one based on a two-socket Intel Cascade Lake and the other on a two-socket AMD Zen 3, revealed a 25 to 40 per cent speedup compared to traditional GEMM implementations in BLAS when using GEMM of memory usage within 100 MB."}
{"id": "2601.09146", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09146", "abs": "https://arxiv.org/abs/2601.09146", "authors": ["Lingkang Shangguan"], "title": "Transaction-Driven Dynamic Reconfiguration for Certificate-Based Payment Systems", "comment": "draft initial version", "summary": "We present a transaction-driven dynamic reconfiguration protocol in Modern payment systems based on Byzantine Consistent Broadcast which can achieve high performance by avoiding global transaction ordering. We demonstrate the fundamental paradigm of modern payment systems, which combines user nonce based transactions ordering with periodic system-wide consensus mechanisms. Building on this foundation, we design PDCC(Payment Dynamic Config Change), which can lead a smooth reconfiguration process without impacting the original system's performance."}
{"id": "2601.09184", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2601.09184", "abs": "https://arxiv.org/abs/2601.09184", "authors": ["Yifei Xie", "Btissam Er-Rahmadi", "Xiao Chen", "Tiejun Ma", "Jane Hillston"], "title": "Optimizing View Change for Byzantine Fault Tolerance in Parallel Consensus", "comment": null, "summary": "The parallel Byzantine Fault Tolerant (BFT) protocol is viewed as a promising solution to address the consensus scalability issue of the permissioned blockchain. One of the main challenges in parallel BFT is the view change process that happens when the leader node fails, which can lead to performance bottlenecks. Existing parallel BFT protocols typically rely on passive view change mechanisms with blind leader rotation. Such approaches frequently select unavailable or slow nodes as leaders, resulting in degraded performance. To address these challenges, we propose a View Change Optimization (VCO) model based on mixed integer programming that optimizes leader selection and follower reassignment across parallel committees by considering communication delays and failure scenarios. We applied a decomposition method with efficient subproblems and improved benders cuts to solve the VCO model. Leveraging the results of improved decomposition solution method, we propose an efficient iterative backup leader selection algorithm as views proceed. By performing experiments in Microsoft Azure cloud environments, we demonstrate that the VCO-driven parallel BFT outperforms existing configuration methods under both normal operation and faulty condition. The results show that the VCO model is effective as network size increases, making it a suitable solution for high-performance parallel BFT systems."}
{"id": "2601.09258", "categories": ["cs.DC", "cs.LG", "cs.OS"], "pdf": "https://arxiv.org/pdf/2601.09258", "abs": "https://arxiv.org/abs/2601.09258", "authors": ["Du Yin", "Jiayi Ren", "Xiayu Sun", "Tianyao Zhou", "Haizhu Zhou", "Ruiyan Ma", "Danyang Zhang"], "title": "LatencyPrism: Online Non-intrusive Latency Sculpting for SLO-Guaranteed LLM Inference", "comment": "12 pages, 6 figures", "summary": "LLM inference latency critically determines user experience and operational costs, directly impacting throughput under SLO constraints. Even brief latency spikes degrade service quality despite acceptable average performance. However, distributed inference environments featuring diverse software frameworks and XPU architectures combined with dynamic workloads make latency analysis challenging. Constrained by intrusive designs that necessitate service restarts or even suspension, and by hardware-bound implementations that fail to adapt to heterogeneous inference environments, existing AI profiling methods are often inadequate for real-time production analysis.\n  We present LatencyPrism, the first zero-intrusion multi-platform latency sculpting system. It aims to break down the inference latency across pipeline, proactively alert on inference latency anomalies, and guarantee adherence to SLOs, all without requiring code modifications or service restarts. LatencyPrism has been deployed across thousands of XPUs for over six months. It enables low-overhead real-time monitoring at batch level with alerts triggered in milliseconds. This approach distinguishes between workload-driven latency variations and anomalies indicating underlying issues with an F1-score of 0.98. We also conduct extensive experiments and investigations into root cause analysis to demonstrate LatencyPrism's capability."}
{"id": "2601.08989", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.08989", "abs": "https://arxiv.org/abs/2601.08989", "authors": ["Matteo Caporrella", "Stefano Leucci"], "title": "An Almost-Optimal Upper Bound on the Push Number of the Torus Puzzle", "comment": "22 pages, 8 figures", "summary": "We study the Torus Puzzle, a solitaire game in which the elements of an input $m \\times n$ matrix need to be rearranged into a target configuration via a sequence of unit rotations (i.e., circular shifts) of rows and/or columns. Amano et al.\\ proposed a more permissive variant of the above puzzle, where each row and column rotation can shift the involved elements by any amount of positions. The number of rotations needed to solve the puzzle in the original and in the permissive variants of the puzzle are respectively known as the \\emph{push number} and the \\emph{drag number}, where the latter is always smaller than or equal to the former and admits an existential lower bound of $Ω(mn)$. While this lower bound is matched by an $O(mn)$ upper bound, the push number is not so well understood. Indeed, to the best of our knowledge, only an $O(mn \\cdot \\max\\{ m, n \\})$ upper bound is currently known. In this paper, we provide an algorithm that solves the Torus Puzzle using $O(mn \\cdot \\log \\max \\{m, n\\})$ unit rotations in a model that is more restricted than that of the original puzzle. This implies a corresponding upper bound on the push number and reduces the gap between the known upper and lower bounds from $Θ(\\max\\{m,n\\})$ to $Θ(\\log \\max\\{m, n\\})$."}
{"id": "2601.09217", "categories": ["cs.PL", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.09217", "abs": "https://arxiv.org/abs/2601.09217", "authors": ["Izumi Tanaka", "Ken Sakayori", "Shinya Takamaeda-Yamazaki", "Naoki Kobayashi"], "title": "Relational Hoare Logic for High-Level Synthesis of Hardware Accelerators", "comment": "An extended version of the paper to appear in Proceedings of ESOP 2026", "summary": "High-level synthesis (HLS) is a powerful tool for developing efficient hardware accelerators that rely on specialized memory systems to achieve sufficient on-chip data reuse and off-chip bandwidth utilization. However, even with HLS, designing such systems still requires careful manual tuning, as automatic optimizations provided by existing tools are highly sensitive to programming style and often lack transparency. To address these issues, we present a formal translation framework based on relational Hoare logic, which enables robust and transparent transformations. Our method recognizes complex memory access patterns in naïve HLS programs and automatically transforms them by inserting on-chip buffers to enforce linear access to off-chip memory, and by replacing non-sequential processing with stream processing, while preserving program semantics. Experiments using our prototype translator, combined with an off-the-shelf HLS compiler and a real FPGA board, have demonstrated significant performance improvements."}
{"id": "2601.09002", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.09002", "abs": "https://arxiv.org/abs/2601.09002", "authors": ["Peter M. Kogge"], "title": "Annotated PIM Bibliography", "comment": "Initial version. Will be updated with more references and detail in future releases", "summary": "Processing in Memory (PIM) and similar terms such as Compute In Memory (CIM), Logic in Memory (LIM), In Memory Computing (IMC), and Near Memory Computing (NMC) have gained attention recently as a potentially ``revolutionary new'' technique. The truth, however, is that many examples of the technology go back over 60 years. This document attempts to provide an annotated bibliography of PIM technology that attempts to cover the whole time-frame, and is organized to augment a forth-coming article."}
{"id": "2601.09334", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09334", "abs": "https://arxiv.org/abs/2601.09334", "authors": ["Valerio Besozzi", "Matteo Della Bartola", "Patrizio Dazzi", "Marco Danelutto"], "title": "High-Performance Serverless Computing: A Systematic Literature Review on Serverless for HPC, AI, and Big Data", "comment": null, "summary": "The widespread deployment of large-scale, compute-intensive applications such as high-performance computing, artificial intelligence, and big data is leading to convergence between cloud and high-performance computing infrastructures. Cloud providers are increasingly integrating high-performance computing capabilities in their infrastructures, such as hardware accelerators and high-speed interconnects, while researchers in the high-performance computing community are starting to explore cloud-native paradigms to improve scalability, elasticity, and resource utilization. In this context, serverless computing emerges as a promising execution model to efficiently handle highly dynamic, parallel, and distributed workloads. This paper presents a comprehensive systematic literature review of 122 research articles published between 2018 and early 2025, exploring the use of the serverless paradigm to develop, deploy, and orchestrate compute-intensive applications across cloud, high-performance computing, and hybrid environments. From these, a taxonomy comprising eight primary research directions and nine targeted use case domains is proposed, alongside an analysis of recent publication trends and collaboration networks among authors, highlighting the growing interest and interconnections within this emerging research field. Overall, this work aims to offer a valuable foundation for both new researchers and experienced practitioners, guiding the development of next-generation serverless solutions for parallel compute-intensive applications."}
{"id": "2601.09081", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.09081", "abs": "https://arxiv.org/abs/2601.09081", "authors": ["Zekun Wang", "Binghao Yue", "Weitao Pan", "Jianyi Shi", "Yue Hao"], "title": "A Grouped Sorting Queue Supporting Dynamic Updates for Timer Management in High-Speed Network Interface Cards", "comment": null, "summary": "With the hardware offloading of network functions, network interface cards (NICs) undertake massive stateful, high-precision, and high-throughput tasks, where timers serve as a critical enabling component. However, existing timer management schemes suffer from heavy software load, low precision, lack of hardware update support, and overflow. This paper proposes two novel operations for priority queues--update and group sorting--to enable hardware timer management. To the best of our knowledge, this work presents the first hardware priority queue to support an update operation through the composition and propagation of basic operations to modify the priorities of elements within the queue. The group sorting mechanism ensures correct timing behavior post-overflow by establishing a group boundary priority to alter the sorting process and element insertion positions. Implemented with a hybrid architecture of a one-dimension (1D) systolic array and shift registers, our design is validated through packet-level simulations for flow table timeout management. Results demonstrate that a 4K-depth, 16-bit timer queue achieves over 500 MHz (175 Mpps, 12 ns precision) in a 28nm process and over 300 MHz (116 Mpps) on an FPGA. Critically, it reduces LUTs and FFs usage by 31% and 25%, respectively, compared to existing designs."}
{"id": "2601.09583", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2601.09583", "abs": "https://arxiv.org/abs/2601.09583", "authors": ["Berke Ates", "Philipp Schaad", "Timo Schneider", "Alexandru Calotoiu", "Torsten Hoefler"], "title": "MLIR-Forge: A Modular Framework for Language Smiths", "comment": null, "summary": "Optimizing compilers are essential for the efficient and correct execution of software across various scientific fields. Domain-specific languages (DSL) typically use higher level intermediate representations (IR) in their compiler pipelines for domain-specific optimizations. As these IRs add to complexity, it is crucial to test them thoroughly. Random program generators have proven to be an effective tool to test compilers through differential and fuzz testing. However, developing specialized program generators for compiler IRs is not straightforward and demands considerable resources. We introduce MLIR-Forge, a novel random program generator framework that leverages the flexibility of MLIR, aiming to simplify the creation of specialized program generators. MLIR-Forge achieves this by splitting the generation process into fundamental building blocks that are language specific, and reusable program creation logic that constructs random programs from these building blocks. This hides complexity and furthermore, even the language specific components can be defined using a set of common tools. We demonstrate MLIR-Forge's capabilities by generating MLIR with built-in dialects, WebAssembly, and a data-centric program representation, DaCe -- requiring less than a week of development time in total for each of them. Using the generated programs we conduct differential testing and find 9 MLIR, 15 WebAssembly, and 774 DaCe groups of bugs with the corresponding program generators, after running them until the rate of new bugs stagnates."}
{"id": "2601.09139", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.09139", "abs": "https://arxiv.org/abs/2601.09139", "authors": ["Gramoz Goranci", "Monika Henzinger", "Peter Kiss", "Ali Momeni", "Gernot Zöcklein"], "title": "Dynamic Hierarchical $j$-Tree Decomposition and Its Applications", "comment": "SODA 2026", "summary": "We develop a new algorithmic framework for designing approximation algorithms for cut-based optimization problems on capacitated undirected graphs that undergo edge insertions and deletions. Specifically, our framework dynamically maintains a variant of the hierarchical $j$-tree decomposition of [Madry FOCS'10], achieving a poly-logarithmic approximation factor to the graph's cut structure and supporting edge updates in $O(n^ε)$ amortized update time, for any arbitrarily small constant $ε\\in (0,1)$.\n  Consequently, we obtain new trade-offs between approximation and update/query time for fundamental cut-based optimization problems in the fully dynamic setting, including all-pairs minimum cuts, sparsest cut, multi-way cut, and multi-cut. For the last three problems, these trade-offs give the first fully-dynamic algorithms achieving poly-logarithmic approximation in sub-linear time per operation.\n  The main technical ingredient behind our dynamic hierarchy is a dynamic cut-sparsifier algorithm that can handle vertex splits with low recourse. This is achieved by white-boxing the dynamic cut sparsifier construction of [Abraham et al. FOCS'16], based on forest packing, together with new structural insights about the maintenance of these forests under vertex splits. Given the versatility of cut sparsification in both the static and dynamic graph algorithms literature, we believe this construction may be of independent interest."}
{"id": "2601.09289", "categories": ["cs.DS", "cs.CC", "math.CO"], "pdf": "https://arxiv.org/pdf/2601.09289", "abs": "https://arxiv.org/abs/2601.09289", "authors": ["Takashi Horiyama", "Takehiro Ito", "Jun Kawahara", "Shin-ichi Minato", "Akira Suzuki", "Ryuhei Uehara", "Yutaro Yamaguchi"], "title": "Computational Complexity of Swish", "comment": "10 pages, 5 figures", "summary": "Swish is a card game in which players are given cards having symbols (hoops and balls), and find a valid superposition of cards, called a \"swish.\" Dailly, Lafourcade, and Marcadet (FUN 2024) studied a generalized version of Swish and showed that the problem is solvable in polynomial time with one symbol per card, while it is NP-complete with three or more symbols per card. In this paper, we resolve the previously open case of two symbols per card, which corresponds to the original game. We show that Swish is NP-complete for this case. Specifically, we prove the NP-hardness when the allowed transformations of cards are restricted to a single (horizontal or vertical) flip or 180-degree rotation, and extend the results to the original setting allowing all three transformations. In contrast, when neither transformation is allowed, we present a polynomial-time algorithm. Combining known and our results, we establish a complete characterization of the computational complexity of Swish with respect to both the number of symbols per card and the allowed transformations."}
{"id": "2601.09477", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.09477", "abs": "https://arxiv.org/abs/2601.09477", "authors": ["Joel Andersson", "Matti Karppa"], "title": "Engineering Compressed Matrix Multiplication with the Fast Walsh-Hadamard Transform", "comment": "23 pages", "summary": "We present an implementation of Pagh's compressed matrix multiplication algorithm, a randomized algorithm that constructs sketches of matrices to compute an unbiased estimate of their product. By leveraging fast polynomial multiplication via the FFT, the algorithm achieves high performance when the product matrix is sparse or contains only a small number of entries with magnitudes significantly larger than the rest. We show empirically that the algorithm is practical and can outperform state-of-the-art DGEMM implementations when the product matrix has few nonzero entries or is otherwise dominated by a small subset of elements with large magnitude. As a minor theoretical contribution, we replace the FFT with the Fast Walsh-Hadamard Transform (FWHT) in sketched multiplication, preserving all correctness and variance guarantees of the original algorithm.\n  Experiments with our carefully engineered multithreaded CPU implementation for dense double-precision matrices on 64-core CPU nodes across a range of synthetic benchmarks, exhibiting variable sparsity patterns, show that the FWHT variant is up to 4 times faster than the FFT-based version. Under favorable sparsity and magnitude patterns in the product matrix, our FWHT-based implementation achieves a speedup of up to 40 over DGEMM from Intel MKL, with low probability of error in the estimates. Our implementation is released as free software and comes with NumPy-compatible Python bindings."}
{"id": "2601.09489", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2601.09489", "abs": "https://arxiv.org/abs/2601.09489", "authors": ["Peyman Afshani", "Rezaul Chowdhury", "Inge Li Gørtz", "Mayank Goswami", "Francesco Silvestri", "Mariafiore Tognon"], "title": "How many users have been here for a long time? Efficient solutions for counting long aggregated visits", "comment": null, "summary": "This paper addresses the Counting Long Aggregated Visits problem, which is defined as follows. We are given $n$ users and $m$ regions, where each user spends some time visiting some regions. For a parameter $k$ and a query consisting of a subset of $r$ regions, the task is to count the number of distinct users whose aggregate time spent visiting the query regions is at least $k$. This problem is motivated by queries arising in the analysis of large-scale mobility datasets. We present several exact and approximate data structures for supporting counting long aggregated visits, as well as conditional and unconditional lower bounds. First, we describe an exact data structure that exhibits a space-time tradeoff, as well as efficient approximate solutions based on sampling and sketching techniques. We then study the problem in geometric settings where regions are points in $\\mathbb{R}^d$ and queries are hyperrectangles, and derive exact data structures that achieve improved performance in these structured spaces."}
{"id": "2601.09577", "categories": ["cs.DS", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09577", "abs": "https://arxiv.org/abs/2601.09577", "authors": ["MD Nazmul Alam Shanto", "Md. Tanzeem Rahat", "Md. Manzurul Hasan"], "title": "Permutation Matching Under Parikh Budgets: Linear-Time Detection, Packing, and Disjoint Selection", "comment": "12 pages (Excluding reference)", "summary": "We study permutation (jumbled/Abelian) pattern matching over a general alphabet $Σ$. Given a pattern P of length m and a text T of length n, the classical task is to decide whether T contains a length-m substring whose Parikh vector equals that of P . While this existence problem admits a linear-time sliding-window solution, many practical applications require optimization and packing variants beyond mere detection. We present a unified sliding-window framework based on maintaining the Parikh-vector difference between P and the current window of T , enabling permutation matching in O(n + σ) time and O(σ) space, where σ = |Σ|. Building on this foundation, we introduce a combinatorial-optimization variant that we call Maximum Feasible Substring under Pattern Supply (MFSP): find the longest substring S of T whose symbol counts are component-wise bounded by those of P . We show that MFSP can also be solved in O(n + σ) time via a two-pointer feasibility maintenance algorithm, providing an exact packing interpretation of P as a resource budget. Finally, we address non-overlapping occurrence selection by modeling each permutation match as an equal-length interval and proving that a greedy earliest-finishing strategy yields a maximum-cardinality set of disjoint matches, computable in linear time once all matches are enumerated. Our results provide concise, provably correct algorithms with tight bounds, and connect frequency-based string matching to packing-style optimization primitives."}
