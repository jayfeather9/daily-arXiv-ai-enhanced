<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 3]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Finding $b$-colorings Using Feedback Edges](https://arxiv.org/abs/2512.14390)
*Jakub Balabán*

Main category: cs.DS

TL;DR: The paper is related to graph processing. The paper investigates the parameterized complexity of the $b$-coloring problem. The main findings are that $b$-coloring is Fixed-Parameter Tractable (FPT) when parameterized by the feedback edge number (a parameter more restrictive than treewidth, measuring similarity to trees) and when parameterized by the distance to co-cluster (measuring similarity to complete multipartite graphs). It also confirms that $b$-coloring is W[$1$]-hard when parameterized by tree-depth.


<details>
  <summary>Details</summary>
Motivation: $b$-着色问题在一般情况下是 NP-完全的，但在树上是多项式时间可解的。此前的研究表明，对于 $b$-着色问题，只有少数参数（如点覆盖数）可以得到 FPT 算法。而基于树宽的参数化是 W[$t$]-难的。因此，本文旨在找到更具限制性的、能导致 $b$-着色问题在固定参数可解的参数化，以更好地理解其复杂性。

Method: 本文首先证明了基于反馈边数参数的 $b$-着色问题是 FPT，该算法结合了参数化算法的标准技术和树上多项式时间算法的特定想法。其次，本文证明了基于到共聚类距离参数的 $b$-着色问题是 FPT。最后，本文基于已知结果提出了关于树深参数化的 $b$-着色问题的观察。

Result: 本文取得了两个主要结果：1. 基于反馈边数（一个比树宽更严格的、衡量与树相似性的参数）参数化的 $b$-着色问题是固定参数可解的（FPT）。2. 基于到共聚类距离（一个衡量与完全多部图相似性的参数）参数化的 $b$-着色问题是 FPT。此外，本文还观察到基于树深参数化的 $b$-着色问题是 W[$1$]-难的。

Conclusion: 本文研究了图的 $b$-着色问题的参数化复杂度。主要结论是基于反馈边数和到共聚类的距离这两个参数，$b$-着色问题是固定参数可解的（FPT）。此外，本文还观察到基于树深参数的 $b$-着色问题是 W[$1$]-难的。

Abstract: A $b$-coloring of a graph is a proper vertex coloring such that each color class contains a vertex that sees all other colors in its neighborhood. The $b$-coloring problem, in which the task is to decide whether a graph admits a $b$-coloring with $k$ colors, is NP-complete in general but polytime solvable on trees. Moreover, it is known that $b$-coloring is in XP but W[$t$]-hard for all $t \in \mathbb{N}$ when parameterized by tree-width. In fact, only very few parameters, such as the vertex cover number, were known to admit an FPT algorithm for $b$-coloring. In this paper, we consider a more restrictive parameter measuring similarity to trees than tree-width, namely the feedback edge number, and show that $b$-coloring is fixed-parameter tractable under this parameterization. Our algorithm combines standard techniques used in parameterized algorithmics with the problem-specific ideas used in the polytime algorithm for trees. In addition, we present an FPT algorithm for $b$-coloring parameterized by distance to co-cluster, which is a parameter measuring similarity to complete multipartite graphs. Finally, we make several observations based on known results, including that $b$-coloring is W[$1$]-hard when parameterized by tree-depth.

</details>


### [2] [Cost-Free Neutrality for the River Method](https://arxiv.org/abs/2512.14409)
*Michelle Döring,Jannes Malanowski,Stefan Neubert*

Main category: cs.DS

TL;DR: 该论文与DSL或图处理或MLIR或编译器或HLS不相关。本文介绍了《河流方法》，它是《分裂循环投票规则》的一种改进，并与《排名对方法》相似。它们都通过消除边缘图中的多数循环来选择获胜者。为了恢复中立性，论文考虑了“并行宇宙破平局”（PUT），但计算具有PUT的《排名对方法》是NP完全的。本文的主要贡献是提出了一个多项式时间算法（被称为“融合宇宙”或FUN算法）来计算具有PUT的《河流方法》的获胜者。这表明《河流方法》在结构上优于《排名对方法》。


<details>
  <summary>Details</summary>
Motivation: 《河流方法》和广为人知的《排名对方法》都通过消除投票者偏好计算得出的边缘图中的多数循环来选出获胜者。然而，由于边缘图中可能存在平局，需要一个破平局规则。使用破平局规则虽然提高了计算效率，却损害了中立性（即不应事先偏袒任何候选者）。为了重新引入中立性，可以使用并行宇宙破平局（PUT），其中如果某个选项在任何可能的破平局规则下获胜，则它就是获胜者。然而，计算具有PUT的《排名对方法》获胜者是NP完全的。鉴于《河流方法》与《排名对方法》的相似性，人们可能会预期《河流方法》也会面临同样的复杂性问题。因此，本文的动机是探索《河流方法》是否具有相似的复杂性，并试图找到一种有效的计算方法。

Method: 作者提出了一种名为“融合宇宙”（FUN）的多项式时间算法，该算法能够一次性模拟每种可能的破平局情况下的《河流方法》计算。通过由此产生的FUN图，可以直接读出获胜者集合，并为每个获胜者提供一个解释其如何优于其他选项的证明。

Result: 证明了与具有PUT的《排名对方法》是NP完全问题相反，计算具有并行宇宙破平局（PUT）的《河流方法》获胜者可以在多项式时间内完成。作者提出了一个名为“融合宇宙”（FUN）的多项式时间算法来解决此问题，并能够为获胜者提供解释其优势的证明。

Conclusion: 《河流方法》在引入并行宇宙破除平局（PUT）后，计算其获胜者可以在多项式时间内完成，这与计算具有PUT的《排名对方法》是NP完全问题形成了鲜明对比。这表明《河流方法》相对于《排名对方法》具有显著的结构优势。

Abstract: Recently, the River Method was introduced as novel refinement of the Split Cycle voting rule.
  The decision-making process of River is closely related to the well established Ranked Pairs Method.
  Both methods consider a margin graph computed from the voters' preferences and eliminate majority cycles in that graph to choose a winner.
  As ties can occur in the margin graph, a tiebreaker is required along with the preferences.
  While such a tiebreaker makes the computation efficient, it compromises the fundamental property of neutrality: the voting rule should not favor alternatives in advance.
  One way to reintroduce neutrality is to use Parallel-Universe Tiebreaking (PUT), where each alternative is a winner if it wins according to any possible tiebreaker.
  Unfortunately, computing the winners selected by Ranked Pairs with PUT is NP-complete.
  Given the similarity of River to Ranked Pairs, one might expect River to suffer from the same complexity.
  Surprisingly, we show the opposite:
  We present a polynomial-time algorithm for computing River winners with PUT, highlighting significant structural advantages of River over Ranked Pairs.
  Our Fused-Universe (FUN) algorithm simulates River for every possible tiebreaking in one pass.
  From the resulting FUN diagram one can then directly read off both the set of winners and, for each winner, a certificate that explains how this alternative dominates the others.

</details>


### [3] [An Improved Approximation Algorithm for Maximum Weight 3-Path Packing](https://arxiv.org/abs/2512.14457)
*Jingyang Zhao,Mingyu Xiao*

Main category: cs.DS

TL;DR: 与抽象中所述的重点领域（DSL、图处理、MLIR、编译器、HLS）相关的是图处理。该论文侧重于图论中的近似算法的设计和分析，特别是最大权 3-路径填充问题，这是一个图优化问题。

**TL;DR:** (1) The paper is related to **graph processing** (specifically, a graph optimization problem: maximum weight 3-path packing). (2) An improved approximation algorithm with a ratio of $10/17$ is proposed for the maximum weight 3-path packing problem in complete graphs where $n$ is divisible by 3, beating the previous best ratio of $7/12$. The result is achieved by combining three distinct algorithms (based on maximum weight matchings of size $n/2$ and $n/3$, and star packing) and introducing a new analytical technique called the "charging method."


<details>
  <summary>Details</summary>
Motivation: 解决最大权 3-路径填充问题，并在理论上改进其近似比。该问题是最大权匹配问题的推广。先前的最佳近似算法保持的近似比是 $7/12$，本文旨在提高这一比率。

Method: 提出了一种 $10/17$-近似算法，该算法结合了三种不同的方法：1. 基于大小为 $n/2$ 的最大权匹配（与先前最佳算法相同）。2. 基于大小为 $n/3$ 的最大权匹配。3. 基于星型填充（star packing）的近似算法。对于第一种方法，提出了一种新的分析技术——“充电方法”，该方法对分析第二种方法至关重要。通过在这三种算法之间进行权衡（trade-off）来获得最终的近似比。

Result: 提出了一种 $10/17$-近似算法，将最大权 3-路径填充问题的近似比从已知的最佳 $7/12$ 提高到了 $10/17$。同时，提出了一种新的基于最大权匹配的分析方法——“充电方法”。

Conclusion: 本文解决了最大权 3-路径填充问题，该问题是最大权匹配问题的推广。通过提出一种结合了三种方法的 $10/17$-近似算法，改进了此前最佳的 $7/12$-近似比率。新提出的基于最大权匹配的分析方法——“充电方法”——不仅对分析新算法至关重要，也可能推广到分析相关问题。

Abstract: Given a complete graph with $n$ vertices and non-negative edge weights, where $n$ is divisible by 3, the maximum weight 3-path packing problem is to find a set of $n/3$ vertex-disjoint 3-paths such that the total weight of the 3-paths in the packing is maximized. This problem is closely related to the classic maximum weight matching problem. In this paper, we propose a $10/17$-approximation algorithm, improving the best-known $7/12$-approximation algorithm (ESA 2015). Our result is obtained by making a trade-off among three algorithms. The first is based on the maximum weight matching of size $n/2$, the second is based on the maximum weight matching of size $n/3$, and the last is based on an approximation algorithm for star packing. Our first algorithm is the same as the previous $7/12$-approximation algorithm, but we propose a new analysis method -- a charging method -- for this problem, which is not only essential to analyze our second algorithm but also may be extended to analyze algorithms for some related problems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [4] [A Hybrid Reactive-Proactive Auto-scaling Algorithm for SLA-Constrained Edge Computing](https://arxiv.org/abs/2512.14290)
*Suhrid Gupta,Muhammed Tawfiqul Islam,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 涉及边缘计算、微服务、Kubernetes、自动伸缩算法、机器学习。
一种用于SLA受限边缘计算应用的新型混合自动伸缩算法被提出。该算法结合了基于ML的主动预测和基于当前资源利用率的被动调整，并作为扩展集成到Kubernetes中。实验证明，该方法将SLA违规率从现有解决方案的23%降低到6%，显著提高了SLA合规性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 边缘计算中的微服务架构需要低延迟来满足严格的服务水平协议（SLA）。虽然混合云和边缘环境通过Kubernetes等协调策略实现资源管理，但现有的自动伸缩算法存在性能问题和配置复杂性，且无法保证SLA的遵守，导致SLA违规率较高（文中提到高达23%）。因此，需要一种新的自动伸缩算法来确保SLA合规性。

Method: 提出了一种新颖的自动伸缩算法，用于受SLA约束的边缘计算应用。该算法结合了基于机器学习（ML）的预测性自动伸缩算法（能够预测传入的资源请求以预测需求）和被动伸缩器（考虑当前的资源利用率和SLA约束进行即时调整）。该算法作为扩展集成到Kubernetes中。

Result: 所提出的混合自动伸缩算法在边缘环境下的实际应用中进行了广泛实验评估。结果显示，现有解决方案的SLA违规率高达23%，而所提出的混合解决方案的SLA违规率仅为6%。这表明新方法在确保各种应用的稳定SLA合规性方面显著优于基线方法。

Conclusion: 本文提出了一种混合自动伸缩算法，用于解决边缘计算环境中传统自动伸缩算法存在的SLA违规率高和配置复杂的问题。实验结果证明，该混合方法优于基线解决方案，SLA违规率仅为6%，显著低于现有解决方案的23%，从而确保了各种应用的稳定SLA合规性。

Abstract: Edge computing decentralizes computing resources, allowing for novel applications in domains such as the Internet of Things (IoT) in healthcare and agriculture by reducing latency and improving performance. This decentralization is achieved through the implementation of microservice architectures, which require low latencies to meet stringent service level agreements (SLA) such as performance, reliability, and availability metrics. While cloud computing offers the large data storage and computation resources necessary to handle peak demands, a hybrid cloud and edge environment is required to ensure SLA compliance. This is achieved by sophisticated orchestration strategies such as Kubernetes, which help facilitate resource management. The orchestration strategies alone do not guarantee SLA adherence due to the inherent delay of scaling resources. Existing auto-scaling algorithms have been proposed to address these challenges, but they suffer from performance issues and configuration complexity. In this paper, a novel auto-scaling algorithm is proposed for SLA-constrained edge computing applications. This approach combines a Machine Learning (ML) based proactive auto-scaling algorithm, capable of predicting incoming resource requests to forecast demand, with a reactive autoscaler which considers current resource utilization and SLA constraints for immediate adjustments. The algorithm is integrated into Kubernetes as an extension, and its performance is evaluated through extensive experiments in an edge environment with real applications. The results demonstrate that existing solutions have an SLA violation rate of up to 23%, whereas the proposed hybrid solution outperforms the baselines with an SLA violation rate of only 6%, ensuring stable SLA compliance across various applications.

</details>


### [5] [Performance and Stability of Barrier Mode Parallel Systems with Heterogeneous and Redundant Jobs](https://arxiv.org/abs/2512.14445)
*Brenton Walker,Markus Fidler*

Main category: cs.DC

TL;DR: 该论文与图处理（Apache Spark 是一个流行的图处理和数据处理引擎）、编译器（并行计算和调度优化相关）、MLIR（与编译器和高性能计算相关）有关。它分析了并行计算模型中的同步屏障（例如 Apache Spark 的 Barrier Execution Mode）对系统稳定性和性能的影响。作者分析了不同屏障系统的稳定性，导出了混合屏障系统的性能界限，并将理论结果与Spark基准数据进行比较，并调查了真实系统中的开销原因（归因于调度机制）。


<details>
  <summary>Details</summary>
Motivation: 在许多并行化机器学习工作负载中，并行任务存在约束，要求它们同步启动，并可能同步离开。流行的 Apache Spark 处理引擎最近添加了对 Barrier Execution Mode 的支持，允许用户向其作业添加此类屏障。然而，这些屏障不可避免地导致部分工作节点处于空闲状态，从而降低了系统的稳定性和性能。因此，本文旨在考虑和分析由同步屏障导致的稳定性和性能损失，并探索其在实际系统中的表现和潜在原因。

Method: 本文首先考虑并分析了同步屏障对并行计算系统稳定性和性能造成的损失。特别分析了 $(s,k,l)$ 屏障系统的稳定性，该系统允许作业在其 $k$ 个任务中的 $l$ 个完成后离开。其次，推导并评估了混合屏障系统（服务于有屏障和无屏障作业的混合体，具有不同程度的并行性）的性能界限。最后，对于纯粹的 1 屏障情况，将界限和模拟结果与独立的 Spark 系统中的基准数据进行了比较，研究了真实系统中的开销，并基于开销的分布将其归因于用于调度屏障模式作业的双重事件和轮询驱动机制。并针对性地开发了一个模型，并对照真实系统进行模拟验证。

Result: 研究了允许部分任务完成后离开的 $(s,k,l)$ 屏障系统的稳定性，并推导并评估了混合屏障系统的性能界限。对于纯粹的 1 屏障情况，性能界限和模拟结果与独立的 Spark 系统的基准数据进行了比较。在真实系统中，观察到的开销被归因于用于调度屏障模式作业的双重事件和轮询驱动机制。作者最终开发了一个模型来预测和验证这种类型的开销。

Conclusion: 本文分析了并行计算中同步屏障对稳定性和性能的影响。研究了允许部分任务完成后离开的屏障系统的稳定性，以及混合屏障系统（包含有屏障和无屏障作业）的性能界限。对于纯粹的 1 屏障情况，将界限和模拟结果与独立的 Spark 系统的基准数据进行了比较，并研究了真实系统中的开销。最后，作者认为开销源于 Spark 中用于调度屏障模式作业的双重事件和轮询驱动机制，并构建了一个模型来验证。

Abstract: In some models of parallel computation, jobs are split into smaller tasks and can be executed completely asynchronously. In other situations the parallel tasks have constraints that require them to synchronize their start and possibly departure times. This is true of many parallelized machine learning workloads, and the popular Apache Spark processing engine has recently added support for Barrier Execution Mode, which allows users to add such barriers to their jobs. These barriers necessarily result in idle periods on some of the workers, which reduces their stability and performance, compared to equivalent workloads with no barriers.
  In this paper we will consider and analyze the stability and performance penalties resulting from barriers. We include an analysis of the stability of $(s,k,l)$ barrier systems that allow jobs to depart after $l$ out of $k$ of their tasks complete. We also derive and evaluate performance bounds for hybrid barrier systems servicing a mix of jobs, both with and without barriers, and with varying degrees of parallelism. For the purely 1-barrier case we compare the bounds and simulation results to benchmark data from a standalone Spark system. We study the overhead in the real system, and based on its distribution we attribute it to the dual event and polling-driven mechanism used to schedule barrier-mode jobs. We develop a model for this type of overhead and validate it against the real system through simulation.

</details>


### [6] [PruneX: A Hierarchical Communication-Efficient System for Distributed CNN Training with Structured Pruning](https://arxiv.org/abs/2512.14628)
*Alireza Olama,Andreas Lundell,Izzat El Hajj,Johan Lilius,Jerker Björkqvist*

Main category: cs.DC

TL;DR: 该论文与编译器、DL/ML/AI 相关。DL/ML/AI 相关部分是其提出的 PruneX 系统用于解决分布式训练中的通信瓶颈问题。
该论文提出了一种名为 PruneX 的分布式数据并行训练系统，通过协同设计剪枝算法和集群层次结构来减少节点间通信带宽的使用。PruneX 引入了分层结构化 ADMM（H-SADMM）算法，在进行节点间同步前强制执行节点级结构化稀疏性，从而实现动态缓冲压缩，显著减少了通信量 (约 60%)。系统采用 leader-follower 执行模型，将密集集合操作应用于压缩后的张量，实现了相对于密集基线和 Top-K 梯度压缩更好的强扩展性加速比（6.75 倍）。


<details>
  <summary>Details</summary>
Motivation: 在大规模多节点 GPU 集群上进行分布式训练时，节点间的通信带宽日益成为瓶颈。传统的剪枝感知分布式训练系统无法有效减少通信开销，因为高度优化的密集集合通信原语（collective primitives）不能高效地利用非结构化稀疏性。因此，需要设计一种新的系统来减少节点间的通信带宽使用。

Method: PruneX 提出的方法是协同设计剪枝算法和集群层次结构，以减少节点间带宽的使用。具体包括：1. 引入分层结构化 ADMM（H-SADMM）算法，在节点间同步前强制执行节点级结构化稀疏性。2. H-SADMM 算法实现了动态缓冲区压缩，消除了零值传输和索引开销。3. 系统采用“领导者-追随者”（leader-follower）执行模型，分离节点内和节点间进程组，在带宽受限的链路上对压缩后的张量执行密集集合操作，同时将完全同步限制在高带宽的节点内互连上。

Result: 在 64 个 GPU 上对 ResNet 架构的评估结果显示，PruneX 将节点间通信量减少了约 60%。在 Puhti 超级计算机上，PruneX 实现了 6.75 倍的强扩展性（strong scaling）加速比，优于密集基线（5.81 倍）和 Top-K 梯度压缩（3.71 倍）。

Conclusion: PruneX 通过结合剪枝算法和集群层次结构设计，有效解决了大规模分布式训练中节点间通信带宽瓶颈问题。其核心 H-SADMM 算法实现了节点级的结构化稀疏性，使得在节点间同步前可以动态压缩通信缓冲区，显著减少了通信量，实现了更好的强扩展性加速比。

Abstract: Inter-node communication bandwidth increasingly constrains distributed training at scale on multi-node GPU clusters. While compact models are the ultimate deployment target, conventional pruning-aware distributed training systems typically fail to reduce communication overhead because unstructured sparsity cannot be efficiently exploited by highly optimized dense collective primitives. We present PruneX, a distributed data-parallel training system that co-designs pruning algorithms with cluster hierarchy to reduce inter-node bandwidth usage. PruneX introduces the Hierarchical Structured ADMM (H-SADMM) algorithm, which enforces node-level structured sparsity before inter-node synchronization, enabling dynamic buffer compaction that eliminates both zero-valued transmissions and indexing overhead. The system adopts a leader-follower execution model with separated intra-node and inter-node process groups, performing dense collectives on compacted tensors over bandwidth-limited links while confining full synchronization to high-bandwidth intra-node interconnects. Evaluation on ResNet architectures across 64 GPUs demonstrates that PruneX reduces inter-node communication volume by approximately 60% and achieves 6.75x strong scaling speedup, outperforming the dense baseline (5.81x) and Top-K gradient compression (3.71x) on the Puhti supercomputer at CSC - IT Center for Science (Finland).

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [7] [ReadyPower: A Reliable, Interpretable, and Handy Architectural Power Model Based on Analytical Framework](https://arxiv.org/abs/2512.14172)
*Qijun Zhang,Shang Liu,Yao Lu,Mengming Li,Zhiyao Xie*

Main category: cs.AR

TL;DR: 该论文与编译器相关，因为它涉及处理器设计和架构级建模，这与编译器优化的目标紧密相关。该论文与 DSL 或图处理或 MLIR 或 HLS 无直接关系。
现有的经典分析功耗模型不准确，而基于 ML 的功耗模型因其固有的局限性（不可*靠性、可解释性有限和使用困难）在工业界没有被广泛采用。本文提出了一个新的分析性功耗建模框架 ReadyPower，它通过在 McPAT 模型中引入架构级、实现级和技术级参数，弥合了模型与实际实现之间的差异。实验证明，ReadyPower 在 BOOM 和香山 CPU 架构上均优于基于 ML 的基线模型，实现了更高的准确性和可靠性、可解释性以及易用性。


<details>
  <summary>Details</summary>
Motivation: 现有的经典分析架构级功耗模型（如 McPAT）存在严重不准确性，而新兴的基于机器学习（ML）的功耗模型虽然在研究论文中表现出较高的准确性，但在业界没有被广泛采用，因为它们存在固有的局限性：不可靠性、可解释性有限和使用困难。因此，需要一种既准确又高效，同时具有可靠性、可解释性和易用性的新的功耗建模方法。

Method: 作者提出了 ReadyPower 框架，该框架通过在广泛采用的 McPAT 分析模型中引入架构级、实现级和技术级参数来弥合经典分析功耗模型与实际处理器实现之间的差异。这些参数通过不同的方式确定。

Result: ReadyPower 在不同的训练场景下，在 BOOM 和香山 CPU 架构上，与基于 ML 的基线模型相比，平均绝对百分比误差（MAPE）降低了 20% 以上，相关系数 R 提高了 0.2 以上。

Conclusion: ReadyPower 是一种新的分析性功耗建模框架，它通过引入架构级、实现级和技术级参数来弥合经典分析模型（如 McPAT）与实际处理器实现之间的差异，从而克服了现有 ML 功耗模型的局限性（不可靠性、可解释性有限、使用困难）。实验结果表明，ReadyPower 在 BOOM 和香山 CPU 架构上均优于基于 ML 的基线模型，平均 MAPE 低于 20%，相关系数 R 高于 0.2。

Abstract: Power is a primary objective in modern processor design, requiring accurate yet efficient power modeling techniques. Architecture-level power models are necessary for early power optimization and design space exploration. However, classical analytical architecture-level power models (e.g., McPAT) suffer from significant inaccuracies. Emerging machine learning (ML)-based power models, despite their superior accuracy in research papers, are not widely adopted in the industry. In this work, we point out three inherent limitations of ML-based power models: unreliability, limited interpretability, and difficulty in usage. This work proposes a new analytical power modeling framework named ReadyPower, which is ready-for-use by being reliable, interpretable, and handy. We observe that the root cause of the low accuracy of classical analytical power models is the discrepancies between the real processor implementation and the processor's analytical model. To bridge the discrepancies, we introduce architecture-level, implementation-level, and technology-level parameters into the widely adopted McPAT analytical model to build ReadyPower. The parameters at three different levels are decided in different ways. In our experiment, averaged across different training scenarios, ReadyPower achieves >20% lower mean absolute percentage error (MAPE) and >0.2 higher correlation coefficient R compared with the ML-based baselines, on both BOOM and XiangShan CPU architectures.baselines, on both BOOM and XiangShan CPU architectures.

</details>


### [8] [TEMP: A Memory Efficient Physical-aware Tensor Partition-Mapping Framework on Wafer-scale Chips](https://arxiv.org/abs/2512.14256)
*Huizheng Wang,Taiquan Wei,Zichuan Wang,Dingcheng Jiang,Qize Yang,Jiaxin Liu,Jingxiang Hou,Chao Li,Jinyi Deng,Yang Hu,Shouyi Yin*

Main category: cs.AR

TL;DR: 该论文与Graph Processing和Compiler不相关，与MLIR和HLS不相关，与DSL不相关，与Compiler相关（与高性能计算和并行化相关）。
总结：大型语言模型（LLMs）对内存和计算资源需求巨大，晶圆级芯片（WSCs）虽然提供高计算能力和D2D带宽，但在片上内存和计算之间存在权衡。为解决此问题，本文提出了张量流划分范式（TSPP）利用WSC的通信优势缓解内存限制。然而，WSC的2D网格拓扑带来了尾延迟、流量竞争和优化搜索的挑战。为克服这些挑战，本文提出了TEMP框架，该框架集成了拓扑感知划分、流量感知映射和双层晶圆求解方法，旨在优化内存效率和吞吐量。评估结果显示，TEMP在LLM训练中实现了比现有SOTA系统平均高1.7倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）需要大量的内存和计算资源。晶圆级芯片（WSCs）提供了高计算能力和芯片间（D2D）带宽，但由于有限的晶圆面积，在片上内存和计算资源之间存在独特的权衡。因此，WSC的张量并行策略需要利用通信优势，同时保持内存效率，以最大化WSC性能。然而，现有方法未能解决这些挑战。此外，WSC的2D网格拓扑缺乏长距离和灵活的互连，导致了三个挑战：严重的尾延迟、禁止的D2D流量竞争以及最佳设计难以处理的搜索时间。

Method: 本文提出了张量流划分范式（TSPP），它利用WSC的高通信带宽来缓解片上内存限制。为克服WSC的2D网格拓扑带来的挑战（尾延迟、D2D流量竞争和搜索时间），本文提出了TEMP框架，该框架包括拓扑感知张量流划分（topology-aware tensor-stream partition）、流量感知映射（traffic-conscious mapping）和双层晶圆求解（dual-level wafer solving）这三种集成方法。这些方法旨在优化内存效率和吞吐量，充分发挥TSPP在WSC上的潜力。

Result: 本文提出的TEMP框架实现了显著的性能提升。评估结果表明，TEMP在各种模型上的平均吞吐量比现有最先进的LLM训练系统提高了1.7倍。

Conclusion: 本文提出了TEMP框架，该框架集成了拓扑感知张量流划分、流量感知映射和双层晶圆求解方法，有效解决了在晶圆级芯片上训练LLM时面临的内存限制和并行性挑战。评估结果显示，TEMP的平均吞吐量比现有最先进的LLM训练系统提高了1.7倍，证明了其在最大化WSC性能方面的有效性。

Abstract: Large language models (LLMs) demand significant memory and computation resources. Wafer-scale chips (WSCs) provide high computation power and die-to-die (D2D) bandwidth but face a unique trade-off between on-chip memory and compute resources due to limited wafer area. Therefore, tensor parallelism strategies for wafer should leverage communication advantages while maintaining memory efficiency to maximize WSC performance. However, existing approaches fail to address these challenges.
  To address these challenges, we propose the tensor stream partition paradigm (TSPP), which reveals an opportunity to leverage WSCs' abundant communication bandwidth to alleviate stringent on-chip memory constraints. However, the 2D mesh topology of WSCs lacks long-distance and flexible interconnects, leading to three challenges: 1) severe tail latency, 2) prohibitive D2D traffic contention, and 3) intractable search time for optimal design.
  We present TEMP, a framework for LLM training on WSCs that leverages topology-aware tensor-stream partition, traffic-conscious mapping, and dual-level wafer solving to overcome hardware constraints and parallelism challenges. These integrated approaches optimize memory efficiency and throughput, unlocking TSPP's full potential on WSCs. Evaluations show TEMP achieves 1.7x average throughput improvement over state-of-the-art LLM training systems across various models.

</details>


### [9] [PADE: A Predictor-Free Sparse Attention Accelerator via Unified Execution and Stage Fusion](https://arxiv.org/abs/2512.14322)
*Huizheng Wang,Hongbin Wang,Zichuan Wang,Zhiheng Yue,Yang Wang,Chao Li,Yang Hu,Shouyi Yin*

Main category: cs.AR

TL;DR: 该论文与**MLIR**, **编译器**, **HLS**或**DSL**无关，但与**图处理**相关因为它处理注意力机制中的稀疏化和加速。它与**编译器**和**HLS**相关，因为它涉及硬件/算法的协同设计和定制加速器设计。该论文提出了PADE，一个用于动态稀疏注意力加速的无预测器算法-硬件协同设计，通过采用BUI-GF、BS-OOE和ISTA等技术，解决了现有稀疏注意力方法中预测器开销导致的实用性问题和BSF机制面临的挑战。PADE在22个基准测试中实现了7.43倍于Nvidia H100 GPU的加速和31.1倍更高的能效，显著优于现有的SOTA加速器。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏注意力方法由于引入了额外的稀疏性预测器，导致硬件效率严重下降，缺乏实用性。本文提出**位串行支持的阶段融合（BSF）**机制，旨在消除对独立预测器的依赖，但面临三个主要挑战：1）不准确的位切片稀疏性推测导致错误的剪枝；2）细粒度和不平衡的位级工作负载导致的硬件利用率低下；3）稀疏性剪枝标准中的行间依赖导致的平铺困难。

Method: PADE提出了三项关键创新：1) **位不确定性区间支持的保护过滤（BUI-GF）**：在每个位迭代中准确识别不重要的token，解决不准确剪枝问题；2) **基于双向稀疏性的乱序执行（BS-OOE）**：提高硬件利用率，解决硬件利用率低的问题；3) **基于交错的稀疏平铺注意力（ISTA）**：减少I/O和计算复杂性，解决平铺难题。这些创新与定制加速器设计相结合，实现了无需额外稀疏性预测器的稀疏性加速。

Result: PADE在22个基准测试中进行了广泛实验，结果显示：PADE实现了7.43倍于Nvidia H100 GPU的加速，并将能效提高了31.1倍。与SOTA加速器相比，PADE在节能方面分别比Sanger、DOTA和SOFA提高了5.1倍、4.3倍和3.4倍。

Conclusion: PADE通过软硬件协同设计，实现了无预测器的动态稀疏注意力加速，有效地解决了稀疏注意力机制在硬件实现中的实际应用问题，并在加速比和能效方面取得了显著进步。

Abstract: Attention-based models have revolutionized AI, but the quadratic cost of self-attention incurs severe computational and memory overhead. Sparse attention methods alleviate this by skipping low-relevance token pairs. However, current approaches lack practicality due to the heavy expense of added sparsity predictor, which severely drops their hardware efficiency.
  This paper advances the state-of-the-art (SOTA) by proposing a bit-serial enable stage-fusion (BSF) mechanism, which eliminates the need for a separate predictor. However, it faces key challenges: 1) Inaccurate bit-sliced sparsity speculation leads to incorrect pruning; 2) Hardware under-utilization due to fine-grained and imbalanced bit-level workloads. 3) Tiling difficulty caused by the row-wise dependency in sparsity pruning criteria.
  We propose PADE, a predictor-free algorithm-hardware co-design for dynamic sparse attention acceleration. PADE features three key innovations: 1) Bit-wise uncertainty interval-enabled guard filtering (BUI-GF) strategy to accurately identify trivial tokens during each bit round; 2) Bidirectional sparsity-based out-of-order execution (BS-OOE) to improve hardware utilization; 3) Interleaving-based sparsity-tiled attention (ISTA) to reduce both I/O and computational complexity. These techniques, combined with custom accelerator designs, enable practical sparsity acceleration without relying on an added sparsity predictor. Extensive experiments on 22 benchmarks show that PADE achieves 7.43x speed up and 31.1x higher energy efficiency than Nvidia H100 GPU. Compared to SOTA accelerators, PADE achieves 5.1x, 4.3x and 3.4x energy saving than Sanger, DOTA and SOFA.

</details>
