<div id=toc></div>

# Table of Contents

- [cs.DS](#cs.DS) [Total: 6]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 6]


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [1] [Optimizing Text Search: A Novel Pattern Matching Algorithm Based on Ukkonen's Approach](https://arxiv.org/abs/2512.16927)
*Xinyu Guan,Shaohua Zhang*

Main category: cs.DS

TL;DR: 本文与图处理、MLIR、编译器、HLS、DSL均不直接相关。

太长而无法阅读摘要：传统的文本搜索算法难以应对现代大规模数据。本文通过将Ukkonen算法与一种新的搜索技术相结合来优化后缀树（Suffix Tree），达到了线性的时间和空间效率，并通过在生物信息学和自然语言处理等领域的数据集上的实证测试，证明了其在准确性和效率上优于KMP等传统算法。


<details>
  <summary>Details</summary>
Motivation: 在计算机科学领域，尤其是在自然语言处理和生物信息学等需要处理海量数据的领域，文本搜索算法的效率至关重要。传统的搜索方法（如朴素搜索、KMP、Boyer-Moore）在处理现代数据集的复杂性和规模时难以胜任。因此，本文的动机是研究并优化文本搜索算法，旨在开发出一种更高效、更具扩展性的方法来应对现代大规模数据集的挑战。

Method: 本文首先对传统的文本搜索算法（如朴素搜索、KMP、Boyer-Moore）进行了评估，指出了它们在处理现代大规模数据集时的局限性。接着，本文的核心方法是研究并优化后缀树（Suffix Tree），具体采用了“分裂（Splitting）”和“Ukkonen算法”等方法进行优化。最后，本文提出了一种新的优化方案，将Ukkonen算法与一种新颖的搜索技术相结合，以实现线性时间复杂度（Linear Time）和线性空间复杂度（Linear Space）的效率，并通过实验验证了其优越性。

Result: 研究结果表明，优化的后缀树（结合Ukkonen算法和新的搜索技术）实现了线性时间复杂度（Linear Time）和线性空间复杂度（Linear Space）的高效率。在Reuter语料库和人类基因组序列等数据集上的实证测试证实了这一理论优势，特别是在基因组序列的模式识别等任务中，该优化方法达到了100%的准确率，性能显著优于朴素搜索、KMP和Boyer-Moore等传统方法。

Conclusion: 本文通过理论分析和实证测试，确认了优化的后缀树在文本搜索算法中的优势，特别是将其应用于生物信息学和自然语言处理等领域时，表现出卓越的资源效率和可靠性。该研究不仅推动了文本搜索算法的学术进步，也展示了其在实际应用中的巨大潜力。

Abstract: In the realm of computer science, the efficiency of text-search algorithms is crucial for processing vast amounts of data in areas such as natural language processing and bioinformatics. Traditional methods like Naive Search, KMP, and Boyer-Moore, while foundational, often fall short in handling the complexities and scale of modern datasets, such as the Reuters corpus and human genomic sequences. This study rigorously investigates text-search algorithms, focusing on optimizing Suffix Trees through methods like Splitting and Ukkonen's Algorithm, analyzed on datasets including the Reuters corpus and human genomes. A novel optimization combining Ukkonen's Algorithm with a new search technique is introduced, showing linear time and space efficiencies, outperforming traditional methods like Naive Search, KMP, and Boyer-Moore. Empirical tests confirm the theoretical advantages, highlighting the optimized Suffix Tree's effectiveness in tasks like pattern recognition in genomic sequences, achieving 100% accuracy. This research not only advances academic knowledge in text-search algorithms but also demonstrates significant practical utility in fields like natural language processing and bioinformatics, due to its superior resource efficiency and reliability.

</details>


### [2] [Toward Optimal Approximations for Resource-Minimization for Fire Containment on Trees and Non-Uniform k-Center](https://arxiv.org/abs/2512.17049)
*Jannis Blauth,Christian Nöbel,Rico Zenklusen*

Main category: cs.DS

TL;DR: This paper is related to graph processing (spreading models on graphs) and compiler (approximation algorithms, which are often used in optimization aspects of compilers). The paper closes the approximability gap for the Resource Minimization for Fire Containment (RMFC) problem on trees by providing an optimal $2$-approximation and an asymptotic PTAS. This is achieved through a unified approach based on an LP-guided enumeration procedure for a smooth variant of RMFC. Furthermore, the techniques are extended to the non-uniform $k$-center problem (NUkC), yielding the first approximation algorithm for NUkC that is optimal in terms of the number of additional centers.


<details>
  <summary>Details</summary>
Motivation: 树上的“火灾遏制资源最小化”（RMFC）是一个具有挑战性的计算问题，尽管模型基本但即使在树上仍然是计算困难的。先前的工作在 RMFC 的可近似性方面留下了显著的空白。该论文的动机在于填补这一空白，为 RMFC 提供近似最优的算法，并解决文献中的两个公开问题。同时，作者也希望证明这些新技术可以应用于相关的非均匀 $k$-中心问题（NUkC），以改进其近似算法。

Method: 文章通过一个统一的方法来获得树上 RMFC 问题的 $2$-近似和渐近 PTAS 结果。核心方法是：首先，设计一个平滑版 RMFC 的 PTAS，该 PTAS 是通过一个仔细的 LP 引导枚举程序（LP-guided enumeration procedure）获得的。然后，将这些新技术与额外的要素结合，应用于非均匀 $k$-中心问题（NUkC），利用 RMFC 和 NUkC 之间的联系，从而得到 NUkC 的近似算法。

Result: 1. 为树上的“火灾遏制资源最小化”（RMFC）问题提供了最优的 $2$-近似算法。
2. 为树上的 RMFC 问题提供了渐近多项式时间近似方案（PTAS）。
3. 解决了文献中关于 RMFC 的可近似性方面的两个公开问题。
4. 基于 LP 引导的枚举程序，成功设计了一个平滑版 RMFC 的 PTAS。
5. 将新技术推广应用于非均匀 $k$-中心问题（NUkC），提供了第一个在需要打开的额外中心数量方面达到最优的近似算法。

Conclusion: 本文解决了树上“火灾遏制资源最小化”（RMFC）问题在可近似性方面的显著空白，提供了最佳的 $2$-近似算法和渐近多项式时间近似方案（PTAS），并证明了相关技术可以推广到非均匀 $k$-中心问题（NUkC），从而为 NUkC 提供了第一个在额外中心数量方面达到最优的近似算法。文章的核心贡献在于提出了一个统一的方法论，特别是基于 LP 引导的枚举程序设计了一个平滑版 RMFC 的 PTAS。

Abstract: One of the most elementary spreading models on graphs can be described by a fire spreading from a burning vertex in discrete time steps. At each step, all neighbors of burning vertices catch fire. A well-studied extension to model fire containment is to allow for fireproofing a number $B$ of non-burning vertices at each step. Interestingly, basic computational questions about this model are computationally hard even on trees. One of the most prominent such examples is Resource Minimization for Fire Containment (RMFC), which asks how small $B$ can be chosen so that a given subset of vertices will never catch fire. Despite recent progress on RMFC on trees, prior work left a significant gap in terms of its approximability. We close this gap by providing an optimal $2$-approximation and an asymptotic PTAS, resolving two open questions in the literature. Both results are obtained in a unified way, by first designing a PTAS for a smooth variant of RMFC, which is obtained through a careful LP-guided enumeration procedure.
  Moreover, we show that our new techniques, with several additional ingredients, carry over to the non-uniform $k$-center problem (NUkC), by exploiting a link between RMFC on trees and NUkC established by Chakrabarty, Goyal, and Krishnaswamy. This leads to the first approximation algorithm for NUkC that is optimal in terms of the number of additional centers that have to be opened.

</details>


### [3] [Optimal Verification of a Minimum-Weight Basis in an Uncertainty Matroid](https://arxiv.org/abs/2512.17116)
*Haya Diwan,Lisa Hellerstein,Nicole Megow,Jens Schlöter*

Main category: cs.DS

TL;DR: 这个论文与图处理（最小权基通常与图中的最小生成树等价，涉及图结构）和编译器或MLIR或HLS或DSL无关。摘要可总结为：本文解决了可探索不确定性下拟阵最小权基的验证问题，提出了一种处理更广泛不确定性区域的多项式时间算法，并利用其结构结果为相应的自适应在线问题的承诺变体提供了最佳算法，并应用于最小权基的学习增强变体。


<details>
  <summary>Details</summary>
Motivation: 研究可探索不确定性背景下的组合优化问题，这类问题涉及对数值输入参数值的部分信息，通过昂贵的查询可以确定参数的精确值。目标是设计一个自适应查询策略以最小化计算最优解所需的查询成本。解决这类问题通常需要解决相关的验证问题，即在预先知道所有查询答案的情况下，找到一个最小成本的查询集合来证明组合优化问题的最优解。现有的工作（Erlebach和Hoffman）仅处理了开放区间特殊情况，本文旨在解决更广泛的不确定性区域类型，并为相关在线问题及其随机变体提供结构洞察。

Method: 本文提出了一种多项式时间算法来解决给定不确定性区域（包括有限集、实数区间或开放和封闭区间的并集）下的拟阵最小权基的验证问题。该算法通过引入新技术来处理更复杂的不确定性区域。此外，文章还利用验证问题的结构结果，为相应的自适应在线问题的承诺变体提供了一种最佳算法，并将其应用于最小权基问题的两种学习增强变体。

Result: 本文提出了一种多项式时间算法，用于验证不确定性区域下的拟阵最小权基，能够处理有限集、实数区间或开放和封闭区间的并集，这严格地推广了先前仅处理开放区间的工作。该算法引入了新的技术以解决由此带来的挑战。此外，文章利用验证问题的结构结果，为相应的自适应在线问题的承诺变体提供了一种最佳算法，并将其应用于最小权基问题的两种学习增强变体。

Conclusion: 本文解决了在可探索不确定性背景下的最小权基的验证问题，并提出了一种多项式时间算法，该算法能够处理比现有工作更广泛的不确定性区域类型。此外，文章还将验证问题的结构洞察应用于相应的自适应在线问题的承诺变体，并提供了一种最佳算法，最后还将其应用于最小权基问题的两种学习增强变体。这些方法和结果对于可探索不确定性优化问题的研究具有重要价值。

Abstract: Research in explorable uncertainty addresses combinatorial optimization problems where there is partial information about the values of numeric input parameters, and exact values of these parameters can be determined by performing costly queries. The goal is to design an adaptive query strategy that minimizes the query cost incurred in computing an optimal solution. Solving such problems generally requires that we be able to solve the associated verification problem: given the answers to all queries in advance, find a minimum-cost set of queries that certifies an optimal solution to the combinatorial optimization problem. We present a polynomial-time algorithm for verifying a minimum-weight basis of a matroid, where each weight lies in a given uncertainty area. These areas may be finite sets, real intervals, or unions of open and closed intervals, strictly generalizing previous work by Erlebach and Hoffman which only handled the special case of open intervals. Our algorithm introduces new techniques to address the resulting challenges.
  Verification problems are of particular importance in the area of explorable uncertainty, as the structural insights and techniques used to solve the verification problem often heavily influence work on the corresponding online problem and its stochastic variant. In our case, we use structural results from the verification problem to give a best-possible algorithm for a promise variant of the corresponding adaptive online problem. Finally, we show that our algorithms can be applied to two learning-augmented variants of the minimum-weight basis problem under explorable uncertainty.

</details>


### [4] [LZ78 Substring Compression in Compressed Space](https://arxiv.org/abs/2512.17217)
*Hiroki Shibata,Dominik Köppl*

Main category: cs.DS

TL;DR: 该论文与图处理（LZ78 分解是数据结构的图表示）和编译器/HLS/MLIR/DSL 均不相关。
**总结（TLDR）**: LZ78 分解是广泛使用的数据压缩技术，但很少有研究关注快速索引和查询子串的分解。本文研究了在子串压缩模型中 LZ78 分解及其衍生算法，并提出了一种在压缩空间中工作的新算法，该算法在计算分解时，与最优时间复杂度相比，仅有对数级的速度降低。


<details>
  <summary>Details</summary>
Motivation: LZ78 分解及其衍生算法（如“compress”或“gif”格式所使用的）在数据压缩中是成熟的技术。然而，目前的研究大多集中在对纯数据的分解上，而关于如何对数据进行索引以实现快速 LZ78 分解的研究相对较少。本文的动机是研究在查询时指定子串的场景下，如何在压缩空间中快速计算 LZ78 分解。

Method: 作者研究了在子串压缩模型（substring compression model）下进行 LZ78 分解及其衍生方法的问题。在这种模型下，允许对数据进行索引，并在查询时返回指定子串的分解结果。作者提出了一种在该压缩空间中工作的算法，该算法在计算分解时，与最优时间复杂度相比，仅有对数级的速度降低（logarithmic slowdown）。

Result: 本文提出了一种在子串压缩模型下工作的 LZ78 分解算法。该算法的显著优势在于它能够在压缩空间中运行，并且在计算查询时指定的子串分解时，与最优时间复杂度相比，仅有对数级的速度降低。这表明该方法在保持数据压缩效率的同时，能够实现近乎最优的查询效率。

Conclusion: 本文提出了一种在压缩空间中工作的 LZ78 分解算法，并将查询时的分解速度降低到最优时间复杂度的对数级。这意味着可以在保持数据压缩优势的同时，实现对任意子串的快速 LZ78 分解，这在处理大规模数据压缩和索引查询的场景中具有重要价值。

Abstract: The Lempel--Ziv 78 (LZ78) factorization is a well-studied technique for data compression. It and its derivatives are used in compression formats such as "compress" or "gif". Although most research focuses on the factorization of plain data, not much research has been conducted on indexing the data for fast LZ78 factorization. Here, we study the LZ78 factorization and its derivatives in the substring compression model, where we are allowed to index the data and return the factorization of a substring specified at query time. In that model, we propose an algorithm that works in compressed space, computing the factorization with a logarithmic slowdown compared to the optimal time complexity.

</details>


### [5] [Refining the Complexity Landscape of Speed Scaling: Hardness and Algorithms](https://arxiv.org/abs/2512.17663)
*Antonios Antoniadis,Denise Graafsma,Ruben Hoeksma,Maria Vlasiou*

Main category: cs.DS

TL;DR: 与 DSL, graph processing, MLIR, compiler, HLS 均不直接相关，但属于经典的调度和算法复杂性分析范畴。

总结：本文研究了在单可变速处理器上调度作业以权衡（加权）流时间与能耗的计算复杂性。解决了四个先前未决的重要问题变体：证明了在最小化总（加权）流时间加能量的目标下，对于具有任意大小的单位权重作业和具有单位大小的任意权重作业，问题是 NP-hard 的，即使在有优先级约束时也成立；相反，证明了在给定完成时间排序时，相同的问题变体变得多项式时间可解，从而强调了优先级排序和完成时间排序之间的微妙区别。


<details>
  <summary>Details</summary>
Motivation: 研究单可变速处理器上作业调度的计算复杂性，旨在权衡（加权）流时间与能耗之间的关系。此前文献中已经探索了许多不同的问题表述，但仍有四个重要问题变体的计算复杂性悬而未决，是先前工作中明确提出的开放问题。本文旨在解决这些变体的计算复杂性。

Method: 本文通过理论证明的方法解决了四个重要问题变体的计算复杂度。具体方法包括证明最小化总（加权）流时间加能量问题的 NP-hard 性，以及在给定完成时间排序时，证明问题是多项式时间可解的。

Result: 证明了最小化总（加权）流时间加能量的问题是 NP-hard 的，适用于以下情况：（i）具有任意大小的单位权重作业，以及（ii）具有单位大小的任意权重作业。这些结果推广到在能量预算下最小化总（加权）流时间的目标，即使调度被要求遵循给定的优先级排序时也成立。相反，证明了当提供完成时间排序时，相同的变体在多项式时间内可解。

Conclusion: 本文解决了四个重要的单可变速处理器调度问题的计算复杂度。对于最小化总（加权）流时间加能量的目标，证明了对于具有任意大小的单位权重作业，以及具有单位大小的任意权重作业，问题是 NP-hard 的，这一结论推广到在能量预算下最小化总（加权）流时间的目标，即使调度被要求遵循给定的优先级排序时也成立。相反，当提供完成时间排序时，相同的变体在多项式时间内可解。结果突出了优先级排序和完成时间排序在问题中的微妙区别。

Abstract: We study the computational complexity of scheduling jobs on a single speed-scalable processor with the objective of capturing the trade-off between the (weighted) flow time and the energy consumption. This trade-off has been extensively explored in the literature through a number of problem formulations that differ in the specific job characteristics and the precise objective function. Nevertheless, the computational complexity of four important problem variants has remained unresolved and was explicitly identified as an open question in prior work. In this paper, we settle the complexity of these variants.
  More specifically, we prove that the problem of minimizing the objective of total (weighted) flow time plus energy is NP-hard for the cases of (i) unit-weight jobs with arbitrary sizes, and (ii)~arbitrary-weight jobs with unit sizes. These results extend to the objective of minimizing the total (weighted) flow time subject to an energy budget and hold even when the schedule is required to adhere to a given priority ordering.
  In contrast, we show that when a completion-time ordering is provided, the same problem variants become polynomial-time solvable. The latter result highlights the subtle differences between priority and completion orderings for the problem.

</details>


### [6] [Capacitated Partition Vertex Cover and Partition Edge Cover](https://arxiv.org/abs/2512.17844)
*Rajni Dabas,Samir Khuller,Emilie Rivkin*

Main category: cs.DS

TL;DR: This content has not passed the compliance test and has been hidden.


<details>
  <summary>Details</summary>
Motivation: 本文的动机在于研究超图中的容量划分顶点覆盖（C-PVC）问题和加权划分边覆盖（W-PEC）问题。C-PVC问题是经典的顶点覆盖、部分顶点覆盖和划分顶点覆盖的推广，它引入了容量约束和超边集合划分的约束，使其更具挑战性和实际应用价值。W-PEC问题是边覆盖问题的自然推广，它引入了边权重和顶点集合划分的约束。研究这些问题旨在提供解决超图覆盖问题的理论分析和高效算法。

Method: 对于C-PVC问题，本文提出了两种近似算法：针对加权软容量C-PVC问题，提出了一个$(f+1)$-近似算法，运行时间为$n^{O(\omega)}$；针对无权硬容量C-PVC问题，提出了一个$(f+\epsilon)$-近似算法，运行时间为$n^{O(\omega/\epsilon)}$。对于W-PEC问题，本文提出了首个精确多项式时间算法，运行时间为$O(mn+n^2 \log n)$，同时简化了算法结构。

Result: 本文的主要贡献是：1. 针对加权软容量C-PVC问题，提出了一个$(f+1)$-近似算法，运行时间为$n^{O(\omega)}$，其中$f$是超图的秩。2. 针对无权硬容量C-PVC问题，提出了一个$(f+\epsilon)$-近似算法，运行时间为$n^{O(\omega/\epsilon)}$。3. 针对W-PEC问题，提出了首个精确多项式时间算法，将运行时间从$O(\omega n^3)$改进到$O(mn+n^2 \log n)$，并简化了先前的无权算法结构。

Conclusion: 本文研究了超图中的软容量和硬容量的C-PVC问题，并分别给出了$(f+1)$-近似和$(f+\epsilon)$-近似算法。同时，本文还研究了W-PEC问题，并提出了首个精确多项式时间算法，改进了运行时间并简化了算法结构。这些结果对解决超图覆盖问题及其在容量和划分约束下的变体提供了新的理论基础和高效的解决方案。

Abstract: Our first focus is the Capacitated Partition Vertex Cover (C-PVC) problem in hypergraphs. In C-PVC, we are given a hypergraph with capacities on its vertices and a partition of the hyperedge set into $ω$ distinct groups. The objective is to select a minimum size subset of vertices that satisfies two main conditions: (1) in each group, the total number of covered hyperedges meets a specified threshold, and (2) the number of hyperedges assigned to any vertex respects its capacity constraint. A covered hyperedge is required to be assigned to a selected vertex that belongs to the hyperedge. This formulation generalizes classical Vertex Cover, Partial Vertex Cover, and Partition Vertex Cover.
  We investigate two primary variants: soft capacitated (multiple copies of a vertex are allowed) and hard capacitated (each vertex can be chosen at most once). Let $f$ denote the rank of the hypergraph. Our main contributions are: $(i)$ an $(f+1)$-approximation algorithm for the weighted soft-capacitated C-PVC problem, which runs in $n^{O(ω)}$ time, and $(ii)$ an $(f+ε)$-approximation algorithm for the unweighted hard-capacitated C-PVC problem, which runs in $n^{O(ω/ε)}$ time.
  We also study a natural generalization of the edge cover problem, the \emph{Weighted Partition Edge Cover} (W-PEC) problem, where each edge has an associated weight, and the vertex set is partitioned into groups. For each group, the goal is to cover at least a specified number of vertices using incident edges, while minimizing the total weight of the selected edges. We present the first exact polynomial-time algorithm for the weighted case, improving runtime from $O(ωn^3)$ to $O(mn+n^2 \log n)$ and simplifying the algorithmic structure over prior unweighted approaches.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [7] [A 14ns-Latency 9Gb/s 0.44mm$^2$ 62pJ/b Short-Blocklength LDPC Decoder ASIC in 22FDX](https://arxiv.org/abs/2512.17834)
*Darja Nonaca,Jérémy Guichemerre,Reinhard Wiesmayr,Nihat Engin Tunali,Christoph Studer*

Main category: cs.AR

TL;DR: The paper is related to wireless communication and potentially compiler/HLS/hardware aspect of it. The abstract does not explicitly mention DSL, graph processing, or MLIR, but the discussion of a hardware implementation (ASIC) and its performance metrics (latency, throughput, energy efficiency) strongly suggests a focus on the **compiler/HLS** of the communication algorithm for *hardware high-performance computing*. The tldr is: 5G URLLC需要低延迟短块长编码。传统极化码SCL解码器延迟高。本文提出了一种新的短块长多速率二进制LDPC码，性能优于5G-LDPC码，并适用于全并行MP解码。通过一个0.44mm$^2$的ASIC实现，该解码器实现了业内最低的14ns解码延迟，吞吐量9Gb/s，能效62pJ/b，展示了在URLLC应用中的高效性能。


<details>
  <summary>Details</summary>
Motivation: URLLC是5G的关键组成部分，其要求低延迟，这需要短块长编码。尽管极化码（Polar codes）在短块长下性能优于基于消息传递的LDPC码，但其SCL解码器延迟高、面积效率差。因此，需要一种高性能、低延迟且面积效率高的短块长编码方案。

Method: 提出了一种新的短块长多速率二进制LDPC码，用于URLLC应用，并结合全并行消息传递（MP）解码策略。为证明其有效性，设计并实现了一个基于GlobalFoundries 22FDX工艺的LDPC解码器ASIC，用于实现该代码。

Result: 提出了一种新的短块长多速率二进制LDPC码，其性能优于相同块长的5G-LDPC码，适用于URLLC应用中的全并行MP解码。基于该代码设计的ASIC芯片，在0.44mm$^2$的GlobalFoundries 22FDX工艺上实现，支持三种速率，达到了业内最低的14ns解码延迟，信息吞吐量为9Gb/s，对于块长为128位、速率为1/2的码，能效比为62pJ/b。

Conclusion: 本文提出了一种新的适用于URLLC的短块长多速率二进制LDPC码，它在性能上优于5G LDPC码，并能通过全并行消息传递（MP）应用于高能效、低延迟的硬件实现。实验结果表明，该ASIC在极低的延迟（14ns）下实现了高吞吐量（9Gb/s）和良好的能效（62pJ/b），证明了所提代码和架构在URLLC应用中的潜力。

Abstract: Ultra-reliable low latency communication (URLLC) is a key part of 5G wireless systems. Achieving low latency necessitates codes with short blocklengths for which polar codes with successive cancellation list (SCL) decoding typically outperform message-passing (MP)-based decoding of low-density parity-check (LDPC) codes. However, SCL decoders are known to exhibit high latency and poor area efficiency. In this paper, we propose a new short-blocklength multi-rate binary LDPC code that outperforms the 5G-LDPC code for the same blocklength and is suitable for URLLC applications using fully parallel MP. To demonstrate our code's efficacy, we present a 0.44mm$^2$ GlobalFoundries 22FDX LDPC decoder ASIC which supports three rates and achieves the lowest-in-class decoding latency of 14ns while reaching an information throughput of 9Gb/s at 62pJ/b energy efficiency for a rate-1/2 code with 128-bit blocklength.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [8] [Fixed-Priority and EDF Schedules for ROS2 Graphs on Uniprocessor](https://arxiv.org/abs/2512.16926)
*Oren Bell,Harun Teper,Mario Günzel,Chris Gill,Jian-Jia Chen*

Main category: cs.DC

TL;DR: 该论文与编译器、HLS、DSL以及MLIR不直接相关，但与图处理（Directed Acyclic Graphs, DAG）和实时系统调度（属于编译或OS相关领域）有关。
本文解决了ROS2中调度超出简单链任务和任意DAG任务的局限性。作者提出了一种新的方法，使用事件执行器（events executor）在单处理器上实现固定作业级优先级调度器，用于处理任意ROS2任务图。这要求特殊设计的事件队列和支持LIFO消息传递的通信中间件。研究发现ROS2应用可以抽象为树的森林，映射到传统的实时DAG任务模型，并且该实现能在缺乏必要先决信息的情况下，产生与常规固定优先级DAG任务调度器相同的调度结果，从而缩小了实时理论和ROS2调度分析之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的ROS2调度方法主要关注简单链式任务的调度，并采用临时（ad-hoc）的响应时间分析，这些方法对分析超越简单链的任务和任意有向无环图（DAG）存在局限性。因此，本文的动机是提出一种能有效调度和分析任意ROS2图任务的通用方法，以增强ROS2在实时系统中的应用能力。

Method: 本文提出了一种新的方法，即使用事件执行器（events executor）在单处理器系统上实现针对任意ROS2图的固定作业级优先级调度器。为此，需要对事件队列进行特殊实现，并要求通信中间件支持后进先出（LIFO）顺序的消息传递。通过将ROS2应用抽象为树的森林，将其映射到传统的实时DAG任务模型，并证明了这种实现在缺乏优先级信息的情况下仍能生成与常规固定优先级DAG任务调度器相同的调度结果。

Result: 研究结果表明，ROS2应用可以被抽象为树的森林，从而能够映射到传统的实时DAG任务模型。提出的基于事件执行器的固定作业级优先级调度器，尽管缺乏通常所需的优先信息，仍能生成与常规固定优先级DAG任务调度器相同的调度结果。这证明了该方法的可行性，并有助于弥合既有的实时系统理论与ROS2调度分析之间的差距。

Conclusion: 本文解决了ROS2中现有调度方法的局限性，特别是针对任意DAG任务的调度和分析，提出了使用事件执行器实现固定作业级优先级的调度器的新方法。这有助于将ROS2应用映射到传统的实时DAG任务模型，并验证了这种调度器与常规固定优先级DAG任务调度器产生相同的调度结果，从而缩小了实时系统理论与ROS2调度分析之间的差距。

Abstract: This paper addresses limitations of current scheduling methods in the Robot Operating System (ROS)2, focusing on scheduling tasks beyond simple chains and analyzing arbitrary Directed Acyclic Graphs (DAGs). While previous research has focused mostly on chain-based scheduling with ad-hoc response time analyses, we propose a novel approach using the events executor to implement fixed-job-level-priority schedulers for arbitrary ROS2 graphs on uniprocessor systems. We demonstrate that ROS 2 applications can be abstracted as forests of trees, enabling the mapping of ROS 2 applications to traditional real-time DAG task models. Our usage of the events executor requires a special implementation of the events queue and a communication middleware that supports LIFO-ordered message delivery, features not yet standard in ROS2. We show that our implementation generates the same schedules as a conventional fixed-priority DAG task scheduler, in spite of lacking access to the precedence information that usually is required. This further closes the gap between established real-time systems theory and ROS2 scheduling analyses.

</details>


### [9] [LLM-HPC++: Evaluating LLM-Generated Modern C++ and MPI+OpenMP Codes for Scalable Mandelbrot Set Computation](https://arxiv.org/abs/2512.17023)
*Patrick Diehl,Noujoud Nader,Deepti Gupta*

Main category: cs.DC

TL;DR: 与HPC和编译器相关。/本研究系统评估了包括ChatGPT-4/5和Claude在内的领先LLM在生成高性能计算（HPC）并行C++代码（Mandelbrot集，涵盖共享内存、指令式和分布式范式）方面的能力。结果显示，ChatGPT-4和ChatGPT-5在语法准确性和可扩展性能上表现强劲，证实了LLM在自动化HPC并行编程中的巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管现代C++标准和OpenMP/MPI等框架简化了并行编程，但高性能计算（HPC）中的并行编程仍然是一项极具挑战性的工作，需要掌握深奥的同步、通信和内存模型知识。最近出现的LLM在代码自动生成方面显示出潜力，但它们在**生成正确且高效的HPC代码方面的有效性**尚未被充分理解和系统评估。因此，本文旨在填补这一空白。

Method: 本文采用系统性评估的方法：
1. **任务设定：** 选择生成Mandelbrot集（一个经典的并行计算示例）的C++实现代码。
2. **范式涵盖：** 要求LLM生成三种主要的并行编程范式代码：共享内存、基于指令（如OpenMP）和分布式内存（如MPI）。
3. **模型选择：** 评估领先的LLM，包括ChatGPT 4、ChatGPT 5、Claude和LLaMA。
4. **评估标准与环境：** 对生成的代码进行编译（使用GCC 11.5.0）和执行，评估其正确性、鲁棒性和可扩展性。

Result: 评估结果显示，在生成的并行C++代码中：
1. ChatGPT-4和ChatGPT-5表现出卓越的能力。
2. 它们生成的代码具有强大的句法准确性（syntactic precision）。
3. 它们生成的代码在执行上展示出可扩展的性能（scalable performance）。

Conclusion: 本文得出结论，最新一代的LLM（特别是ChatGPT-4和ChatGPT-5）在生成高性能计算（HPC）并行代码，具体来说是C++实现的Mandelbrot集代码时，表现出很强的句法准确性和可扩展的性能。这表明LLM在HPC领域的代码生成方面具有巨大的潜力，可以减轻并行编程的复杂性。

Abstract: Parallel programming remains one of the most challenging aspects of High-Performance Computing (HPC), requiring deep knowledge of synchronization, communication, and memory models. While modern C++ standards and frameworks like OpenMP and MPI have simplified parallelism, mastering these paradigms is still complex. Recently, Large Language Models (LLMs) have shown promise in automating code generation, but their effectiveness in producing correct and efficient HPC code is not well understood. In this work, we systematically evaluate leading LLMs including ChatGPT 4 and 5, Claude, and LLaMA on the task of generating C++ implementations of the Mandelbrot set using shared-memory, directive-based, and distributed-memory paradigms. Each generated program is compiled and executed with GCC 11.5.0 to assess its correctness, robustness, and scalability. Results show that ChatGPT-4 and ChatGPT-5 achieve strong syntactic precision and scalable performance.

</details>


### [10] [Taming the Memory Footprint Crisis: System Design for Production Diffusion LLM Serving](https://arxiv.org/abs/2512.17077)
*Jiakun Fan,Yanglin Zhang,Xiangchen Li,Dimitrios S. Nikolopoulos*

Main category: cs.DC

TL;DR: 该论文与编译器和图处理等相关。它属于系统和服务优化的一部分，特别是针对作为自回归模型并行解码替代方案的Diffusion Large Language Models (dLLMs) 的高效服务，这与编译器和图处理领域中的优化技术（例如调度、内存管理、稀疏计算和硬件加速）有交叉。TLDR: dLLM-Serve 是一个高效的dLLM服务系统，旨在解决dLLMs特有的“内存占用危机”，该危机由单块对数张量和计算密集型/带宽密集型阶段的严重资源振荡引起。它通过引入Logit-Aware Activation Budgeting、Phase-Multiplexed Scheduler和Head-Centric Sparse Attention进行内存、调度和质量的协同优化。实验证明，dLLM-Serve相对于SOTA基线，在不同GPU上可将吞吐量提高1.60$\times$-1.81$\times$，并将重负载下的尾部延迟降低近4倍，为可扩展的dLLM推理提供了首个蓝图。


<details>
  <summary>Details</summary>
Motivation: 现有的dLLM研究主要集中在核级别优化，缺乏一个整体的服务框架来解决生产环境中扩散过程独特的内存动态。研究者识别出一个关键的“内存占用危机”（memory footprint crisis），该危机由单块对数张量（monolithic logit tensors）和计算密集型“Refresh”阶段与带宽密集型“Reuse”阶段之间严重的资源振荡所驱动。因此，提出dLLM-Serve旨在弥合这一差距，并解决dLLM在生产环境中的效率和服务质量挑战。

Method: dLLM-Serve系统的核心优化方法包括：1. **Logit-Aware Activation Budgeting（对数感知激活预算）**：用于分解瞬时张量峰值，解决内存占用问题。2. **Phase-Multiplexed Scheduler（相位多路复用调度器）**：用于交错处理异构的请求阶段（计算密集型“Refresh”和带宽密集型“Reuse”），以平衡资源利用。3. **Head-Centric Sparse Attention（以头为中心的稀疏注意力）**：将逻辑稀疏性与物理存储分离，进一步优化内存和计算。

Result: dLLM-Serve在各种工作负载（LiveBench、Burst、OSC）和不同GPU（RTX 4090, L40S）上进行了评估。相较于现有最先进的基线，dLLM-Serve在消费级RTX 4090上将吞吐量提高了1.61$\times$至1.81$\times$，在服务器级NVIDIA L40S上提高了1.60$\times$至1.74$\times$。此外，在重负载竞争下，尾部延迟降低了近4$\times$。

Conclusion: dLLM-Serve为可扩展的dLLM推理建立了第一个蓝图，通过在异构硬件上将理论算法稀疏性转化为实际的挂钟加速，证明了其在解决dLLMs特有的内存瓶颈和提升服务效率方面的有效性和必要性。

Abstract: Diffusion Large Language Models (dLLMs) have emerged as a promising alternative to Autoregressive Models (ARMs), utilizing parallel decoding to overcome sequential bottlenecks. However, existing research focuses primarily on kernel-level optimizations, lacking a holistic serving framework that addresses the unique memory dynamics of diffusion processes in production. We identify a critical "memory footprint crisis" specific to dLLMs, driven by monolithic logit tensors and the severe resource oscillation between compute-bound "Refresh" phases and bandwidth-bound "Reuse" phases. To bridge this gap, we present dLLM-Serve, an efficient dLLM serving system that co-optimizes memory footprint, computational scheduling, and generation quality. dLLM-Serve introduces Logit-Aware Activation Budgeting to decompose transient tensor peaks, a Phase-Multiplexed Scheduler to interleave heterogeneous request phases, and Head-Centric Sparse Attention to decouple logical sparsity from physical storage. We evaluate dLLM-Serve on diverse workloads (LiveBench, Burst, OSC) and GPUs (RTX 4090, L40S). Relative to the state-of-the-art baseline, dLLM-Serve improves throughput by 1.61$\times$-1.81$\times$ on the consumer-grade RTX 4090 and 1.60$\times$-1.74$\times$ on the server-grade NVIDIA L40S, while reducing tail latency by nearly 4$\times$ under heavy contention. dLLM-Serve establishes the first blueprint for scalable dLLM inference, converting theoretical algorithmic sparsity into tangible wall-clock acceleration across heterogeneous hardware.

</details>


### [11] [Scalable Distributed Vector Search via Accuracy Preserving Index Construction](https://arxiv.org/abs/2512.17264)
*Yuming Xu,Qianxi Zhang,Qi Chen,Baotong Lu,Menghao Li,Philip Adams,Mingqin Li,Zengzhong Li,Jing Liu,Cheng Li,Fan Yang*

Main category: cs.DC

TL;DR: 该论文与图处理相关（近似最近邻搜索通常涉及图索引结构）。/SPIRE 提出了一种可扩展的向量索引，通过平衡的分区粒度和保持准确性的递归构建方法，解决了现有索引在数十亿向量 ANNS 中的权衡难题，实现了高可扩展性和高达 9.64 倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有的索引设计难以在扩展到数十亿向量的近似最近邻搜索（ANNS）中平衡准确性、延迟和吞吐量之间的权衡。

Method: SPIRE 索引方法基于两个核心设计：一是确定平衡的分区粒度，以避免读取成本的爆炸式增长；二是引入保持准确性的递归构建方法，构建具有可预测搜索成本和稳定准确性的多级索引。

Result: SPIRE 在最多 80 亿向量和 46 个节点的实验中表现出高可扩展性，并达到了比现有最先进系统高出 9.64 倍的吞吐量。

Conclusion: SPIRE 通过平衡的分区粒度以及保持准确性的递归构建策略，有效地解决了大规模 ANNS 中现有索引设计在准确性、延迟和吞吐量之间权衡的难题，实现了高可扩展性和显著的吞吐量提升。

Abstract: Scaling Approximate Nearest Neighbor Search (ANNS) to billions of vectors requires distributed indexes that balance accuracy, latency, and throughput. Yet existing index designs struggle with this tradeoff. This paper presents SPIRE, a scalable vector index based on two design decisions. First, it identifies a balanced partition granularity that avoids read-cost explosion. Second, it introduces an accuracy-preserving recursive construction that builds a multi-level index with predictable search cost and stable accuracy. In experiments with up to 8 billion vectors across 46 nodes, SPIRE achieves high scalability and up to 9.64X higher throughput than state-of-the-art systems.

</details>


### [12] [The HEAL Data Platform](https://arxiv.org/abs/2512.17506)
*Brienna M. Larrick,L. Philip Schumm,Mingfei Shao,Craig Barnes,Anthony Juehne,Hara Prasad Juvvla,Michael B. Kranz,Michael Lukowski,Clint Malson,Jessica N. Mazerik,Christopher G. Meyer,Jawad Qureshi,Erin Spaniol,Andrea Tentner,Alexander VanTol,Peter Vassilatos,Sara Volk de Garcia,Robert L. Grossman*

Main category: cs.DC

TL;DR: 否，该论文与DSL、图处理、MLIR、编译器或HLS无关。
**太长不看（TL;DR）**：HEAL数据平台是一个基于云的联邦系统，它整合了NIH终结成瘾计划中的分散数据，提供了一个单一的入口来搜索、发现和分析这些数据。该平台基于开源Gen3构建，通过提供身份验证、元数据和互操作性API，成功地连接了19个数据存储库，使数以千计的研究数据符合FAIR原则，极大地促进了数据的二次利用和分析。


<details>
  <summary>Details</summary>
Motivation: 为美国国立卫生研究院（NIH）“长期终结成瘾”（HEAL）计划产生的数据开发一个基于云的、联邦化的系统，作为搜索、发现和分析数据的单一入口点。

Method: HEAL数据平台基于开源Gen3平台构建，利用少量框架服务和公开的API与NIH和非NIH数据存储库进行互操作。框架服务包括：身份验证和授权、为数据对象创建持久标识符，以及添加和更新元数据。

Result: HEAL数据平台是HEAL计划资助的一千多项研究的单一发现点。每月有数百名用户，该平台提供丰富的元数据，并与数据存储库和数据共享平台进行互操作，以提供对共享数据集的访问。与STRIDES集成的安全云端计算环境促进了HEAL数据的二次分析。HEAL数据平台目前与19个数据存储库互操作。

Conclusion: HEAL数据平台实现了对连接的数据存储库和数据共享平台中所存储数据的搜索、发现和分析。通过确保这些数据完全符合FAIR原则（可发现、可访问、可互操作和可重用），HEAL数据平台最大限度地发挥了HEAL计划所产生数据的价值。

Abstract: Objective: The objective was to develop a cloud-based, federated system to serve as a single point of search, discovery and analysis for data generated under the NIH Helping to End Addiction Long-term (HEAL) Initiative.
  Materials and methods: The HEAL Data Platform is built on the open source Gen3 platform, utilizing a small set of framework services and exposed APIs to interoperate with both NIH and non-NIH data repositories. Framework services include those for authentication and authorization, creating persistent identifiers for data objects, and adding and updating metadata.
  Results: The HEAL Data Platform serves as a single point of discovery of over one thousand studies funded under the HEAL Initiative. With hundreds of users per month, the HEAL Data Platform provides rich metadata and interoperates with data repositories and commons to provide access to shared datasets. Secure, cloud-based compute environments that are integrated with STRIDES facilitate secondary analysis of HEAL data. The HEAL Data Platform currently interoperates with nineteen data repositories.
  Discussion: Studies funded under the HEAL Initiative generate a wide variety of data types, which are deposited across multiple NIH and third-party data repositories. The mesh architecture of the HEAL Data Platform provides a single point of discovery of these data resources, accelerating and facilitating secondary use.
  Conclusion: The HEAL Data Platform enables search, discovery, and analysis of data that are deposited in connected data repositories and commons. By ensuring that these data are fully Findable, Accessible, Interoperable and Reusable (FAIR), the HEAL Data Platform maximizes the value of data generated under the HEAL Initiative.

</details>


### [13] [Enabling Disaggregated Multi-Stage MLLM Inference via GPU-Internal Scheduling and Resource Sharing](https://arxiv.org/abs/2512.17574)
*Lingxiao Zhao,Haoran Zhou,Yuezhi Che,Dazhao Cheng*

Main category: cs.DC

TL;DR: 该论文与 MLIR、编译器、HLS 无关，但与 **图处理**（特指其处理的 MLLM 模型的计算图）和 **DSL**（特指其优化的 MLLM 服务）及 **编译器**（考虑到它对系统执行的优化与传统编译优化有相似之处）相关。
多模态大语言模型（MLLMs）推理管道中的多模态预处理和视觉编码器造成了严重的性能瓶颈（高延迟、低吞吐量和低 GPU 利用率）。本文提出了 FlashCodec 和 UnifiedServe 互补框架：FlashCodec 利用协同多 GPU 视频解码加速预处理，降低延迟；UnifiedServe 优化视觉到文本和推理阶段，通过逻辑解耦和物理资源共享来消除阶段间阻塞并最大化 GPU 利用率。整个框架实现了高达 4.4 倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在推理过程中面临显著的系统瓶颈：第一，多模态预处理（尤其是视频解码）通常主导首个令牌生成时间（TTFT），现有系统依赖 CPU 解码限制了吞吐量，而现有的 GPU 解码方法侧重于吞吐量并行，不适用于 MLLM 推理对低延迟的要求。第二，视觉编码器作为一个独立的、计算密集型阶段，无法与 LLM 的预填充或解码进行批量处理，这种异构性导致了阶段间阻塞，增加了令牌生成延迟。即使部署在独立的 GPU 上，这些阶段也存在计算和内存资源利用不足的问题，降低了整体利用率并限制了系统吞吐量。

Method: 本文提出了两个互补的设计：FlashCodec 和 UnifiedServe。FlashCodec 通过协同多 GPU 视频解码来加速多模态预处理阶段，在保持高吞吐量的同时降低解码延迟。UnifiedServe 通过逻辑上解耦视觉到文本和推理阶段的执行，来消除阶段间阻塞，同时物理上共享 GPU 资源以最大化 GPU 系统利用率，并精心协调各阶段的执行以最小化干扰。

Result: FlashCodec 和 UnifiedServe 框架共同形成了端到端优化的堆栈。与现有系统相比，该框架能够服务高达 3.0 倍的请求，或实现 1.5 倍更严格的服务水平目标（SLOs），并获得高达 4.4 倍的更高吞吐量。

Conclusion: 本文提出的 FlashCodec 和 UnifiedServe 框架，通过优化多模态预处理、视觉编码和 LLM 推理这三个阶段，共同加速了端到端的 MLLM 推理管线。FlashCodec 利用协同多 GPU 视频解码，显著降低了视频解码延迟，提升了吞吐量；UnifiedServe 则通过逻辑上解耦和物理上共享 GPU 资源，消除了阶段间阻塞，最大化了 GPU 利用率，从而优化了视觉到文本和推理阶段。整个框架相比现有系统，能够服务高达 3.0 倍的请求或实现 1.5 倍更严格的服务水平目标（SLOs），并达到高达 4.4 倍的更高吞吐量。

Abstract: Multimodal large language models (MLLMs) extend LLMs with visual understanding through a three-stage pipeline: multimodal preprocessing, vision encoding, and LLM inference. While these stages enhance capability, they introduce significant system bottlenecks. First, multimodal preprocessing-especially video decoding-often dominates Time-to-First-Token (TTFT). Most systems rely on CPU-based decoding, which severely limits throughput, while existing GPU-based approaches prioritize throughput-oriented parallelism and fail to meet the latency-sensitive requirements of MLLM inference. Second, the vision encoder is a standalone, compute-intensive stage that produces visual embeddings and cannot be co-batched with LLM prefill or decoding. This heterogeneity forces inter-stage blocking and increases token-generation latency. Even when deployed on separate GPUs, these stages underutilize available compute and memory resources, reducing overall utilization and constraining system throughput.
  To address these challenges, we present FlashCodec and UnifiedServe, two complementary designs that jointly optimize the end-to-end MLLM pipeline. FlashCodec accelerates the multimodal preprocessing stage through collaborative multi-GPU video decoding, reducing decoding latency while preserving high throughput. UnifiedServe optimizes the vision-to-text and inference stages using a logically decoupled their execution to eliminate inter-stage blocking, yet physically sharing GPU resources to maximize GPU system utilization. By carefully orchestrating execution across stages and minimizing interference, UnifiedServe Together, our proposed framework forms an end-to-end optimized stack that can serve up to 3.0$\times$ more requests or enforce 1.5$\times$ tighter SLOs, while achieving up to 4.4$\times$ higher throughput compared to state-of-the-art systems.

</details>
