{"id": "2512.09277", "categories": ["cs.DC", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.09277", "abs": "https://arxiv.org/abs/2512.09277", "authors": ["Yanpeng Yu", "Haiyue Ma", "Krish Agarwal", "Nicolai Oswald", "Qijing Huang", "Hugo Linsenmaier", "Chunhui Mei", "Ritchie Zhao", "Ritika Borkar", "Bita Darvish Rouhani", "David Nellans", "Ronny Krashinsky", "Anurag Khandelwal"], "title": "Efficient MoE Serving in the Memory-Bound Regime: Balance Activated Experts, Not Tokens", "comment": null, "summary": "Expert Parallelism (EP) permits Mixture of Experts (MoE) models to scale beyond a single GPU. To address load imbalance across GPUs in EP, existing approaches aim to balance the number of tokens each GPU processes. Surprisingly, we find that this objective degrades performance rather than improving it when processing is memory-bound - a common occurrence in MoE serving, especially in the decode phase. Our analysis reveals that balancing the number of tokens processed per GPU increases the number of activated experts, exacerbating memory pressure in the memory-bound regime.\n  We propose Minimum Expert Token ROuting, a novel token-routing algorithm for high-performance expert-parallel MoE serving in the memory-bound regime that balances the number of activated experts per GPU rather than token counts. METRO achieves near-optimal routing quality with minimal computational overhead by jointly optimizing algorithmic efficiency and leveraging the GPU's parallel processing power. To guarantee routing quality, METRO also employs a novel allGather scheme to gather global top-k knowledge, which has minimal overhead compared to conventional allToAll. Our evaluation of METRO against EPLB on both real systems (vLLM over 8 A100 GPUs) and a proprietary simulator (8-16 B200 GPUs) shows that METRO reduces decode latency by 11 - 22%, and total token throughput by 3 - 21% for Qwen3 and DeepSeek-V3 serving, where prefill and decode phases are co-deployed. In addition, by trading latency headroom for throughput, METRO improves decode throughput by up to 4.11x over EPLB at a fixed decode SLO.", "AI": {"tldr": "\u672c\u6587\u4e0e**\u56fe\u5904\u7406**\u3001**MLIR**\u3001**\u7f16\u8bd1\u5668**\u3001**HLS**\u548c**DSL**\u65e0\u5173\uff0c\u4e0e**\u7f16\u8bd1\u5668**\u4e2d\u7684**\u4f18\u5316**\u76f8\u5173\u3002\u672c\u6587\u63d0\u51fa METRO (Minimum Expert Token ROuting) \u7b97\u6cd5\u6765\u89e3\u51b3 MoE \u4e13\u5bb6\u5e76\u884c\u670d\u52a1\u5728\u5185\u5b58\u53d7\u9650\u7684\u89e3\u7801\u9636\u6bb5\u4e2d\uff0c\u73b0\u6709\u65e8\u5728\u5e73\u8861\u4ee4\u724c\u6570\u91cf\u7684\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u53cd\u800c\u964d\u4f4e\u6027\u80fd\u7684\u95ee\u9898\u3002METRO \u8f6c\u800c\u5e73\u8861\u6bcf GPU \u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\uff0c\u51cf\u5c11\u5185\u5b58\u538b\u529b\u3002\u5b9e\u9a8c\u8868\u660e\uff0cMETRO \u76f8\u6bd4\u57fa\u7ebf EPLB \u53ef\u663e\u8457\u964d\u4f4e\u89e3\u7801\u5ef6\u8fdf (11-22%) \u5e76\u63d0\u9ad8\u541e\u5410\u91cf (3-21%)\uff0c\u751a\u81f3\u5728\u56fa\u5b9a SLO \u4e0b\u53ef\u5c06\u89e3\u7801\u541e\u5410\u91cf\u63d0\u5347\u9ad8\u8fbe 4.11 \u500d\u3002", "motivation": "\u73b0\u6709\u7684\u4e13\u5bb6\u5e76\u884c\uff08EP\uff09MoE \u6a21\u578b\u8d1f\u8f7d\u5747\u8861\u65b9\u6cd5\u901a\u5e38\u65e8\u5728\u5e73\u8861\u6bcf\u4e2a GPU \u5904\u7406\u7684\u4ee4\u724c\u6570\u91cf\uff0c\u4ee5\u89e3\u51b3\u8d1f\u8f7d\u4e0d\u5747\u8861\u95ee\u9898\u3002\u7136\u800c\uff0c\u5728 MoE \u670d\u52a1\u4e2d\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5185\u5b58\u53d7\u9650\uff08memory-bound\uff09\u7684\u89e3\u7801\u9636\u6bb5\u65f6\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u79cd\u4ee5\u5e73\u8861\u4ee4\u724c\u6570\u91cf\u4e3a\u76ee\u6807\u7684\u505a\u6cd5\u53cd\u800c\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u7a76\u5176\u539f\u56e0\uff0c\u5e73\u8861\u4ee4\u724c\u6570\u91cf\u4f1a\u589e\u52a0\u6fc0\u6d3b\u7684\u4e13\u5bb6\u6570\u91cf\uff0c\u4ece\u800c\u52a0\u5267\u4e86\u5185\u5b58\u53d7\u9650\u72b6\u6001\u4e0b\u7684\u5185\u5b58\u538b\u529b\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u7684\u52a8\u673a\u5728\u4e8e\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u80fd\u591f\u6709\u6548\u5730\u5728\u5185\u5b58\u53d7\u9650\u7684 MoE \u670d\u52a1\u4e2d\u63d0\u5347\u6027\u80fd\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86 METRO (Minimum Expert Token ROuting) \u7b97\u6cd5\uff0c\u8fd9\u662f\u4e00\u79cd\u65b0\u9896\u7684\u4ee4\u724c\u8def\u7531\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u5185\u5b58\u53d7\u9650\uff08memory-bound\uff09\u72b6\u6001\u4e0b\u5b9e\u73b0\u9ad8\u6027\u80fd\u7684\u4e13\u5bb6\u5e76\u884c MoE \u670d\u52a1\u3002METRO \u7684\u6838\u5fc3\u601d\u60f3\u662f\u5e73\u8861\u6bcf\u4e2a GPU \u4e0a\u7684\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\uff0c\u800c\u4e0d\u662f\u4ee4\u724c\u6570\u91cf\u3002\u4e3a\u4e86\u4fdd\u8bc1\u8def\u7531\u8d28\u91cf\uff0cMETRO \u91c7\u7528\u4e86\u4e00\u79cd\u65b0\u7684 allGather \u65b9\u6848\u6765\u6536\u96c6\u5168\u5c40\u7684 top-k \u77e5\u8bc6\uff0c\u8be5\u65b9\u6848\u4e0e\u4f20\u7edf\u7684 allToAll \u76f8\u6bd4\u5177\u6709\u6700\u5c0f\u7684\u5f00\u9500\u3002\u540c\u65f6\uff0cMETRO \u65e8\u5728\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7b97\u6cd5\u6548\u7387\u548c\u5229\u7528 GPU \u7684\u5e76\u884c\u5904\u7406\u80fd\u529b\uff0c\u4ee5\u6700\u5c0f\u7684\u8ba1\u7b97\u5f00\u9500\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u8def\u7531\u8d28\u91cf\u3002", "result": "\u4f5c\u8005\u5728\u771f\u5b9e\u7cfb\u7edf\uff08vLLM over 8 A100 GPUs\uff09\u548c\u4e13\u6709\u6a21\u62df\u5668\uff088-16 B200 GPUs\uff09\u4e0a\u8bc4\u4f30\u4e86 METRO \u7b97\u6cd5\uff0c\u5e76\u5c06\u5176\u4e0e EPLB \u8fdb\u884c\u4e86\u6bd4\u8f83\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\n1. \u5728 Qwen3 \u548c DeepSeek-V3 \u670d\u52a1\u4e2d\uff0c\u5f53\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u534f\u540c\u90e8\u7f72\u65f6\uff0cMETRO \u76f8\u6bd4 EPLB \u964d\u4f4e\u4e86\u89e3\u7801\u5ef6\u8fdf 11% \u5230 22%\uff0c\u5e76\u63d0\u5347\u4e86\u603b\u4ee4\u724c\u541e\u5410\u91cf 3% \u5230 21%\u3002\n2. \u901a\u8fc7\u727a\u7272\u5ef6\u8fdf\u4f59\u91cf\u6765\u6362\u53d6\u541e\u5410\u91cf\u65f6\uff0c\u5728\u56fa\u5b9a\u7684\u89e3\u7801\u670d\u52a1\u7b49\u7ea7\u76ee\u6807\uff08SLO\uff09\u4e0b\uff0cMETRO \u76f8\u6bd4 EPLB \u53ef\u5c06\u89e3\u7801\u541e\u5410\u91cf\u63d0\u9ad8\u9ad8\u8fbe 4.11 \u500d\u3002\n\u8fd9\u4e9b\u7ed3\u679c\u8868\u660e METRO \u5728\u5185\u5b58\u53d7\u9650\u573a\u666f\u4e0b\u7684 MoE \u670d\u52a1\u4e2d\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u53d1\u73b0\u4e86\u5728\u4e13\u5bb6\u5e76\u884c\uff08EP\uff09MoE \u670d\u52a1\u4e2d\uff0c\u7279\u522b\u662f\u5728\u5185\u5b58\u53d7\u9650\u7684\u89e3\u7801\u9636\u6bb5\uff0c\u73b0\u6709\u65e8\u5728\u5e73\u8861\u6bcf GPU \u4ee4\u724c\u6570\u91cf\u7684\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u5b9e\u9645\u4e0a\u4f1a\u964d\u4f4e\u6027\u80fd\u3002\u4f5c\u8005\u63d0\u51fa\u4e86 METRO \u7b97\u6cd5\uff0c\u8f6c\u800c\u5e73\u8861\u6bcf GPU \u7684\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\uff0c\u5e76\u7ed3\u5408\u9ad8\u6548\u7684\u8def\u7531\u548c\u65b0\u9896\u7684 allGather \u65b9\u6848\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cMETRO \u5728\u5b9e\u9645\u7cfb\u7edf\u548c\u6a21\u62df\u5668\u4e0a\u76f8\u5bf9\u4e8e EPLB \u663e\u8457\u964d\u4f4e\u4e86\u89e3\u7801\u5ef6\u8fdf\u5e76\u63d0\u5347\u4e86\u6574\u4f53\u541e\u5410\u91cf\u6216\u89e3\u7801\u541e\u5410\u91cf\uff0c\u7279\u522b\u662f\u5728\u5185\u5b58\u53d7\u9650\u573a\u666f\u4e0b\uff0c\u5c55\u73b0\u51fa\u5176\u5728\u9ad8\u6027\u80fd MoE \u670d\u52a1\u4e2d\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2512.09309", "categories": ["cs.DC", "cs.CR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.09309", "abs": "https://arxiv.org/abs/2512.09309", "authors": ["Zihao Ding", "Mufeng Zhu", "Zhongze Tang", "Sheng Wei", "Yao Liu"], "title": "A Distributed Framework for Privacy-Enhanced Vision Transformers on the Edge", "comment": "16 pages, 7 figures. Published in the Proceedings of the Tenth ACM/IEEE Symposium on Edge Computing (SEC '25), Dec 3-6, 2025, Washington, D.C., USA", "summary": "Nowadays, visual intelligence tools have become ubiquitous, offering all kinds of convenience and possibilities. However, these tools have high computational requirements that exceed the capabilities of resource-constrained mobile and wearable devices. While offloading visual data to the cloud is a common solution, it introduces significant privacy vulnerabilities during transmission and server-side computation. To address this, we propose a novel distributed, hierarchical offloading framework for Vision Transformers (ViTs) that addresses these privacy challenges by design. Our approach uses a local trusted edge device, such as a mobile phone or an Nvidia Jetson, as the edge orchestrator. This orchestrator partitions the user's visual data into smaller portions and distributes them across multiple independent cloud servers. By design, no single external server possesses the complete image, preventing comprehensive data reconstruction. The final data merging and aggregation computation occurs exclusively on the user's trusted edge device. We apply our framework to the Segment Anything Model (SAM) as a practical case study, which demonstrates that our method substantially enhances content privacy over traditional cloud-based approaches. Evaluations show our framework maintains near-baseline segmentation performance while substantially reducing the risk of content reconstruction and user data exposure. Our framework provides a scalable, privacy-preserving solution for vision tasks in the edge-cloud continuum.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001HLS\u3001DSL\u3001MLIR\u3001\u56fe\u5904\u7406\u7b49\u5747\u4e0d\u76f4\u63a5\u76f8\u5173\u3002\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411 ViTs \u7684\u5206\u5e03\u5f0f\u3001\u5206\u5c42\u5378\u8f7d\u6846\u67b6\uff0c\u901a\u8fc7\u5229\u7528\u672c\u5730\u8fb9\u7f18\u8bbe\u5907\u4f5c\u4e3a\u7f16\u6392\u5668\uff0c\u5c06\u89c6\u89c9\u6570\u636e\u5206\u5272\u5e76\u5206\u914d\u7ed9\u591a\u4e2a\u4e91\u670d\u52a1\u5668\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u4e91\u5378\u8f7d\u65b9\u6848\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u5e76\u5728 Segment Anything Model (SAM) \u4e0a\u9a8c\u8bc1\u4e86\u5176\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u589e\u5f3a\u9690\u79c1\u4fdd\u62a4\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9\u667a\u80fd\u5de5\u5177\u8ba1\u7b97\u8981\u6c42\u9ad8\uff0c\u8d85\u51fa\u4e86\u8d44\u6e90\u53d7\u9650\u7684\u79fb\u52a8\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u80fd\u529b\u3002\u4f20\u7edf\u7684\u5c06\u89c6\u89c9\u6570\u636e\u5378\u8f7d\u5230\u4e91\u7aef\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4f20\u8f93\u548c\u670d\u52a1\u5668\u7aef\u8ba1\u7b97\u8fc7\u7a0b\u4e2d\u5b58\u5728\u663e\u8457\u7684\u9690\u79c1\u6f0f\u6d1e\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u9690\u79c1\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u3001\u5206\u5c42\u5378\u8f7d\u6846\u67b6\uff0c\u7528\u4e8e ViTs\uff08Vision Transformers\uff09\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u672c\u5730\u53ef\u4fe1\u8fb9\u7f18\u8bbe\u5907\uff08\u5982\u624b\u673a\u6216 Nvidia Jetson\uff09\u4f5c\u4e3a\u8fb9\u7f18\u7f16\u6392\u5668\uff0c\u5c06\u7528\u6237\u89c6\u89c9\u6570\u636e\u5206\u6210\u8f83\u5c0f\u7684\u7247\u6bb5\uff0c\u5e76\u5206\u53d1\u5230\u591a\u4e2a\u72ec\u7acb\u7684\u4e91\u670d\u52a1\u5668\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\uff0c\u786e\u4fdd\u6ca1\u6709\u5355\u4e2a\u5916\u90e8\u670d\u52a1\u5668\u62e5\u6709\u5b8c\u6574\u7684\u56fe\u50cf\uff0c\u9632\u6b62\u4e86\u6570\u636e\u7684\u5168\u9762\u91cd\u5efa\u3002\u6700\u7ec8\u7684\u6570\u636e\u5408\u5e76\u548c\u805a\u5408\u8ba1\u7b97\u4ec5\u5728\u7528\u6237\u7684\u53ef\u4fe1\u8fb9\u7f18\u8bbe\u5907\u4e0a\u8fdb\u884c\u3002\u4ee5 Segment Anything Model (SAM) \u4e3a\u6848\u4f8b\u7814\u7a76\uff0c\u6f14\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u5e94\u7528\u8be5\u6846\u67b6\u5230 Segment Anything Model (SAM) \u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u7684\u57fa\u4e8e\u4e91\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5185\u5bb9\u9690\u79c1\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u63a5\u8fd1\u57fa\u7ebf\u5206\u5272\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5bb9\u91cd\u5efa\u548c\u7528\u6237\u6570\u636e\u66b4\u9732\u7684\u98ce\u9669\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411 ViTs \u7684\u5206\u5e03\u5f0f\u3001\u5206\u5c42\u5378\u8f7d\u6846\u67b6\uff0c\u53ef\u4ee5\u5728\u8fb9\u7f18-\u4e91\u8fde\u7eed\u4f53\u4e2d\u4e3a\u89c6\u89c9\u4efb\u52a1\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u3001\u4fdd\u62a4\u9690\u79c1\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u7528\u6237\u6570\u636e\u5206\u5272\u5e76\u5206\u914d\u7ed9\u591a\u4e2a\u72ec\u7acb\u7684\u4e91\u670d\u52a1\u5668\uff0c\u786e\u4fdd\u6ca1\u6709\u5355\u4e2a\u670d\u52a1\u5668\u62e5\u6709\u5b8c\u6574\u7684\u56fe\u50cf\uff0c\u4ece\u800c\u663e\u8457\u589e\u5f3a\u4e86\u5185\u5bb9\u9690\u79c1\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a5\u8fd1\u57fa\u7ebf\u7684\u6027\u80fd\u3002"}}
{"id": "2512.09331", "categories": ["cs.DC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.09331", "abs": "https://arxiv.org/abs/2512.09331", "authors": ["Nam Anh Dang", "Ben Landrum", "Ken Birman"], "title": "Passing the Baton: High Throughput Distributed Disk-Based Vector Search with BatANN", "comment": "12 pages, 14 figures, submitted to VLDB 2026", "summary": "Vector search underpins modern information-retrieval systems, including retrieval-augmented generation (RAG) pipelines and search engines over unstructured text and images. As datasets scale to billions of vectors, disk-based vector search has emerged as a practical solution. However, looking to the future, we need to anticipate datasets too large for any single server. We present BatANN, a distributed disk-based approximate nearest neighbor (ANN) system that retains the logarithmic search efficiency of a single global graph while achieving near-linear throughput scaling in the number of servers. Our core innovation is that when accessing a neighborhood which is stored on another machine, we send the full state of the query to the other machine to continue executing there for improved locality. On 100M- and 1B-point datasets at 0.95 recall using 10 servers, BatANN achieves 6.21-6.49x and 2.5-5.10x the throughput of the scatter-gather baseline, respectively, while maintaining mean latency below 6 ms. Moreover, we get these results on standard TCP. To our knowledge, BatANN is the first open-source distributed disk-based vector search system to operate over a single global graph.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u56fe\u5904\u7406\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u7814\u7a76\u4e86\u5728\u5206\u5e03\u5f0f\u5411\u91cf\u641c\u7d22\u4e2d\u5982\u4f55\u6784\u5efa\u548c\u64cd\u4f5c\u5355\u4e2a\u5168\u5c40\u56fe\uff08HNSW \u7b49\u56fe\u7ed3\u6784\uff09\u3002\u5b83\u8fd8\u4e0e\u7f16\u8bd1\u5668\u548c HLS \u7684\u5173\u7cfb\u4e0d\u5927\u3002\n\u5411\u91cf\u641c\u7d22\u662f\u73b0\u4ee3\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u7684\u57fa\u7840\u3002\u5f53\u6570\u636e\u96c6\u6269\u5c55\u5230\u6570\u5341\u4ebf\u5411\u91cf\u65f6\uff0c\u5355\u670d\u52a1\u5668\u5df2\u65e0\u6cd5\u6ee1\u8db3\u9700\u6c42\uff0c\u5373\u4f7f\u662f\u57fa\u4e8e\u78c1\u76d8\u7684\u5411\u91cf\u641c\u7d22\u4e5f\u9762\u4e34\u6311\u6218\u3002BatANN \u662f\u4e00\u79cd\u5206\u5e03\u5f0f\u78c1\u76d8\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u7cfb\u7edf\uff0c\u5b83\u7ef4\u62a4\u4e00\u4e2a\u5355\u4e2a\u5168\u5c40\u56fe\u4ee5\u4fdd\u7559\u5bf9\u6570\u641c\u7d22\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5728\u8de8\u673a\u5668\u8bbf\u95ee\u90bb\u57df\u65f6\u53d1\u9001\u5b8c\u6574\u7684\u67e5\u8be2\u72b6\u6001\u6765\u63d0\u9ad8\u5c40\u90e8\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u7ebf\u6027\u7684\u541e\u5410\u91cf\u6269\u5c55\u3002\u5728 10 \u53f0\u670d\u52a1\u5668\u4e0a\uff0cBatANN \u5728 1 \u4ebf\u548c 10 \u4ebf\u70b9\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u7cfb\u7edf\uff0c\u5206\u522b\u5b9e\u73b0\u4e86 6.21-6.49 \u500d\u548c 2.5-5.10 \u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u5c06\u5e73\u5747\u5ef6\u8fdf\u4fdd\u6301\u5728 6 \u6beb\u79d2\u4ee5\u4e0b\u3002\u5b83\u662f\u9996\u4e2a\u57fa\u4e8e\u5355\u4e2a\u5168\u5c40\u56fe\u7684\u5f00\u6e90\u5206\u5e03\u5f0f\u78c1\u76d8\u5411\u91cf\u641c\u7d22\u7cfb\u7edf\u3002", "motivation": "\u73b0\u4ee3\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\uff08\u5982 RAG \u548c\u641c\u7d22\u5f15\u64ce\uff09\u4f9d\u8d56\u5411\u91cf\u641c\u7d22\uff0c\u4f46\u968f\u7740\u6570\u636e\u96c6\u89c4\u6a21\u6269\u5927\u5230\u6570\u5341\u4ebf\uff0c\u5373\u4f7f\u662f\u57fa\u4e8e\u78c1\u76d8\u7684\u5411\u91cf\u641c\u7d22\u4e5f\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u6570\u636e\u53ef\u80fd\u8d85\u51fa\u4e00\u4e2a\u5355\u670d\u52a1\u5668\u7684\u5bb9\u91cf\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u8d85\u5927\u6570\u636e\u96c6\u3001\u5177\u5907\u826f\u597d\u6269\u5c55\u6027\u7684\u5206\u5e03\u5f0f\u78c1\u76d8\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u7cfb\u7edf\u3002", "method": "BatANN \u901a\u8fc7\u5728\u673a\u5668\u4e4b\u95f4\u79fb\u52a8\u67e5\u8be2\u7684\u5b8c\u6574\u72b6\u6001\uff08\u5168\u67e5\u8be2\u72b6\u6001\u8fc1\u79fb\uff09\u6765\u5904\u7406\u8de8\u673a\u5668\u7684\u90bb\u57df\u8bbf\u95ee\uff0c\u4ee5\u63d0\u9ad8\u67e5\u8be2\u7684\u5c40\u90e8\u6027\u3002\u8fd9\u79cd\u65b9\u6cd5\u5141\u8bb8\u67e5\u8be2\u5728\u5b58\u50a8\u6240\u9700\u6570\u636e\u7684\u673a\u5668\u4e0a\u7ee7\u7eed\u6267\u884c\uff0c\u4ece\u800c\u4f18\u5316\u4e86\u5206\u5e03\u5f0f\u73af\u5883\u4e0b\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\uff08ANN\uff09\u641c\u7d22\u6027\u80fd\u3002", "result": "\u5728\u5177\u6709 0.95 \u53ec\u56de\u7387\u7684 1 \u4ebf\u548c 10 \u4ebf\u70b9\u6570\u636e\u96c6\u4e0a\uff0cBatANN \u5728\u4f7f\u7528 10 \u53f0\u670d\u52a1\u5668\u65f6\uff0c\u76f8\u5bf9\u4e8e\u5206\u6563-\u805a\u96c6\uff08scatter-gather\uff09\u57fa\u7ebf\u7cfb\u7edf\u7684\u541e\u5410\u91cf\u5206\u522b\u63d0\u9ad8\u4e86 6.21-6.49 \u500d\u548c 2.5-5.10 \u500d\uff0c\u540c\u65f6\u5e73\u5747\u5ef6\u8fdf\u4fdd\u6301\u5728 6 \u6beb\u79d2\u4ee5\u4e0b\u3002\u8fd9\u4e9b\u7ed3\u679c\u662f\u5728\u6807\u51c6 TCP \u4e0a\u5b9e\u73b0\u7684\u3002", "conclusion": "BatANN \u662f\u7b2c\u4e00\u4e2a\u57fa\u4e8e\u5355\u4e2a\u5168\u5c40\u56fe\u7684\u5f00\u6e90\u5206\u5e03\u5f0f\u78c1\u76d8\u5411\u91cf\u641c\u7d22\u7cfb\u7edf\uff0c\u5b83\u5728\u4fdd\u6301\u5bf9\u6570\u641c\u7d22\u6548\u7387\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u8fd1\u4e4e\u7ebf\u6027\u7684\u541e\u5410\u91cf\u6269\u5c55\uff0c\u5e76\u5728\u5343\u4e07\u7ea7\u548c\u5341\u4ebf\u7ea7\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u5bf9\u4e8e\u57fa\u7ebf\u7cfb\u7edf\u5c55\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u4f18\u52bf\u3002"}}
{"id": "2512.09472", "categories": ["cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.09472", "abs": "https://arxiv.org/abs/2512.09472", "authors": ["Chiheng Lou", "Sheng Qi", "Rui Kang", "Yong Zhang", "Chen Sun", "Pengcheng Wang", "Bingyang Liu", "Xuanzhe Liu", "Xin Jin"], "title": "WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving", "comment": null, "summary": "Deploying multiple models within shared GPU clusters is promising for improving resource efficiency in large language model (LLM) serving. Existing multi-LLM serving systems optimize GPU utilization at the cost of worse inference performance, especially time-to-first-token (TTFT). We identify the root cause of such compromise as their unawareness of future workload characteristics. In contrast, recent analysis on real-world traces has shown the high periodicity and long-term predictability of LLM serving workloads.\n  We propose universal GPU workers to enable one-for-many GPU prewarming that loads models with knowledge of future workloads. Based on universal GPU workers, we design and build WarmServe, a multi-LLM serving system that (1) mitigates cluster-wide prewarming interference by adopting an evict-aware model placement strategy, (2) prepares universal GPU workers in advance by proactive prewarming, and (3) manages GPU memory with a zero-overhead memory switching mechanism. Evaluation under real-world datasets shows that WarmServe improves TTFT by up to 50.8$\\times$ compared to the state-of-the-art autoscaling-based system, while being capable of serving up to 2.5$\\times$ more requests compared to the GPU-sharing system.", "AI": {"tldr": "\u5173\u8054\uff1a\u8be5\u8bba\u6587\u4e0e**\u56fe\u5904\u7406 (GPU)**\u3001**\u7f16\u8bd1\u5668 (\u7cfb\u7edf)**\u76f8\u5173\uff0c\u56e0\u4e3a\u5b83\u6d89\u53ca\u5728\u5171\u4eabGPU\u96c6\u7fa4\u4e0a\u90e8\u7f72\u548c\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u670d\u52a1\u7cfb\u7edf\u3002\n\nTLDR: \u73b0\u6709\u7684\u591a\u6a21\u578bLLM\u670d\u52a1\u7cfb\u7edf\u5728\u63d0\u9ad8GPU\u5229\u7528\u7387\u65f6\uff0c\u4f1a\u727a\u7272\u9996\u4e2a\u4ee4\u724c\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\uff0c\u539f\u56e0\u5728\u4e8e\u5b83\u4eec\u6ca1\u6709\u611f\u77e5\u672a\u6765\u5de5\u4f5c\u8d1f\u8f7d\u3002\u7136\u800c\uff0cLLM\u5de5\u4f5c\u8d1f\u8f7d\u662f\u53ef\u9884\u6d4b\u7684\u3002\u672c\u6587\u63d0\u51fa\u4e86WarmServe\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u5de5\u4f5c\u8d1f\u8f7d\u7684\u53ef\u9884\u77e5\u6027\u8bbe\u8ba1**\u901a\u7528GPU\u5de5\u4f5c\u5668**\u5b9e\u73b0\u201c\u4e00\u66ff\u591a\u201d\u9884\u70ed\uff0c\u5e76\u7ed3\u5408**\u9a71\u9010\u611f\u77e5\u6a21\u578b\u653e\u7f6e**\u3001**\u4e3b\u52a8\u9884\u70ed**\u548c**\u96f6\u5f00\u9500\u5185\u5b58\u5207\u6362**\u673a\u5236\u6765\u4f18\u5316GPU\u5185\u5b58\u7ba1\u7406\u548c\u9884\u70ed\u5e72\u6270\u3002\u5b9e\u9a8c\u8868\u660e\uff0cWarmServe\u76f8\u8f83\u4e8e\u73b0\u6709\u7cfb\u7edf\uff0cTTFT\u6700\u9ad8\u63d0\u534750.8\u500d\uff0c\u8bf7\u6c42\u670d\u52a1\u80fd\u529b\u63d0\u53472.5\u500d\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u578bLLM\u670d\u52a1\u7cfb\u7edf\u5728\u63d0\u9ad8GPU\u8d44\u6e90\u5229\u7528\u7387\u7684\u540c\u65f6\uff0c\u727a\u7272\u4e86\u63a8\u7406\u6027\u80fd\uff0c\u7279\u522b\u662f\u9996\u4e2a\u4ee4\u724c\u751f\u6210\u65f6\u95f4\uff08TTFT\uff09\u7684\u6027\u80fd\u3002\u8fd9\u79cd\u6298\u8877\u7684\u6839\u672c\u539f\u56e0\u5728\u4e8e\u5b83\u4eec\u5bf9\u672a\u6765\u5de5\u4f5c\u8d1f\u8f7d\u7279\u6027\u7f3a\u4e4f\u611f\u77e5\u3002\u7136\u800c\uff0c\u6700\u8fd1\u7684\u5206\u6790\u8868\u660eLLM\u670d\u52a1\u5de5\u4f5c\u8d1f\u8f7d\u5177\u6709\u9ad8\u5ea6\u7684\u5468\u671f\u6027\u548c\u957f\u671f\u53ef\u9884\u6d4b\u6027\uff0c\u8fd9\u6fc0\u53d1\u4e86\u53ef\u4ee5\u5229\u7528\u8fd9\u4e9b\u7279\u6027\u6765\u4f18\u5316\u6027\u80fd\u7684\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": " WarmServe\u7684\u6838\u5fc3\u65b9\u6cd5\u662f\u5229\u7528LLM\u670d\u52a1\u8d1f\u8f7d\u7684\u5468\u671f\u6027\u548c\u53ef\u9884\u6d4b\u6027\uff0c\u901a\u8fc7\u201c\u4e00\u66ff\u591a\u201d\u7684GPU\u9884\u70ed\u65b9\u6cd5\u6765\u63d0\u524d\u52a0\u8f7d\u6a21\u578b\uff0c\u4ece\u800c\u907f\u514dTTFT\u6076\u5316\u3002\u5177\u4f53\u5b9e\u65bd\u5305\u62ec\uff1a1. **\u901a\u7528GPU\u5de5\u4f5c\u5668\uff08Universal GPU Workers\uff09**\uff1a\u7528\u4e8e\u5b9e\u73b0\u9884\u70ed\uff0c\u63d0\u524d\u52a0\u8f7d\u672a\u6765\u53ef\u80fd\u9700\u8981\u7684\u6a21\u578b\u30022. **\u9a71\u9010\u611f\u77e5\u6a21\u578b\u653e\u7f6e\u7b56\u7565\uff08Evict-aware Model Placement Strategy\uff09**\uff1a\u7f13\u89e3\u96c6\u7fa4\u8303\u56f4\u5185\u7684\u9884\u70ed\u5e72\u6270\u30023. **\u4e3b\u52a8\u9884\u70ed\uff08Proactive Prewarming\uff09**\uff1a\u63d0\u524d\u51c6\u5907\u901a\u7528GPU\u5de5\u4f5c\u5668\u30024. **\u96f6\u5f00\u9500\u5185\u5b58\u5207\u6362\u673a\u5236\uff08Zero-overhead Memory Switching Mechanism\uff09**\uff1a\u9ad8\u6548\u7ba1\u7406GPU\u5185\u5b58\u3002", "result": "WarmServe\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff1a1. \u76f8\u6bd4\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u81ea\u52a8\u6269\u5c55\u7684\u7cfb\u7edf\uff0cWarmServe\u5c06TTFT\u63d0\u9ad8\u4e86\u9ad8\u8fbe50.8\u500d\u30022. \u76f8\u6bd4\u4e8eGPU\u5171\u4eab\u7cfb\u7edf\uff0cWarmServe\u80fd\u591f\u670d\u52a1\u591a\u8fbe2.5\u500d\u7684\u8bf7\u6c42\u3002\u8fd9\u8868\u660eWarmServe\u6210\u529f\u5730\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8d44\u6e90\u6548\u7387\u548c\u63a8\u7406\u6027\u80fd\u3002", "conclusion": "WarmServe\u901a\u8fc7\u5229\u7528LLM\u670d\u52a1\u5de5\u4f5c\u8d1f\u8f7d\u7684\u957f\u671f\u53ef\u9884\u6d4b\u6027\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5305\u62ec\u901a\u7528GPU\u5de5\u4f5c\u5668\u3001\u9a71\u9010\u611f\u77e5\u6a21\u578b\u653e\u7f6e\u7b56\u7565\u3001\u4e3b\u52a8\u9884\u70ed\u4ee5\u53ca\u96f6\u5f00\u9500\u5185\u5b58\u5207\u6362\u673a\u5236\u5728\u5185\u7684\u7cfb\u7edf\uff0c\u6210\u529f\u5730\u5728\u591a\u6a21\u578bLLM\u670d\u52a1\u7cfb\u7edf\u4e2d\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6848\u4e2dGPU\u5229\u7528\u7387\u548cTTFT\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cWarmServe\u5728TTFT\u548c\u8bf7\u6c42\u541e\u5410\u91cf\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u7cfb\u7edf\u3002"}}
{"id": "2512.09412", "categories": ["cs.PL"], "pdf": "https://arxiv.org/pdf/2512.09412", "abs": "https://arxiv.org/abs/2512.09412", "authors": ["Patrick Bahr"], "title": "Simple Modal Types for Functional Reactive Programming", "comment": null, "summary": "Functional reactive programming (FRP) is a declarative programming paradigm for implementing reactive programs at a high level of abstraction. It applies functional programming principles to construct and manipulate time-varying values, also known as signals. However, for this programming paradigm to work in practice, an FRP language must ensure that programs are causal, productive, and free from space leaks. Over the past fifteen years, several modal type systems to enforce these operational properties have been developed.\n  We present a new FRP language with a significantly simplified modal type system that imposes fewer restrictions than previous modal FRP languages while still guaranteeing the central operational properties of causality, productivity, and absence of space leaks. The key enabling idea is to alter the semantics of signals so that the type system can safely allow more programs to type-check, which also makes the language more expressive. With this new semantics, signals are modelled as mutable references whose mutability is tightly controlled by the 'later' type modality. This disciplined form of mutability also enables more efficient in-place updates of signals, all while preserving a functional programming style.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0eDSL\uff08\u51fd\u6570\u5f0f\u53cd\u5e94\u5f0f\u7f16\u7a0b\u662f\u4e00\u79cd\u58f0\u660e\u5f0f\u7f16\u7a0b\u8303\u5f0f\uff0c\u53ef\u4ee5\u89c6\u4f5c\u4e00\u79cd\u7279\u5b9a\u9886\u57df\u7684\u5efa\u6a21\u8bed\u8a00\uff09\u76f8\u5173\u3002\n\u51fd\u6570\u5f0f\u53cd\u5e94\u5f0f\u7f16\u7a0b\uff08FRP\uff09\u662f\u4e00\u79cd\u7528\u4e8e\u5b9e\u73b0\u9ad8\u62bd\u8c61\u7ea7\u522b\u53cd\u5e94\u5f0f\u7a0b\u5e8f\u7684\u58f0\u660e\u6027\u7f16\u7a0b\u8303\u5f0f\uff0c\u4f46\u5176\u8981\u6c42\u7a0b\u5e8f\u5fc5\u987b\u4fdd\u8bc1\u56e0\u679c\u6027\u3001\u751f\u4ea7\u6027\u548c\u65e0\u7a7a\u95f4\u6cc4\u6f0f\u3002\u73b0\u6709\u7684\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\u867d\u7136\u80fd\u5f3a\u5236\u5b9e\u73b0\u8fd9\u4e9b\u64cd\u4f5c\u5c5e\u6027\uff0c\u4f46\u9650\u5236\u4e86\u7a0b\u5e8f\u8868\u8fbe\u80fd\u529b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684FRP\u8bed\u8a00\uff0c\u8be5\u8bed\u8a00\u91c7\u7528\u663e\u8457\u7b80\u5316\u7684\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\uff0c\u901a\u8fc7\u6539\u53d8\u4fe1\u53f7\u7684\u8bed\u4e49\uff0c\u5141\u8bb8\u5c06\u4fe1\u53f7\u5efa\u6a21\u4e3a\u53ef\u53d8\u5f15\u7528\uff0c\u5e76\u7531'later'\u7c7b\u578b\u6a21\u6001\u4e25\u683c\u63a7\u5236\u5176\u53ef\u53d8\u6027\u3002\u8fd9\u79cd\u65b9\u6cd5\u5728\u4fdd\u8bc1\u6838\u5fc3\u64cd\u4f5c\u5c5e\u6027\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u4fe1\u53f7\u5c31\u5730\u66f4\u65b0\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u51fd\u6570\u5f0f\u7f16\u7a0b\u98ce\u683c\u3002", "motivation": "\u4f20\u7edf\u7684\u51fd\u6570\u5f0f\u53cd\u5e94\u5f0f\u7f16\u7a0b\uff08FRP\uff09\u9700\u8981\u4fdd\u8bc1\u7a0b\u5e8f\u662f\u56e0\u679c\u7684\uff08causal\uff09\u3001\u751f\u4ea7\u6027\u7684\uff08productive\uff09\u548c\u6ca1\u6709\u7a7a\u95f4\u6cc4\u6f0f\u7684\uff08free from space leaks\uff09\u3002\u5df2\u6709\u7684\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\u867d\u7136\u80fd\u5f3a\u5236\u5b9e\u73b0\u8fd9\u4e9b\u64cd\u4f5c\u5c5e\u6027\uff0c\u4f46\u5f80\u5f80\u9650\u5236\u4e86\u7a0b\u5e8f\u7684\u8868\u8fbe\u80fd\u529b\u3002\u56e0\u6b64\uff0c\u672c\u6587\u7684\u52a8\u673a\u662f\u5e0c\u671b\u8bbe\u8ba1\u4e00\u4e2a\u5177\u6709\u663e\u8457\u7b80\u5316\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\u7684\u65b0FRP\u8bed\u8a00\uff0c\u5728\u4fdd\u8bc1\u6838\u5fc3\u64cd\u4f5c\u5c5e\u6027\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u7c7b\u578b\u7cfb\u7edf\u7684\u9650\u5236\uff0c\u63d0\u9ad8\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6548\u7387\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684FRP\u8bed\u8a00\uff0c\u5176\u5177\u6709\u663e\u8457\u7b80\u5316\u7684\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\u3002\u5173\u952e\u65b9\u6cd5\u662f\u901a\u8fc7\u6539\u53d8\u4fe1\u53f7\u7684\u8bed\u4e49\uff0c\u5c06\u4fe1\u53f7\u5efa\u6a21\u4e3a\u53ef\u53d8\u5f15\u7528\uff0c\u5e76\u5229\u7528'later'\u7c7b\u578b\u6a21\u6001\u6765\u4e25\u683c\u63a7\u5236\u5176\u53ef\u53d8\u6027\uff0c\u4ece\u800c\u5728\u4fdd\u8bc1\u7a0b\u5e8f\u56e0\u679c\u6027\u3001\u751f\u4ea7\u6027\u548c\u65e0\u7a7a\u95f4\u6cc4\u6f0f\u7684\u540c\u65f6\uff0c\u5141\u8bb8\u66f4\u591a\u7684\u7a0b\u5e8f\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\uff0c\u5e76\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u4fe1\u53f7\u5c31\u5730\u66f4\u65b0\u3002", "result": "\u672c\u6587\u6210\u529f\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684FRP\u8bed\u8a00\uff0c\u5176\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\u88ab\u663e\u8457\u7b80\u5316\uff0c\u76f8\u6bd4\u73b0\u6709\u6a21\u6001FRP\u8bed\u8a00\u65bd\u52a0\u7684\u9650\u5236\u66f4\u5c11\u3002\u901a\u8fc7\u6539\u53d8\u4fe1\u53f7\u7684\u8bed\u4e49\uff0c\u65b0\u7684\u7cfb\u7edf\u80fd\u591f\u5b89\u5168\u5730\u5141\u8bb8\u66f4\u591a\u7684\u7a0b\u5e8f\u901a\u8fc7\u7c7b\u578b\u68c0\u67e5\uff0c\u589e\u5f3a\u4e86\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u3002\u6b64\u5916\uff0c\u5c06\u4fe1\u53f7\u5efa\u6a21\u4e3a\u88ab\u2018later\u2019\u7c7b\u578b\u6a21\u6001\u4e25\u683c\u63a7\u5236\u7684\u53ef\u53d8\u5f15\u7528\uff0c\u5b9e\u73b0\u4e86\u4fe1\u53f7\u7684\u66f4\u9ad8\u6548\u5c31\u5730\u66f4\u65b0\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u51fd\u6570\u5f0f\u7f16\u7a0b\u98ce\u683c\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u65b0\u7684FRP\u8bed\u8a00\u53ca\u5176\u7b80\u5316\u7684\u6a21\u6001\u7c7b\u578b\u7cfb\u7edf\uff0c\u5f3a\u8c03\u5176\u5728\u4fdd\u8bc1\u6838\u5fc3\u64cd\u4f5c\u5c5e\u6027\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u8bed\u8a00\u7684\u8868\u8fbe\u80fd\u529b\u548c\u6548\u7387\u3002\u901a\u8fc7\u5bf9\u4fe1\u53f7\u8bed\u4e49\u7684\u4fee\u6539\uff0c\u5141\u8bb8\u4fe1\u53f7\u88ab\u5efa\u6a21\u4e3a\u53ef\u53d8\u5f15\u7528\uff0c\u5e76\u7531'later'\u7c7b\u578b\u6a21\u6001\u4e25\u683c\u63a7\u5236\uff0c\u8fd9\u79cd\u53d7\u63a7\u7684\u53ef\u53d8\u6027\u5728\u4fdd\u6301\u51fd\u6570\u5f0f\u7f16\u7a0b\u98ce\u683c\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u5c31\u5730\u66f4\u65b0\u3002"}}
{"id": "2512.09304", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.09304", "abs": "https://arxiv.org/abs/2512.09304", "authors": ["Siyuan Ma", "Jiajun Hu", "Jeeho Ryoo", "Aman Arora", "Lizy Kurian John"], "title": "RACAM: Enhancing DRAM with Reuse-Aware Computation and Automated Mapping for ML Inference", "comment": null, "summary": "In-DRAM Processing-In-Memory (DRAM-PIM) has emerged as a promising approach to accelerate memory-intensive workloads by mitigating data transfer overhead between DRAM and the host processor. Bit-serial DRAM-PIM architectures, further enhance efficiency by supporting runtime variable data precision, which is critical for emerging workloads, such as large language model (LLM) inference. However, existing works still have major limitations: lack of data reuse, significant amounts of redundant data transfer, and insufficient support for workload mapping. To address these issues, we propose RACAM, the first in-DRAM bit-serial architecture which uses dedicated locality buffers, bit-serial PEs, popcount reduction units and broadcast units to enable data reuse and alleviate redundant data transfers. Furthermore, a workload mapping mechanism is proposed to fully explore the massive parallelism of DRAM architecture and identify the best mapping scheme of a given workload. We evaluate RACAM against GPUs and the state-of-the-art, in-DRAM PIM system, Proteus, across end-to-end LLM inferences. RACAM achieves 9x to 102x speedup over GPUs and 233x higher performance per mm2 compared to Proteus in case of GPT3.", "AI": {"tldr": "\u4e0e\u6b64\u8bba\u6587\u76f8\u5173\u7684\u9886\u57df\u5305\u62ec\uff1a\u56fe\u5904\u7406\uff08Graph processing\uff09 (\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca), MLIR (\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca), \u7f16\u8bd1\u5668 (\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca), HLS (\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca)\u3002\u4e3b\u8981\u76f8\u5173\u9886\u57df\u662f**DSL** (\u6ca1\u6709\u76f4\u63a5\u63d0\u53ca\uff0c\u4f46\u5176\u52a0\u901f\u76ee\u6807\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u53ef\u80fd\u6d89\u53ca\u9886\u57df\u7279\u5b9a\u4f18\u5316), **\u7f16\u8bd1\u5668** (\u6d89\u53ca\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u548c\u4f18\u5316).\n\n**\u592a\u957f\u4e0d\u770b (TLDR) \u6982\u8981\uff1a**\u4e3a\u4e86\u89e3\u51b3\u73b0\u6709\u4f4d\u4e32\u884cDRAM-PIM\u67b6\u6784\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u63a8\u7406\u4e2d\u7f3a\u4e4f\u6570\u636e\u91cd\u7528\u3001\u5197\u4f59\u6570\u636e\u4f20\u8f93\u548c\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86RACAM\uff0c\u8fd9\u662f\u9996\u4e2a\u91c7\u7528\u4e13\u7528\u5c40\u90e8\u6027\u7f13\u51b2\u533a\u3001\u4f4d\u4e32\u884cPE\u3001\u4ee5\u53ca\u5f52\u7ea6\u548c\u5e7f\u64ad\u5355\u5143\u7684DRAM\u5185\u4f4d\u4e32\u884c\u67b6\u6784\uff0c\u4ee5\u5b9e\u73b0\u6570\u636e\u91cd\u7528\u548c\u51cf\u5c11\u4f20\u8f93\u5197\u4f59\u3002 RACAM\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u673a\u5236\u6765\u5145\u5206\u5229\u7528DRAM\u5e76\u884c\u6027\u5e76\u4f18\u5316\u6620\u5c04\u65b9\u6848\u3002 \u5728LLM\u63a8\u7406\u8bc4\u4f30\u4e2d\uff0cRACAM\u76f8\u6bd4GPU\u5b9e\u73b0\u4e869\u500d\u5230102\u500d\u7684\u52a0\u901f\uff0c\u5e76\u4e14\u76f8\u5bf9\u4e8e\u6700\u5148\u8fdb\u7684DRAM\u5185PIM\u7cfb\u7edfProteus\uff0c\u6027\u80fd\u5bc6\u5ea6\u63d0\u9ad8\u4e86233\u500d\u3002", "motivation": "\u73b0\u6709\u7684\u5185\u5b58\u5904\u7406\uff08PIM\uff09\u6280\u672f\uff0c\u5c24\u5176\u662f\u4f4d\u4e32\u884cDRAM-PIM\u67b6\u6784\uff0c\u867d\u7136\u901a\u8fc7\u652f\u6301\u8fd0\u884c\u65f6\u53ef\u53d8\u6570\u636e\u7cbe\u5ea6\u5728LLM\u63a8\u7406\u7b49\u65b0\u5174\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u4e3b\u8981\u9650\u5236\uff1a\u7f3a\u4e4f\u6570\u636e\u91cd\u7528\u3001\u5927\u91cf\u7684\u5197\u4f59\u6570\u636e\u4f20\u8f93\u4ee5\u53ca\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u652f\u6301\u4e0d\u8db3\u3002\u8fd9\u4e9b\u9650\u5236\u963b\u788d\u4e86\u5176\u6548\u7387\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "RACAM\u662f\u9996\u4e2aDRAM\u5185\u4f4d\u4e32\u884c\u67b6\u6784\uff0c\u5176\u6838\u5fc3\u673a\u5236\u5305\u62ec\uff1a1. \u4e13\u7528\u7684\u5c40\u90e8\u6027\u7f13\u51b2\u533a\uff08dedicated locality buffers\uff09\u4ee5\u63d0\u9ad8\u6570\u636e\u91cd\u7528\u30022. \u4f4d\u4e32\u884c\u5904\u7406\u5355\u5143\uff08bit-serial PEs\uff09\u652f\u6301\u8fd0\u884c\u65f6\u7684\u53ef\u53d8\u6570\u636e\u7cbe\u5ea6\u30023. popcount\u5f52\u7ea6\u5355\u5143\uff08popcount reduction units\uff09\u548c\u5e7f\u64ad\u5355\u5143\uff08broadcast units\uff09\u4ee5\u51cf\u8f7b\u5197\u4f59\u6570\u636e\u4f20\u8f93\u30024. \u63d0\u51fa\u4e86\u4e00\u79cd\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u673a\u5236\uff08workload mapping mechanism\uff09\u4ee5\u5145\u5206\u5229\u7528DRAM\u67b6\u6784\u7684\u5927\u89c4\u6a21\u5e76\u884c\u6027\uff0c\u5e76\u627e\u5230\u7ed9\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6700\u4f73\u6620\u5c04\u65b9\u6848\u3002", "result": "RACAM\u5728\u7aef\u5230\u7aefLLM\u63a8\u7406\u65b9\u9762\u7684\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff1a\u76f8\u5bf9\u4e8eGPU\uff0cRACAM\u5b9e\u73b0\u4e869\u500d\u5230102\u500d\u7684\u52a0\u901f\u3002\u5728GPT3\u7684\u60c5\u51b5\u4e0b\uff0cRACAM\u7684\u6bcf\u5e73\u65b9\u6beb\u7c73\u6027\u80fd\uff08performance per mm2\uff09\u6bd4\u73b0\u6709\u7684\u6700\u5148\u8fdbDRAM\u5185PIM\u7cfb\u7edfProteus\u9ad8\u51fa233\u500d\u3002", "conclusion": "RACAM\u662f\u9996\u4e2aDRAM\u5185\u4f4d\u4e32\u884cPIM\u67b6\u6784\uff0c\u901a\u8fc7\u4e13\u7528\u7684\u5c40\u90e8\u6027\u7f13\u51b2\u533a\u3001\u4f4d\u4e32\u884cPE\u3001popcount\u5f52\u7ea6\u5355\u5143\u548c\u5e7f\u64ad\u5355\u5143\u5b9e\u73b0\u4e86\u6570\u636e\u91cd\u7528\u5e76\u51cf\u5c11\u4e86\u5197\u4f59\u6570\u636e\u4f20\u8f93\u3002\u540c\u65f6\uff0c\u63d0\u51fa\u7684\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u673a\u5236\u5145\u5206\u5229\u7528\u4e86DRAM\u67b6\u6784\u7684\u5e76\u884c\u6027\uff0c\u5e76\u786e\u5b9a\u4e86\u7ed9\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u7684\u6700\u4f73\u6620\u5c04\u65b9\u6848\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cRACAM\u5728\u7aef\u5230\u7aef\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u9762\uff0c\u76f8\u5bf9\u4e8eGPU\u548c\u73b0\u6709\u6700\u5148\u8fdb\u7684DRAM\u5185PIM\u7cfb\u7edfProteus\uff0c\u5177\u6709\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u66f4\u9ad8\u7684\u6bcf\u5e73\u65b9\u6beb\u7c73\u6027\u80fd\u3002"}}
{"id": "2512.09080", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.09080", "abs": "https://arxiv.org/abs/2512.09080", "authors": ["Ron Mosenzon"], "title": "Almost-Optimal Approximation Algorithms for Global Minimum Cut in Directed Graphs", "comment": "40 pages. Submitted to STOC 2026", "summary": "We develop new $(1+\u03b5)$-approximation algorithms for finding the global minimum edge-cut in a directed edge-weighted graph, and for finding the global minimum vertex-cut in a directed vertex-weighted graph. Our algorithms are randomized, and have a running time of $O\\left(m^{1+o(1)}/\u03b5\\right)$ on any $m$-edge $n$-vertex input graph, assuming all edge/vertex weights are polynomially-bounded. In particular, for any constant $\u03b5>0$, our algorithms have an almost-optimal running time of $O\\left(m^{1+o(1)}\\right)$. The fastest previously-known running time for this setting, due to (Cen et al., FOCS 2021), is $\\tilde{O}\\left(\\min\\left\\{n^2/\u03b5^2,m^{1+o(1)}\\sqrt{n}\\right\\}\\right)$ for Minimum Edge-Cut, and $\\tilde{O}\\left(n^2/\u03b5^2\\right)$ for Minimum Vertex-Cut. Our results further extend to the rooted variants of the Minimum Edge-Cut and Minimum Vertex-Cut problems, where the algorithm is additionally given a root vertex $r$, and the goal is to find a minimum-weight cut separating any vertex from the root $r$. In terms of techniques, we build upon and extend a framework that was recently introduced by (Chuzhoy et al., SODA 2026) for solving the Minimum Vertex-Cut problem in unweighted directed graphs. Additionally, in order to obtain our result for the Global Minimum Vertex-Cut problem, we develop a novel black-box reduction from this problem to its rooted variant. Prior to our work, such reductions were only known for more restricted settings, such as when all vertex-weights are unit.", "AI": {"tldr": "This paper is not related to DSL or MLIR or HLS or compiler. The paper is related to **graph processing** (minimum cut problems in directed graphs).\n\nTLDR: The paper presents new randomized $(1+\u03b5)$-approximation algorithms for finding the global minimum edge-cut and vertex-cut in directed weighted graphs. These algorithms achieve an almost-optimal running time of $O\\left(m^{1+o(1)}/\u03b5\\right)$, significantly improving upon previous results. The techniques build on and extend existing frameworks, and a novel black-box reduction is developed to relate the global minimum vertex-cut problem to its rooted variant.", "motivation": "\u672c\u6587\u7684\u52a8\u673a\u662f\u5bfb\u627e\u6709\u5411\u52a0\u6743\u56fe\uff08\u5305\u62ec\u8fb9\u52a0\u6743\u56fe\u7684\u5168\u5c40\u6700\u5c0f\u8fb9\u5272\u548c\u70b9\u52a0\u6743\u56fe\u7684\u5168\u5c40\u6700\u5c0f\u70b9\u5272\uff09\u7684\u66f4\u5feb\u901f\u7684\u8fd1\u4f3c\u7b97\u6cd5\u3002\u5df2\u6709\u7684\u6700\u5feb\u7b97\u6cd5\u5728\u6700\u5c0f\u8fb9\u5272\u95ee\u9898\u4e0a\u7684\u8fd0\u884c\u65f6\u95f4\u4e3a $\\tilde{O}(\\min\\{n^2/\\epsilon^2,m^{1+o(1)}\\sqrt{n}\\})$\uff0c\u5728\u6700\u5c0f\u70b9\u5272\u95ee\u9898\u4e0a\u4e3a $\\tilde{O}(n^2/\\epsilon^2)$\u3002\u672c\u6587\u65e8\u5728\u6539\u8fdb\u8fd9\u4e9b\u590d\u6742\u5ea6\uff0c\u8fbe\u5230\u66f4\u63a5\u8fd1\u6700\u4f18\u7684 $O(m^{1+o(1)}/\\epsilon)$ \u8fd0\u884c\u65f6\u95f4\u3002\u540c\u65f6\uff0c\u672c\u6587\u8fd8\u5e0c\u671b\u5c06\u5176\u7ed3\u679c\u6269\u5c55\u5230\u5e26\u6839\u7248\u672c\u7684\u6700\u5c0f\u5272\u95ee\u9898\uff0c\u5e76\u4e3a\u5168\u5c40\u6700\u5c0f\u70b9\u5272\u95ee\u9898\u63d0\u4f9b\u66f4\u901a\u7528\u7684\u5f52\u7ea6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e4b\u524d\u4ec5\u9002\u7528\u4e8e\u66f4\u53d7\u9650\u8bbe\u7f6e\uff08\u5982\u5355\u4f4d\u70b9\u6743\uff09\u7684\u5f52\u7ea6\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002", "method": "\u672c\u6587\u5f00\u53d1\u4e86\u65b0\u7684\u6c42\u89e3\u6709\u5411\u52a0\u6743\u56fe\u7684\u5168\u5c40\u6700\u5c0f\u8fb9\u5272\u548c\u5168\u5c40\u6700\u5c0f\u70b9\u5272\u7684 $(1+\u03b5)$-\u8fd1\u4f3c\u968f\u673a\u7b97\u6cd5\u3002\u7b97\u6cd5\u501f\u9274\u5e76\u6269\u5c55\u4e86 Chuzhoy \u7b49\u4eba\uff08SODA 2026\uff09 \u4e3a\u89e3\u51b3\u65e0\u6743\u6709\u5411\u56fe\u6700\u5c0f\u70b9\u5272\u95ee\u9898\u5f15\u5165\u7684\u6846\u67b6\u3002\u6b64\u5916\uff0c\u4e3a\u4e86\u89e3\u51b3\u5168\u5c40\u6700\u5c0f\u70b9\u5272\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u9ed1\u76d2\u5f52\u7ea6\u65b9\u6cd5\uff0c\u5c06\u8be5\u95ee\u9898\u5f52\u7ea6\u5230\u5176\u5e26\u6839\u7248\u672c\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u6c42\u89e3\u6709\u5411\u52a0\u6743\u56fe\u5168\u5c40\u6700\u5c0f\u8fb9\u5272\u548c\u5168\u5c40\u6700\u5c0f\u70b9\u5272\u7684 $(1+\u03b5)$-\u8fd1\u4f3c\u968f\u673a\u7b97\u6cd5\uff0c\u5176\u8fd0\u884c\u65f6\u95f4\u4e3a $O\\left(m^{1+o(1)}/\u03b5\\right)$\uff0c\u5728\u591a\u9879\u5f0f\u6709\u754c\u6743\u91cd\u4e0b\uff0c\u5bf9\u4e8e\u5e38\u6570 $\u03b5>0$\uff0c\u8fbe\u5230\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684 $O\\left(m^{1+o(1)}\\right)$ \u590d\u6742\u5ea6\u3002\u8fd9\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u6700\u5feb\u7684\u7b97\u6cd5\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u7ed3\u679c\u53ef\u4ee5\u6269\u5c55\u5230\u5e26\u6839\u7248\u672c\u7684\u6700\u5c0f\u8fb9\u5272\u548c\u6700\u5c0f\u70b9\u5272\u95ee\u9898\u3002\u672c\u6587\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a novel \u7684\u9ed1\u76d2\u5f52\u7ea6\u65b9\u6cd5\uff0c\u5c06\u5168\u5c40\u6700\u5c0f\u70b9\u5272\u95ee\u9898\u5f52\u7ea6\u5230\u5176\u5e26\u6839\u7248\u672c\uff0c\u8fd9\u5728\u4ee5\u524d\u4ec5\u9002\u7528\u4e8e\u66f4\u53d7\u9650\u7684\u8bbe\u7f6e\uff08\u5982\u5355\u4f4d\u70b9\u6743\uff09\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u6c42\u89e3\u6709\u5411\u56fe\u5168\u5c40\u6700\u5c0f\u8fb9\u5272\u548c\u5168\u5c40\u6700\u5c0f\u70b9\u5272\u7684 $(1+\u03b5)$-\u8fd1\u4f3c\u7b97\u6cd5\u3002\u8fd9\u4e9b\u7b97\u6cd5\u5728\u591a\u9879\u5f0f\u6709\u754c\u6743\u91cd\u4e0b\uff0c\u8fd0\u884c\u65f6\u95f4\u590d\u6742\u5ea6\u8fbe\u5230\u4e86\u8fd1\u4e4e\u6700\u4f18\u7684 $O(m^{1+o(1)}/\\epsilon)$\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u5168\u5c40\u6700\u5c0f\u70b9\u5272\u95ee\u9898\u5f52\u7ea6\u5230\u5176\u5e26\u6839\u7248\u672c\u7684\u65b0\u7684\u9ed1\u76d2\u5f52\u7ea6\u65b9\u6cd5\uff0c\u4e3a\u89e3\u51b3\u66f4\u4e00\u822c\u7684\u56fe\u5207\u5272\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u601d\u8def\u3002"}}
{"id": "2512.09427", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.09427", "abs": "https://arxiv.org/abs/2512.09427", "authors": ["Guoqiang Zou", "Wanyu Wang", "Hao Zheng", "Longxiang Yin", "Yinhe Han"], "title": "ODMA: On-Demand Memory Allocation Framework for LLM Serving on LPDDR-Class Accelerators", "comment": "10 pages, 5 figures", "summary": "Serving large language models (LLMs) on accelerators with poor random-access bandwidth (e.g., LPDDR5-based) is limited by current memory managers. Static pre-allocation wastes memory, while fine-grained paging (e.g., PagedAttention) is ill-suited due to high random-access costs. Existing HBM-centric solutions do not exploit the characteristics of random-access-constrained memory (RACM) accelerators like Cambricon MLU370. We present ODMA, an on-demand memory allocation framework for RACM. ODMA addresses distribution drift and heavy-tailed requests by coupling a lightweight length predictor with dynamic bucket partitioning and a large-bucket safeguard. Boundaries are periodically updated from live traces to maximize utilization. On Alpaca and Google-NQ, ODMA improves prediction accuracy of prior work significantly (e.g., from 82.68% to 93.36%). Serving DeepSeek-R1-Distill-Qwen-7B on Cambricon MLU370-X4, ODMA raises memory utilization from 55.05% to 72.45% and improves RPS and TPS by 29% and 27% over static baselines. This demonstrates that hardware-aware allocation unlocks efficient LLM serving on RACM platforms.", "AI": {"tldr": "\u76f8\u5173\u6027\uff1a\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\uff08\u786c\u4ef6\u611f\u77e5\u5206\u914d\uff09\u548c\u56fe\u5904\u7406\uff08Cambricon MLU370\u662f\u9488\u5bf9AI\u8ba1\u7b97\u7684\u52a0\u901f\u5668\uff0c\u901a\u5e38\u6d89\u53ca\u56fe\u6216\u5f20\u91cf\u5904\u7406\uff0c\u5c3d\u7ba1\u62bd\u8c61\u4e2d\u672a\u76f4\u63a5\u63d0\u53ca\u56fe\u5904\u7406\uff0c\u4f46\u5176\u4e0a\u4e0b\u6587\u5f3a\u76f8\u5173\uff09\u76f8\u5173\uff0c\u5c5e\u4e8eLLM\u63a8\u7406\u7684\u7cfb\u7edf\u4f18\u5316\u548c\u5b58\u50a8\u7ba1\u7406\u8303\u7574\u3002\u6b64\u5916\uff0c\u5b83\u63d0\u5230\u4e86\u786c\u4ef6\uff08Cambricon MLU370\uff09\u548c\u4f4e\u5e26\u5bbd\u5185\u5b58\uff08LPDDR5-based\uff09\uff0c\u4e0eHLS\uff08High-Level Synthesis\uff09\u6216\u7279\u5b9a\u786c\u4ef6\u4f18\u5316\u65b9\u6cd5\u6709\u6f5c\u5728\u5173\u8054\u3002\n\n\u592a\u957f\u4e0d\u770b\uff08TLDR\uff09\uff1a\u5f53\u5728\u53d7\u968f\u673a\u8bbf\u95ee\u5e26\u5bbd\u9650\u5236\u7684\u52a0\u901f\u5668\uff08RACM\uff0c\u5982\u4f7f\u7528LPDDR5\u7684\u52a0\u901f\u5668\uff09\u4e0a\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u65f6\uff0c\u5f53\u524d\u7684\u5185\u5b58\u7ba1\u7406\u65b9\u6cd5\u6548\u7387\u4f4e\u4e0b\uff08\u9759\u6001\u9884\u5206\u914d\u6d6a\u8d39\u5185\u5b58\uff0c\u7ec6\u7c92\u5ea6\u5206\u9875\u56e0\u9ad8\u968f\u673a\u8bbf\u95ee\u6210\u672c\u4e0d\u9002\u5408\uff09\u3002\u672c\u6587\u63d0\u51faODMA\uff0c\u4e00\u79cd\u7528\u4e8eRACM\u7684\u6309\u9700\u5185\u5b58\u5206\u914d\u6846\u67b6\uff0c\u5b83\u901a\u8fc7\u7ed3\u5408\u8f7b\u91cf\u7ea7\u957f\u5ea6\u9884\u6d4b\u5668\u3001\u52a8\u6001\u6876\u5206\u533a\u548c\u5927\u578b\u6876\u4fdd\u62a4\u673a\u5236\uff0c\u5904\u7406\u8bf7\u6c42\u5206\u5e03\u6f02\u79fb\u548c\u91cd\u5c3e\u8bf7\u6c42\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cODMA\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u7387\uff08\u5982\u4ece82.68%\u523093.36%\uff09\uff0c\u5e76\u5c06Cambricon MLU370\u4e0aLLM\u670d\u52a1\u7684\u5185\u5b58\u5229\u7528\u7387\u4ece55.05%\u63d0\u9ad8\u523072.45%\uff0cRPS\u548cTPS\u5206\u522b\u63d0\u9ad8\u4e8629%\u548c27%\u3002\u8fd9\u8868\u660e\u786c\u4ef6\u611f\u77e5\u7684\u5206\u914d\u662f\u89e3\u9501RACM\u5e73\u53f0\u4e0a\u9ad8\u6548LLM\u670d\u52a1\u7684\u5173\u952e\u3002", "motivation": "\u73b0\u6709\u7684\u5185\u5b58\u7ba1\u7406\u5668\uff08\u5982\u9759\u6001\u9884\u5206\u914d\u548c\u7ec6\u7c92\u5ea6\u5206\u9875PagingAttention\uff09\u5728\u968f\u673a\u8bbf\u95ee\u53d7\u9650\u7684\u5185\u5b58\uff08RACM\uff09\u52a0\u901f\u5668\uff08\u5982\u57fa\u4e8eLPDDR5\u7684\u52a0\u901f\u5668\uff09\u4e0a\u670d\u52a1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u65f6\u6548\u7387\u4f4e\u4e0b\u3002\u9759\u6001\u9884\u5206\u914d\u6d6a\u8d39\u5185\u5b58\uff0c\u800c\u7ec6\u7c92\u5ea6\u5206\u9875\u7531\u4e8e\u9ad8\u968f\u673a\u8bbf\u95ee\u6210\u672c\u800c\u4e0d\u9002\u7528\u3002\u73b0\u6709\u7684\u4ee5HBM\u4e3a\u4e2d\u5fc3\u7684\u89e3\u51b3\u65b9\u6848\u672a\u9488\u5bf9RACM\u7684\u7279\u6027\u8fdb\u884c\u4f18\u5316\u3002", "method": "ODMA\u901a\u8fc7\u7ed3\u5408\u8f7b\u91cf\u7ea7\u957f\u5ea6\u9884\u6d4b\u5668\u3001\u52a8\u6001\u6876\u5206\u533a\u548c\u5927\u578b\u6876\u4fdd\u62a4\u673a\u5236\uff0c\u6765\u5904\u7406\u8bf7\u6c42\u957f\u5ea6\u5206\u5e03\u6f02\u79fb\u548c\u91cd\u5c3e\u8bf7\u6c42\u3002\u540c\u65f6\uff0c\u5b83\u5468\u671f\u6027\u5730\u6839\u636e\u5b9e\u65f6\u8ffd\u8e2a\u6570\u636e\u66f4\u65b0\u5206\u754c\uff0c\u4ee5\u6700\u5927\u5316\u5185\u5b58\u5229\u7528\u7387\u3002", "result": "\u5728Alpaca\u548cGoogle-NQ\u6570\u636e\u96c6\u4e0a\uff0cODMA\u663e\u8457\u63d0\u9ad8\u4e86\u9884\u6d4b\u51c6\u786e\u7387\uff08\u4f8b\u5982\uff0c\u4ece82.68%\u63d0\u9ad8\u523093.36%\uff09\u3002\u5728Cambricon MLU370-X4\u4e0a\u670d\u52a1DeepSeek-R1-Distill-Qwen-7B\u65f6\uff0cODMA\u5c06\u5185\u5b58\u5229\u7528\u7387\u4ece55.05%\u63d0\u9ad8\u523072.45%\uff0c\u5e76\u76f8\u5bf9\u4e8e\u9759\u6001\u57fa\u7ebf\u5c06RPS\u548cTPS\u5206\u522b\u63d0\u9ad8\u4e8629%\u548c27%\u3002", "conclusion": "ODMA\u8bc1\u660e\u4e86\u786c\u4ef6\u611f\u77e5\u7684\u5185\u5b58\u5206\u914d\u53ef\u4ee5\u6709\u6548\u63d0\u5347LLM\u5728\u53d7\u968f\u673a\u8bbf\u5b58\u5e26\u5bbd\u9650\u5236\u7684\u52a0\u901f\u5668\uff08RACM\uff09\u4e0a\u7684\u670d\u52a1\u6548\u7387\u3002"}}
{"id": "2512.09218", "categories": ["cs.DS"], "pdf": "https://arxiv.org/pdf/2512.09218", "abs": "https://arxiv.org/abs/2512.09218", "authors": ["Mohsen Ghaffari", "Jaehyun Koo"], "title": "Dynamic Graph Coloring: Sequential, Parallel, and Distributed", "comment": null, "summary": "We present a simple randomized algorithm that can efficiently maintain a $(\u0394+1)$ coloring as the graph undergoes edge insertion and deletion updates, where $\u0394$ denotes an upper bound on the maximum degree. A key advantage is the algorithm's ability to process many updates simultaneously, which makes it naturally adaptable to the parallel and distributed models. Concretely, it gives a unified framework across the models, leading to the following results:\n  - In the sequential setting, the algorithm processes each update in $O(1)$ expected time, worst-case. This matches and strengthens the results of Henzinger and Peng [TALG 2022] and Bhattacharya et al. [TALG 2022], who achieved an $O(1)$ bound but amortized (in expectation and with high probability, respectively), whose work was an improvement of the $O(\\log \u0394)$ expected amortized bound of Bhattacharya et al. [SODA'18].\n  - In the parallel setting, the algorithm processes each (arbitrary size) batch of updates using $O(1)$ work per update in the batch in expectation, and in $\\text{poly}(\\log n)$ depth with high probability. This is, in a sense, an ideal parallelization of the above results.\n  - In the distributed setting, the algorithm can maintain a coloring of the network graph as (potentially many) edges are added or deleted. The maintained coloring is always proper; it may become partial upon updates, i.e., some nodes may temporarily lose their colors, but quickly converges to a full, proper coloring. Concretely, each insertion and deletion causes at most $O(1)$ nodes to become uncolored, but this is resolved within $O(\\log n)$ rounds with high probability (e.g., in the absence of further updates nearby--the precise guarantee is stronger, but technical). Importantly, the algorithm incurs only $O(1)$ expected message complexity and computation per update.", "AI": {"tldr": "\u672c\u6587\u6d89\u53ca\u56fe\u5904\u7406\uff08Graph Processing\uff09\u3002\n\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7b80\u5355\u7684\u968f\u673a\u7b97\u6cd5\uff0c\u7528\u4e8e\u5728\u56fe\u7ecf\u5386\u8fb9\u63d2\u5165\u548c\u5220\u9664\uff08\u52a8\u6001\u56fe\uff09\u65f6\u9ad8\u6548\u5730\u7ef4\u62a4 $(\\Delta+1)$ \u67d3\u8272\u3002\u8be5\u7b97\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u5728\u987a\u5e8f\u8bbe\u5b9a\u4e2d\uff0c\u5b83\u4ee5 $O(1)$ \u9884\u671f\u7684\u6700\u574f\u60c5\u51b5\u65f6\u95f4\u5904\u7406\u6bcf\u4e2a\u66f4\u65b0\uff0c\u6539\u8fdb\u4e86\u4ee5\u5f80\u7684\u644a\u8fd8\u7ed3\u679c\u3002\u5728\u5e76\u884c\u8bbe\u5b9a\u4e2d\uff0c\u5b83\u4ee5\u6bcf\u4e2a\u66f4\u65b0 $O(1)$ \u9884\u671f\u5de5\u4f5c\u91cf\u548c $\\text{poly}(\\log n)$ \u6df1\u5ea6\u5904\u7406\u4efb\u610f\u5927\u5c0f\u7684\u66f4\u65b0\u6279\u6b21\u3002\u5728\u5206\u5e03\u5f0f\u8bbe\u5b9a\u4e2d\uff0c\u5b83\u5728\u6bcf\u6b21\u66f4\u65b0\u540e\u4ee5 $O(\\log n)$ \u8f6e\u548c $O(1)$ \u9884\u671f\u7684\u6d88\u606f/\u8ba1\u7b97\u590d\u6742\u5ea6\u5feb\u901f\u6062\u590d\u6b63\u786e\u7684\u7740\u8272\u3002", "motivation": "\u52a8\u6001\u56fe\u7740\u8272\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u7406\u8bba\u548c\u5e94\u7528\u95ee\u9898\uff0c\u8981\u6c42\u5728\u56fe\u7ed3\u6784\u53d1\u751f\u53d8\u5316\uff08\u8fb9\u63d2\u5165/\u5220\u9664\uff09\u65f6\uff0c\u4fdd\u6301\u56fe\u7684\u6709\u6548\u7740\u8272\u3002\u4ee5\u524d\u7684\u5de5\u4f5c\uff08\u5982 Bhattacharya \u7b49\u4eba\u7684 SODA'18\u3001TALG 2022\uff09\u5df2\u7ecf\u53d6\u5f97\u4e86 $O(1)$ \u644a\u8fd8\u65f6\u95f4\u6216 $O(\\log \\Delta)$ \u644a\u8fd8\u65f6\u95f4\u7684\u7ed3\u679c\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\u6765\u9ad8\u6548\u5730\u5904\u7406\u987a\u5e8f\u3001\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u6a21\u578b\u4e2d\u7684\u6279\u91cf\u66f4\u65b0\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u5177\u6709 $O(1)$ \u9884\u671f\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u7b97\u6cd5\u3002\u672c\u6587\u7684\u52a8\u673a\u662f\u8bbe\u8ba1\u4e00\u4e2a\u7b80\u5355\u3001\u9ad8\u6548\u7684\u968f\u673a\u7b97\u6cd5\uff0c\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u540c\u65f6\u5728\u6240\u6709\u6a21\u578b\u4e2d\u6539\u8fdb\u6216\u5339\u914d\u73b0\u6709\u6700\u4f73\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u987a\u5e8f\u6a21\u578b\u4e2d\u5b9e\u73b0 $O(1)$ \u9884\u671f\u7684\u6700\u574f\u60c5\u51b5\u65f6\u95f4\u590d\u6742\u5ea6\u548c\u5728\u5e76\u884c/\u5206\u5e03\u5f0f\u6a21\u578b\u4e2d\u9ad8\u6548\u5904\u7406\u6279\u91cf\u66f4\u65b0\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u201c\u7b80\u5355\u201d\u7684\u968f\u673a\u7b97\u6cd5\uff08SODA'18 \u5de5\u4f5c\u7684\u53d8\u4f53\uff0c\u4f46\u5177\u6709\u66f4\u5f3a\u7684\u754c\u9650\uff09\uff0c\u8be5\u7b97\u6cd5\u5229\u7528\u5176\u540c\u65f6\u5904\u7406\u591a\u4e2a\u66f4\u65b0\u7684\u80fd\u529b\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6846\u67b6\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u6a21\u578b\u3002\u6838\u5fc3\u65b9\u6cd5\u662f\u57fa\u4e8e\u968f\u673a\u5316\u7684\u7ef4\u62a4\u7b56\u7565\uff0c\u65e8\u5728\u5728\u66f4\u65b0\u53d1\u751f\u65f6\u4fdd\u6301\u56fe\u7684 $(\\Delta+1)$ \u67d3\u8272\u3002", "result": "- **\u987a\u5e8f\u8bbe\u5b9a\uff1a** \u7b97\u6cd5\u4ee5 $O(1)$ \u9884\u671f\u7684\u6700\u574f\u60c5\u51b5\u65f6\u95f4\u5904\u7406\u6bcf\u4e2a\u66f4\u65b0\uff0c\u5339\u914d\u5e76\u63d0\u9ad8\u4e86\u73b0\u6709\u7ed3\u679c\uff08\u5982 Henzinger \u548c Peng \u7684 TALG 2022\uff09\uff0c\u540e\u8005\u4ec5\u5b9e\u73b0\u4e86\u644a\u8fd8\u7ed3\u679c\u3002\n- **\u5e76\u884c\u8bbe\u5b9a\uff1a** \u7b97\u6cd5\u4ee5\u6bcf\u4e2a\u66f4\u65b0 $O(1)$ \u9884\u671f\u7684\u5de5\u4f5c\u91cf\u5904\u7406\u4efb\u610f\u5927\u5c0f\u7684\u66f4\u65b0\u6279\u6b21\uff0c\u5e76\u4ee5 $\\text{poly}(\\log n)$ \u7684\u6df1\u5ea6\uff08\u9ad8\u6982\u7387\uff09\u5b8c\u6210\u3002\u8fd9\u88ab\u8ba4\u4e3a\u662f\u73b0\u6709\u7ed3\u679c\u7684\u201c\u7406\u60f3\u201d\u5e76\u884c\u5316\u3002\n- **\u5206\u5e03\u5f0f\u8bbe\u5b9a\uff1a** \u7b97\u6cd5\u5728\u6bcf\u6b21\u63d2\u5165\u548c\u5220\u9664\u540e\u4ec5\u5bfc\u81f4\u81f3\u591a $O(1)$ \u4e2a\u8282\u70b9\u53d8\u4e3a\u672a\u7740\u8272\uff0c\u5e76\u5728 $O(\\log n)$ \u8f6e\u5185\uff08\u9ad8\u6982\u7387\uff09\u6536\u655b\u5230\u4e00\u4e2a\u5b8c\u6574\u7684\u3001\u6b63\u786e\u7684\u7740\u8272\u3002\u91cd\u8981\u7684\u662f\uff0c\u7b97\u6cd5\u7684\u9884\u671f\u6d88\u606f\u590d\u6742\u5ea6\u4e3a $O(1)$\uff0c\u6bcf\u6b21\u66f4\u65b0\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u4e5f\u4e3a $O(1)$\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u968f\u673a\u7b97\u6cd5\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u56fe\u7ecf\u5386\u8fb9\u63d2\u5165\u548c\u5220\u9664\u66f4\u65b0\u65f6\uff08\u5373\u52a8\u6001\u56fe\uff09\u9ad8\u6548\u5730\u7ef4\u62a4\u4e00\u4e2a $(\\Delta+1)$ \u67d3\u8272\u3002\u8be5\u7b97\u6cd5\u5728\u987a\u5e8f\u3001\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u6a21\u578b\u4e2d\u90fd\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5c24\u5176\u662f\u5728\u987a\u5e8f\u6a21\u578b\u4e2d\u5b9e\u73b0\u4e86\u6bcf\u66f4\u65b0 $O(1)$ \u9884\u671f\u7684\u6700\u574f\u60c5\u51b5\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u5e76\u5728\u5e76\u884c\u548c\u5206\u5e03\u5f0f\u6a21\u578b\u4e2d\u5c55\u793a\u4e86\u9ad8\u6548\u7684\u6279\u91cf\u66f4\u65b0\u5904\u7406\u80fd\u529b\u548c\u8f83\u4f4e\u7684\u901a\u4fe1/\u8ba1\u7b97\u5f00\u9500\uff0c\u4e3a\u52a8\u6001\u56fe\u7740\u8272\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.09568", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.09568", "abs": "https://arxiv.org/abs/2512.09568", "authors": ["Zhi Zhao", "Hang Xiao", "Wei Rang"], "title": "PHWSOA: A Pareto-based Hybrid Whale-Seagull Scheduling for Multi-Objective Tasks in Cloud Computing", "comment": "24 pages,5 figures", "summary": "Task scheduling is a critical research challenge in cloud computing, a transformative technology widely adopted across industries. Although numerous scheduling solutions exist, they predominantly optimize singular or limited metrics such as execution time or resource utilization often neglecting the need for comprehensive multi-objective optimization. To bridge this gap, this paper proposes the Pareto-based Hybrid Whale-Seagull Optimization Algorithm (PHWSOA). This algorithm synergistically combines the strengths of the Whale Optimization Algorithm (WOA) and the Seagull Optimization Algorithm (SOA), specifically mitigating WOA's limitations in local exploitation and SOA's constraints in global exploration. Leveraging Pareto dominance principles, PHWSOA simultaneously optimizes three key objectives: makespan, virtual machine (VM) load balancing, and economic cost. Key enhancements include: Halton sequence initialization for superior population diversity, a Pareto-guided mutation mechanism to avert premature convergence, and parallel processing for accelerated convergence. Furthermore, a dynamic VM load redistribution mechanism is integrated to improve load balancing during task execution. Extensive experiments conducted on the CloudSim simulator, utilizing real-world workload traces from NASA-iPSC and HPC2N, demonstrate that PHWSOA delivers substantial performance gains. Specifically, it achieves up to a 72.1% reduction in makespan, a 36.8% improvement in VM load balancing, and 23.5% cost savings. These results substantially outperform baseline methods including WOA, GA, PEWOA, and GCWOA underscoring PHWSOA's strong potential for enabling efficient resource management in practical cloud environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001DSL\u3001MLIR\u3001\u6216HLS\u65e0\u5173\uff0c\u4f46\u662f\u4e0e\u56fe\u5904\u7406\u4e2d\u7684\u4f18\u5316\u7b97\u6cd5\u6709\u5173\uff08WOA/SOA/PHWSOA\uff09\u3002\n\n\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePareto\u7684\u6df7\u5408\u9cb8\u9c7c-\u6d77\u9e25\u4f18\u5316\u7b97\u6cd5\uff08PHWSOA\uff09\uff0c\u7528\u4e8e\u4e91\u8ba1\u7b97\u4efb\u52a1\u8c03\u5ea6\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u3002PHWSOA\u7ed3\u5408\u4e86\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\uff08WOA\uff09\u548c\u6d77\u9e25\u4f18\u5316\u7b97\u6cd5\uff08SOA\uff09\u7684\u4f18\u52bf\uff0c\u5e76\u5229\u7528Pareto\u652f\u914d\u539f\u7406\u540c\u65f6\u4f18\u5316\u5b8c\u5de5\u65f6\u95f4\u3001VM\u8d1f\u8f7d\u5747\u8861\u548c\u7ecf\u6d4e\u6210\u672c\u3002\u901a\u8fc7\u5f15\u5165Halton\u5e8f\u5217\u521d\u59cb\u5316\u3001Pareto\u6307\u5bfc\u7684\u53d8\u5f02\u548c\u52a8\u6001VM\u8d1f\u8f7d\u518d\u5206\u914d\u7b49\u589e\u5f3a\u529f\u80fd\uff0cPHWSOA\u5728\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u8f68\u8ff9\u4e0a\u7684\u5b9e\u9a8c\u8868\u73b0\u51fa\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u7b97\u6cd5\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe72.1%\u7684\u5b8c\u5de5\u65f6\u95f4\u7f29\u51cf\u300136.8%\u7684VM\u8d1f\u8f7d\u5747\u8861\u6539\u5584\u548c23.5%\u7684\u6210\u672c\u8282\u7701\uff0c\u5c55\u793a\u4e86\u5176\u5728\u9ad8\u6548\u4e91\u8d44\u6e90\u7ba1\u7406\u4e2d\u7684\u5f3a\u5927\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u4e91\u8ba1\u7b97\u4efb\u52a1\u8c03\u5ea6\u89e3\u51b3\u65b9\u6848\u5927\u591a\u53ea\u4f18\u5316\u5355\u4e00\u6216\u6709\u9650\u6307\u6807\uff0c\u4f8b\u5982\u6267\u884c\u65f6\u95f4\u6216\u8d44\u6e90\u5229\u7528\u7387\uff0c\u800c\u5ffd\u7565\u4e86\u5bf9\u5b8c\u5de5\u65f6\u95f4\u3001\u865a\u62df\u673a\u8d1f\u8f7d\u5747\u8861\u548c\u7ecf\u6d4e\u6210\u672c\u7b49\u591a\u4e2a\u5173\u952e\u76ee\u6807\u8fdb\u884c\u5168\u9762\u591a\u76ee\u6807\u4f18\u5316\u7684\u9700\u6c42\u3002\u672c\u6587\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u5dee\u8ddd\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8ePareto\u7684\u6df7\u5408\u9cb8\u9c7c-\u6d77\u9e25\u4f18\u5316\u7b97\u6cd5\uff08PHWSOA\uff09\u3002\u8be5\u7b97\u6cd5\u7ed3\u5408\u4e86\u9cb8\u9c7c\u4f18\u5316\u7b97\u6cd5\uff08WOA\uff09\u548c\u6d77\u9e25\u4f18\u5316\u7b97\u6cd5\uff08SOA\uff09\u7684\u4f18\u70b9\uff0c\u4ee5\u5f25\u8865WOA\u5728\u5c40\u90e8\u5f00\u53d1\u548cSOA\u5728\u5168\u5c40\u63a2\u7d22\u4e2d\u7684\u4e0d\u8db3\u3002PHWSOA\u5229\u7528Pareto\u652f\u914d\u539f\u7406\uff0c\u540c\u65f6\u4f18\u5316\u5b8c\u5de5\u65f6\u95f4\uff08makespan\uff09\u3001\u865a\u62df\u673a\uff08VM\uff09\u8d1f\u8f7d\u5747\u8861\u548c\u7ecf\u6d4e\u6210\u672c\u4e09\u4e2a\u5173\u952e\u76ee\u6807\u3002\u6838\u5fc3\u589e\u5f3a\u5305\u62ec\uff1a\u4f7f\u7528Halton\u5e8f\u5217\u521d\u59cb\u5316\u4ee5\u63d0\u9ad8\u79cd\u7fa4\u591a\u6837\u6027\uff1b\u5f15\u5165Pareto\u6307\u5bfc\u7684\u53d8\u5f02\u673a\u5236\u4ee5\u907f\u514d\u8fc7\u65e9\u6536\u655b\uff1b\u91c7\u7528\u5e76\u884c\u5904\u7406\u4ee5\u52a0\u901f\u6536\u655b\u3002\u6b64\u5916\uff0c\u8fd8\u96c6\u6210\u4e86\u52a8\u6001VM\u8d1f\u8f7d\u518d\u5206\u914d\u673a\u5236\u4ee5\u6539\u8fdb\u4efb\u52a1\u6267\u884c\u671f\u95f4\u7684\u8d1f\u8f7d\u5747\u8861\u3002\u5b9e\u9a8c\u5728CloudSim\u6a21\u62df\u5668\u4e0a\uff0c\u4f7f\u7528\u6765\u81eaNASA-iPSC\u548cHPC2N\u7684\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u8f68\u8ff9\u8fdb\u884c\u3002", "result": "\u5728CloudSim\u6a21\u62df\u5668\u4e0a\u4f7f\u7528\u771f\u5b9e\u5de5\u4f5c\u8d1f\u8f7d\u8f68\u8ff9\u8fdb\u884c\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cPHWSOA\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u5177\u4f53\u800c\u8a00\uff0c\u5b83\u5728\u5b8c\u5de5\u65f6\u95f4\u65b9\u9762\u5b9e\u73b0\u4e86\u9ad8\u8fbe72.1%\u7684\u51cf\u5c11\uff0c\u5728VM\u8d1f\u8f7d\u5747\u8861\u65b9\u9762\u63d0\u5347\u4e8636.8%\uff0c\u5728\u7ecf\u6d4e\u6210\u672c\u65b9\u9762\u8282\u7701\u4e8623.5%\u3002\u8fd9\u4e9b\u7ed3\u679c\u663e\u8457\u4f18\u4e8e\u5305\u62ecWOA\u3001GA\u3001PEWOA\u548cGCWOA\u5728\u5185\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "PHWSOA\u7b97\u6cd5\u901a\u8fc7\u7ed3\u5408WOA\u548cSOA\u7684\u4f18\u52bf\uff0c\u5e76\u5f15\u5165Pareto\u652f\u914d\u3001Halton\u5e8f\u5217\u521d\u59cb\u5316\u3001Pareto\u6307\u5bfc\u7684\u53d8\u5f02\u673a\u5236\u3001\u5e76\u884c\u5904\u7406\u548c\u52a8\u6001VM\u8d1f\u8f7d\u518d\u5206\u914d\u7b49\u589e\u5f3a\u529f\u80fd\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4e91\u8ba1\u7b97\u4efb\u52a1\u8c03\u5ea6\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cPHWSOA\u5728\u7f29\u77ed\u5b8c\u5de5\u65f6\u95f4\u3001\u6539\u5584VM\u8d1f\u8f7d\u5747\u8861\u548c\u964d\u4f4e\u7ecf\u6d4e\u6210\u672c\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u5b9e\u9645\u4e91\u73af\u5883\u4e2d\u5b9e\u73b0\u9ad8\u6548\u8d44\u6e90\u7ba1\u7406\u7684\u5de8\u5927\u6f5c\u529b\u3002"}}
{"id": "2512.09664", "categories": ["cs.DC", "cs.CV", "cs.LG", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.09664", "abs": "https://arxiv.org/abs/2512.09664", "authors": ["Antonio Terpin", "Alan Bonomi", "Francesco Banelli", "Raffaello D'Andrea"], "title": "SynthPix: A lightspeed PIV images generator", "comment": "Code: https://github.com/antonioterpin/synthpix", "summary": "We describe SynthPix, a synthetic image generator for Particle Image Velocimetry (PIV) with a focus on performance and parallelism on accelerators, implemented in JAX. SynthPix supports the same configuration parameters as existing tools but achieves a throughput several orders of magnitude higher in image-pair generation per second. SynthPix was developed to enable the training of data-hungry reinforcement learning methods for flow estimation and for reducing the iteration times during the development of fast flow estimation methods used in recent active fluids control studies with real-time PIV feedback. We believe SynthPix to be useful for the fluid dynamics community, and in this paper we describe the main ideas behind this software package.", "AI": {"tldr": "Paper is related to **DSL** (JAX's functional programming/compiler optimization aspects, though not a general-purpose DSL paper) and **Compiler** (JAX relies on XLA compiler for performance). **Graph Processing** and **MLIR** and **HLS** are not directly related.\nSynthPix\u662f\u4e00\u4e2a\u57fa\u4e8eJAX\u5b9e\u73b0\u7684\u3001\u4e13\u6ce8\u4e8e\u5728\u52a0\u901f\u5668\u4e0a\u5b9e\u73b0\u9ad8\u6027\u80fd\u548c\u5e76\u884c\u5316\u7684\u9ad8\u541e\u5410\u91cf\u7c92\u5b50\u56fe\u50cf\u6d4b\u901f\uff08PIV\uff09\u5408\u6210\u56fe\u50cf\u751f\u6210\u5668\u3002\u5176\u65e8\u5728\u901a\u8fc7\u6bd4\u73b0\u6709\u5de5\u5177\u9ad8\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u56fe\u50cf\u5bf9\u751f\u6210\u901f\u5ea6\uff0c\u6765\u6ee1\u8db3\u6570\u636e\u5bc6\u96c6\u578b\u5f3a\u5316\u5b66\u4e60\u6d41\u573a\u4f30\u8ba1\u65b9\u6cd5\u7684\u8bad\u7ec3\u9700\u6c42\uff0c\u5e76\u7f29\u77ed\u5f00\u53d1\u7528\u4e8e\u5b9e\u65f6PIV\u53cd\u9988\u7684\u4e3b\u52a8\u6d41\u4f53\u63a7\u5236\u65b9\u6cd5\u7684\u8fed\u4ee3\u65f6\u95f4\u3002", "motivation": "\u73b0\u6709\u7684\u7c92\u5b50\u56fe\u50cf\u6d4b\u901f\uff08PIV\uff09\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\uff0c\u5c24\u5176\u662f\u5bf9\u4e8e\u6570\u636e\u5bc6\u96c6\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6d41\u573a\u4f30\u8ba1\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5728\u9700\u8981\u5b9e\u65f6 PIV \u53cd\u9988\u7684\u4e3b\u52a8\u6d41\u4f53\u63a7\u5236\u7814\u7a76\u4e2d\uff0c\u5f00\u53d1\u5feb\u901f\u6d41\u573a\u4f30\u8ba1\u65b9\u6cd5\u65f6\u9700\u8981\u7f29\u77ed\u8fed\u4ee3\u65f6\u95f4\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u9ad8\u6027\u80fd\u3001\u9ad8\u541e\u5410\u91cf\u7684\u5408\u6210\u56fe\u50cf\u751f\u6210\u5668\uff08\u5982 SynthPix\uff09\u6765\u6ee1\u8db3\u8fd9\u4e9b\u9700\u6c42\u3002", "method": "\u8bba\u6587\u63cf\u8ff0\u4e86 SynthPix \u8f6f\u4ef6\u80cc\u540e\u7684\u4e3b\u8981\u601d\u60f3\u548c\u5b9e\u73b0\u7ec6\u8282\u3002\u5b83\u662f\u4e00\u4e2a\u5728 JAX \u4e2d\u5b9e\u73b0\u7684\u3001\u5173\u6ce8\u6027\u80fd\u548c\u5e76\u884c\u6027\u7684\u5408\u6210\u56fe\u50cf\u751f\u6210\u5668\uff0c\u80fd\u591f\u652f\u6301\u4e0e\u73b0\u6709\u5de5\u5177\u76f8\u540c\u7684\u914d\u7f6e\u53c2\u6570\uff0c\u4f46\u5177\u6709\u66f4\u9ad8\u7684\u541e\u5410\u91cf\u3002", "result": "SynthPix \u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u5de5\u5177\u76f8\u540c\u7684\u914d\u7f6e\u53c2\u6570\u652f\u6301\uff0c\u4f46\u5728\u56fe\u50cf\u5bf9\u751f\u6210\u541e\u5410\u91cf\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u5de5\u5177\u9ad8\u51fa\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u63d0\u5347\uff0c\u6781\u5927\u5730\u52a0\u901f\u4e86\u6570\u636e\u751f\u6210\u548c\u65b9\u6cd5\u5f00\u53d1\u8fed\u4ee3\u8fc7\u7a0b\u3002", "conclusion": "SynthPix \u662f\u4e00\u4e2a\u9488\u5bf9 PIV \u7684\u9ad8\u6027\u80fd\u5408\u6210\u56fe\u50cf\u751f\u6210\u5668\uff0c\u57fa\u4e8e JAX \u5b9e\u73b0\uff0c\u6ce8\u91cd\u5728\u52a0\u901f\u5668\u4e0a\u7684\u6027\u80fd\u548c\u5e76\u884c\u6027\u3002\u5b83\u53ef\u4ee5\u5b9e\u73b0\u6bd4\u73b0\u6709\u5de5\u5177\u9ad8\u51fa\u6570\u4e2a\u6570\u91cf\u7ea7\u7684\u56fe\u50cf\u5bf9\u751f\u6210\u541e\u5410\u91cf\uff0c\u8fd9\u5bf9\u4e8e\u8bad\u7ec3\u6570\u636e\u5bc6\u96c6\u578b\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u4ee5\u53ca\u52a0\u901f\u5b9e\u65f6 PIV \u53cd\u9988\u4e0b\u7684\u5feb\u901f\u6d41\u573a\u4f30\u8ba1\u65b9\u6cd5\u7684\u5f00\u53d1\u81f3\u5173\u91cd\u8981\u3002\u4f5c\u8005\u76f8\u4fe1 SynthPix \u5bf9\u6d41\u4f53\u52a8\u529b\u5b66\u793e\u533a\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.09685", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.09685", "abs": "https://arxiv.org/abs/2512.09685", "authors": ["Zeyu Zhang", "Haiying Shen"], "title": "Straggler Tolerant and Resilient DL Training on Homogeneous GPUs", "comment": null, "summary": "Despite the popularity of homogeneous GPU-based deep learning (DL) training, the prevalence, causes and impact of stragglers and the effectiveness of existing straggler mitigation approaches are still not well understood in this scenario due to limited research on these questions. To fill this gap, we conducted comprehensive experiments and found that stragglers remain widespread due to CPU and bandwidth usage imbalances. Additionally, existing mitigation methods that switch from synchronous stochastic gradient descent (SSGD) to asynchronous SGD (ASGD) may not improve Time-To-Accuracy (TTA) and can even generate more stragglers due to its higher resource consumption. To address these newly found problems, we propose the Straggler Tolerant And Resilient DL training system (STAR). STAR includes new synchronization modes that group workers for each parameter updating. It has a heuristic and an ML method to choose the optimal synchronization mode for minimizing TTA, and reallocates resources to support the selected mode while minimizing the impact on co-located jobs. Moreover, it proactively prevents stragglers by avoiding overloading the CPU and bandwidth resources in allocating PSs (which consume high CPU and bandwidth) and in gradient transmission. Our trace-driven evaluation on AWS shows that STAR generates 48-84% and 51-70% lower TTA than state-of-the-art systems in the PS and all-reduce architectures, respectively, while maintaining the converged accuracy of SSGD. The code for STAR is open-sourced.", "AI": {"tldr": "\u8fd9\u4e2a\u8bba\u6587\u4e0e\u7f16\u8bd1\u5668\u3001HLS\u3001DSL\u3001MLIR \u4e0d\u76f8\u5173\uff0c\u4e0e\u56fe\u5904\u7406\u4e0d\u76f4\u63a5\u76f8\u5173\u3002\u5b83\u4e0e**\u6df1\u5ea6\u5b66\u4e60\u7cfb\u7edf**\u76f8\u5173\u3002\n**\u592a\u957f\u4e0d\u770b\uff08TLDR\uff09\uff1a**\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u540c\u6784 GPU \u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\u843d\u540e\u8005\uff08stragglers\uff09\u7684\u666e\u904d\u6027\u3001\u539f\u56e0\uff08CPU \u548c\u5e26\u5bbd\u4e0d\u5e73\u8861\uff09\u4ee5\u53ca\u73b0\u6709\u5f02\u6b65 SGD \u7f13\u89e3\u65b9\u6848\u7684\u5c40\u9650\u6027\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a STAR \u7684\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u5f15\u5165\u4e86\u65b0\u7684\u540c\u6b65\u6a21\u5f0f\u3001\u57fa\u4e8e\u542f\u53d1\u5f0f\u548c ML \u7684\u6a21\u5f0f\u9009\u62e9\u7b56\u7565\uff0c\u4ee5\u53ca\u4e3b\u52a8\u7684\u8d44\u6e90\u9884\u9632\u673a\u5236\uff0c\u4ee5\u5bb9\u5fcd\u548c\u51cf\u8f7b\u843d\u540e\u8005\u3002\u5728 AWS \u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cSTAR \u5728\u4fdd\u6301\u540c\u6b65 SGD \u7cbe\u5ea6\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u5bf9\u4e8e\u73b0\u6709\u6280\u672f\u663e\u8457\u964d\u4f4e\u4e86 TTA\uff08Time-To-Accuracy\uff09\u3002", "motivation": "\u5c3d\u7ba1\u57fa\u4e8e\u540c\u6784 GPU \u7684\u6df1\u5ea6\u5b66\u4e60\uff08DL\uff09\u8bad\u7ec3\u5f88\u6d41\u884c\uff0c\u4f46\u4eba\u4eec\u5bf9\u8be5\u573a\u666f\u4e0b\u843d\u540e\u8005\u7684\u666e\u904d\u6027\u3001\u8d77\u56e0\u3001\u5f71\u54cd\u4ee5\u53ca\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\u7684\u6709\u6548\u6027\u77e5\u4e4b\u751a\u5c11\u3002\u73b0\u6709\u7814\u7a76\u4e0d\u8db3\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u901a\u8fc7\u63d0\u51fa\u4e00\u79cd\u540d\u4e3a STAR \u7684\u7cfb\u7edf\u6765\u6709\u6548\u5bb9\u5fcd\u548c\u51cf\u8f7b DL \u8bad\u7ec3\u4e2d\u7684\u843d\u540e\u8005\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e TTA \u5e76\u4fdd\u6301\u540c\u6b65 SGD \u7684\u6536\u655b\u7cbe\u5ea6\u3002", "method": "\u672c\u6587\u9996\u5148\u901a\u8fc7\u5b9e\u9a8c\u7814\u7a76\u4e86\u843d\u540e\u8005\u5728\u540c\u6784 GPU \u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\u7684\u666e\u904d\u6027\u3001\u539f\u56e0\uff08CPU \u548c\u5e26\u5bbd\u4f7f\u7528\u4e0d\u5e73\u8861\uff09\u4ee5\u53ca\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u4e86\u73b0\u6709\u7f13\u89e3\u65b9\u6cd5\uff08\u5982\u5f02\u6b65 SGD\uff09\u7684\u5c40\u9650\u6027\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u63d0\u51fa\u4e86 STAR \u7cfb\u7edf\u3002STAR \u7684\u6838\u5fc3\u673a\u5236\u5305\u62ec\uff1a1\uff09\u65b0\u7684\u540c\u6b65\u6a21\u5f0f\uff0c\u901a\u8fc7\u5bf9\u5de5\u4f5c\u8282\u70b9\u5206\u7ec4\u8fdb\u884c\u53c2\u6570\u66f4\u65b0\uff1b2\uff09\u9009\u62e9\u6700\u4f73\u540c\u6b65\u6a21\u5f0f\u7684\u542f\u53d1\u5f0f\u548c ML \u65b9\u6cd5\uff0c\u4ee5\u6700\u5c0f\u5316 TTA\uff1b3\uff09\u4e3b\u52a8\u8d44\u6e90\u9884\u9632\u673a\u5236\uff0c\u901a\u8fc7\u907f\u514d\u5bf9 CPU \u548c\u5e26\u5bbd\u8d44\u6e90\u8fc7\u8f7d\uff0c\u4ece\u800c\u9632\u6b62\u843d\u540e\u8005\uff0c\u5c24\u5176\u662f\u5728\u53c2\u6570\u670d\u52a1\u5668\uff08PS\uff09\u5206\u914d\u548c\u68af\u5ea6\u4f20\u8f93\u4e2d\u3002\u6700\u540e\uff0c\u901a\u8fc7\u5728 AWS \u4e0a\u8fdb\u884c\u8ddf\u8e2a\u9a71\u52a8\u7684\u8bc4\u4f30\u6765\u9a8c\u8bc1 STAR \u7684\u6027\u80fd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u843d\u540e\u8005\u5728\u540c\u6784 GPU \u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\u4ecd\u7136\u666e\u904d\u5b58\u5728\uff0c\u4e3b\u8981\u662f\u7531\u4e8e CPU \u548c\u5e26\u5bbd\u4f7f\u7528\u4e0d\u5e73\u8861\u3002\u73b0\u6709\u7684\u7f13\u89e3\u65b9\u6cd5\uff08\u5982\u4ece SSGD \u5207\u6362\u5230 ASGD\uff09\u53ef\u80fd\u4e0d\u80fd\u6539\u5584 TTA\uff0c\u751a\u81f3\u4f1a\u56e0\u4e3a\u66f4\u9ad8\u7684\u8d44\u6e90\u6d88\u8017\u800c\u4ea7\u751f\u66f4\u591a\u7684\u843d\u540e\u8005\u3002\u672c\u6587\u63d0\u51fa\u7684 STAR \u7cfb\u7edf\u901a\u8fc7\u65b0\u7684\u540c\u6b65\u6a21\u5f0f\u3001\u667a\u80fd\u6a21\u5f0f\u9009\u62e9\uff08\u542f\u53d1\u5f0f\u548c ML\uff09\u4ee5\u53ca\u4e3b\u52a8\u7684\u8d44\u6e90\u9884\u9632\u7b56\u7565\uff0c\u5728 AWS \u4e0a\u5bf9 PS \u67b6\u6784\u7684 TTA \u964d\u4f4e\u4e86 48% \u5230 84%\uff0c\u5bf9 All-Reduce \u67b6\u6784\u7684 TTA \u964d\u4f4e\u4e86 51% \u5230 70%\uff0c\u5e76\u4fdd\u6301\u4e86 SSGD \u7684\u6536\u655b\u7cbe\u5ea6\u3002", "conclusion": "\u672c\u6587\u5206\u6790\u4e86\u5728\u540c\u6784 GPU \u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u5728\u89e3\u51b3\u843d\u540e\u8005\u95ee\u9898\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63d0\u51fa\u4e86 STAR \u7cfb\u7edf\u53ca\u5176\u6838\u5fc3\u673a\u5236\uff08\u65b0\u7684\u540c\u6b65\u6a21\u5f0f\u3001\u542f\u53d1\u5f0f\u548c ML \u6a21\u5f0f\u9009\u62e9\u4ee5\u53ca\u4e3b\u52a8\u8d44\u6e90\u9884\u9632\uff09\uff0c\u8bc1\u660e\u4e86 STAR \u5728 AWS \u4e0a\u7684\u5b9e\u9645\u6027\u80fd\u4f18\u52bf\u3002\u56e0\u6b64\uff0cSTAR \u662f\u4e00\u4e2a\u6709\u6548\u5bb9\u5fcd\u548c\u51cf\u8f7b\u6df1\u5ea6\u5b66\u4e60\u8bad\u7ec3\u4e2d\u843d\u540e\u8005\u95ee\u9898\u7684\u7cfb\u7edf\u3002"}}
{"id": "2512.09710", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2512.09710", "abs": "https://arxiv.org/abs/2512.09710", "authors": ["Hagit Attiya", "Panagiota Fatourou", "Eleftherios Kosmas", "Yuanhao Wei"], "title": "Recoverable Lock-Free Locks", "comment": null, "summary": "This paper presents the first transformation that introduces both lock-freedom and recoverability. Our transformation starts with a lock-based implementation, and provides a recoverable, lock-free substitution to lock acquire and lock release operations. The transformation supports nested locks for generality and ensures recoverability without jeopardising the correctness of the lock-based implementation it is applied on.", "AI": {"tldr": "\u76f8\u5173\u6027\uff1a\u8be5\u8bba\u6587\u4e0eDSL\u3001\u56fe\u5904\u7406\u3001MLIR\u3001\u7f16\u8bd1\u5668\u6216HLS\u4e0d\u76f4\u63a5\u76f8\u5173\u3002\u5b83\u5c5e\u4e8e\u5e76\u53d1\u7f16\u7a0b/\u64cd\u4f5c\u7cfb\u7edf\u3001\u5e76\u884c\u8ba1\u7b97\u6216\u7cfb\u7edf\u8f6f\u4ef6\u9886\u57df\uff0c\u805a\u7126\u4e8e\u5e76\u53d1\u63a7\u5236\u673a\u5236\uff08\u9501\u3001\u65e0\u9501\u3001\u53ef\u6062\u590d\u6027\uff09\u7684\u8f6c\u6362\u3002\n\n\u592a\u957f\u4e0d\u8bfb\uff08TLDR\uff09\u6458\u8981\uff1a\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u80fd\u5c06\u57fa\u4e8e\u9501\u7684\u5b9e\u73b0\u8f6c\u6362\u4e3a**\u540c\u65f6\u5177\u6709\u65e0\u9501\uff08Lock-Free\uff09\u548c\u53ef\u6062\u590d\u6027**\u7684\u65b0\u578b\u8f6c\u6362\u65b9\u6cd5\u3002\u5b83\u901a\u8fc7\u66ff\u6362\u9501\u7684\u83b7\u53d6\u548c\u91ca\u653e\u64cd\u4f5c\uff0c\u652f\u6301\u5d4c\u5957\u9501\uff0c\u5e76\u5728\u4e0d\u727a\u7272\u539f\u5b9e\u73b0\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\u786e\u4fdd\u7cfb\u7edf\u53ef\u4ece\u6545\u969c\u4e2d\u6062\u590d\u3002", "motivation": "\u9996\u6b21\u63d0\u51fa\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u65e0\u9501\u548c\u53ef\u6062\u590d\u6027\u7684\u8f6c\u6362\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u57fa\u4e8e\u9501\u7684\u5b9e\u73b0\u5f00\u59cb\u7684\u8f6c\u6362\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u53ef\u6062\u590d\u7684\u3001\u65e0\u9501\u7684\u66ff\u4ee3\u65b9\u6848\u6765\u5904\u7406\u9501\u7684\u83b7\u53d6\u548c\u91ca\u653e\u64cd\u4f5c\u3002", "result": "\u8be5\u8f6c\u6362\u652f\u6301\u5d4c\u5957\u9501\u4ee5\u63d0\u5347\u901a\u7528\u6027\uff0c\u5e76\u80fd\u5728\u4fdd\u8bc1\u88ab\u5e94\u7528\uff08\u57fa\u4e8e\u9501\uff09\u5b9e\u73b0\u6b63\u786e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u53ef\u6062\u590d\u6027\u3002", "conclusion": "\u672c\u6587\u4ecb\u7ecd\u4e86\u7b2c\u4e00\u4e2a\u540c\u65f6\u5f15\u5165\u65e0\u9501\uff08lock-freedom\uff09\u548c\u53ef\u6062\u590d\u6027\uff08recoverability\uff09\u7684\u8f6c\u6362\u65b9\u6cd5\u3002\u8be5\u8f6c\u6362\u5c06\u57fa\u4e8e\u9501\u7684\u5b9e\u73b0\u4f5c\u4e3a\u8d77\u70b9\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6062\u590d\u3001\u65e0\u9501\u7684\u65b9\u5f0f\u6765\u66ff\u4ee3\u9501\u7684\u83b7\u53d6\u548c\u91ca\u653e\u64cd\u4f5c\u3002\u8fd9\u79cd\u8f6c\u6362\u652f\u6301\u5d4c\u5957\u9501\u4ee5\u589e\u5f3a\u901a\u7528\u6027\uff0c\u5e76\u80fd\u786e\u4fdd\u53ef\u6062\u590d\u6027\uff0c\u540c\u65f6\u4e0d\u635f\u5bb3\u5176\u6240\u5e94\u7528\u7684\u57fa\u4e8e\u9501\u7684\u5b9e\u73b0\u7684\u6b63\u786e\u6027\u3002"}}
